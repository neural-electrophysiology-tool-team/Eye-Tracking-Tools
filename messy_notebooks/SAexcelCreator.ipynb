{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-12T10:33:31.969969Z",
     "start_time": "2025-08-12T10:33:31.956885Z"
    }
   },
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from BlockSync_current import *"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T10:33:34.891488Z",
     "start_time": "2025-08-12T10:33:34.746129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Organiser-workbook generator  |  This works, but pay attention to recNames\n",
    "# ----------------------------------------------------------------------------------\n",
    "from __future__ import annotations\n",
    "import re, datetime, pathlib, pandas as pd\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def map_windows_to_unix(win_path: str, mapping: dict[str,str]) -> str:\n",
    "    \"\"\"\n",
    "    Replace the Windows prefix in win_path with the UNIX prefix, and turn backslashes\n",
    "    into forward slashes.  If no prefix matches, still convert to forward slashes.\n",
    "    \"\"\"\n",
    "    for win_prefix, unix_prefix in mapping.items():\n",
    "        if win_path.lower().startswith(win_prefix.lower()):\n",
    "            rel = win_path[len(win_prefix):]\n",
    "            return unix_prefix.rstrip(\"/\") + rel.replace(\"\\\\\", \"/\")\n",
    "    return win_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 1.  helper – crawl PV_xx tree and collect “Record Node …” folders\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def get_paths_to_record_nodes(tree_root_path: pathlib.Path) -> list[pathlib.Path]:\n",
    "    def match_date(s: str)  -> bool: return re.fullmatch(r\"\\d{4}_\\d{2}_\\d{2}\", s) is not None\n",
    "    def match_block(s: str) -> bool: return re.fullmatch(r\"block_\\d{3}\", s)    is not None\n",
    "\n",
    "    paths = []\n",
    "    for date_dir in filter(lambda p: p.is_dir() and match_date(p.name), tree_root_path.iterdir()):\n",
    "        for block in filter(lambda p: p.is_dir() and match_block(p.name), date_dir.iterdir()):\n",
    "            oe_path      = block / \"oe_files\"\n",
    "            datetime_dir = next(oe_path.iterdir())                     # only one subfolder\n",
    "            rec_node_dir = next(i for i in datetime_dir.iterdir() if \"Node\" in i.name)\n",
    "            paths.append(rec_node_dir.resolve())\n",
    "    return paths\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 2.  main – build organiser DataFrame and write .xlsx\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def build_organiser_excel(\n",
    "        animal_root   : str | pathlib.Path,\n",
    "        export_dir    : str | pathlib.Path,\n",
    "        template_xlsx : str | pathlib.Path | None = None,\n",
    "        path_map      : dict[str,str] = None,       # ← new!\n",
    ") -> pathlib.Path:\n",
    "    \"\"\"\n",
    "    Scan *animal_root* and create an organiser workbook in *export_dir*.\n",
    "    If *path_map* is provided, windows paths will be remapped to UNIX.\n",
    "    \"\"\"\n",
    "    animal_root = pathlib.Path(animal_root).expanduser().resolve()\n",
    "    export_dir  = pathlib.Path(export_dir ).expanduser().resolve()\n",
    "    export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # discover record nodes\n",
    "    rec_nodes = sorted(get_paths_to_record_nodes(animal_root))\n",
    "    if not rec_nodes:\n",
    "        raise RuntimeError(f\"No record-node folders found under {animal_root}\")\n",
    "\n",
    "    # column layout + defaults (unchanged) …\n",
    "    if template_xlsx:\n",
    "        tpl      = pd.read_excel(template_xlsx, engine=\"openpyxl\")\n",
    "        columns  = list(tpl.columns)\n",
    "        defaults = {c: tpl[c].dropna().iloc[0] if tpl[c].notna().any() else pd.NA for c in columns}\n",
    "    else:\n",
    "        columns = [\n",
    "            'Unnamed: 0','Exclude','spikes','sortedManually','videoSync','Breathing',\n",
    "            'Animal','recNames','Remarks','Date','MEAfiles','recFormat','Sex','Species',\n",
    "            'MEA_Layout','folder','VideoFiles','temperatureFile','Video_notes',\n",
    "            'LFPCh_verified','defaulLFPCh','Temp','tempMedian','accelerometerCh',\n",
    "            'Complete_recording','TempLogger_file','Temp_verifcation','video_start_time',\n",
    "            'video_end_time','AUX_data','video_triggers'\n",
    "        ]\n",
    "        defaults = dict.fromkeys(columns, pd.NA)\n",
    "        defaults.update({\n",
    "            'recFormat': 'OERecording',\n",
    "            'Sex'      : 'M',\n",
    "            'Species'  : 'Pogona_Vitticeps',\n",
    "            'MEA_Layout': 'layout_120_32x1_H4_CamNeuro',\n",
    "            'defaulLFPCh': 15,\n",
    "            'Temp'       : 27,\n",
    "            'accelerometerCh': '1,2,3',\n",
    "        })\n",
    "\n",
    "    # one row per record node\n",
    "    rows = []\n",
    "    for idx, rec_path in enumerate(rec_nodes):\n",
    "        date_folder  = rec_path.parents[4].name\n",
    "        block_folder = rec_path.parents[3].name\n",
    "        block_num    = int(block_folder.split('_')[1])\n",
    "        rec_name     = f\"Block{block_num:04d}\"\n",
    "\n",
    "        row = {c: defaults.get(c, pd.NA) for c in columns}\n",
    "        row.update({\n",
    "            'Unnamed: 0': idx,\n",
    "            'Animal'    : animal_root.name,\n",
    "            'Date'      : date_folder,\n",
    "            'recNames'  : rec_name,\n",
    "        })\n",
    "\n",
    "        # ← here’s the change: map or just normalize slashes\n",
    "        orig = str(rec_path)\n",
    "        if path_map:\n",
    "            folder = map_windows_to_unix(orig, path_map)\n",
    "        else:\n",
    "            folder = orig.replace(\"\\\\\", \"/\")\n",
    "        row['folder'] = folder\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    organiser = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    # write workbook\n",
    "    outfile = export_dir / f\"{animal_root.name}_organiser_{datetime.datetime.now():%Y%m%d_%H%M}.xlsx\"\n",
    "    organiser.to_excel(outfile, index=False)\n",
    "    print(f\"✔ organiser written to {outfile}\")\n",
    "    return outfile\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 3.  quick test --- edit these two paths and re-run\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "animal_folder   = r\"X:\\Nimrod\\experiments\\PV_143\"\n",
    "output_folder   = r\"X:\\Nimrod\\experiments\\PV_143\\HelperFiles\"\n",
    "template_file   = r\"X:\\Nimrod\\experiments\\PV_106\\HelperFiles\\PV_106_monolith_old.xlsx\"\n",
    "\n",
    "# define your Windows→Linux mapping here:\n",
    "win_to_unix = {\n",
    "    r\"X:\\Nimrod\\experiments\": r\"/media/sil1/Data/Nimrod/experiments\",\n",
    "    r\"Z:\\Nimrod\\experiments\": r\"/media/sil2/Data/Nimrod/experiments\"\n",
    "}\n",
    "\n",
    "# then call:\n",
    "build_organiser_excel(animal_folder, output_folder, template_file, path_map=win_to_unix)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ organiser written to \\\\sil1\\data\\Nimrod\\experiments\\PV_143\\HelperFiles\\PV_143_organiser_20250812_1333.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('//sil1/data/Nimrod/experiments/PV_143/HelperFiles/PV_143_organiser_20250812_1333.xlsx')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [Exclude, spikes, sortedManually, videoSync, Breathing, Animal, recNames, Remarks, Date, MEAfiles, recFormat, Sex, Species, MEA_Layout, folder, VideoFiles, temperatureFile, Video_notes, LFPCh_verified, defaulLFPCh, Temp, tempMedian, accelerometerCh, Complete_recording, TempLogger_file, Temp_verifcation, video_start_time, video_end_time, AUX_data, video_triggers]\nIndex: []\n\n[0 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Exclude</th>\n      <th>spikes</th>\n      <th>sortedManually</th>\n      <th>videoSync</th>\n      <th>Breathing</th>\n      <th>Animal</th>\n      <th>recNames</th>\n      <th>Remarks</th>\n      <th>Date</th>\n      <th>MEAfiles</th>\n      <th>...</th>\n      <th>Temp</th>\n      <th>tempMedian</th>\n      <th>accelerometerCh</th>\n      <th>Complete_recording</th>\n      <th>TempLogger_file</th>\n      <th>Temp_verifcation</th>\n      <th>video_start_time</th>\n      <th>video_end_time</th>\n      <th>AUX_data</th>\n      <th>video_triggers</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arrange all recordings according to csv format for matlab analysis\n",
    "p = pathlib.Path(r'Z:\\Nimrod\\experiments\\PV_24\\sortedBlocks.xlsx')\n",
    "df_dict = {\n",
    "    'Exclude':'',\n",
    "    'spikes': '',\n",
    "    'sortedManually': '',\n",
    "    'videoSync':'',\n",
    "    'Breathing': '',\n",
    "    'Animal': '',\n",
    "    'recNames': '',\n",
    "    'Remarks': '',\n",
    "    'Date': '',\n",
    "    'MEAfiles':'',\n",
    "    'recFormat': '',\n",
    "    'Sex': '',\n",
    "    'Species':'',\n",
    "    'MEA_Layout':'',\n",
    "    'folder': '',\n",
    "    'VideoFiles':'',\n",
    "    'temperatureFile':'',\n",
    "    'Video_notes':'',\n",
    "    'LFPCh_verified':'',\n",
    "    'defaulLFPCh':'',\n",
    "    'Temp':'',\n",
    "    'tempMedian':'',\n",
    "    'accelerometerCh':'',\n",
    "    'Complete_recording':'',\n",
    "    'TempLogger_file':'',\n",
    "    'Temp_verifcation':'',\n",
    "    'video_start_time':'',\n",
    "    'video_end_time':'',\n",
    "    'AUX_data':'',\n",
    "    'video_triggers':''\n",
    "}\n",
    "df = pd.DataFrame(columns=df_dict.keys())\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "source": [
    "# collect blocks into the dataframe:\n",
    "\n",
    "# define the path to the experiment folder:\n",
    "path_to_experiments = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "animal = \"PV_106\"\n",
    "p = path_to_experiments / animal\n",
    "# collect dates\n",
    "date_folder_list = [i for i in p.iterdir() if 'block' not in str(i).lower() and i.is_dir()]\n",
    "print(date_folder_list)\n",
    "for date in date_folder_list:\n",
    "    dp = p / animal / date\n",
    "\n",
    "    # list all blocks in the folder:\n",
    "    blocks = [i for i in dp.iterdir() if 'block' in str(i).lower() and i.is_dir()]\n",
    "    for block in blocks:\n",
    "        bp = dp / block\n",
    "        blocksync = BlockSync(animal_call=animal,\n",
    "                      experiment_date=date.name,\n",
    "                      block_num=block.name[6:],\n",
    "                      path_to_animal_folder=str(path_to_experiments))\n",
    "        df_row = {\n",
    "            'Exclude':'',\n",
    "            'spikes': '',\n",
    "            'sortedManually': '',\n",
    "            'videoSync':'',\n",
    "            'Breathing': '',\n",
    "            'Animal': animal,\n",
    "            'recNames': f'Block0{block.name[6:]}',\n",
    "            'Remarks': '',\n",
    "            'Date': blocksync.experiment_date,\n",
    "            'MEAfiles':'',\n",
    "            'recFormat': 'OERecording',\n",
    "            'Sex': 'M',\n",
    "            'Species':'Pogona_Vitticeps',\n",
    "            'MEA_Layout':'layout_120_32x1_H4_CamNeuro',\n",
    "            'folder': '/media/sil2/Data' + str(blocksync.oe_path.as_posix())[2:],\n",
    "            'VideoFiles':'',\n",
    "            'temperatureFile':'',\n",
    "            'Video_notes':'',\n",
    "            'LFPCh_verified':'',\n",
    "            'defaulLFPCh':'15',\n",
    "            'Temp':'27',\n",
    "            'tempMedian':'',\n",
    "            'accelerometerCh':'33,34,35',\n",
    "            'Complete_recording':'',\n",
    "            'TempLogger_file':'',\n",
    "            'Temp_verifcation':'',\n",
    "            'video_start_time':'',\n",
    "            'video_end_time':'',\n",
    "            'AUX_data':'',\n",
    "            'video_triggers':''\n",
    "        }\n",
    "        df = df.append(df_row,ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-08-02T15:51:17.889497Z",
     "start_time": "2025-08-02T15:51:17.199606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('Z:/Nimrod/experiments/PV_106/2025_07_28'), WindowsPath('Z:/Nimrod/experiments/PV_106/2025_07_29'), WindowsPath('Z:/Nimrod/experiments/PV_106/unsorted_OE')]\n",
      "instantiated block number 001 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_07_28\\block_001, new OE version\n",
      "Found the sample rate for block 001 in the xml file, it is 20000 Hz\n",
      "No open ephys record node here!!!\n",
      "retrieving zertoh sample number for block 001\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BlockSync' object has no attribute 'oe_rec'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-8c4aecd14e1b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mblock\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mblocks\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0mbp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdp\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mblock\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         blocksync = BlockSync(animal_call=animal,\n\u001B[0m\u001B[0;32m     18\u001B[0m                       \u001B[0mexperiment_date\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdate\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m                       \u001B[0mblock_num\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m6\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\pythonProject3\\BlockSync_current.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, animal_call, experiment_date, block_num, path_to_animal_folder, channeldict, regev)\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meye_diff_mode\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    242\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeroth_sample_number\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 243\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_zeroth_sample_number\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    244\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaccade_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    245\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msynced_saccades_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\pythonProject3\\BlockSync_current.py\u001B[0m in \u001B[0;36mget_zeroth_sample_number\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   3251\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3252\u001B[0m         \u001B[1;31m# first, try and get the sample_num from a pre-performed step:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3253\u001B[1;33m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moe_rec\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3254\u001B[0m             \u001B[1;31m# if access to the recording metadata exists calculate the zeroth lag with the sample_rate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3255\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeroth_sample_number\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moe_rec\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mglobalStartTime_ms\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msample_rate\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m1000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'BlockSync' object has no attribute 'oe_rec'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'animal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-99e1e932aa20>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m block = BlockSync(animal_call=animal,\n\u001B[0m\u001B[0;32m      2\u001B[0m                   \u001B[0mexperiment_date\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'2022_01_02'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m                   \u001B[0mblock_num\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'038'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m                   path_to_animal_folder=str(path_to_experiments))\n\u001B[0;32m      5\u001B[0m \u001B[1;31m#block.oe_path\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'animal' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "block = BlockSync(animal_call=animal,\n",
    "                  experiment_date='2022_01_02',\n",
    "                  block_num='038',\n",
    "                  path_to_animal_folder=str(path_to_experiments))\n",
    "#block.oe_path\n",
    "print(block.experiment_date)\n",
    "#block.experiment_date[8:] + block.experiment_date[5:7] + block.experiment_date[2:4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "export_path = pathlib.Path(r'Z:\\Nimrod\\experiments\\PV_62\\automated_block_collection_ubuntu.csv')\n",
    "csv_path = export_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-05-25T16:16:25.244445Z",
     "start_time": "2025-05-25T16:16:25.232439Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Linux→Windows helper (for reading)\n",
    "def linux_to_win(linux_path: str,\n",
    "                 prefix: str = '/media/sil2/Data',\n",
    "                 win_drive: str = 'Z:') -> Path:\n",
    "    if linux_path.startswith(prefix):\n",
    "        rest = linux_path[len(prefix):].lstrip('/')\n",
    "        return Path(f\"{win_drive}\\\\{rest}\")\n",
    "    return Path(linux_path)\n",
    "\n",
    "# 2) Windows→Linux helper (for writing)\n",
    "def win_to_linux(win_path: Path,\n",
    "                 win_drive: str = 'Z:',\n",
    "                 linux_prefix: str = '/media/sil2/Data') -> str:\n",
    "    # only remap if on the expected drive\n",
    "    if win_path.drive.lower() == win_drive.lower():\n",
    "        anchor = win_path.anchor         # e.g. \"Z:\\\\\"\n",
    "        rel = win_path.relative_to(anchor)  # e.g. Path(\"PV_62/2023_04_22/…\")\n",
    "        return f\"{linux_prefix}/{rel.as_posix()}\"\n",
    "    # otherwise just give POSIX version of whatever path we found\n",
    "    return win_path.as_posix()\n",
    "\n",
    "def fill_arena_video_paths(excel_input: str,\n",
    "                           excel_output: str = None,\n",
    "                           sheet_name=0):\n",
    "    df = pd.read_excel(excel_input, sheet_name=sheet_name, engine='openpyxl')\n",
    "    video_exts = {'.mp4', '.h264'}\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # remap folder field into a Windows Path we can actually walk\n",
    "        oe_path = linux_to_win(row['folder'])\n",
    "\n",
    "        # find the block_xxx ancestor\n",
    "        block_dir = next(\n",
    "            (p for p in oe_path.parents if p.name.lower().startswith('block_')),\n",
    "            None\n",
    "        )\n",
    "        if block_dir is None:\n",
    "            print(f\"[WARN] no block_xxx for row {idx}: {oe_path}\")\n",
    "            continue\n",
    "\n",
    "        # try to find arena_videos subfolder\n",
    "        try:\n",
    "            arena_dirs = [\n",
    "                d for d in block_dir.iterdir()\n",
    "                if d.is_dir() and d.name.lower() == 'arena_videos'\n",
    "            ]\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[WARN] {block_dir} missing on disk, skipping row {idx}\")\n",
    "            continue\n",
    "\n",
    "        if not arena_dirs:\n",
    "            print(f\"[WARN] no arena_videos under {block_dir}, skipping row {idx}\")\n",
    "            continue\n",
    "\n",
    "        arena_root = arena_dirs[0]\n",
    "\n",
    "        # recursive collect any .mp4/.h264 (case-insensitive)\n",
    "        matches = [\n",
    "            f for f in arena_root.rglob('*')\n",
    "            if f.is_file() and f.suffix.lower() in video_exts\n",
    "        ]\n",
    "\n",
    "        if matches:\n",
    "            # remap back to Linux-style before writing\n",
    "            linux_path = win_to_linux(matches[0])\n",
    "            df.at[idx, 'VideoFiles'] = linux_path\n",
    "        else:\n",
    "            print(f\"[INFO] no video files under {arena_root}, row {idx}\")\n",
    "            df.at[idx, 'VideoFiles'] = ''\n",
    "\n",
    "    out = excel_output or excel_input\n",
    "    df.to_excel(out, index=False, engine='openpyxl')\n",
    "    print(f\"✅ Written updated Excel to {out!r}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-05-26T16:02:07.213164Z",
     "start_time": "2025-05-26T16:02:07.188190Z"
    }
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T16:02:20.097875Z",
     "start_time": "2025-05-26T16:02:19.902846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# csv_path = pathlib.Path(r'Z:\\Nimrod\\experiments\\PV_62\\pv_62_sleep_analysis_monolith.xlsx')\n",
    "# output_path = pathlib.Path(r'Z:\\Nimrod\\experiments\\PV_62\\pv_62_sleep_analysis_monolith_filled.xlsx')\n",
    "csv_path = pathlib.Path(r'Z:\\Nimrod\\experiments\\PV_126\\pv126_xl_for_mark_analysis.xlsx')\n",
    "output_path = pathlib.Path(r'Z:\\Nimrod\\experiments\\PV_126\\pv126_xl_for_mark_analysis_filled.xlsx')\n",
    "\n",
    "fill_arena_video_paths(csv_path,output_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Written updated Excel to WindowsPath('Z:/Nimrod/experiments/PV_126/pv126_xl_for_mark_analysis_filled.xlsx')\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T16:20:31.841738Z",
     "start_time": "2025-05-25T16:20:26.122204Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install openpyxl",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
