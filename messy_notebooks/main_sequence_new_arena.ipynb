{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import wx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import subprocess as sp\n",
    "import os\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from ellipse import LsqEllipse\n",
    "import cv2\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "from matplotlib.patches import Ellipse\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import CustomJS, Slider\n",
    "import bokeh.layouts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Imports\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def oe_events_parser(open_ephys_csv_path, channel_names, export_path=None):\n",
    "    \"\"\"\n",
    "    :param open_ephys_csv_path: The path to an open ephys analysis tools exported csv (using TrialReporter.ipynb)\n",
    "    :param channel_names: a dictionary of the form -\n",
    "                    { 1 : 'channel name' (L_eye_camera)\n",
    "                      2 : 'channel name' (Arena_TTL)\n",
    "                      etc..\n",
    "                    }\n",
    "    :param export_path: default None, if a path is specified a csv file will be saved\n",
    "    :returns open_ephys_events: a pandas DataFrame object where each column has the ON events of one channel\n",
    "                                and has a title from channel_names\n",
    "    :returns open_ephys_off_events: same but for the OFF states (only important for the logical start-stop signal)\n",
    "    \"\"\"\n",
    "\n",
    "    # Infer the active channels:\n",
    "    df = pd.read_csv(open_ephys_csv_path)\n",
    "    channels = df['channel'].to_numpy(copy=True)\n",
    "    channels = np.unique(channels)\n",
    "    df_onstate = df[df['state']==1] #cut the df to represent only rising edges\n",
    "    df_offstate = df[df['state']==0] # This one is important for the ON/OFF signal of the arena\n",
    "    list = []\n",
    "    off_list= []\n",
    "    for chan in channels: #extract a pandas series of the ON stats timestamps for each channel\n",
    "        Sname = channel_names[chan]\n",
    "        s = pd.Series(df_onstate['timestamp'][df_onstate['channel'] == chan], name=Sname)\n",
    "        offs = pd.Series(df_offstate['timestamp'][df_offstate['channel'] == chan], name=Sname)\n",
    "        list.append(s)\n",
    "        off_list.append(offs)\n",
    "    open_ephys_events = pd.concat(list, axis=1)\n",
    "    open_ephys_off_events = pd.concat(off_list, axis=1)\n",
    "    if export_path is not None :\n",
    "        if not export_path in os.listdir(open_ephys_csv_path.split('events.csv')[0][:-1]):\n",
    "            open_ephys_events.to_csv(export_path)\n",
    "    return open_ephys_events , open_ephys_off_events\n",
    "\n",
    "def convert_h264_mp4(path):\n",
    "    files_to_convert = glob.glob(path + r'\\**\\*.h264', recursive=True)\n",
    "    converted_files = glob.glob(path + r'\\**\\*.mp4', recursive=True)\n",
    "    for file in files_to_convert:\n",
    "        fps = file[file.find('hz') - 2:file.find('hz')]\n",
    "        if len(fps) != 2:\n",
    "            fps = 60\n",
    "            print('could not determine fps, using 60...')\n",
    "        if not str(fr'{file[:-5]}.mp4') in converted_files:\n",
    "            sp.run(f'MP4Box -fps {fps} -add {file} {file[:-5]}.mp4')\n",
    "            print(fr'{file} converted ')\n",
    "        else:\n",
    "            print(f'The file {file[:-5]}.mp4 already exists, no conversion necessary')\n",
    "\n",
    "def validate_no_framedrop(path):\n",
    "    videos_to_inspect = glob.glob(path + r'\\**\\*.mp4', recursive=True)\n",
    "    timestamps_to_inspect = glob.glob(path + r'\\**\\*.csv', recursive=True)\n",
    "    for vid in range(len(videos_to_inspect)):\n",
    "        timestamps = pd.read_csv(timestamps_to_inspect[vid])\n",
    "        num_reported = timestamps.shape[0]\n",
    "        cap = cv2.VideoCapture(videos_to_inspect[vid])\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(f'The video named {os.path.split(videos_to_inspect[vid])[1]} has reported {num_reported} frames '\n",
    "              f'and has {length} frames, it has dropped {num_reported - length} frames')\n",
    "        cap.release()\n",
    "\n",
    "def stamp_diff_videos(path_to_stamp,stamp):\n",
    "    videos_to_stamp = glob.glob(path_to_stamp + r'\\**\\*.mp4', recursive=True)\n",
    "    for vid in videos_to_stamp:\n",
    "        os.rename(vid, fr'{vid[:-4]}_{stamp}{vid[-4:]}')\n",
    "\n",
    "def get_frame_timeseries(df,channel):\n",
    "    index_range = range(0,len(df[channel][df[channel].notna()]))\n",
    "    timeseries = pd.Series(df[channel][df[channel].notna()])\n",
    "    timeseries = pd.Series(timeseries.values, index=index_range, name=channel)\n",
    "    return timeseries\n",
    "\n",
    "def get_closest_frame(timestamp, vid_timeseries, report_acc=None):\n",
    "    \"\"\"\n",
    "    This function extracts a frame from a series so that it is as close as possible to a given timestamp\n",
    "    :param timestamp: The time to match a frame to\n",
    "    :param vid_timeseries: The time frames series to look at for a match\n",
    "    :param report_acc: if set to 1, will report the accuracy of the match\n",
    "    :return: index_of_lowest_diff , accuracy of match (if requested)\n",
    "    \"\"\"\n",
    "    array = np.abs((vid_timeseries.to_numpy())-timestamp)\n",
    "    index_of_lowest_diff = np.argmin(array)\n",
    "    if report_acc == 1:\n",
    "        accuracy = abs(vid_timeseries[index_of_lowest_diff] - timestamp)\n",
    "        return index_of_lowest_diff, accuracy\n",
    "    else:\n",
    "        return index_of_lowest_diff\n",
    "\n",
    "def synchronize_timestamps(arena_timestamps, ar_vidnames):\n",
    "    '''\n",
    "    :param arena_timestamps: a list of pathlib paths with arena timestamp files\n",
    "    :param ar_vidnames: names of the arena videos as extracted in the code\n",
    "    :return: arena_sync_df, a dataframe with the corresponding frames for each frame of the anchor video\n",
    "    '''\n",
    "    #read the timestamp files\n",
    "    len_list = []\n",
    "    df_list = []\n",
    "    for p in arena_timestamps:\n",
    "        df = pd.read_csv(p)\n",
    "        df_list.append(df)\n",
    "        len_list.append(len(df))\n",
    "\n",
    "    #pick the longest as an anchor\n",
    "    anchor_ind = len_list.index(max(len_list))\n",
    "    anchor_vid = df_list[anchor_ind]\n",
    "    anchor_vid_name = ar_vidnames[anchor_ind]\n",
    "    #construct a synchronization dataframe\n",
    "    arena_sync_df = pd.DataFrame(data=[],\n",
    "                                 columns=ar_vidnames,\n",
    "                                 index=range(len(anchor_vid)))\n",
    "\n",
    "    #populate the df, starting with the anchor:\n",
    "    arena_sync_df[arena_sync_df.columns[anchor_ind]] = range(len(anchor_vid))\n",
    "\n",
    "    # now, the corresponding frames from the remaining videos:\n",
    "    #start with removing the anchor video from the synchronization lists\n",
    "    vids_to_sync = list(arena_sync_df.columns)\n",
    "    del vids_to_sync[anchor_ind]\n",
    "    anchor_df = df_list.pop(anchor_ind)\n",
    "    df_to_sync = df_list\n",
    "    #iterate over rows and videos to find the corresponding frames\n",
    "    print('Synchronizing the different arena videos')\n",
    "    for row in tqdm(arena_sync_df.index):\n",
    "        anchor = anchor_vid.timestamp[row]\n",
    "        for vid in range(len(df_to_sync)):\n",
    "            frame_num = get_closest_frame(anchor,df_to_sync[vid])\n",
    "            arena_sync_df.loc[row,vids_to_sync[vid]] = frame_num\n",
    "\n",
    "    return arena_sync_df, anchor_vid_name\n",
    "\n",
    "def arena_video_initial_thr(vid_path, threshold_value, show_frames=False):\n",
    "    \"\"\"\n",
    "        This function works through an arena video to determine where the LEDs are on and when off\n",
    "        :param threshold_value: value of the frame threshold\n",
    "        :param show_frames: if true will show the video after thresholding\n",
    "        :param  vid_path: Path to video. When ShowFrames is True a projection of the frames after threshold is presented\n",
    "\n",
    "        :return: np.array with frame numbers and mean values after threshold\n",
    "        \"\"\"\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    all_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    flag = 0\n",
    "    i = 0\n",
    "    mean_values = []\n",
    "    indexes = []\n",
    "    while flag == 0:\n",
    "        print('Frame number {} of {}'.format(i, all_frames), end='\\r', flush=True)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        grey[grey < threshold_value] = 0\n",
    "        mean_values.append(np.mean(grey))\n",
    "        indexes.append(i)\n",
    "        if show_frames:\n",
    "            cv2.imshow('Thresholded_Frames', grey)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        i += 1\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    frame_val = np.array((indexes, mean_values))\n",
    "    return frame_val\n",
    "\n",
    "def produce_frame_val_list(vid_paths,threshold_value):\n",
    "    \"\"\"\n",
    "    :param vid_paths: a list of str paths to videos for analysis\n",
    "    :param threshold_value: the threshold to use in order to concentrate on LEDs\n",
    "    :return: frame_val_list: a list of mean pixel values for each frame after threshold\n",
    "    \"\"\"\n",
    "    frame_val_list = []\n",
    "    for vid in vid_paths:\n",
    "        print(f'working on video {vid}')\n",
    "        frame_val = arena_video_initial_thr(str(vid), threshold_value)\n",
    "        frame_val_list.append(frame_val)\n",
    "    print(f'done, frame_val_list contains {len(frame_val_list)} objects',flush=True)\n",
    "\n",
    "    return frame_val_list\n",
    "\n",
    "def four_video_concat(output_name, arena_vid1, arvid1_name, arena_vid2, arvid2_name,\n",
    "                      eye_vid_left, eye_vid_right, arena_sync_df, start_frame, shortest_vid_length, format='H264'):\n",
    "    \"\"\"\n",
    "    :param vid1: left down\n",
    "    :param vid2: right down\n",
    "    :param vid3: left up\n",
    "    :param vid4: right up\n",
    "    :param shortest_vid_length\n",
    "    :param output_name: output file name\n",
    "    :return: a concatenated video of the 4 inputs\n",
    "    \"\"\"\n",
    "    cap0 = cv2.VideoCapture(arena_vid1)\n",
    "    cap1 = cv2.VideoCapture(arena_vid2)\n",
    "    cap2 = cv2.VideoCapture(eye_vid_left)\n",
    "    cap3 = cv2.VideoCapture(eye_vid_right)\n",
    "    anchor = start_frame\n",
    "    last_ar1_f = arena_sync_df[arvid1_name][sync_vids.Arena_VideoFrame[start_frame]]\n",
    "    last_ar2_f = arena_sync_df[arvid2_name][sync_vids.Arena_VideoFrame[start_frame]]\n",
    "    last_le = sync_vids.Left_eye[start_frame]\n",
    "    last_re = sync_vids.Right_eye[start_frame]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*format)\n",
    "    out = cv2.VideoWriter((str(block_path) + r'\\\\' + output_name + '.mp4'),fourcc, 60.0, (640*2,480*2))\n",
    "    try:\n",
    "        while cap2.isOpened():\n",
    "            ar1_f = arena_sync_df[arvid1_name][sync_vids.Arena_VideoFrame[anchor]]\n",
    "            ar2_f = arena_sync_df[arvid2_name][sync_vids.Arena_VideoFrame[anchor]]\n",
    "            l_eye_f = sync_vids.Left_eye[anchor]\n",
    "            r_eye_f = sync_vids.Right_eye[anchor]\n",
    "\n",
    "            if ar1_f != last_ar1_f + 1:\n",
    "                cap0.set(1,ar1_f)\n",
    "            ar1_ret, ar1_frame = cap0.read()\n",
    "            ar1_frame = cv2.cvtColor(ar1_frame, cv2.COLOR_BGR2GRAY)\n",
    "            ar1_frame = cv2.resize(ar1_frame,(640,480))\n",
    "            last_ar1_f = ar1_f\n",
    "\n",
    "            if ar2_f != last_ar2_f + 1:\n",
    "                cap1.set(1,ar2_f)\n",
    "            ar2_ret, ar2_frame = cap1.read()\n",
    "            ar2_frame = cv2.cvtColor(ar2_frame, cv2.COLOR_BGR2GRAY)\n",
    "            ar2_frame = cv2.resize(ar2_frame,(640,480))\n",
    "            last_ar2_f = ar2_f\n",
    "\n",
    "            if l_eye_f != last_le + 1:\n",
    "                cap2.set(1,l_eye_f)\n",
    "            le_ret, le_f = cap2.read()\n",
    "            le_f = cv2.cvtColor(le_f, cv2.COLOR_BGR2GRAY)\n",
    "            le_f = cv2.flip(le_f, 0)\n",
    "            le_f = cv2.resize(le_f,(640,480))\n",
    "            last_le = l_eye_f\n",
    "\n",
    "            if r_eye_f != last_re + 1:\n",
    "                cap3.set(1,r_eye_f)\n",
    "            re_ret, re_f = cap3.read()\n",
    "            re_f = cv2.cvtColor(re_f, cv2.COLOR_BGR2GRAY)\n",
    "            re_f = cv2.flip(re_f, 0)\n",
    "            re_f = cv2.resize(re_f,(640,480))\n",
    "            last_re = r_eye_f\n",
    "\n",
    "            eye_concat = np.hstack((le_f,re_f))\n",
    "            ar_concat = np.hstack((ar1_frame, ar2_frame))\n",
    "            vconcat = np.vstack((eye_concat, ar_concat))\n",
    "\n",
    "            out.write(vconcat)\n",
    "            anchor += 1\n",
    "            print(f'writing video frame {anchor} out of {shortest_vid_length}', end='\\r', flush=True)\n",
    "            if anchor > shortest_vid_length-1:\n",
    "                break\n",
    "    except Exception:\n",
    "        print(f'Encountered a problem with frame {anchor}, stopping concatenation')\n",
    "    finally:\n",
    "        cap0.release()\n",
    "        cap1.release()\n",
    "        cap2.release()\n",
    "        cap3.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print('\\n')\n",
    "        print('Processed finished')\n",
    "\n",
    "def eye_tracking_analysis(dlc_video_analysis_csv):\n",
    "    \"\"\"\n",
    "    :param dlc_video_analysis_csv: the csv output of a dlc analysis of one video, already read by pandas with header=1\n",
    "    :param bodyparts_list: a list of bodyparts as described in the dlc csv (i.e ['Pupil_12', 'Pupil_6'....])\n",
    "    :returns ellipse_df: a DataFrame of ellipses parameters (center, width, height, phi, size) for each video frame\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data = dlc_video_analysis_csv\n",
    "    ellipses = []\n",
    "    caudal_edge_ls= []\n",
    "    rostral_edge_ls = []\n",
    "    for row in range(1, len(data)-1):\n",
    "        x_values = np.array(list([float(data['Pupil_12'][row]),\n",
    "                                  float(data['Pupil_1'][row]),\n",
    "                                  float(data['Pupil_3'][row]),\n",
    "                                  float(data['Pupil_4'][row]),\n",
    "                                  float(data['Pupil_6'][row]),\n",
    "                                  float(data['Pupil_8'][row]),\n",
    "                                  float(data['Pupil_10'][row])]))\n",
    "        y_values = np.array(list([float(data['Pupil_12.1'][row]),\n",
    "                                  float(data['Pupil_1.1'][row]),\n",
    "                                  float(data['Pupil_3.1'][row]),\n",
    "                                  float(data['Pupil_4.1'][row]),\n",
    "                                  float(data['Pupil_6.1'][row]),\n",
    "                                  float(data['Pupil_8.1'][row]),\n",
    "                                  float(data['Pupil_10.1'][row])]))\n",
    "        X = np.c_[x_values,y_values]\n",
    "\n",
    "        el = LsqEllipse().fit(X)\n",
    "        center, width, height, phi = el.as_parameters()\n",
    "        center_x = center[0]\n",
    "        center_y = center[1]\n",
    "        ellipses.append([center_x,center_y,width,height,phi])\n",
    "        caudal_edge = [\n",
    "            float(data['Caudal_edge'][row]),\n",
    "            float(data['Caudal_edge.1'][row])\n",
    "        ]\n",
    "        rostral_edge = [\n",
    "            float(data['Rostral_edge'][row]),\n",
    "            float(data['Rostral_edge.1'][row])\n",
    "        ]\n",
    "        caudal_edge_ls.append(caudal_edge)\n",
    "        rostral_edge_ls.append(rostral_edge)\n",
    "        if row % 50 == 0:\n",
    "           print(f'just finished with {row} out of {len(data)-1}', end='\\r',flush=True)\n",
    "    ellipse_df = pd.DataFrame(columns = ['center_x','center_y', 'width', 'height', 'phi'], data = ellipses)\n",
    "    a = np.array(ellipse_df['height'][:])\n",
    "    b = np.array(ellipse_df['width'][:])\n",
    "    ellipse_size_per_frame = a*b*math.pi\n",
    "    ellipse_df['ellipse_size'] = ellipse_size_per_frame\n",
    "    ellipse_df['rostral_edge'] = rostral_edge_ls\n",
    "    ellipse_df['caudal_edge'] = caudal_edge_ls\n",
    "    print('Done')\n",
    "    return ellipse_df\n",
    "\n",
    "def date_parser(epoch_ns):\n",
    "    return pd.to_datetime(epoch_ns).tz_localize(\"UTC\").tz_convert(\"Asia/Jerusalem\")\n",
    "\n",
    "def analyze_timestamp_csv(csv_path):\n",
    "    tdf = pd.read_csv(\n",
    "        csv_path,\n",
    "        dtype={\"timestamp\": np.long},\n",
    "        index_col=\"timestamp\",\n",
    "        parse_dates=True,\n",
    "        date_parser=date_parser,\n",
    "    )\n",
    "\n",
    "    diff_secs = tdf.index.to_series().diff() / np.timedelta64(1, 's')\n",
    "    freq = 1 / diff_secs\n",
    "    fps = freq.mean()\n",
    "    sd_fps = freq.std()\n",
    "    n = len(tdf)\n",
    "\n",
    "    return {\"n\": n, \"diff\": diff_secs, \"freq\": freq, \"mean_fps\": fps, \"sd_fps\": sd_fps, \"df\": tdf}\n",
    "\n",
    "def four_arena_video_concat(output_name, arena_vid1, arvid1_name, arena_vid2, arvid2_name,\n",
    "                            arena_vid3, arvid3_name, arena_vid4, arvid4_name, arena_sync_df,\n",
    "                            start_frame, shortest_vid_length, format='H264'):\n",
    "    \"\"\"\n",
    "    :param vid1: left down\n",
    "    :param vid2: right down\n",
    "    :param vid3: left up\n",
    "    :param vid4: right up\n",
    "    :param shortest_vid_length\n",
    "    :param output_name: output file name\n",
    "    :return: a concatenated video of the 4 inputs\n",
    "    \"\"\"\n",
    "    cap0 = cv2.VideoCapture(arena_vid1)\n",
    "    cap1 = cv2.VideoCapture(arena_vid2)\n",
    "    cap2 = cv2.VideoCapture(arena_vid3)\n",
    "    cap3 = cv2.VideoCapture(arena_vid4)\n",
    "    anchor = start_frame\n",
    "    last_ar1_f = arena_sync_df[arvid1_name][sync_vids.Arena_VideoFrame[start_frame]]\n",
    "    last_ar2_f = arena_sync_df[arvid2_name][sync_vids.Arena_VideoFrame[start_frame]]\n",
    "    last_ar3_f = arena_sync_df[arvid3_name][sync_vids.Arena_VideoFrame[start_frame]]\n",
    "    last_ar4_f = arena_sync_df[arvid4_name][sync_vids.Arena_VideoFrame[start_frame]]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*format)\n",
    "    out = cv2.VideoWriter((str(block_path) + r'\\\\' + output_name + '.mp4'),fourcc, 60.0, (640*2,480*2))\n",
    "    try:\n",
    "        while cap2.isOpened():\n",
    "            ar1_f = arena_sync_df[arvid1_name][sync_vids.Arena_VideoFrame[anchor]]\n",
    "            ar2_f = arena_sync_df[arvid2_name][sync_vids.Arena_VideoFrame[anchor]]\n",
    "            ar3_f = arena_sync_df[arvid3_name][sync_vids.Arena_VideoFrame[anchor]]\n",
    "            ar4_f = arena_sync_df[arvid4_name][sync_vids.Arena_VideoFrame[anchor]]\n",
    "\n",
    "            if ar1_f != last_ar1_f + 1:\n",
    "                cap0.set(1,ar1_f)\n",
    "            ar1_ret, ar1_frame = cap0.read()\n",
    "            ar1_frame = cv2.cvtColor(ar1_frame, cv2.COLOR_BGR2GRAY)\n",
    "            ar1_frame = cv2.resize(ar1_frame,(640,480))\n",
    "            last_ar1_f = ar1_f\n",
    "\n",
    "            if ar2_f != last_ar2_f + 1:\n",
    "                cap1.set(1,ar2_f)\n",
    "            ar2_ret, ar2_frame = cap1.read()\n",
    "            ar2_frame = cv2.cvtColor(ar2_frame, cv2.COLOR_BGR2GRAY)\n",
    "            ar2_frame = cv2.resize(ar2_frame,(640,480))\n",
    "            last_ar2_f = ar2_f\n",
    "\n",
    "            if ar3_f != last_ar3_f + 1:\n",
    "                cap1.set(1,ar3_f)\n",
    "            ar3_ret, ar3_frame = cap2.read()\n",
    "            ar3_frame = cv2.cvtColor(ar3_frame, cv2.COLOR_BGR2GRAY)\n",
    "            ar3_frame = cv2.resize(ar3_frame,(640,480))\n",
    "            last_ar3_f = ar3_f\n",
    "\n",
    "            if ar4_f != last_ar4_f + 1:\n",
    "                cap1.set(1,ar4_f)\n",
    "            ar4_ret, ar4_frame = cap3.read()\n",
    "            ar4_frame = cv2.cvtColor(ar4_frame, cv2.COLOR_BGR2GRAY)\n",
    "            ar4_frame = cv2.resize(ar4_frame,(640,480))\n",
    "            last_ar4_f = ar4_f\n",
    "\n",
    "\n",
    "            eye_concat = np.hstack((ar3_frame,ar4_frame))\n",
    "            ar_concat = np.hstack((ar1_frame, ar2_frame))\n",
    "            vconcat = np.vstack((eye_concat, ar_concat))\n",
    "\n",
    "            out.write(vconcat)\n",
    "            anchor += 1\n",
    "            print(f'writing video frame {anchor} out of {shortest_vid_length}', end='\\r', flush=True)\n",
    "            if anchor > shortest_vid_length-1:\n",
    "                break\n",
    "    except Exception:\n",
    "        print(f'Encountered a problem with frame {anchor}, stopping concatenation')\n",
    "    finally:\n",
    "        cap0.release()\n",
    "        cap1.release()\n",
    "        cap2.release()\n",
    "        cap3.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print('\\n')\n",
    "        print('Processed finished')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Function definitions\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nThis notebook should be the main sequence for incoming experimental data - there are prerequisites for a functional process:\\n- the process is designed to work block-by-block\\n- Data will be arranged into block folders under animal folders, where each block contains the next structure:\\n\\n                                       /----> arena_videos  ->[config.yaml , info.yaml] videos -> [video files, output.log] timestamps -> [csv of timestamps]\\n\\nAnimal_x ->date(xx_xx_xxxx) -> block_x -----> eye_videos >> LE\\\\RE -> video folder with name -> [video.h264 , video.mp4 , params.json , timestamps.csv]\\n\\n                                       \\\\----> oe_files >> date_time(xxxx_xx_xx_xx-xx-xx) --> [events.csv] internal open ephys structure from here (NWB format only!!!)\\n                                                                                             /////////////////////\\n                                                                                         TODO: internal parsing of this file\\n'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This notebook should be the main sequence for incoming experimental data - there are prerequisites for a functional process:\n",
    "- the process is designed to work block-by-block\n",
    "- Data will be arranged into block folders under animal folders, where each block contains the next structure:\n",
    "\n",
    "                                       /----> arena_videos  ->[config.yaml , info.yaml] videos -> [video files, output.log] timestamps -> [csv of timestamps]\n",
    "\n",
    "Animal_x ->date(xx_xx_xxxx) -> block_x -----> eye_videos >> LE\\RE -> video folder with name -> [video.h264 , video.mp4 , params.json , timestamps.csv]\n",
    "\n",
    "                                       \\----> oe_files >> date_time(xxxx_xx_xx_xx-xx-xx) --> [events.csv] internal open ephys structure from here (NWB format only!!!)\n",
    "                                                                                             /////////////////////\n",
    "                                                                                         TODO: internal parsing of this file\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Sketch\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block Path: D:\\experiments\\Animal_1000\\26_05_2021\\block_0\n"
     ]
    }
   ],
   "source": [
    "animal_number = '1000'\n",
    "experiment_date = '26_05_2021'\n",
    "block = '0'\n",
    "block_path = Path(rf'D:\\experiments\\Animal_{animal_number}\\{experiment_date}\\block_{block}')\n",
    "print(f'Block Path: {block_path}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Define block path\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arena video Names:\n",
      "calib_long_back_20210526_132415.mp4\n",
      "calib_long_left_20210526_132415.mp4\n",
      "calib_long_right_20210526_132415.mp4\n",
      "calib_long_top_20210526_132415.mp4\n"
     ]
    }
   ],
   "source": [
    "# find names with '-' and replace it with '_'\n",
    "arena_path = block_path / 'arena_videos'\n",
    "arena_files = [x for x in arena_path.iterdir()]\n",
    "for i in arena_files:\n",
    "    if '-' in i.name:\n",
    "        newname = i.name.replace('-','_')\n",
    "        newpath = i.parent / newname\n",
    "        i.replace(newpath)\n",
    "arena_files= [x for x in arena_path.iterdir()]\n",
    "arena_videos = [x for x in arena_files if x.suffix == '.mp4']\n",
    "arena_timestamps = [x for x in arena_files if x.suffix == '.csv']\n",
    "#arena_timestamps = [x for x in arena_timestamps if 'block' in x.name]\n",
    "ar_vidnames = [i.name for i in arena_videos]\n",
    "print(f'Arena video Names:')\n",
    "print(*ar_vidnames, sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%Arena files handler\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vid_path = block_path / 'eye_videos'\n",
    "print('converting videos...')\n",
    "convert_h264_mp4(str(vid_path))\n",
    "print('Validating videos...')\n",
    "validate_no_framedrop(str(vid_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Eye_Vids initial conversion & validation (RUN ONLY ONCE PER BLOCK!!!)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('stamping LE video')\n",
    "stamp_diff_videos(str(vid_path) + r'\\LE' , 'LE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Stamp LE videos (RUN ONLY ONCE PER BLOCK!!!!)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "le_video = glob.glob(str(block_path) + r'\\eye_videos\\LE\\**\\*.mp4')\n",
    "re_video = glob.glob(str(block_path) + r'\\eye_videos\\RE\\**\\*.mp4')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% find the converted eye videos\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[WindowsPath('D:/experiments/Animal_1000/26_05_2021/block_0/arena_videos/calib_long_back_20210526_132415.csv'),\n WindowsPath('D:/experiments/Animal_1000/26_05_2021/block_0/arena_videos/calib_long_left_20210526_132415.csv'),\n WindowsPath('D:/experiments/Animal_1000/26_05_2021/block_0/arena_videos/calib_long_right_20210526_132415.csv'),\n WindowsPath('D:/experiments/Animal_1000/26_05_2021/block_0/arena_videos/calib_long_top_20210526_132415.csv')]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena_timestamps\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12451/12451 [00:11<00:00, 1047.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronizing the different arena videos\n"
     ]
    }
   ],
   "source": [
    "arena_sync_df, arena_anchor_vid_name = synchronize_timestamps(arena_timestamps, ar_vidnames)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% synchronize the arena videos with each other\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The anchor video used was \"calib_long_back_20210526_132415.mp4\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "       calib_long_back_20210526_132415.mp4  \\\n0                                        0   \n1                                        1   \n2                                        2   \n3                                        3   \n4                                        4   \n...                                    ...   \n12446                                12446   \n12447                                12447   \n12448                                12448   \n12449                                12449   \n12450                                12450   \n\n      calib_long_left_20210526_132415.mp4  \\\n0                                       0   \n1                                       1   \n2                                       2   \n3                                       3   \n4                                       4   \n...                                   ...   \n12446                               12446   \n12447                               12447   \n12448                               12448   \n12449                               12449   \n12450                               12450   \n\n      calib_long_right_20210526_132415.mp4 calib_long_top_20210526_132415.mp4  \n0                                        1                                  1  \n1                                        1                                  1  \n2                                        2                                  2  \n3                                        3                                  3  \n4                                        4                                  4  \n...                                    ...                                ...  \n12446                                12446                              12446  \n12447                                12447                              12447  \n12448                                12448                              12448  \n12449                                12449                              12449  \n12450                                12450                              12450  \n\n[12451 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>calib_long_back_20210526_132415.mp4</th>\n      <th>calib_long_left_20210526_132415.mp4</th>\n      <th>calib_long_right_20210526_132415.mp4</th>\n      <th>calib_long_top_20210526_132415.mp4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12446</th>\n      <td>12446</td>\n      <td>12446</td>\n      <td>12446</td>\n      <td>12446</td>\n    </tr>\n    <tr>\n      <th>12447</th>\n      <td>12447</td>\n      <td>12447</td>\n      <td>12447</td>\n      <td>12447</td>\n    </tr>\n    <tr>\n      <th>12448</th>\n      <td>12448</td>\n      <td>12448</td>\n      <td>12448</td>\n      <td>12448</td>\n    </tr>\n    <tr>\n      <th>12449</th>\n      <td>12449</td>\n      <td>12449</td>\n      <td>12449</td>\n      <td>12449</td>\n    </tr>\n    <tr>\n      <th>12450</th>\n      <td>12450</td>\n      <td>12450</td>\n      <td>12450</td>\n      <td>12450</td>\n    </tr>\n  </tbody>\n</table>\n<p>12451 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'The anchor video used was \"{arena_anchor_vid_name}\"')\n",
    "arena_sync_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Utilize the open-ephys files by sorting the event times by channel\n",
    "channeldict = {\n",
    "    5 : 'L_eye_TTL',\n",
    "    6 : 'Arena_TTL',\n",
    "    8 : 'R_eye_TTL'\n",
    "}\n",
    "exp_date_time = os.listdir(fr'{str(block_path)}\\oe_files')[0]\n",
    "oe_events , oe_off_events = oe_events_parser(str(block_path) + rf'\\oe_files\\{exp_date_time}\\events.csv',\n",
    "                                             channeldict,\n",
    "                                             export_path=str(block_path) + rf'\\oe_files\\{exp_date_time}\\parsed_events.csv')\n",
    "ts_list = []\n",
    "\n",
    "for chan in list(oe_events.columns):\n",
    "    ts = get_frame_timeseries(oe_events, str(chan))\n",
    "    ts_list.append(ts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_len_list = list(map(len, ts_list))\n",
    "shortest_ind = ts_len_list.index(min(ts_len_list))\n",
    "shortest_ind"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "block_start_time = ts_list[shortest_ind].values[0]\n",
    "block_end_time = ts_list[shortest_ind].values[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arena video start: 101.97853088378906 \n",
      "Arena video end: 335.6025390625 \n",
      "Block length: 233.62400817871094 Seconds\n"
     ]
    }
   ],
   "source": [
    "print(f'Arena video start: {block_start_time} \\n'\n",
    "      f'Arena video end: {block_end_time} \\n'\n",
    "      f'Block length: {block_end_time - block_start_time} Seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-25-023c401ccaff>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;31m#Left eye\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mle_ff\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mts_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mts_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0mblock_start_time\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0mle_first_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mts_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mts_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mle_ff\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mle_lf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mts_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "#Arena\n",
    "arena_ff = ts_list[1].values[ts_list[1] > block_start_time][0]\n",
    "arena_first_index = ts_list[1][ts_list[1] == arena_ff].index\n",
    "arena_lf = ts_list[1].values[ts_list[1]<block_end_time][-1]\n",
    "arena_last_index = ts_list[1][ts_list[1] == arena_lf].index\n",
    "arena_sync_s = pd.Series(ts_list[1][arena_first_index.asi8[0] : arena_last_index.asi8[0]])\n",
    "\n",
    "#Left eye\n",
    "le_ff = ts_list[0].values[ts_list[0] > block_start_time][0]\n",
    "le_first_index = ts_list[0][ts_list[0] == le_ff].index\n",
    "le_lf = ts_list[0].values[-1]\n",
    "le_last_index = ts_list[0][ts_list[0] == le_lf].index\n",
    "le_sync_s = ts_list[0]\n",
    "\n",
    "#Right eye\n",
    "re_ff = ts_list[2].values[ts_list[2] > block_start_time][0]\n",
    "re_first_index = ts_list[2][ts_list[2] == re_ff].index\n",
    "re_lf = ts_list[2].values[-1]\n",
    "re_last_index = ts_list[2][ts_list[2] == re_lf].index\n",
    "re_sync_s = ts_list[2]\n",
    "\n",
    "sync_time_starts = max([arena_ff, le_ff, re_ff])\n",
    "sync_time_ends = min([arena_lf, le_lf, re_lf])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% find the first and last frames within the capture window for each source\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sync_time_starts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-17-5d38085cacda>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#Define Anchor signal\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0manchor_signal\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msync_time_starts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msync_time_ends\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m60\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m#Create the DataFrame\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m sync_vids = pd.DataFrame(data=None,\n",
      "\u001B[1;31mNameError\u001B[0m: name 'sync_time_starts' is not defined"
     ]
    }
   ],
   "source": [
    "#Define Anchor signal\n",
    "anchor_signal = np.arange(sync_time_starts, sync_time_ends, 1/60)\n",
    "\n",
    "#Create the DataFrame\n",
    "sync_vids = pd.DataFrame(data=None,\n",
    "                         index=range(len(anchor_signal)),\n",
    "                         columns=['Left_eye','Arena','Arena_VideoFrame','Right_eye'])\n",
    "\n",
    "accuracy_report = pd.DataFrame(data=None,\n",
    "                               index=range(len(anchor_signal)),\n",
    "                               columns=['Left_eye','Arena','Right_eye'])\n",
    "\n",
    "# define dictionary for timestamp retrieval\n",
    "ts_dict = {'Left_eye': ts_list[0],\n",
    "           'Arena': ts_list[1],\n",
    "           'Right_eye':ts_list[2]}\n",
    "\n",
    "#Iterate over the length of the dataframe and fit\n",
    "for frame in tqdm(range(len(anchor_signal))):\n",
    "    anchor_time = anchor_signal[frame]\n",
    "    for vid in ['Left_eye', 'Right_eye', 'Arena']:\n",
    "        f,a = get_closest_frame(anchor_time, ts_dict[vid], report_acc=1)\n",
    "        sync_vids[vid][frame] = f\n",
    "        accuracy_report[vid][frame] = a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Align Frames in synchronization DataFrame\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO: organize the manual synchronization\n",
    "\n",
    "sync_vids.Arena_VideoFrame = sync_vids.Arena\n",
    "sync_vids.Right_eye = sync_vids.Right_eye\n",
    "sync_vids.Left_eye = sync_vids.Left_eye\n",
    "sync_vids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "fig.set_facecolor('white')\n",
    "_ = accuracy_report['Arena'].plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arena_videos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arena_frame_val_list = produce_frame_val_list(arena_videos,250)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% analyze arena video for led-off frames\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l_eye_frame_val_list = produce_frame_val_list(le_video, 30)\n",
    "r_eye_frame_val_list = produce_frame_val_list(re_video,30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%analyze eye videos\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l_eye_values = stats.zscore(l_eye_frame_val_list[0][1])\n",
    "r_eye_values = stats.zscore(r_eye_frame_val_list[0][1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% create the l/r eyes value df\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arena_brightness_df = pd.DataFrame(index = anchor_signal)\n",
    "for ind, vid in enumerate(ar_vidnames):\n",
    "    vid_val_arr = stats.zscore(arena_frame_val_list[ind][1])\n",
    "    sync_list = sync_vids.Arena_VideoFrame.astype(int)\n",
    "    sync_list[sync_list >= len(vid_val_arr)] = len(vid_val_arr)-1\n",
    "    arena_brightness_df.insert(loc=0,\n",
    "                               column=str(vid),\n",
    "                               value=vid_val_arr[sync_list])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% create synchronization dataframes\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arena_brightness_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eye_brightness_df = pd.DataFrame(index=anchor_signal)\n",
    "sync_left = sync_vids.Left_eye.astype(int)\n",
    "eye_brightness_df.insert(loc=0,\n",
    "                         column='left_eye',\n",
    "                         value=l_eye_values[(sync_vids.Left_eye.values.astype(int)-1)[0:len(anchor_signal)]])\n",
    "eye_brightness_df.insert(loc=0,\n",
    "                         column='right_eye',\n",
    "                         value=r_eye_values[(sync_vids.Right_eye.values.astype(int)-1)[0:len(anchor_signal)]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sec = 3600\n",
    "x = 0\n",
    "region = range(0+x*sec, 3600+x*sec)\n",
    "\n",
    "fig = plt.figure(figsize=[20,7])\n",
    "fig.set_facecolor('xkcd:white')\n",
    "plt.plot(eye_brightness_df.iloc[region].index, eye_brightness_df.iloc[region].right_eye, label='right')\n",
    "plt.plot(eye_brightness_df.iloc[region].index, eye_brightness_df.iloc[region].left_eye, label='left')\n",
    "plt.plot(eye_brightness_df.iloc[region].index, arena_brightness_df.iloc[region][arena_anchor_vid_name], label='arena anchor')\n",
    "plt.plot(eye_brightness_df.iloc[region].index, arena_brightness_df.iloc[region][arena_brightness_df.columns[1]], label='arena2')\n",
    "plt.plot(eye_brightness_df.iloc[region].index, arena_brightness_df.iloc[region][arena_brightness_df.columns[2]], label='arena3')\n",
    "plt.plot(eye_brightness_df.iloc[region].index, arena_brightness_df.iloc[region][arena_brightness_df.columns[3]], label='arena4')\n",
    "plt.vlines(eye_brightness_df.iloc[region].index, -20, -8, linestyles={'dashed'})\n",
    "_ = plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% explore synchronization\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trialrun = 0\n",
    "bokeh_fig = figure(title='Synchronization Brightness Z scores',\n",
    "                   x_axis_label='Time',\n",
    "                   y_axis_label='Brightness Z scores',\n",
    "                   plot_width=1500,\n",
    "                   plot_height=700\n",
    "                   )\n",
    "bokeh_fig.line(eye_brightness_df.index, eye_brightness_df.right_eye,\n",
    "               legend_label='right eye',\n",
    "               line_width=1.5,\n",
    "               line_color='red')\n",
    "bokeh_fig.line(eye_brightness_df.index, eye_brightness_df.left_eye,\n",
    "               legend_label='left eye',\n",
    "               line_width=1.5,\n",
    "               line_color='blue')\n",
    "\n",
    "bokeh_fig.line(eye_brightness_df.index, arena_brightness_df[arena_anchor_vid_name],\n",
    "               legend_label='Arena',\n",
    "               line_width=1.5,\n",
    "               line_color='black')\n",
    "bokeh_fig.line(eye_brightness_df.index, trialrun,\n",
    "               legend_label='tryme',\n",
    "               line_color='green',\n",
    "               line_width=4\n",
    "               )\n",
    "\n",
    "slider = Slider(start=0, end=10, value=1, step=.1, title=\"Stuff\")\n",
    "slider.js_on_change(\"value\", CustomJS(code=\"\"\"\n",
    "    console.log('slider: value=' + this.value, this.toString())\n",
    "\"\"\"))\n",
    "layout = bokeh.layouts.column(slider,bokeh_fig)\n",
    "show(layout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% explore synchronization #2\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "four_arena_video_concat('Sync_trial_tal_v0',\n",
    "                  str(arena_videos[0]),ar_vidnames[0],\n",
    "                  str(arena_videos[1]), ar_vidnames[1],\n",
    "                  str(arena_videos[2]),ar_vidnames[2],\n",
    "                  str(arena_videos[3]),ar_vidnames[3], arena_sync_df,\n",
    "                  2000,3000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#arena_sync_df['block0_left_20210419_143946.mp4'][0]\n",
    "ar_vidnames"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arena_sync_df.to_csv('sanity_check_df.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}