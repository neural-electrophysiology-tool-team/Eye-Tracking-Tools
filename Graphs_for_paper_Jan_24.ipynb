{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-31T17:43:41.101281900Z",
     "start_time": "2024-01-31T17:43:39.496868100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import cycle\n",
    "import pathlib\n",
    "import math\n",
    "import tqdm\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import re\n",
    "from lxml import etree as ET\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "from scipy.stats import kde\n",
    "from BlockSync_current import BlockSync\n",
    "import UtilityFunctions_newOE as uf\n",
    "from scipy import signal\n",
    "import bokeh"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# new utility functions defined here:\n",
    "def bokeh_plotter(data_list, label_list,\n",
    "                  plot_name='default',\n",
    "                  x_axis='X', y_axis='Y',\n",
    "                  peaks=None, export_path=False):\n",
    "    \"\"\"Generates an interactive Bokeh plot for the given data vector.\n",
    "    Args:\n",
    "        data_list (list or array): The data to be plotted.\n",
    "        label_list (list of str): The labels of the data vectors\n",
    "        plot_name (str, optional): The title of the plot. Defaults to 'default'.\n",
    "        x_axis (str, optional): The label for the x-axis. Defaults to 'X'.\n",
    "        y_axis (str, optional): The label for the y-axis. Defaults to 'Y'.\n",
    "        peaks (list or array, optional): Indices of peaks to highlight on the plot. Defaults to None.\n",
    "        export_path (False or str): when set to str, will output the resulting html fig\n",
    "    \"\"\"\n",
    "    color_cycle = cycle(bokeh.palettes.Category10_10)\n",
    "    fig = bokeh.plotting.figure(title=f'bokeh explorer: {plot_name}',\n",
    "                                x_axis_label=x_axis,\n",
    "                                y_axis_label=y_axis,\n",
    "                                plot_width=1500,\n",
    "                                plot_height=700)\n",
    "\n",
    "    for i, vec in enumerate(range(len(data_list))):\n",
    "        color = next(color_cycle)\n",
    "        data_vector = data_list[vec]\n",
    "        if label_list is None:\n",
    "            fig.line(range(len(data_vector)), data_vector, line_color=color, legend_label=f\"Line {len(fig.renderers)}\")\n",
    "        elif len(label_list) == len(data_list):\n",
    "            fig.line(range(len(data_vector)), data_vector, line_color=color, legend_label=f\"{label_list[i]}\")\n",
    "\n",
    "    if peaks is not None:\n",
    "        fig.circle(peaks, data_vector[peaks], size=10, color='red')\n",
    "\n",
    "    if export_path is not False:\n",
    "        print(f'exporting to {export_path}')\n",
    "        bokeh.io.output.output_file(filename=str(export_path / f'{plot_name}.html'), title=f'{plot_name}')\n",
    "    bokeh.plotting.show(fig)\n",
    "    \n",
    "    \n",
    "    # verification function for a single eye video + ellipse (requires cv2)\n",
    "\n",
    "# currently working very slowly\n",
    "def play_video_with_ellipses(block, eye, path_to_video=False, xflip=False):\n",
    "\n",
    "    if eye == 'left':\n",
    "        video_path = block.le_videos[0]\n",
    "        ellipse_dataframe = block.le_df\n",
    "    elif eye == 'right':\n",
    "        video_path = block.re_videos[0]\n",
    "        ellipse_dataframe = block.re_df\n",
    "    else:\n",
    "        raise ValueError(f\"eye can only be 'left' or 'right'\")\n",
    "    if video_path is not False:\n",
    "        video_path = path_to_video\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file.\")\n",
    "        return\n",
    "\n",
    "    # Loop through each frame\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        if not ret:\n",
    "            # Break the loop if the video is finished\n",
    "            break\n",
    "        \n",
    "        # Optionally flip the frame along the x-axis\n",
    "        if xflip:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Get the corresponding ellipse data for the current frame\n",
    "        current_frame_num = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "        try:\n",
    "            if eye == 'right':\n",
    "                current_frame_data = ellipse_dataframe.iloc[ellipse_dataframe.query('R_eye_frame == @current_frame_num').index[0]]\n",
    "            elif eye == 'left':\n",
    "                current_frame_data = ellipse_dataframe.iloc[ellipse_dataframe.query('L_eye_frame == @current_frame_num').index[0]]\n",
    "        except IndexError:\n",
    "            continue\n",
    "        # Extract ellipse parameters\n",
    "        try:\n",
    "            center_x = int(current_frame_data['center_x'])\n",
    "            center_y = int(current_frame_data['center_y'])\n",
    "            width = int(current_frame_data['width'])\n",
    "            height = int(current_frame_data['height'])\n",
    "            phi = float(current_frame_data['phi'])\n",
    "    \n",
    "            # Draw the ellipse on the frame\n",
    "            cv2.ellipse(frame, (center_x, center_y), (width, height), phi, 0, 360, (0, 255, 0), 2)\n",
    "    \n",
    "            # Display the frame\n",
    "            cv2.imshow('Video with Ellipses', frame)\n",
    "        \n",
    "            # Check for the 'q' key to quit\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        except ValueError:\n",
    "            continue\n",
    "    # Release video capture object and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def play_video_with_ellipses_rotation(block, eye, path_to_video=False, xflip=False, transformation_matrix=None):\n",
    "    if eye == 'left':\n",
    "        video_path = block.le_videos[0]\n",
    "        ellipse_dataframe = block.le_df\n",
    "    elif eye == 'right':\n",
    "        video_path = block.re_videos[0]\n",
    "        ellipse_dataframe = block.re_df\n",
    "    else:\n",
    "        raise ValueError(f\"eye can only be 'left' or 'right'\")\n",
    "    \n",
    "    if video_path is not False:\n",
    "        video_path = path_to_video\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file.\")\n",
    "        return\n",
    "\n",
    "    # Loop through each frame\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        if not ret:\n",
    "            # Break the loop if the video is finished\n",
    "            break\n",
    "        \n",
    "        # Optionally flip the frame along the x-axis\n",
    "        if xflip:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Apply transformation matrix if provided\n",
    "        if transformation_matrix is not None:\n",
    "            frame = cv2.warpAffine(frame, transformation_matrix, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        # Get the corresponding ellipse data for the current frame\n",
    "        current_frame_num = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "        try:\n",
    "            if eye == 'right':\n",
    "                current_frame_data = ellipse_dataframe.iloc[ellipse_dataframe.query('R_eye_frame == @current_frame_num').index[0]]\n",
    "            elif eye == 'left':\n",
    "                current_frame_data = ellipse_dataframe.iloc[ellipse_dataframe.query('L_eye_frame == @current_frame_num').index[0]]\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "        # Extract ellipse parameters\n",
    "        if transformation_matrix is not None:\n",
    "            try:\n",
    "                center_x = int(current_frame_data['center_x_rotated'])\n",
    "                center_y = int(current_frame_data['center_y_rotated'])\n",
    "                width = int(current_frame_data['width'])\n",
    "                height = int(current_frame_data['height'])\n",
    "                phi = float(current_frame_data['phi_rotated'])\n",
    "                \n",
    "                # Draw the ellipse on the frame\n",
    "                cv2.ellipse(frame, (center_x, center_y), (width, height), phi, 0, 360, (0, 255, 0), 2)\n",
    "                \n",
    "                # Add text to the frame\n",
    "                text = f'ellipse angle: {phi}'\n",
    "                cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "                \n",
    "                # Display the frame\n",
    "                cv2.imshow('Video with Ellipses', frame)\n",
    "            \n",
    "                # Check for the 'q' key to quit\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            except ValueError:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                center_x = int(current_frame_data['center_x'])\n",
    "                center_y = int(current_frame_data['center_y'])\n",
    "                width = int(current_frame_data['width'])\n",
    "                height = int(current_frame_data['height'])\n",
    "                phi = float(current_frame_data['phi'])\n",
    "        \n",
    "                # Draw the ellipse on the frame\n",
    "                cv2.ellipse(frame, (center_x, center_y), (width, height), phi, 0, 360, (0, 255, 0), 2)\n",
    "                \n",
    "                # Add text to the frame\n",
    "                text = f'ellipse angle: {phi}'\n",
    "                cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Display the frame\n",
    "                cv2.imshow('Video with Ellipses', frame)\n",
    "            \n",
    "                # Check for the 'q' key to quit\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Release video capture object and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def collect_lights_out_events(data, roll_w_size=1500, plot=False): \n",
    "    \"\"\"Identifies potential lights-out events from the given data.\n",
    "    \n",
    "    Args:\n",
    "        data (list or array): The data containing light measurements.\n",
    "        roll_w_size (int, optional): The window size for rolling z-score calculation. Defaults to 1500.\n",
    "\n",
    "    Returns:\n",
    "        list: Indices of the identified potential lights-out events.\n",
    "    \"\"\"\n",
    "    # use a function to get relative z-scores and deal with changes in ambient light\n",
    "    z_score_data = rolling_window_z_scores(data, roll_w_size=roll_w_size)\n",
    "    z_score_data = z_score_data[:len(data)]\n",
    "    \n",
    "    # detect peaks based on the scipy algorithm\n",
    "    peak_indices, _ = scipy.signal.find_peaks(-1 * z_score_data, width=1, distance = 3000)\n",
    "    \n",
    "    # expand the peaks to include the dimming and re-lighting frames\n",
    "    expanded_indices = np.sort(np.array([peak_indices -1, peak_indices, peak_indices + 1]).flatten())\n",
    "    \n",
    "    if plot:\n",
    "        bokeh_plotter([z_score_data],label_list=['phi diff'], plot_name='peak detector output', x_axis='Frame', y_axis='brightness Z score', peaks=expanded_indices)\n",
    "    \n",
    "    return expanded_indices\n",
    "\n",
    "def rolling_window_z_scores(data, roll_w_size=120):\n",
    "    \"\"\"\n",
    "    Detect threshold-crossing data points in a 1D data vector using a rolling window approach.\n",
    "\n",
    "    Parameters:\n",
    "    - data (numpy array): 1D data vector with values.\n",
    "    - roll_w_size (int): Size, in samples, of the rolling window.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array: A 1D array where each element is the relative z-score of the original value in its window\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    len_data = len(data)\n",
    "\n",
    "    for i in tqdm.tqdm(range(0, len_data - roll_w_size + 1, roll_w_size)):\n",
    "        window_data = data[i:i + roll_w_size]\n",
    "        \n",
    "        std_value = np.std(window_data)\n",
    "        zscores = scipy.stats.zscore(window_data)\n",
    "        \n",
    "        \n",
    "        #threshold_crossing_indices = np.where(window_data < std_value*threshold)[0]\n",
    "        if i==0:\n",
    "            result = zscores\n",
    "        else:\n",
    "            result = np.concatenate([result, zscores])\n",
    "        \n",
    "\n",
    "    # Handle remaining elements after the last complete rolling window\n",
    "    last_window_start = len_data - roll_w_size\n",
    "    last_window_data = data[last_window_start:]\n",
    "\n",
    "    std_value_last = np.std(last_window_data)\n",
    "    zscores_last = scipy.stats.zscore(last_window_data)\n",
    "    result = np.concatenate([result, zscores_last])\n",
    "    \n",
    "    return result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T17:43:41.102402Z",
     "start_time": "2024-01-31T17:43:40.757249Z"
    }
   },
   "id": "af772d371f6cc645",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 024 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_024, new OE version\n",
      "Found the sample rate for block 024 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 024\n",
      "got it!\n"
     ]
    }
   ],
   "source": [
    "# define a single block to figure things out with:\n",
    "# this step creates block_collection - a list of BlockSync objects of interest\n",
    "block_numbers = range(24,25)\n",
    "bad_blocks = [42, 61, 62, 64, 65, 66] # True for PV_62\n",
    "experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "animal = 'PV_62'\n",
    "block_collection = uf.block_generator(block_numbers=block_numbers,\n",
    "                                      experiment_path=experiment_path,\n",
    "                                      animal=animal,\n",
    "                                      bad_blocks=bad_blocks)\n",
    "# create a block_dict object for ease of access:\n",
    "block_dict = {}\n",
    "for b in block_collection:\n",
    "    block_dict[str(b.block_num)] = b\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T17:43:41.133742300Z",
     "start_time": "2024-01-31T17:43:40.770033900Z"
    }
   },
   "id": "67ff6f0b4cceaaae",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parse_open_ephys_events...\n",
      "block 024 has a parsed events file, reading...\n",
      "getting eye brigtness values for block 024...\n",
      "found a file!\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n"
     ]
    }
   ],
   "source": [
    "# This step is used to quickly go over the analyzed blocks and load their internal data\n",
    "for block in block_collection:\n",
    "    block.parse_open_ephys_events()\n",
    "    block.get_eye_brightness_vectors()\n",
    "    block.synchronize_block()\n",
    "    block.create_eye_brightness_df(threshold_value=20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T17:43:41.707892100Z",
     "start_time": "2024-01-31T17:43:40.924683700Z"
    }
   },
   "id": "c3039b2271316c6f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye dataframes loaded from analysis folder\n"
     ]
    }
   ],
   "source": [
    "# This is a continuation of the previous - more data loadings\n",
    "for block in block_collection:\n",
    "    block.import_manual_sync_df()\n",
    "    block.read_dlc_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T17:43:42.804438Z",
     "start_time": "2024-01-31T17:43:41.711890900Z"
    }
   },
   "id": "9b0b395f67f85fcb",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I want to create a datastream_map object that will hold information about different data sources and their mapping onto the block timeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "167d26eeb38be856"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sync_map = block.final_sync_df\n",
    "sync_map = sync_map[['Arena_TTL', 'Arena_frame', 'L_eye_frame','R_eye_frame']]\n",
    "sync_map = sync_map.rename(columns={'Arena_TTL':'OE_timestamp'})\n",
    "df = block.le_df[[]\n",
    "demo_stream = DataStream(df=df,own_sync_map=sync_map[['OE_timestamp', 'L_eye_frame']] )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T18:23:43.047189900Z",
     "start_time": "2024-01-31T18:23:43.025197100Z"
    }
   },
   "id": "5a53649a2aee60bc",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        Arena_TTL  Unnamed: 0.1  L_eye_frame  L_values  R_values    center_x  \\\n0        605092.0             0          NaN       NaN  0.885172         NaN   \n1        605431.0             1          NaN       NaN  0.887300         NaN   \n2        605771.0             2          NaN       NaN  0.890668         NaN   \n3        606111.0             3          NaN       NaN  0.892202         NaN   \n4        606451.0             4          3.0 -2.813021  0.893261  315.466003   \n...           ...           ...          ...       ...       ...         ...   \n91948  31841220.0         91948      93878.0 -1.851355  1.670915  409.768703   \n91949  31841560.0         91949      93879.0 -1.855220  1.670836  409.593340   \n91950  31841900.0         91950      93880.0 -1.851100  1.670840  409.575137   \n91951  31842239.0         91951      93881.0 -1.852275  1.670417  409.573627   \n91952  31842579.0         91952      93882.0 -1.849970  1.670401  409.536768   \n\n         center_y      width     height       phi  ellipse_size     ms_axis  \\\n0             NaN        NaN        NaN       NaN           NaN    30254.60   \n1             NaN        NaN        NaN       NaN           NaN    30271.55   \n2             NaN        NaN        NaN       NaN           NaN    30288.55   \n3             NaN        NaN        NaN       NaN           NaN    30305.55   \n4      176.975903  46.355792  37.094571 -0.509178   5402.120118    30322.55   \n...           ...        ...        ...       ...           ...         ...   \n91948  142.412726  44.392050  28.938988  0.320629   4035.881617  1592061.00   \n91949  142.371146  44.201880  28.903984  0.317515   4013.731602  1592078.00   \n91950  142.392658  44.242473  28.899884  0.316178   4016.847748  1592095.00   \n91951  142.381196  44.153392  28.857153  0.317981   4002.832648  1592111.95   \n91952  142.405142  44.133213  28.841346  0.321073   3998.811603  1592128.95   \n\n       center_x_corrected  center_y_corrected  \n0                     NaN                 NaN  \n1                     NaN                 NaN  \n2                     NaN                 NaN  \n3                     NaN                 NaN  \n4              315.466003          176.975903  \n...                   ...                 ...  \n91948          405.768703          142.412726  \n91949          405.593340          142.371146  \n91950          405.575137          142.392658  \n91951          405.573627          142.381196  \n91952          405.536768          142.405142  \n\n[91953 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Arena_TTL</th>\n      <th>Unnamed: 0.1</th>\n      <th>L_eye_frame</th>\n      <th>L_values</th>\n      <th>R_values</th>\n      <th>center_x</th>\n      <th>center_y</th>\n      <th>width</th>\n      <th>height</th>\n      <th>phi</th>\n      <th>ellipse_size</th>\n      <th>ms_axis</th>\n      <th>center_x_corrected</th>\n      <th>center_y_corrected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>605092.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.885172</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>30254.60</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>605431.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.887300</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>30271.55</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>605771.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.890668</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>30288.55</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>606111.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.892202</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>30305.55</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>606451.0</td>\n      <td>4</td>\n      <td>3.0</td>\n      <td>-2.813021</td>\n      <td>0.893261</td>\n      <td>315.466003</td>\n      <td>176.975903</td>\n      <td>46.355792</td>\n      <td>37.094571</td>\n      <td>-0.509178</td>\n      <td>5402.120118</td>\n      <td>30322.55</td>\n      <td>315.466003</td>\n      <td>176.975903</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>91948</th>\n      <td>31841220.0</td>\n      <td>91948</td>\n      <td>93878.0</td>\n      <td>-1.851355</td>\n      <td>1.670915</td>\n      <td>409.768703</td>\n      <td>142.412726</td>\n      <td>44.392050</td>\n      <td>28.938988</td>\n      <td>0.320629</td>\n      <td>4035.881617</td>\n      <td>1592061.00</td>\n      <td>405.768703</td>\n      <td>142.412726</td>\n    </tr>\n    <tr>\n      <th>91949</th>\n      <td>31841560.0</td>\n      <td>91949</td>\n      <td>93879.0</td>\n      <td>-1.855220</td>\n      <td>1.670836</td>\n      <td>409.593340</td>\n      <td>142.371146</td>\n      <td>44.201880</td>\n      <td>28.903984</td>\n      <td>0.317515</td>\n      <td>4013.731602</td>\n      <td>1592078.00</td>\n      <td>405.593340</td>\n      <td>142.371146</td>\n    </tr>\n    <tr>\n      <th>91950</th>\n      <td>31841900.0</td>\n      <td>91950</td>\n      <td>93880.0</td>\n      <td>-1.851100</td>\n      <td>1.670840</td>\n      <td>409.575137</td>\n      <td>142.392658</td>\n      <td>44.242473</td>\n      <td>28.899884</td>\n      <td>0.316178</td>\n      <td>4016.847748</td>\n      <td>1592095.00</td>\n      <td>405.575137</td>\n      <td>142.392658</td>\n    </tr>\n    <tr>\n      <th>91951</th>\n      <td>31842239.0</td>\n      <td>91951</td>\n      <td>93881.0</td>\n      <td>-1.852275</td>\n      <td>1.670417</td>\n      <td>409.573627</td>\n      <td>142.381196</td>\n      <td>44.153392</td>\n      <td>28.857153</td>\n      <td>0.317981</td>\n      <td>4002.832648</td>\n      <td>1592111.95</td>\n      <td>405.573627</td>\n      <td>142.381196</td>\n    </tr>\n    <tr>\n      <th>91952</th>\n      <td>31842579.0</td>\n      <td>91952</td>\n      <td>93882.0</td>\n      <td>-1.849970</td>\n      <td>1.670401</td>\n      <td>409.536768</td>\n      <td>142.405142</td>\n      <td>44.133213</td>\n      <td>28.841346</td>\n      <td>0.321073</td>\n      <td>3998.811603</td>\n      <td>1592128.95</td>\n      <td>405.536768</td>\n      <td>142.405142</td>\n    </tr>\n  </tbody>\n</table>\n<p>91953 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.le_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T13:18:50.207024Z",
     "start_time": "2024-02-01T13:18:50.167471400Z"
    }
   },
   "id": "f51e76a0305856c5",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I want to understand how to translate my data such that the X and Y axes are reliable and not determined by the camera tilt\n",
    "This will be achieved by the following solution:\n",
    "1. get a line that cuts the image along the tearducts of the animal when the pupil is as close to a circle as possible\n",
    "2. translate phi, x-center and y-center together with the line such that the line is horizontal"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d432a0979c481cb4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nExample usage\\npath_to_video = block.le_videos[0]\\nframe_number = frame_number_to_show\\noutput_path = block.analysis_path / \\'frame_rotation.avi\\'\\ntransformation_matrix, angle = rotate_frame_to_horizontal_with_interpolation(path_to_video, frame_number, block.le_df, output_path=None)\\nprint(\"Transformation Matrix:\")\\nprint(transformation_matrix)\\n'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the second iteration of the rotation verification function:\n",
    "def rotate_frame_to_horizontal_with_interpolation(path_to_video_file, frame_number, ellipse_df, xflip=True, output_path= None):\n",
    "    \"\"\"\n",
    "    Rotate the specified frame from a video file to horizontal orientation with interpolation.\n",
    "\n",
    "    Parameters:\n",
    "    - path_to_video_file (str): Path to the video file.\n",
    "    - frame_number (int): Frame number to be processed.\n",
    "    - ellipse_df (pd.DataFrame): DataFrame containing ellipse parameters for each frame.\n",
    "    - xflip (bool, optional): Flag to horizontally flip the frame (default is True).\n",
    "    - output_path (str, optional): Path to save the output video file (default is None).\n",
    "\n",
    "    Returns:\n",
    "    - rotation_matrix (np.ndarray): The rotation matrix used for the transformation.\n",
    "    - angle (float): The rotation angle applied to the frame.\n",
    "    \"\"\"\n",
    "    # Read the video file\n",
    "    cap = cv2.VideoCapture(path_to_video_file)\n",
    "\n",
    "    # Check if the video file is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video file.\")\n",
    "        return None\n",
    "\n",
    "    # Set the frame position\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is read successfully\n",
    "    if not ret:\n",
    "        print(f\"Error: Unable to read frame {frame_number}.\")\n",
    "        cap.release()\n",
    "        return None\n",
    "\n",
    "    # horizontally flip frame if applicable:\n",
    "    if xflip:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # get the original ellipse from the block dataframe\n",
    "    if 'R_eye_frame' in ellipse_df.columns:\n",
    "        current_frame_data = ellipse_df.iloc[ellipse_df.query('R_eye_frame == @frame_number').index[0]]\n",
    "    elif 'L_eye_frame' in ellipse_df.columns:\n",
    "        current_frame_data = ellipse_df.iloc[ellipse_df.query('L_eye_frame == @frame_number').index[0]]\n",
    "\n",
    "    # Extract ellipse parameters\n",
    "    try:\n",
    "        center_x = int(current_frame_data['center_x'])\n",
    "        center_y = int(current_frame_data['center_y'])\n",
    "        width = int(current_frame_data['width'])\n",
    "        height = int(current_frame_data['height'])\n",
    "        phi = float(current_frame_data['phi'])\n",
    "\n",
    "        # Draw the ellipse on the frame\n",
    "        cv2.ellipse(frame, (center_x, center_y), (width, height), phi, 0, 360, (0, 255, 0), 2)\n",
    "    except ValueError:\n",
    "        print('could not paint ellipse, missing values')\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Original Frame\", frame)\n",
    "\n",
    "    # Prompt user to select two points\n",
    "    print(\"Please select two points on the frame.\")\n",
    "\n",
    "    # Callback function for mouse events\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "\n",
    "    # Set up the mouse callback\n",
    "    cv2.setMouseCallback(\"Original Frame\", mouse_callback)\n",
    "\n",
    "    # Wait for the user to select two points\n",
    "    points = []\n",
    "    while len(points) < 2:\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    # Draw a line between the selected points\n",
    "    cv2.line(frame, points[0], points[1], (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Line Drawn Frame\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Calculate the rotation angle\n",
    "    angle = np.arctan2(points[1][1] - points[0][1], points[1][0] - points[0][0]) * 180 / np.pi\n",
    "\n",
    "    # Create rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((frame.shape[1] // 2, frame.shape[0] // 2), angle, 1)\n",
    "    #rotation_matrix[:,2] = 0\n",
    "    \n",
    "    # Generate and display video with 50 steps between original and rotated frames\n",
    "    for step in range(51):\n",
    "        alpha = step / 50.0\n",
    "        current_rotation_matrix = cv2.getRotationMatrix2D(\n",
    "            (frame.shape[1] // 2, frame.shape[0] // 2),\n",
    "            angle * alpha,\n",
    "            1\n",
    "        )\n",
    "     #   current_rotation_matrix[:,2] = 0\n",
    "        rotated_frame = cv2.warpAffine(frame, current_rotation_matrix, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        cv2.imshow(\"Interpolated Rotated Frame\", rotated_frame)\n",
    "        \n",
    "        cv2.waitKey(100)  # Adjust the wait time to control the playback speed\n",
    "\n",
    "    # Release resources\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return rotation_matrix, angle\n",
    "\n",
    "\"\"\"\n",
    "Example usage\n",
    "path_to_video = block.le_videos[0]\n",
    "frame_number = frame_number_to_show\n",
    "output_path = block.analysis_path / 'frame_rotation.avi'\n",
    "transformation_matrix, angle = rotate_frame_to_horizontal_with_interpolation(path_to_video, frame_number, block.le_df, output_path=None)\n",
    "print(\"Transformation Matrix:\")\n",
    "print(transformation_matrix)\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T11:28:59.883902200Z",
     "start_time": "2024-01-29T11:28:59.864848600Z"
    }
   },
   "id": "4de9821d1b9018b",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def apply_rotation_around_center_to_df(eye_df, transformation_matrix, rotation_angle):\n",
    "    \"\"\"This is a static method for applying the transformation matrix to eye dataframes within a block class object\"\"\"\n",
    "    original_centers = eye_df[['center_x_corrected', 'center_y_corrected']].values\n",
    "    original_phi = eye_df['phi'].values\n",
    "    M = transformation_matrix\n",
    "    # apply the rotation to xy\n",
    "    rotated_centers = np.dot(original_centers, M[:, :2].T) + M[:, 2]\n",
    "    # apply rotation to phi\n",
    "    rotated_phi = np.rad2deg(original_phi) + rotation_angle\n",
    "    \n",
    "    eye_df['center_x_rotated'] = rotated_centers[:,0]\n",
    "    eye_df['center_y_rotated'] = rotated_centers[:,1]\n",
    "    eye_df['phi_rotated'] = rotated_phi\n",
    "    \n",
    "    return eye_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T11:28:59.921620600Z",
     "start_time": "2024-01-29T11:28:59.872848Z"
    }
   },
   "id": "1c1e00addeb4bf1d",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select two points on the frame.\n",
      "Left rotation matrix:\n",
      "[[   0.82171478   -0.56989896  193.82702117]\n",
      " [   0.56989896    0.82171478 -139.57921362]]\n",
      "Left angle\n",
      "-34.74318015830361\n"
     ]
    }
   ],
   "source": [
    "# Initialize for left eye video\n",
    "# get the frames where the pupil is closest to round:\n",
    "s = block.le_df.width / block.le_df.height\n",
    "closest_ind = np.argmin(np.abs(s - 1)) # find the index of the value closest to 1\n",
    "frame_number_to_show = block.le_df.L_eye_frame.iloc[closest_ind]\n",
    "path_to_video = block.le_videos[0]\n",
    "frame_number = frame_number_to_show\n",
    "ellipse_df = block.le_df\n",
    "\n",
    "left_rotation_matrix, left_angle = rotate_frame_to_horizontal_with_interpolation(path_to_video_file=path_to_video,\n",
    "                                                                                 frame_number=frame_number,\n",
    "                                                                                 ellipse_df=ellipse_df,\n",
    "                                                                                 xflip=True)\n",
    "print(\"Left rotation matrix:\")\n",
    "print(left_rotation_matrix)\n",
    "print(\"Left angle\")\n",
    "print(left_angle)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T11:29:25.578627400Z",
     "start_time": "2024-01-29T11:29:05.793492800Z"
    }
   },
   "id": "52f1be802418e7e0",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select two points on the frame.\n",
      "Right rotation matrix:\n",
      "[[  0.69586712   0.71817056 -75.03841271]\n",
      " [ -0.71817056   0.69586712 302.80646851]]\n",
      "Right angle\n",
      "45.90364398751296\n"
     ]
    }
   ],
   "source": [
    "# initialize for right eye video\n",
    "# get the frames where the pupil is closest to round:\n",
    "s = block.re_df.width / block.re_df.height\n",
    "closest_ind = np.argmin(np.abs(s - 1)) # find the index of the value closest to 1\n",
    "frame_number_to_show = block.re_df.R_eye_frame.iloc[closest_ind]\n",
    "path_to_video = block.re_videos[0]\n",
    "frame_number = frame_number_to_show\n",
    "ellipse_df = block.re_df\n",
    "\n",
    "right_rotation_matrix, right_angle = rotate_frame_to_horizontal_with_interpolation(path_to_video_file=path_to_video,\n",
    "                                                                                   frame_number=frame_number,\n",
    "                                                                                   ellipse_df=ellipse_df,\n",
    "                                                                                   xflip=True)\n",
    "print(\"Right rotation matrix:\")\n",
    "print(right_rotation_matrix)\n",
    "print(\"Right angle\")\n",
    "print(right_angle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T11:29:56.254094Z",
     "start_time": "2024-01-29T11:29:34.165158Z"
    }
   },
   "id": "7052af786a1399a7",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "block.re_df = apply_rotation_around_center_to_df(eye_df = block.re_df.copy(),\n",
    "                                           transformation_matrix = right_rotation_matrix,\n",
    "                                           rotation_angle = right_angle)\n",
    "block.le_df = apply_rotation_around_center_to_df(eye_df = block.le_df.copy(),\n",
    "                                           transformation_matrix = left_rotation_matrix,\n",
    "                                           rotation_angle= left_angle)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T11:30:22.519231800Z",
     "start_time": "2024-01-29T11:30:22.494194100Z"
    }
   },
   "id": "fe3b08f5eab70e87",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0              NaN\n1              NaN\n2              NaN\n3              NaN\n4       -61.259106\n           ...    \n91948   -13.714678\n91949   -13.893080\n91950   -13.969731\n91951   -13.866422\n91952   -13.689242\nName: phi_rotated, Length: 91953, dtype: float64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.le_df.phi_rotated"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:00:02.028269300Z",
     "start_time": "2024-01-29T09:00:02.005187900Z"
    }
   },
   "id": "871ca576eefd62b7",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now I should verify this worked..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0f9d45e24f54339"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# verification plot:\n",
    "original_x_vals = block.re_df['center_x_corrected'].values\n",
    "new_x_vals = re_df['center_x_rotated'].values\n",
    "original_y_vals = re_df['center_y_corrected'].values\n",
    "new_y_vals = re_df['center_y_rotated'].values\n",
    "bokeh_plotter([original_x_vals, new_x_vals, original_y_vals, new_y_vals],['original_x','new_x', 'original_y_vals', 'new_y_vals'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T14:37:42.571011500Z",
     "start_time": "2024-01-24T14:37:41.711334Z"
    }
   },
   "id": "7e217c8eb9b5c00e",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "original_x_vals = block.le_df['center_x_corrected'].values\n",
    "new_x_vals = le_df['center_x_rotated'].values\n",
    "original_y_vals = le_df['center_y_corrected'].values\n",
    "new_y_vals = le_df['center_y_rotated'].values\n",
    "bokeh_plotter([original_x_vals, new_x_vals, original_y_vals, new_y_vals],['original_x','new_x', 'original_y_vals', 'new_y_vals'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T14:42:04.731238800Z",
     "start_time": "2024-01-24T14:42:03.918957900Z"
    }
   },
   "id": "d196a78b13fdb6cc",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# this should rotate + translate the left eye dataframe\n",
    "df = block.le_df\n",
    "xy_array = df[['center_x_corrected', 'center_y_corrected']].values\n",
    "phi_vec = df['phi'].values\n",
    "M = left_rotation_matrix\n",
    "rotated_centers = np.dot(xy_array, M[:, :2].T) + M[:, 2]\n",
    "rotated_phi = np.rad2deg(phi_vec) + left_angle\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T14:04:23.041634Z",
     "start_time": "2024-01-24T14:04:22.990178300Z"
    }
   },
   "id": "d7b1e55309875ba8",
   "execution_count": 189
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bokeh_plotter(data_list=[np.diff(np.rad2deg(block.re_df['phi']))],label_list=['phi'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T10:38:58.667569300Z",
     "start_time": "2024-01-29T10:38:58.402233700Z"
    }
   },
   "id": "4901f8112250510c",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(array([19405, 32379, 32411, 32563, 32671, 32706, 32782, 32821, 89832],\n       dtype=int64),)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "arr = np.diff(np.rad2deg(block.le_df['phi']))\n",
    "peaks = np.where(arr > 50)\n",
    "peaks\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T11:28:51.357750600Z",
     "start_time": "2024-01-30T11:28:51.325658900Z"
    }
   },
   "id": "3345c02e548e46e0",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "block.re_df['phi_rotated'] = block.re_df['phi_rotated'] + 90  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T11:33:52.550787600Z",
     "start_time": "2024-01-29T11:33:52.503941100Z"
    }
   },
   "id": "6386c087574eaf41",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# right eye inspection before rotation\n",
    "play_video_with_ellipses(block=block,eye='right', path_to_video=str(path_to_video) ,xflip=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:52:14.892862300Z",
     "start_time": "2024-01-29T09:51:54.712579800Z"
    }
   },
   "id": "770c6da0175f882a",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# right eye inspection after rotation\n",
    "path_to_video = [x for x in pathlib.Path(block.re_videos[0]).parent.iterdir() if '.mp4' in str(x.name) and 'DLC' in str(x.name)][0]\n",
    "play_video_with_ellipses_rotation(block=block,eye='right', path_to_video=str(path_to_video) ,xflip=True, transformation_matrix=right_rotation_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T11:34:00.552096Z",
     "start_time": "2024-01-29T11:33:56.602527500Z"
    }
   },
   "id": "8550503bfbfa8cd2",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# left eye inspection\n",
    "path_to_video = [x for x in pathlib.Path(block.le_videos[0]).parent.iterdir() if '.mp4' in str(x.name) and 'DLC' in str(x.name)][0]\n",
    "play_video_with_ellipses_rotation(block=block,eye='left', path_to_video=str(path_to_video) ,xflip=True, transformation_matrix=left_rotation_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T11:34:57.543139900Z",
     "start_time": "2024-01-29T11:34:02.264304200Z"
    }
   },
   "id": "a107096e094273da",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "# after verification, I want to have a function that exports the re/le df "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5dab165eb16c2f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def export_eye_dfs(block):\n",
    "    \"\"\"\n",
    "    This function saves the eye dataframes to two csv files\n",
    "    :param block: The current blocksync class with verifiec re/le dfs\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    block.re_df.to_csv(block.analysis_path / 're_df.csv')\n",
    "    block.le_df.to_csv(block.analysis_path / 'le_df.csv')\n",
    "\n",
    "export_eye_dfs(block)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:37:57.549046700Z",
     "start_time": "2024-01-24T16:37:49.483342600Z"
    }
   },
   "id": "a0a510124fa19306",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bc5fd88241a2db76"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jitter report loaded from analysis folder\n",
      "Jitter report computed - check out re/le_jitter_dict attributes\n"
     ]
    }
   ],
   "source": [
    "for block in block_collection:\n",
    "    block.get_jitter_reports(export=False, overwrite=False, remove_led_blinks=False, sort_on_loading=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:07:44.648018600Z",
     "start_time": "2024-01-29T09:07:44.431185700Z"
    }
   },
   "id": "a26d39594010df46",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['top_correlation_values', 'top_correlation_dist', 'y_displacement', 'x_displacement', 'top_correlation_x', 'top_correlation_y'])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.le_jitter_dict.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T13:20:47.547817500Z",
     "start_time": "2024-01-18T13:20:47.527858400Z"
    }
   },
   "id": "b3d6d7c071fdab37",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# get the R vector for a median absolute deviation calc\n",
    "\n",
    "jitter_dict = block.re_jitter_dict\n",
    "# Compute euclidean jitter magnitude\n",
    "x = np.array(jitter_dict['x_displacement'])\n",
    "y = np.array(jitter_dict['y_displacement'])\n",
    "r = np.sqrt(x**2 + y**2)\n",
    "corr_score = jitter_dict['top_correlation_values']\n",
    "mean_value = np.mean(r)\n",
    "mad = np.mean(np.abs(r - mean_value))\n",
    "extreme_inds = np.where(r > 5 * mad)[0]\n",
    "filt_r = scipy.signal.medfilt(r, kernel_size=121)\n",
    "threshold = 3\n",
    "peaks = np.where(np.abs(np.diff(filt_r)) > threshold)[0]\n",
    "bokeh_plotter([ r, filt_r, np.abs(np.diff(filt_r))], ['R', 'filtered_R', 'derivative'],\n",
    "              plot_name='mean absolute deviation', x_axis='frame', y_axis='euclidean displacement', peaks=peaks)\n",
    "print(len(extreme_inds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T14:58:29.127180700Z",
     "start_time": "2024-01-18T14:58:28.212135900Z"
    }
   },
   "id": "df9f6d9c9a848f41",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 3606,  3607,  3608,  3609,  3610,  3734,  4578,  4887, 10638,\n       17224, 17228, 20912, 78914, 79687, 88782, 88783, 93412],\n      dtype=int64)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 3\n",
    "peaks = np.where(np.abs(np.diff(filt_r)) > threshold)[0]\n",
    "peaks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T13:50:00.421406700Z",
     "start_time": "2024-01-18T13:50:00.402380600Z"
    }
   },
   "id": "771e1d52ab1fce32",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select two points on the frame.\n",
      "Transformation Matrix:\n",
      "[[-8.56851544e-01  5.15563217e-01  4.70457322e+02]\n",
      " [-5.15563217e-01 -8.56851544e-01  6.10624600e+02]]\n"
     ]
    }
   ],
   "source": [
    "# This is the first iteration of the manual frame rotation annotator:\n",
    "\n",
    "# OLD VERSION OF THE FUNCTION\n",
    "def rotate_frame_to_horizontal_old(path_to_video_file, frame_number, ellipse_df, xflip=True):\n",
    "    # Read the video file\n",
    "    cap = cv2.VideoCapture(path_to_video_file)\n",
    "\n",
    "    # Check if the video file is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video file.\")\n",
    "        return None\n",
    "\n",
    "    # Set the frame position\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is read successfully\n",
    "    if not ret:\n",
    "        print(f\"Error: Unable to read frame {frame_number}.\")\n",
    "        cap.release()\n",
    "        return None\n",
    "    \n",
    "    # horizontally flip frame if applicable:\n",
    "    if xflip:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    # get the original ellipse from the block dataframe\n",
    "    if 'R_eye_frame' in ellipse_df.columns:\n",
    "        current_frame_data = ellipse_df.iloc[ellipse_df.query('R_eye_frame == @frame_number').index[0]]\n",
    "    elif 'L_eye_frame' in ellipse_df.columns:\n",
    "        current_frame_data = ellipse_df.iloc[ellipse_df.query('L_eye_frame == @frame_number').index[0]]\n",
    "        \n",
    "    # Extract ellipse parameters\n",
    "    try:\n",
    "        center_x = int(current_frame_data['center_x'])\n",
    "        center_y = int(current_frame_data['center_y'])\n",
    "        width = int(current_frame_data['width'])\n",
    "        height = int(current_frame_data['height'])\n",
    "        phi = float(current_frame_data['phi'])\n",
    "\n",
    "        # Draw the ellipse on the frame\n",
    "        cv2.ellipse(frame, (center_x, center_y), (width, height), phi, 0, 360, (0, 255, 0), 2)\n",
    "    except ValueError:\n",
    "        print('could not paint ellipse, missing values')\n",
    "    \n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Original Frame\", frame)\n",
    "\n",
    "    # Prompt user to select two points\n",
    "    print(\"Please select two points on the frame.\")\n",
    "    \n",
    "    # Callback function for mouse events\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "\n",
    "    # Set up the mouse callback\n",
    "    cv2.setMouseCallback(\"Original Frame\", mouse_callback)\n",
    "\n",
    "    # Wait for the user to select two points\n",
    "    points = []\n",
    "    while len(points) < 2:\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    # Draw a line between the selected points\n",
    "    cv2.line(frame, points[0], points[1], (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Line Drawn Frame\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Calculate the rotation angle\n",
    "    angle = np.arctan2(points[1][1] - points[0][1], points[1][0] - points[0][0]) * 180 / np.pi\n",
    "        \n",
    "    # Create rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((frame.shape[1] // 2, frame.shape[0] // 2), angle, 1)\n",
    "    \n",
    "    #rotation_matrix[:, 2] = 0  # Set translation components to zero\n",
    "    \n",
    "    # Rotate the frame\n",
    "    rotated_frame = cv2.warpAffine(frame, rotation_matrix, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "    # Display the rotated frame\n",
    "    cv2.imshow(\"Rotated Frame\", rotated_frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    return rotation_matrix\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:21:18.128941300Z",
     "start_time": "2024-01-24T12:20:45.601310700Z"
    }
   },
   "id": "da11777855fe439b",
   "execution_count": 137
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
