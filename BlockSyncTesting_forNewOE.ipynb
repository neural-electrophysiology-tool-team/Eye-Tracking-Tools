{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import math\n",
    "import tqdm\n",
    "from  open_ephys import analysis as oea\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "from BlockSync_current import *\n",
    "from OERecording import *\n",
    "import scipy.io\n",
    "import h5py\n",
    "import re\n",
    "from lxml import etree as ET\n",
    "import scipy.signal as sig\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def analyzed_block_automated_pipe(block):\n",
    "    \"\"\"This function runs all the import steps that I am already confident about for a block\n",
    "    that has already gone through synchronization and dlc reading\"\"\"\n",
    "    block.handle_eye_videos()\n",
    "    block.handle_arena_files()\n",
    "    block.parse_open_ephys_events()\n",
    "    #block.synchronize_arena_timestamps()\n",
    "    #block.create_arena_brightness_df(threshold_value=240,export=True)\n",
    "    block.synchronize_block(export=True)\n",
    "    block.create_eye_brightness_df(threshold_value=250)\n",
    "    block.import_manual_sync_df()\n",
    "    block.read_dlc_data()\n",
    "    block.saccade_event_analayzer(threshold=1.5,automatic=True)\n",
    "\n",
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    \"\"\"\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def multi_block_saccade_dict_creation_OLD(blocklist):\n",
    "\n",
    "    saccade_dict = {}\n",
    "    # loop over the blocks from here:\n",
    "    for block in blocklist:\n",
    "        # collect accelerometer data\n",
    "        # path definition\n",
    "        p = block.oe_path / 'analysis'\n",
    "        analysis_list = os.listdir(p)\n",
    "        correct_analysis = [i for i in analysis_list if block.animal_call in i][0]\n",
    "        p = p / str(correct_analysis)\n",
    "        matPath = p / 'lizMov.mat'\n",
    "        print(f'path to mat file is {matPath}')\n",
    "        # read mat file\n",
    "        mat_data = h5py.File(str(matPath),'r')\n",
    "        matDict = {'t_mov_ms':mat_data['t_mov_ms'][:],\n",
    "                    'movAll':mat_data['movAll'][:]}\n",
    "        #print(mat_data.keys())\n",
    "\n",
    "        mat_data.close()\n",
    "        # df_dict = {'t_mov_ms':matDict['t_mov_ms'][0,:],\n",
    "        #            'movAll':matDict['movAll'][0,:]}\n",
    "        # df = pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "        # The t_mov_ms column indicates the times when threshold-crossing movements occurred in Milliseconds from electrophysiology recording beginning\n",
    "        # the movAll column gives the amplitude of said movements as a combination of the 3D accelerometer channels\n",
    "\n",
    "        # It is now needed to synchronize the timebase so that 0 will be the beginning of synchronized time and not beginning of oe recording\n",
    "        # first, find the very first timestamp of the oe recording\n",
    "        session = oea.Session(str(block.oe_path.parent))\n",
    "        rec_node = session.recordnodes[0].recordings[0].continuous[0]\n",
    "        rec_starts = rec_node.timestamps[0]\n",
    "        # second, find the first arena_TTL oe based timestamp\n",
    "        sync_starts = block.final_sync_df.Arena_TTL[0]\n",
    "        # t_mov_ms should have the Milliseconds between beginning of the recording and beginning of synchronized time subtracted to align 0 with the synctime 0\n",
    "        delta_samples = sync_starts - rec_starts\n",
    "        delta_samples_ms = (delta_samples / block.sample_rate) * 1000\n",
    "        synced_t_ms_mov = matDict['t_mov_ms'][0,:] - delta_samples_ms # correction happens here\n",
    "        # now create the df and delete the dict\n",
    "        df_dict = {'t_mov_ms': synced_t_ms_mov,\n",
    "                   'movAll': matDict['movAll'][0,:]}\n",
    "        acc_df = pd.DataFrame.from_dict(df_dict)\n",
    "        del df_dict\n",
    "\n",
    "        # collect saccade events\n",
    "        block.saccade_event_analayzer(automatic=True,threshold=2)\n",
    "\n",
    "        # get all the electrophysiology data of a single electrode:\n",
    "        print(f'getting EP data from block {block.block_num}')\n",
    "        #session = oea.Session(str(block.oe_path.parent))\n",
    "        data = session.recordnodes[0].recordings[0].continuous[0].samples[:,ep_channel]\n",
    "        timestamps = session.recordnodes[0].recordings[0].continuous[0].timestamps\n",
    "        print('done')\n",
    "\n",
    "        # create the top-level block dict object\n",
    "        block_dict = {\n",
    "            'L':{},\n",
    "            'R':{}\n",
    "        }\n",
    "\n",
    "        # create and populate the internal dictionaries (for each eye)\n",
    "        for i, e in enumerate(['L','R']):\n",
    "            # get the correct saccades_chunked object and eye_df\n",
    "            saccades_chunked = [block.l_saccades_chunked,block.r_saccades_chunked][i]\n",
    "            eye_df = [block.le_df,block.re_df][i]\n",
    "            saccades = saccades_chunked[saccades_chunked.saccade_length_frames > 0]\n",
    "            saccade_times = np.sort(saccades.saccade_start_ms.values)\n",
    "            saccade_ts = eye_df[eye_df['ms_axis'].isin(saccade_times)].Arena_TTL.values\n",
    "\n",
    "            # now use the saccade_ts vector to choose samples with a given segment length before and after the saccades\n",
    "            seg_seconds = 2\n",
    "            segment_length = seg_seconds*block.sample_rate #samples\n",
    "            before_saccade_ts = saccade_ts - segment_length\n",
    "            after_saccade_ts = saccade_ts + segment_length\n",
    "\n",
    "            # start populating the dictionary\n",
    "            block_dict[e] = {\n",
    "                \"timestamps\":[],\n",
    "                \"fs\":[],\n",
    "                \"pxx\":[],\n",
    "                \"samples\":[],\n",
    "                \"x_coords\":[],\n",
    "                \"y_coords\":[],\n",
    "                \"vid_inds\":[],\n",
    "                \"accel\":[]\n",
    "            }\n",
    "\n",
    "            # go saccade by saccade\n",
    "            for i in tqdm(range(len(saccade_ts))):\n",
    "\n",
    "                # define the segment range\n",
    "                pre_saccade_sample_ind = np.where(timestamps == int(before_saccade_ts[i]))[0][0]\n",
    "                post_saccade_sample_ind = np.where(timestamps == int(after_saccade_ts[i]))[0][0]\n",
    "                samples_range = range(pre_saccade_sample_ind,post_saccade_sample_ind)\n",
    "                segment_samples = data[samples_range]\n",
    "\n",
    "                # get the spectral profile for the segment\n",
    "                fs, pxx = sig.welch(segment_samples,block.sample_rate,nperseg=16384,return_onesided=True)\n",
    "\n",
    "                # get x and y coordinates for the segment and their indices inside the segment (without reference)\n",
    "                i0 = saccade_ts[i] - (block.sample_rate*2)\n",
    "                i1 = saccade_ts[i] + (block.sample_rate*2)\n",
    "                s_df = eye_df.query(\"Arena_TTL >= @i0 and Arena_TTL <= @i1\")\n",
    "                vid_inds = np.array((s_df.Arena_TTL.values - saccade_ts[i]) + segment_length, dtype='int32')\n",
    "                x_coords = s_df.center_x.values\n",
    "                y_coords = s_df.center_y.values\n",
    "\n",
    "                # deal with missing values here:\n",
    "                interpolated_coords = []\n",
    "                bad_saccade = False\n",
    "                for y in [x_coords, y_coords]:\n",
    "                    nan_count = np.sum(np.isnan(y))\n",
    "                    if nan_count > 0 :\n",
    "                        if nan_count < len(y)/2:\n",
    "                            #print(f'saccade at ind {i} has {nan_count} nans, interpolating...')\n",
    "                            # find nan values in the vector\n",
    "                            nans, z = nan_helper(y)\n",
    "                            # interpolate using the helper lambda function\n",
    "                            y[nans] = np.interp(z(nans),z(~nans),y[~nans])\n",
    "                            # replace the interpolated values for the saccade\n",
    "                            interpolated_coords.append(y)\n",
    "                        else:\n",
    "                            print(f'too many nans at ind {i}, ({np.sum(np.isnan(y))}) - cannot interpolate properly',end='\\r',flush=True)\n",
    "                            bad_saccade = True\n",
    "                    else:\n",
    "                        interpolated_coords.append(y)\n",
    "\n",
    "                # get accelerometer data for the ms_based section:\n",
    "                # get_ms_segment\n",
    "                ms_segment = s_df['ms_axis']\n",
    "                s0 = ms_segment.iloc[0]\n",
    "                s1 = ms_segment.iloc[-1]\n",
    "                mov_mag = np.sum(acc_df.query('t_mov_ms > @s0 and t_mov_ms < @s1').movAll.values)\n",
    "\n",
    "                # remove bad saccades\n",
    "                if bad_saccade:\n",
    "                    continue\n",
    "                # append OK saccades\n",
    "                else:\n",
    "                    block_dict[e]['timestamps'].append(saccade_ts[i])\n",
    "                    block_dict[e]['x_coords'].append(interpolated_coords[0])\n",
    "                    block_dict[e]['y_coords'].append(interpolated_coords[1])\n",
    "                    block_dict[e]['vid_inds'].append(vid_inds)\n",
    "                    block_dict[e]['fs'].append(fs)\n",
    "                    block_dict[e]['pxx'].append(pxx)\n",
    "                    block_dict[e]['samples'].append(segment_samples)\n",
    "                    block_dict[e]['accel'].append(mov_mag)\n",
    "        saccade_dict[block.block_num] = block_dict\n",
    "    return saccade_dict\n",
    "\n",
    "def multi_block_saccade_dict_creation_current(blocklist, sampling_window_ms):\n",
    "\n",
    "    saccade_dict = {}\n",
    "    # loop over the blocks from here:\n",
    "    for block in blocklist:\n",
    "        # collect accelerometer data\n",
    "        # path definition\n",
    "        p = block.oe_path / 'analysis'\n",
    "        analysis_list = os.listdir(p)\n",
    "        correct_analysis = [i for i in analysis_list if block.animal_call in i][0]\n",
    "        p = p / str(correct_analysis)\n",
    "        matPath = p / 'lizMov.mat'\n",
    "        print(f'path to mat file is {matPath}')\n",
    "        # read mat file\n",
    "        mat_data = h5py.File(str(matPath),'r')\n",
    "        mat_dict = {'t_mov_ms':mat_data['t_mov_ms'][:],\n",
    "                    'movAll':mat_data['movAll'][:]}\n",
    "\n",
    "        acc_df = pd.DataFrame(data=np.array([mat_dict['t_mov_ms'][:,0],mat_dict['movAll'][:,0]]).T, columns=['t_mov_ms','movAll'])\n",
    "        #print(mat_data.keys())\n",
    "\n",
    "        mat_data.close()\n",
    "\n",
    "        block.saccade_event_analayzer(automatic=True,threshold=2)\n",
    "\n",
    "        # create the top-level block dict object\n",
    "        block_dict = {\n",
    "            'L':{},\n",
    "            'R':{}\n",
    "        }\n",
    "\n",
    "        # create and populate the internal dictionaries (for each eye)\n",
    "        for i, e in enumerate(['L','R']):\n",
    "            # get the correct saccades_chunked object and eye_df\n",
    "            saccades_chunked = [block.l_saccades_chunked,block.r_saccades_chunked][i]\n",
    "            eye_df = [block.le_df,block.re_df][i]\n",
    "            saccades = saccades_chunked[saccades_chunked.saccade_length_frames > 0]\n",
    "            saccade_times = np.sort(saccades.saccade_start_ms.values)\n",
    "            ep_channel_numbers = [8]\n",
    "            pre_saccade_ts = saccade_times - (sampling_window_ms / 2) #\n",
    "\n",
    "            # get the data of the relevant saccade time windows:\n",
    "            print(f'calling get_data with the following inputs:'\n",
    "                  f'eye = {e}'\n",
    "                  f'block = {block}'\n",
    "                  f'pre_saccade_ts = {pre_saccade_ts} \\n'\n",
    "                  f'sampling_window_ms = {sampling_window_ms}')\n",
    "            ep_data, ep_timestamps = block.oe_rec.get_data(ep_channel_numbers,pre_saccade_ts, sampling_window_ms, convert_to_mv=True) # [n_channels, n_windows, nSamples]\n",
    "\n",
    "            # start populating the dictionary\n",
    "            block_dict[e] = {\n",
    "                \"timestamps\":[],\n",
    "                \"fs\":[],\n",
    "                \"pxx\":[],\n",
    "                \"samples\":[],\n",
    "                \"x_coords\":[],\n",
    "                \"y_coords\":[],\n",
    "                \"vid_inds\":[],\n",
    "                \"accel\":[]\n",
    "            }\n",
    "\n",
    "            # go saccade by saccade\n",
    "            for j in range(len(pre_saccade_ts)):\n",
    "                # get specific saccade samples:\n",
    "                saccade_samples = ep_data[0,j,:] # [n_channels, n_windows, nSamples]\n",
    "                # get the spectral profile for the segment\n",
    "                fs, pxx = sig.welch(saccade_samples,block.sample_rate,nperseg=16384,return_onesided=True)\n",
    "\n",
    "                j0 = pre_saccade_ts[j]\n",
    "                j1 = pre_saccade_ts[j] + sampling_window_ms\n",
    "                s_df = eye_df.query(\"ms_axis >= @j0 and ms_axis <= @j1\")\n",
    "                x_coords = s_df['center_x'].values\n",
    "                y_coords = s_df['center_y'].values\n",
    "                vid_inds = np.array(s_df.Arena_TTL.values - s_df.Arena_TTL.values[0], dtype='int32')\n",
    "\n",
    "                #deal with missing datapoints in saccades:\n",
    "                interpolated_coords = []\n",
    "                bad_saccade = False\n",
    "                for y in [x_coords, y_coords]:\n",
    "                    nan_count = np.sum(np.isnan(y.astype(float)))\n",
    "                    if nan_count > 0 :\n",
    "                        if nan_count < len(y)/2:\n",
    "                            #print(f'saccade at ind {i} has {nan_count} nans, interpolating...')\n",
    "                            # find nan values in the vector\n",
    "                            nans, z = nan_helper(y.astype(float))\n",
    "                            # interpolate using the helper lambda function\n",
    "                            y[nans] = np.interp(z(nans),z(~nans),y[~nans].astype(float))\n",
    "                            # replace the interpolated values for the saccade\n",
    "                            interpolated_coords.append(y)\n",
    "                        else:\n",
    "                            print(f'too many nans at ind {j}, ({np.sum(np.isnan(y))}) - cannot interpolate properly',end='\\r',flush=True)\n",
    "                            bad_saccade = True\n",
    "                    else:\n",
    "                        interpolated_coords.append(y)\n",
    "\n",
    "                # get accelerometer data for the ms_based section:\n",
    "                # get_ms_segment\n",
    "                ms_segment = s_df['ms_axis']\n",
    "                s0 = ms_segment.iloc[0]\n",
    "                s1 = ms_segment.iloc[-1]\n",
    "                mov_mag = np.sum(acc_df.query('t_mov_ms > @s0 and t_mov_ms < @s1').movAll.values)\n",
    "\n",
    "                # remove bad saccades\n",
    "                if bad_saccade:\n",
    "                    continue\n",
    "                # append OK saccades\n",
    "                else:\n",
    "                    block_dict[e]['timestamps'].append(pre_saccade_ts[j])\n",
    "                    block_dict[e]['x_coords'].append(interpolated_coords[0])\n",
    "                    block_dict[e]['y_coords'].append(interpolated_coords[1])\n",
    "                    block_dict[e]['vid_inds'].append(vid_inds)\n",
    "                    block_dict[e]['fs'].append(fs)\n",
    "                    block_dict[e]['pxx'].append(pxx)\n",
    "                    block_dict[e]['samples'].append(saccade_samples)\n",
    "                    block_dict[e]['accel'].append(mov_mag)\n",
    "        saccade_dict[block.block_num] = block_dict\n",
    "    return saccade_dict\n",
    "\n",
    "def sort_synced_saccades(b_dict):\n",
    "    \"\"\"\n",
    "    This function takes a saccades dictionary and returns two sorted dictionaries - one with synced saccades, the other with non-synced saccades\n",
    "    :param b_dict:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # get the two timestamps vectors\n",
    "    l_times = np.array(b_dict['L']['timestamps'])\n",
    "    r_times = np.array(b_dict['R']['timestamps'])\n",
    "\n",
    "    # I want to collect the matching indices from the L and R dictionaries and create a \"synced saccades dict\" object that only has two-eyed saccades included in it\n",
    "    # first, I have to understand which rows of the dictionaries go together:\n",
    "    # create a matrix of [left eye timestamp, -,left eye ind, -]\n",
    "    s_mat = np.empty([len(l_times),5])\n",
    "    s_mat[:,0] = l_times\n",
    "    s_mat[:,2] = np.arange(0,len(l_times))\n",
    "    # find and fit the right eye times and indices on columns 1 and 3\n",
    "    for i, lt in enumerate(s_mat[:,0]):\n",
    "        array = np.abs((r_times - lt))\n",
    "        ind_min_diff = np.argmin(array)\n",
    "        min_diff = array[ind_min_diff]\n",
    "        rt = r_times[ind_min_diff]\n",
    "        s_mat[i,3] = ind_min_diff\n",
    "        s_mat[i,1] = rt\n",
    "        s_mat[i,4] = min_diff\n",
    "\n",
    "    # create a dataframe for queries and testing, define a threshold and remove non sync saccades\n",
    "    s_df = pd.DataFrame(s_mat,columns=['lt','rt','left_ind','right_ind','diff'])\n",
    "    threshold = 1400 # 70 ms to consider a saccade simultaneous\n",
    "    s_df = s_df.query('diff<@threshold')\n",
    "    ind_dict = {\n",
    "        'L':s_df['left_ind'].values,\n",
    "        'R':s_df['right_ind'].values\n",
    "    }\n",
    "\n",
    "    # create a synced dictionary for the block:\n",
    "    synced_b_dict = {\n",
    "        'L':{},\n",
    "        'R':{}\n",
    "    }\n",
    "    for e in ['L','R']:\n",
    "        inds = ind_dict[e].astype(int)\n",
    "        synced_b_dict[e] = {\n",
    "            \"timestamps\":np.array(b_dict[e]['timestamps'])[inds],\n",
    "            \"fs\":np.array(b_dict[e]['fs'])[inds],\n",
    "            \"pxx\":np.array(b_dict[e]['pxx'])[inds],\n",
    "            \"samples\":np.array(b_dict[e]['samples'])[inds],\n",
    "            \"x_coords\":np.array(b_dict[e]['x_coords'])[inds],\n",
    "            \"y_coords\":np.array(b_dict[e]['y_coords'])[inds],\n",
    "            \"vid_inds\":np.array(b_dict[e]['vid_inds'])[inds],\n",
    "            \"accel\":np.array(b_dict[e]['accel'])[inds]\n",
    "        }\n",
    "\n",
    "    non_sync_b_dict = {\n",
    "        'L':{},\n",
    "        'R':{}\n",
    "    }\n",
    "    for e in ['L','R']:\n",
    "        inds = ind_dict[e].astype(int)\n",
    "        logical = np.ones(len(b_dict[e]['timestamps'])).astype(np.bool)\n",
    "        logical[inds] = 0\n",
    "        non_sync_b_dict[e] = {\n",
    "            \"timestamps\":np.array(b_dict[e]['timestamps'])[logical],\n",
    "            \"fs\":np.array(b_dict[e]['fs'])[logical],\n",
    "            \"pxx\":np.array(b_dict[e]['pxx'])[logical],\n",
    "            \"samples\":np.array(b_dict[e]['samples'])[logical],\n",
    "            \"x_coords\":np.array(b_dict[e]['x_coords'])[logical],\n",
    "            \"y_coords\":np.array(b_dict[e]['y_coords'])[logical],\n",
    "            \"vid_inds\":np.array(b_dict[e]['vid_inds'])[logical],\n",
    "            \"accel\":np.array(b_dict[e]['accel'])[logical]\n",
    "        }\n",
    "    return synced_b_dict, non_sync_b_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path to mat file is Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072\\oe_files\\2023-06-21_14-31-03\\Record Node 108\\analysis\\recNames=Block0072,Animal=PV_62\\lizMov.mat\n",
      "loaded chunked saccade data from analysis folder\n",
      "calling get_data with the following inputs:eye = Lblock = PV_62, block 072, on 2023-06-21_14-31-03pre_saccade_ts = [ 41978.5   43252.6   44764.7   55451.7   61176.55  64353.55  64659.4\n",
      "  71965.85 104672.8  104859.7  107918.3  108207.2  108733.95 121697.75\n",
      " 121833.65 167822.1  170964.35 181053.75 193062.6  196596.1  197496.6\n",
      " 313384.9  315712.55 340260.15 341891.2  374225.5  374310.4  374378.4\n",
      " 374480.3  374769.05 375737.35 377588.85 377979.65 379814.3  384027.25\n",
      " 384417.9  384502.9  396106.2  396208.1  404888.9  406111.95 406213.9\n",
      " 406417.75 406553.7  417426.   434023.95 442771.8  562042.15 755083.85] \n",
      "sampling_window_ms = 2000\n",
      "sample removed for window #46\n",
      "The requested data segment between 14721 ms and [[16721.]] ms exceeds the recording length, and will be 0-padded to fit the other windows\n",
      "calling get_data with the following inputs:eye = Rblock = PV_62, block 072, on 2023-06-21_14-31-03pre_saccade_ts = [ 38037.45  42063.45  49419.8   55553.65 339699.45 354923.2  355331.05\n",
      " 374497.25] \n",
      "sampling_window_ms = 2000\n",
      "sample removed for window #1\n",
      "The requested data segment between 7288 ms and [[9288.]] ms exceeds the recording length, and will be 0-padded to fit the other windows\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\oe_files\\2023-06-21_14-45-37\\Record Node 108\\analysis\\recNames=Block0073,Animal=PV_62\\lizMov.mat\n",
      "loaded chunked saccade data from analysis folder\n",
      "calling get_data with the following inputs:eye = Lblock = PV_62, block 073, on 2023-06-21_14-45-37pre_saccade_ts = [  52971.55   53566.     53956.65   61855.1    63128.85   63264.75\n",
      "   74357.35   84736.65   89730.35  110964.35  210262.15  276311.75\n",
      "  276396.65  277840.55  279828.35  295764.85  362873.45  363179.35\n",
      "  365965.55  366815.    409439.55  409507.45  410832.25  410934.15\n",
      "  411019.1   411104.    412462.85  413210.05  413940.3   414161.15\n",
      "  414670.65  416301.2   420343.8   440713.15  445080.1   469312.35\n",
      "  625292.1   625461.95  625563.85  625631.8   625733.75  625971.5\n",
      "  627126.6   627381.4   628434.5   632221.7   633767.45  664035.95\n",
      "  664154.8   795406.2   911049.5   922109.65 1007675.35 1009170.05\n",
      " 1010580.1  1010733.   1010885.85 1010970.75 1012975.   1022384.7\n",
      " 1030672.75 1039641.25 1055642.5  1069146.05 1069638.55 1069842.35\n",
      " 1070912.45] \n",
      "sampling_window_ms = 2000\n",
      "sample removed for window #3\n",
      "sample removed for window #6\n",
      "sample removed for window #10\n",
      "sample removed for window #15\n",
      "sample removed for window #18\n",
      "sample removed for window #35\n",
      "sample removed for window #37\n",
      "sample removed for window #39\n",
      "sample removed for window #52\n",
      "sample removed for window #56\n",
      "The requested data segment between 20916 ms and [[22916.]] ms exceeds the recording length, and will be 0-padded to fit the other windows\n",
      "calling get_data with the following inputs:eye = Rblock = PV_62, block 073, on 2023-06-21_14-45-37pre_saccade_ts = [287660.55 413159.1  413889.35 414704.65 443958.6 ] \n",
      "sampling_window_ms = 2000\n",
      "sample removed for window #4\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_074\\oe_files\\2023-06-21_15-05-38\\Record Node 108\\analysis\\recNames=Block0074,Animal=PV_62\\lizMov.mat\n",
      "loaded chunked saccade data from analysis folder\n",
      "calling get_data with the following inputs:eye = Lblock = PV_62, block 074, on 2023-06-21_15-05-38pre_saccade_ts = [128217.5  133856.55 167979.   307826.55 340777.35 367802.7  367887.65\n",
      " 385926.7  386079.55 477124.15 493363.75 509400.55 509893.1  511370.8\n",
      " 511625.6  514734.5 ] \n",
      "sampling_window_ms = 2000\n",
      "sample removed for window #13\n",
      "The requested data segment between 10053 ms and [[12053.]] ms exceeds the recording length, and will be 0-padded to fit the other windows\n",
      "calling get_data with the following inputs:eye = Rblock = PV_62, block 074, on 2023-06-21_15-05-38pre_saccade_ts = [ 62222.15 139002.85 140395.5  140939.15 141058.05 141278.85 143028.55\n",
      " 143419.2  144064.65 145423.4  145525.35 145933.   146017.9  146663.25\n",
      " 148276.8  148769.3  149007.05 156717.1  187887.15 385960.7  386793.1\n",
      " 509111.75 510504.55 511387.8  511659.55 514751.5  514870.45 523449.15\n",
      " 531737.1  532943.05 533061.95 533469.6  533554.55 533673.4  534590.6\n",
      " 534743.45 535405.8  535473.75 541894.2  541962.15 543371.9  543541.75\n",
      " 544187.   547566.4 ] \n",
      "sampling_window_ms = 2000\n",
      "sample removed for window #6\n",
      "sample removed for window #14\n",
      "sample removed for window #18\n",
      "sample removed for window #29\n",
      "sample removed for window #30\n",
      "sample removed for window #35\n",
      "The requested data segment between 10694 ms and [[12694.]] ms exceeds the recording length, and will be 0-padded to fit the other windows\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\oe_files\\2023-06-21_15-25-44\\Record Node 108\\analysis\\recNames=Block0075,Animal=PV_62\\lizMov.mat\n",
      "loaded chunked saccade data from analysis folder\n",
      "calling get_data with the following inputs:eye = Lblock = PV_62, block 075, on 2023-06-21_15-25-44pre_saccade_ts = [ 25968.65  32778.75  56338.6   58513.2   61927.75  66446.65  75601.75\n",
      "  80289.3   81528.95  81698.8   82259.2   83413.95  83566.8   85944.6\n",
      "  86318.3   86386.2   88339.35  91005.9   97358.15 103201.45 120321.95\n",
      " 121256.3  122105.65 133809.2  186887.5  249599.7  299775.35 306432.35\n",
      " 314600.15 317928.2  349376.65 373081.55 390094.9  419112.85 424630.95\n",
      " 424715.85 429554.7  430284.9  431099.95 438181.25 440167.8  449370.65\n",
      " 454584.05 473586.2  484827.45 500860.5  503170.15 503272.   504256.95\n",
      " 511508.8  528966.1  538356.8 ] \n",
      "sampling_window_ms = 2000\n",
      "sample removed for window #5\n",
      "sample removed for window #10\n",
      "sample removed for window #18\n",
      "sample removed for window #23\n",
      "sample removed for window #40\n",
      "sample removed for window #51\n",
      "The requested data segment between 10514 ms and [[12514.]] ms exceeds the recording length, and will be 0-padded to fit the other windows\n",
      "calling get_data with the following inputs:eye = Rblock = PV_62, block 075, on 2023-06-21_15-25-44pre_saccade_ts = [ 52550.95  56083.8   58496.15  75601.75  76875.55  79558.95  80289.3\n",
      "  80357.2   81545.95  82259.2   83396.95  85944.6   86063.5   86131.45\n",
      "  88339.35  91005.9   92568.45  94046.05  97341.15  97494.1  108364.55\n",
      " 120321.95 122122.6  124484.25 125299.45 131566.75 133809.2  141843.15\n",
      " 144034.1  158456.45 167033.8  186938.45 195990.4  213554.95 213639.9\n",
      " 222132.25 228892.05 237504.4  249752.55 259383.9  273839.4  284998.9\n",
      " 295699.35 299792.35 305124.8  306449.3  314600.15 344400.85 373064.55\n",
      " 419095.9  424630.95 425174.25 425293.05 428298.3  428536.   429537.7\n",
      " 430284.9  431066.   438198.2  440167.8  473603.2  481447.9  484810.45\n",
      " 500860.5  503153.15 504240.   505106.   507992.85 511491.85 528949.1\n",
      " 538373.8 ] \n",
      "sampling_window_ms = 2000\n",
      "sample removed for window #0\n",
      "sample removed for window #9\n",
      "sample removed for window #18\n",
      "sample removed for window #26\n",
      "sample removed for window #39\n",
      "sample removed for window #47\n",
      "sample removed for window #59\n",
      "sample removed for window #67\n",
      "The requested data segment between 10515 ms and [[12515.]] ms exceeds the recording length, and will be 0-padded to fit the other windows\n"
     ]
    }
   ],
   "source": [
    "# function variables:\n",
    "sampling_window_ms = 2000 # milliseconds (THIS SHOULD BE IN THE FUNCTION CALL!!!!)\n",
    "\n",
    "\n",
    "saccade_dict = multi_block_saccade_dict_creation_current(block_collection, sampling_window_ms=sampling_window_ms)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-0f49ae986326>:342: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"x_coords\":np.array(b_dict[e]['x_coords'])[inds],\n",
      "<ipython-input-8-0f49ae986326>:343: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"y_coords\":np.array(b_dict[e]['y_coords'])[inds],\n",
      "<ipython-input-8-0f49ae986326>:344: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"vid_inds\":np.array(b_dict[e]['vid_inds'])[inds],\n",
      "<ipython-input-8-0f49ae986326>:361: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"x_coords\":np.array(b_dict[e]['x_coords'])[logical],\n",
      "<ipython-input-8-0f49ae986326>:362: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"y_coords\":np.array(b_dict[e]['y_coords'])[logical],\n",
      "<ipython-input-8-0f49ae986326>:363: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"vid_inds\":np.array(b_dict[e]['vid_inds'])[logical],\n"
     ]
    }
   ],
   "source": [
    "all_sync_dict = {}\n",
    "non_sync_dict = {}\n",
    "for k in saccade_dict.keys():\n",
    "    k_dict = saccade_dict[k]\n",
    "    sync_saccades, non_sync_saccades = sort_synced_saccades(k_dict)\n",
    "    all_sync_dict[k] = sync_saccades\n",
    "    non_sync_dict[k] = non_sync_saccades"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[18171 18172 18173 18174 18175 18176 18177 18178 18179 18180 18181 18182\n",
      " 18183 18184 18185 18186 18187 18188 18189 18190 18191 18192 18193 18194\n",
      " 18195 18196 18197 18198 18199 18200 18201 18202 18203 18204 18205 18206\n",
      " 18207 18208 18209 18210]\n",
      "1\n",
      "[18183 18184 18185 18186 18187 18188 18189 18190 18191 18192 18193 18194\n",
      " 18195 18196 18197 18198 18199 18200 18201 18202 18203 18204 18205 18206\n",
      " 18207 18208 18209 18210 18211 18212 18213 18214 18215 18216 18217 18218\n",
      " 18219 18220 18221 18222]\n",
      "2\n",
      "[18191 18192 18193 18194 18195 18196 18197 18198 18199 18200 18201 18202\n",
      " 18203 18204 18205 18206 18207 18208 18209 18210 18211 18212 18213 18214\n",
      " 18215 18216 18217 18218 18219 18220 18221 18222 18223 18224 18225 18226\n",
      " 18227 18228 18229 18230]\n",
      "sample removed for window #2\n",
      "3\n",
      "[18345 18346 18347 18348 18349 18350 18351 18352 18353 18354 18355 18356\n",
      " 18357 18358 18359 18360 18361 18362 18363 18364 18365 18366 18367 18368\n",
      " 18369 18370 18371 18372 18373 18374 18375 18376 18377 18378 18379 18380\n",
      " 18381 18382 18383 18384]\n",
      "4\n",
      "[18370 18371 18372 18373 18374 18375 18376 18377 18378 18379 18380 18381\n",
      " 18382 18383 18384 18385 18386 18387 18388 18389 18390 18391 18392 18393\n",
      " 18394 18395 18396 18397 18398 18399 18400 18401 18402 18403 18404 18405\n",
      " 18406 18407 18408 18409]\n",
      "5\n",
      "[18372 18373 18374 18375 18376 18377 18378 18379 18380 18381 18382 18383\n",
      " 18384 18385 18386 18387 18388 18389 18390 18391 18392 18393 18394 18395\n",
      " 18396 18397 18398 18399 18400 18401 18402 18403 18404 18405 18406 18407\n",
      " 18408 18409 18410 18411]\n",
      "6\n",
      "[18589 18590 18591 18592 18593 18594 18595 18596 18597 18598 18599 18600\n",
      " 18601 18602 18603 18604 18605 18606 18607 18608 18609 18610 18611 18612\n",
      " 18613 18614 18615 18616 18617 18618 18619 18620 18621 18622 18623 18624\n",
      " 18625 18626 18627 18628]\n",
      "7\n",
      "[18792 18793 18794 18795 18796 18797 18798 18799 18800 18801 18802 18803\n",
      " 18804 18805 18806 18807 18808 18809 18810 18811 18812 18813 18814 18815\n",
      " 18816 18817 18818 18819 18820 18821 18822 18823 18824 18825 18826 18827\n",
      " 18828 18829 18830 18831]\n",
      "8\n",
      "[18889 18890 18891 18892 18893 18894 18895 18896 18897 18898 18899 18900\n",
      " 18901 18902 18903 18904 18905 18906 18907 18908 18909 18910 18911 18912\n",
      " 18913 18914 18915 18916 18917 18918 18919 18920 18921 18922 18923 18924\n",
      " 18925 18926 18927 18928]\n",
      "9\n",
      "[19304 19305 19306 19307 19308 19309 19310 19311 19312 19313 19314 19315\n",
      " 19316 19317 19318 19319 19320 19321 19322 19323 19324 19325 19326 19327\n",
      " 19328 19329 19330 19331 19332 19333 19334 19335 19336 19337 19338 19339\n",
      " 19340 19341 19342 19343]\n",
      "10\n",
      "[21243 21244 21245 21246 21247 21248 21249 21250 21251 21252 21253 21254\n",
      " 21255 21256 21257 21258 21259 21260 21261 21262 21263 21264 21265 21266\n",
      " 21267 21268 21269 21270 21271 21272 21273 21274 21275 21276 21277 21278\n",
      " 21279 21280 21281 21282]\n",
      "11\n",
      "[22533 22534 22535 22536 22537 22538 22539 22540 22541 22542 22543 22544\n",
      " 22545 22546 22547 22548 22549 22550 22551 22552 22553 22554 22555 22556\n",
      " 22557 22558 22559 22560 22561 22562 22563 22564 22565 22566 22567 22568\n",
      " 22569 22570 22571 22572 22573]\n",
      "12\n",
      "[22535 22536 22537 22538 22539 22540 22541 22542 22543 22544 22545 22546\n",
      " 22547 22548 22549 22550 22551 22552 22553 22554 22555 22556 22557 22558\n",
      " 22559 22560 22561 22562 22563 22564 22565 22566 22567 22568 22569 22570\n",
      " 22571 22572 22573 22574]\n",
      "13\n",
      "[22563 22564 22565 22566 22567 22568 22569 22570 22571 22572 22573 22574\n",
      " 22575 22576 22577 22578 22579 22580 22581 22582 22583 22584 22585 22586\n",
      " 22587 22588 22589 22590 22591 22592 22593 22594 22595 22596 22597 22598\n",
      " 22599 22600 22601 22602]\n",
      "14\n",
      "[22602 22603 22604 22605 22606 22607 22608 22609 22610 22611 22612 22613\n",
      " 22614 22615 22616 22617 22618 22619 22620 22621 22622 22623 22624 22625\n",
      " 22626 22627 22628 22629 22630 22631 22632 22633 22634 22635 22636 22637\n",
      " 22638 22639 22640 22641]\n",
      "15\n",
      "[22913 22914 22915 22916 22917 22918 22919 22920 22921 22922 22923 22924\n",
      " 22925 22926 22927 22928 22929 22930 22931 22932 22933 22934 22935 22936\n",
      " 22937 22938 22939 22940 22941 22942 22943 22944 22945 22946 22947 22948\n",
      " 22949 22950 22951 22952]\n",
      "16\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-81-fb82010da934>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m  1948339.65]\n\u001B[0;32m     13\u001B[0m \u001B[0mblock\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblock_collection\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moe_rec\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m17\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m2000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-36-2c8d89d73d33>\u001B[0m in \u001B[0;36mget_data\u001B[1;34m(self, channels, start_time_ms, window_ms, convert_to_mv, return_timestamps)\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp_single_trial_time_stamps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;31m# this collects the indices to start reading from\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m         \u001B[0mread_start_indices\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp_single_trial_time_stamps\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "a = [ 930398.75,  930993.2,   931383.85,  939282.3,   940556.05,  940691.95,\n",
    "  951784.55,  962163.85,  967157.55,  988391.55, 1087689.35, 1153738.95,\n",
    " 1153823.85, 1155267.75, 1157255.55, 1173192.05, 1240300.65, 1240606.55,\n",
    " 1243392.75, 1244242.2,  1286866.75, 1286934.65, 1288259.45, 1288361.35,\n",
    " 1288446.3,  1288531.2,  1289890.05, 1290637.25, 1291367.5,  1291588.35,\n",
    " 1292097.85, 1293728.4,  1297771.,   1318140.35, 1322507.3, 1346739.55,\n",
    " 1502719.3,  1502889.15, 1502991.05, 1503059.,   1503160.95, 1503398.7,\n",
    " 1504553.8,  1504808.6,  1505861.7,  1509648.9,  1511194.65, 1541463.15,\n",
    " 1541582.,   1672833.4,  1788476.7,  1799536.85, 1885102.55, 1886597.25,\n",
    " 1888007.3,  1888160.2,  1888313.05, 1888397.95, 1890402.2,  1899811.9,\n",
    " 1908099.95, 1917068.45, 1933069.7,  1946573.25, 1947065.75, 1947269.55,\n",
    " 1948339.65]\n",
    "block = block_collection[1]\n",
    "data = get_data(block.oe_rec,[17],a,2000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[13776.5]])"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(block.oe_rec.allTimeStamps[0][-1] + block.oe_rec.globalStartTime_ms) - np.array(block.final_sync_df.Arena_TTL.values / 20)[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.0000000e+00, 5.1200000e+01, 1.0240000e+02, ..., 1.1754496e+06,\n        1.1755008e+06, 1.1755520e+06]])"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([block.final_sync_df.Arena_TTL.values / 20, block.ms_axis])\n",
    "block.oe_rec.allTimeStamps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[17548544.]])"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.oe_events.Arena_TTL.values[0]\n",
    "block.oe_rec.globalStartTime_ms * (block.sample_rate/1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "BlockSync object for animal PV_62 with \nblock_num 073 at date 2023-06-21_14-45-37"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4019.2\n",
      "877427.2\n",
      "2078489.6\n",
      "6604.8\n"
     ]
    }
   ],
   "source": [
    "first_block_zero = block_collection[0].zeroth_sample_number\n",
    "\n",
    "second_block_zero = block_collection[1].zeroth_sample_number\n",
    "third_block_zero = block_collection[2].zeroth_sample_number\n",
    "for b in block_collection:\n",
    "    print(b.zeroth_sample_number / 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def get_data(self, channels, start_time_ms, window_ms, convert_to_mv=True, return_timestamps=True):\n",
    "    \"\"\"\n",
    "    This is a translated matlab function that efficiently retrieves data from Open-Ephys format neural recordings\n",
    "    :param self: an OERecording class obj. with a metadata file created by the matlab class with the same name\n",
    "    :param channels: a vector of channel numbers to sample from [1XN channels]\n",
    "    :param start_time_ms: a vector of window start times [1XN] in ms\n",
    "    :param window_ms: a single value, the length of the sampling window from each startTime [ms_value]\n",
    "    :param convert_to_mv: when True, turns the output into the mV representation of the sampled data\n",
    "    :param return_timestamps: when True, the output will include sample timestamps from 0 in ms\n",
    "    :return: data_matrix - an array with the shape [n_channels, n_windows, nSamples] with int16 / mV values\n",
    "    \"\"\"\n",
    "    window_samples = int(\n",
    "        np.round(window_ms / self.sample_ms))  # round the time in ms to the nearest whole sample count\n",
    "    n_windows = len(start_time_ms)  # get the number of start times provided\n",
    "    start_time_ms = np.round(\n",
    "        start_time_ms / self.sample_ms) * self.sample_ms  # round the start times to the nearest whole sample step\n",
    "    window_ms = window_samples * self.sample_ms  # get the ms based length of the rounded window\n",
    "\n",
    "    # deal with the channel numbers:\n",
    "    if len(channels) == 0 or channels is None:  # if no channels were provided\n",
    "        channels = self.channelNumbers\n",
    "\n",
    "    if not all([c in self.channelNumbers for c in channels]):  # if requested channels do not exist in the file\n",
    "        raise ValueError('one or more of the entered channels does not exist in the recording!')\n",
    "    n_ch = len(channels)\n",
    "\n",
    "    # initialize some variables for the data extraction:\n",
    "    # waveform matrix:\n",
    "    data_matrix = np.zeros(shape=(int(window_samples), n_windows, n_ch),\n",
    "                           dtype=self.blkCont['Types'][3],\n",
    "                           order='F')\n",
    "    # List to store the record indices for waveform extraction:\n",
    "    p_rec_idx = []\n",
    "    # List to store the indices where reading from the file should start (one per reading window):\n",
    "    read_start_indices = []\n",
    "    records_per_trial_list = []\n",
    "    for i in range(n_windows):\n",
    "        print(i)\n",
    "        # find the relevant record blocks in the block list:\n",
    "        p_single_trial_time_stamps = np.where((self.allTimeStamps[0] >= (start_time_ms[0][i] - self.recordLength)) &\n",
    "                                              (self.allTimeStamps[0] < (start_time_ms[0][i] + window_ms)))[1]\n",
    "        print(p_single_trial_time_stamps)\n",
    "        # this collects the indices to start reading from\n",
    "        read_start_indices.append(p_single_trial_time_stamps[0])\n",
    "\n",
    "\n",
    "        # Calculate time stamps in milliseconds based on sampling freq & record block length\n",
    "        single_trial_time_stamps = np.round(self.allTimeStamps[0][\n",
    "                                                p_single_trial_time_stamps] / self.sample_ms) * self.sample_ms\n",
    "        # Get the number of records per trial & append to a list\n",
    "        records_per_trial = len(single_trial_time_stamps[0])\n",
    "        records_per_trial_list.append(records_per_trial)\n",
    "\n",
    "        # get the real time values for each sample index:\n",
    "        time_idx = np.tile((np.arange(self.dataSamplesPerRecord) * self.sample_ms).reshape(-1, 1),\n",
    "                           (1, records_per_trial)) + single_trial_time_stamps.reshape(1, -1)\n",
    "        # Find time indices within the requested time window\n",
    "        # (chunks are 1024 in size so they are usually cut for most time windows, result is as a boolean matrix)\n",
    "        p_rec_idx.append((time_idx >= start_time_ms[0][i]) & (time_idx < (start_time_ms[0][i] + window_ms)))\n",
    "\n",
    "        # Due to rounding issues, there may be an error when there is one sample too much -\n",
    "        # in this case the last sample is removed\n",
    "        if np.sum(p_rec_idx[i]) == window_samples + 1:\n",
    "            print(f'sample removed for window #{i}')\n",
    "            p_rec_idx[i][0, np.where(p_rec_idx[i][0, :] == 1)[0][0]] = False\n",
    "\n",
    "    p_rec_idx = np.hstack(p_rec_idx)  # Concatenate record indices into a single array\n",
    "\n",
    "    # now for the data extraction itself:\n",
    "    for i in range(n_ch):  # iterate over channels\n",
    "        data = np.zeros(p_rec_idx.shape, dtype=np.dtype('>i2'))  # Initialize the data array for a specific channel\n",
    "        curr_rec = 0  # for this channel, initialize the record counter\n",
    "        c_file = self.oe_file_path / self.channel_files[channels[i] - 1]  # get path of current channel file\n",
    "        with open(c_file, 'rb') as fid:  # open the file such that it will close when left alone\n",
    "            for j in range(n_windows):  # Iterate over sampling windows\n",
    "                # use seek to go to the appropriate position in the file\n",
    "                fid.seek(int(self.headerSizeByte + (read_start_indices[j] * self.bytesPerRecCont) + np.sum(\n",
    "                    self.blkBytesCont[0:3])), 0)\n",
    "                # calculate the skip size, cut in half because each int16 is 2 bytes and the matlab\n",
    "                # function takes bytes as skip (which fromfile does not, uniform datatype)\n",
    "                skip_size = int(self.bytesPerRecCont[0][0] - self.blkBytesCont[3][0]) // 2\n",
    "                read_size = self.dataSamplesPerRecord\n",
    "                # calculate total element count to read:\n",
    "                total_bytes = (read_size + skip_size) * records_per_trial_list[j]\n",
    "                # read data from file in a single vector, including skip_data:\n",
    "                # (Notice datatype is non-flexible in this version of the function!!!)\n",
    "                data_plus_breaks = np.fromfile(fid, dtype=np.dtype('>i2'), count=total_bytes, sep='')\n",
    "                # reshape into an array with a column-per-record shape:\n",
    "                data_plus_breaks = data_plus_breaks.reshape(int(records_per_trial_list[j]), read_size + skip_size)\n",
    "                # slice the array to get rid of the skip_data at the end of each column (record):\n",
    "                clean_data = data_plus_breaks[:, : read_size]\n",
    "                # transpose and store the current_rec data:\n",
    "                data[:, curr_rec: curr_rec + records_per_trial_list[j]] = clean_data.T\n",
    "                curr_rec = curr_rec + records_per_trial_list[j]  # move forward to the next reading window\n",
    "        # this loop exit closes the current channel file\n",
    "        # vectorize the data from the channel and perform a boolean snipping of non-window samples:\n",
    "        data_vec = data.T[p_rec_idx.T]\n",
    "\n",
    "        # put the data in the final data_matrix waveform matrix:\n",
    "        # check for end-of-recording exceedance :\n",
    "        if len(data_vec) < int(window_samples) * n_windows:\n",
    "            print(f'The requested data segment between {read_start_indices [j]} ms and '\n",
    "                  f'{read_start_indices[j] + window_ms} ms exceeds the recording length, '\n",
    "                  f'and will be 0-padded to fit the other windows')\n",
    "            num_zeros = (int(window_samples) * n_windows) - len(data_vec)\n",
    "            data_vec = np.pad(data_vec,(0, num_zeros), mode='constant')\n",
    "        data_matrix[:, :, i] = data_vec.reshape(int(window_samples), n_windows, order='F')\n",
    "\n",
    "    data_matrix = np.transpose(data_matrix, [2, 1, 0])\n",
    "\n",
    "    if convert_to_mv:\n",
    "        data_matrix = data_matrix * self.MicrovoltsPerAD[0]\n",
    "\n",
    "    if return_timestamps:\n",
    "        timestamps = np.tile(np.arange(window_samples) * self.sample_ms, (n_windows, 1))\n",
    "        start_times = np.tile(start_time_ms.T, window_samples)\n",
    "        timestamps = timestamps + start_times\n",
    "        return data_matrix, timestamps\n",
    "    else:\n",
    "        return data_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 23618.9 ,  23635.9 ,  23652.9 , ..., 548356.95, 548373.9 ,\n       548390.9 ])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "      t_mov_ms        movAll\n0      73032.0  10950.945187\n1      73036.0  11873.337628\n2      73040.0  12821.427499\n3      73044.0  13786.798272\n4      73048.0  14761.033420\n...        ...           ...\n4265  558444.0  36369.811369\n4266  558448.0  31347.361650\n4267  558452.0  25891.303132\n4268  558456.0  20223.557981\n4269  558460.0  14566.048366\n\n[4270 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_mov_ms</th>\n      <th>movAll</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>73032.0</td>\n      <td>10950.945187</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>73036.0</td>\n      <td>11873.337628</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>73040.0</td>\n      <td>12821.427499</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>73044.0</td>\n      <td>13786.798272</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>73048.0</td>\n      <td>14761.033420</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4265</th>\n      <td>558444.0</td>\n      <td>36369.811369</td>\n    </tr>\n    <tr>\n      <th>4266</th>\n      <td>558448.0</td>\n      <td>31347.361650</td>\n    </tr>\n    <tr>\n      <th>4267</th>\n      <td>558452.0</td>\n      <td>25891.303132</td>\n    </tr>\n    <tr>\n      <th>4268</th>\n      <td>558456.0</td>\n      <td>20223.557981</td>\n    </tr>\n    <tr>\n      <th>4269</th>\n      <td>558460.0</td>\n      <td>14566.048366</td>\n    </tr>\n  </tbody>\n</table>\n<p>4270 rows  2 columns</p>\n</div>"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=np.array([mat_dict['t_mov_ms'][:,0],mat_dict['movAll'][:,0]]).T, columns=['t_mov_ms','movAll'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample removed 16\n",
      "sample removed 38\n",
      "sample removed 39\n",
      "The requested data segment between 10643 ms and [[12643.]] ms exceeds the recording length, and will be 0-padded to fit the other windows\n"
     ]
    }
   ],
   "source": [
    "eye_df = block.le_df\n",
    "saccades = block.l_saccades_chunked[block.l_saccades_chunked.saccade_length_frames > 0]\n",
    "saccade_times = np.sort(saccades.saccade_start_ms.values)\n",
    "sampling_window_ms = 2000 # ms\n",
    "pre_saccade_ts = saccade_times - (sampling_window_ms / 2)\n",
    "ep_data = block.oe_rec.get_data([17],pre_saccade_ts, sampling_window_ms,convert_to_mv=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "block.block_eye_plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 072 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072, new OE version\n",
      "Found the sample rate for block 072 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 072\n",
      "got it!\n",
      "instantiated block number 073 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073, new OE version\n",
      "Found the sample rate for block 073 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 073\n",
      "got it!\n",
      "instantiated block number 074 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_074, new OE version\n",
      "Found the sample rate for block 074 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 074\n",
      "got it!\n",
      "instantiated block number 075 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075, new OE version\n",
      "Found the sample rate for block 075 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 075\n",
      "got it!\n"
     ]
    }
   ],
   "source": [
    "#blocklist = block_generator(block_numbers,pathlib.Path(r\"Z:\\Nimrod\\experiments\"),'PV_62',bad_blocks=bad_blocks)\n",
    "experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "animal = 'PV_62'\n",
    "block_list = [i for i in range(72,76)]\n",
    "bad_blocks = []\n",
    "p = pathlib.Path(experiment_path) / animal\n",
    "date_folder_list = [i for i in p.iterdir() if 'block' not in str(i).lower() and i.is_dir()]\n",
    "block_collection = []\n",
    "for date_path in date_folder_list:\n",
    "    date = date_path.name\n",
    "    # list all the blocks in the folder:\n",
    "    folder_list = [i for i in date_path.iterdir()]\n",
    "    for block in folder_list:\n",
    "        if 'block' in str(block):\n",
    "            block_number = block.name[-3:]\n",
    "            if int(block_number) in block_list and int(block_number) not in bad_blocks:\n",
    "                #block definition\n",
    "                b = BlockSync(animal_call=animal,\n",
    "                                  experiment_date=date,block_num=block_number,\n",
    "                                  path_to_animal_folder=str(experiment_path),regev=True)\n",
    "                block_collection.append(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_073\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim2.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_073\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim2.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\eye_videos\\RE\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim2.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim2_LE.mp4 has reported 68629 frames and has 68629 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim2.mp4 has reported 68588 frames and has 68588 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T144553.mp4\n",
      "left_20230621T144553.mp4\n",
      "right_20230621T144553.mp4\n",
      "top_20230621T144553.mp4\n",
      "running parse_open_ephys_events...\n",
      "aligning to zero with 17548544\n",
      "open ephys events aligned to zero & exported to csv file at Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\oe_files\\2023-06-21_14-45-37\\events.csv\n",
      "the arena TTLs are signaling start and stop positions at [  773 68208]\n",
      "arena first frame timestamp: 324882\n",
      "arena end frame timestamp: 23235849\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 381/66814 [00:00<00:17, 3797.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\oe_files\\2023-06-21_14-45-37\\parsed_events.csv\n",
      "creating blocksync_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 66814/66814 [00:27<00:00, 2459.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created blocksync_df\n",
      "exported blocksync_df to Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\analysis/ blocksync_df.csv\n",
      "working on video Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\eye_videos\\LE\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim2_LE.mp4\n",
      "done, frame_val_list contains 1 objects\n",
      "working on video Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\eye_videos\\RE\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim2.mp4\n",
      "done, frame_val_list contains 1 objects\n",
      "creating Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\analysis/eye_brightness_df.csv\n"
     ]
    }
   ],
   "source": [
    "block = block_collection[1]\n",
    "block.handle_eye_videos()\n",
    "block.handle_arena_files()\n",
    "block.parse_open_ephys_events(align_to_zero=True)\n",
    "#block.synchronize_arena_timestamps()\n",
    "#block.create_arena_brightness_df(threshold_value=240,export=True)\n",
    "block.synchronize_block(export=True)\n",
    "block.create_eye_brightness_df(threshold_value=250)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_072\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim1_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim1.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_072\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim1_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim1.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072\\eye_videos\\RE\\230621_pv62_audiostim1_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim1.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim1_LE.mp4 has reported 47995 frames and has 47995 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim1.mp4 has reported 48000 frames and has 48000 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T143120.mp4\n",
      "left_20230621T143120.mp4\n",
      "right_20230621T143120.mp4\n",
      "top_20230621T143120.mp4\n",
      "running parse_open_ephys_events...\n",
      "events.csv file already exists\n",
      "arena first frame timestamp: 326458\n",
      "arena end frame timestamp: 16625874\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n",
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072\\oe_files\\2023-06-21_14-31-03\\parsed_events.csv\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "loaded chunked saccade data from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_073\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim2.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_073\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim2.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\eye_videos\\RE\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim2.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim2_LE.mp4 has reported 68629 frames and has 68629 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim2.mp4 has reported 68588 frames and has 68588 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T144553.mp4\n",
      "left_20230621T144553.mp4\n",
      "right_20230621T144553.mp4\n",
      "top_20230621T144553.mp4\n",
      "running parse_open_ephys_events...\n",
      "events.csv file already exists\n",
      "the arena TTLs are signaling start and stop positions at [  773 68208]\n",
      "arena first frame timestamp: 324882\n",
      "arena end frame timestamp: 23235849\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n",
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\oe_files\\2023-06-21_14-45-37\\parsed_events.csv\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "automatic ON, Going ahead with the baseline threshold\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_074\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim3_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim3.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_074\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim3_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim3.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_074\\eye_videos\\RE\\230621_pv62_audiostim3_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim3.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim3_LE.mp4 has reported 33079 frames and has 33079 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim3.mp4 has reported 33080 frames and has 33080 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T150602.mp4\n",
      "left_20230621T150602.mp4\n",
      "right_20230621T150602.mp4\n",
      "top_20230621T150602.mp4\n",
      "running parse_open_ephys_events...\n",
      "events.csv file already exists\n",
      "the arena TTLs are signaling start and stop positions at [ 1207 33506]\n",
      "arena first frame timestamp: 471859\n",
      "arena end frame timestamp: 11444531\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n",
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_074\\oe_files\\2023-06-21_15-05-38\\parsed_events.csv\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "automatic ON, Going ahead with the baseline threshold\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_075\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim4.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_075\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim4.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\eye_videos\\RE\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim4.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim4_LE.mp4 has reported 31934 frames and has 31934 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim4.mp4 has reported 31933 frames and has 31933 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T152553.mp4\n",
      "left_20230621T152553.mp4\n",
      "right_20230621T152553.mp4\n",
      "top_20230621T152553.mp4\n",
      "running parse_open_ephys_events...\n",
      "events.csv file already exists\n",
      "the arena TTLs are signaling start and stop positions at [  364 31720]\n",
      "arena first frame timestamp: 185704\n",
      "arena end frame timestamp: 10836062\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n",
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\oe_files\\2023-06-21_15-25-44\\parsed_events.csv\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "automatic ON, Going ahead with the baseline threshold\n"
     ]
    }
   ],
   "source": [
    "for block in block_collection:\n",
    "    analyzed_block_automated_pipe(block)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3.        , 4.        , 5.65685425, 6.63324958, 0.        ,\n       0.        , 4.79583152, 5.        , 0.        ])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_squared = np.array([9,16,32,44,0,0,23,25,0],dtype=np.float64)\n",
    "euclidean_distance = np.where(dist_squared != 0, np.sqrt(dist_squared), 0)\n",
    "euclidean_distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "block = block_collection[0]\n",
    "block.saccade_event_analayzer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving zertoh sample number for block 072\n",
      "got it!\n",
      "retrieving zertoh sample number for block 073\n",
      "got it!\n",
      "retrieving zertoh sample number for block 074\n",
      "got it!\n",
      "retrieving zertoh sample number for block 075\n",
      "got it!\n"
     ]
    }
   ],
   "source": [
    "# get zeroth sample number for event synchronization with EP paradigm of sample#0 = 0:\n",
    "for block in block_collection:\n",
    "    block.get_zeroth_sample_number()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def align_events_to_zero(block):\n",
    "    \"\"\"This function deals with aligning open-ephys events such that the 0th sample is at exactly the record beginning\"\"\"\n",
    "\n",
    "    def subtract_from_columns(df, subtraction_number, column_names):\n",
    "        # helper function:\n",
    "        # Create a copy of the DataFrame to avoid modifying the original\n",
    "        subtracted_df = df.copy()\n",
    "\n",
    "        # Iterate over the column names in the list\n",
    "        for column_name in column_names:\n",
    "            # Check if the column exists in the DataFrame\n",
    "            if column_name in subtracted_df.columns:\n",
    "                # Get the indices where the column value is not NaN\n",
    "                indices = subtracted_df.index[~pd.isna(subtracted_df[column_name])]\n",
    "\n",
    "                # Subtract the subtraction number from the selected indices\n",
    "                subtracted_df.loc[indices, column_name] -= subtraction_number\n",
    "\n",
    "        return subtracted_df\n",
    "\n",
    "    df = block.oe_events\n",
    "    df_sub = subtract_from_columns(df,block.zeroth_sample_number, [i for i in df.columns if 'frame' not in i])\n",
    "    block.oe_events = df_sub\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "block = block_collection[1]\n",
    "session = oea.Session(block.oe_path.parent)\n",
    "events_df = session.recordnodes[0].recordings[0].events\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.oe_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ True]])"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.oe_rec.globalStartTime_ms*(block.sample_rate / 1000) == block.zeroth_sample_number"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "         Arena_TTL  Arena_TTL_frame  LED_driver  LED_driver_frame  L_eye_TTL  \\\n1            324.0              NaN         NaN               NaN        NaN   \n3            663.0              NaN         NaN               NaN        NaN   \n5           1003.0              NaN         NaN               NaN        NaN   \n7           1343.0              NaN         NaN               NaN        NaN   \n9           1683.0              NaN         NaN               NaN        NaN   \n...            ...              ...         ...               ...        ...   \n290689  16965764.0              NaN         NaN               NaN        NaN   \n290691  16966103.0              NaN         NaN               NaN        NaN   \n290693  16966443.0              NaN         NaN               NaN        NaN   \n290695  16966783.0              NaN         NaN               NaN        NaN   \n290697  16967122.0              NaN         NaN               NaN        NaN   \n\n        L_eye_TTL_frame  R_eye_TTL  R_eye_TTL_frame  \n1                   NaN        NaN              NaN  \n3                   NaN        NaN              NaN  \n5                   NaN        NaN              NaN  \n7                   NaN        NaN              NaN  \n9                   NaN        NaN              NaN  \n...                 ...        ...              ...  \n290689              NaN        NaN              NaN  \n290691              NaN        NaN              NaN  \n290693              NaN        NaN              NaN  \n290695              NaN        NaN              NaN  \n290697              NaN        NaN              NaN  \n\n[145349 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Arena_TTL</th>\n      <th>Arena_TTL_frame</th>\n      <th>LED_driver</th>\n      <th>LED_driver_frame</th>\n      <th>L_eye_TTL</th>\n      <th>L_eye_TTL_frame</th>\n      <th>R_eye_TTL</th>\n      <th>R_eye_TTL_frame</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>324.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>663.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1003.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1343.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1683.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>290689</th>\n      <td>16965764.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>290691</th>\n      <td>16966103.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>290693</th>\n      <td>16966443.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>290695</th>\n      <td>16966783.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>290697</th>\n      <td>16967122.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>145349 rows  8 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = block.oe_events\n",
    "df_sub = subtract_from_columns(df,block.zeroth_sample_number, [i for i in df.columns if 'frame' not in i])\n",
    "df_sub"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "11805      1198348.0\n33305      2399007.0\n54811      3599667.0\n75838      4800326.0\n97345      6000986.0\n118848     7201646.0\n140351     8402305.0\n161857     9602965.0\n183360    10803625.0\n204865    12004285.0\n226368    13204945.0\n247871    14405606.0\n269375    15606266.0\n289753    16806926.0\nName: LED_driver, dtype: float64"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['LED_driver'][df_sub['LED_driver'] == df_sub['LED_driver']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "11805      1198348.0\n33305      2399007.0\n54811      3599667.0\n75838      4800326.0\n97345      6000986.0\n118848     7201646.0\n140351     8402305.0\n161857     9602965.0\n183360    10803625.0\n204865    12004285.0\n226368    13204945.0\n247871    14405606.0\n269375    15606266.0\n289753    16806926.0\nName: LED_driver, dtype: float64"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['LED_driver'][df_sub['LED_driver'] == df_sub['LED_driver']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "session = oea.Session(str(block.oe_path.parent))\n",
    "rec_node = session.recordnodes[0].recordings[0].continuous[0]\n",
    "rec_starts = rec_node.timestamps[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "zeroth_sample_num = [session.recordnodes[0].recordings[0].continuous[0].sample_numbers[0]]\n",
    "pd.DataFrame({'zeroth_sample_num':zeroth_sample_num}).to_csv(block.analysis_path / 'zeroth_sample_num.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "80384"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(block.analysis_path / 'zeroth_sample_num.csv')\n",
    "df['zeroth_sample_num'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_072\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim1_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim1.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_072\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim1_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim1.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072\\eye_videos\\RE\\230621_pv62_audiostim1_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim1.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim1_LE.mp4 has reported 47995 frames and has 47995 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim1.mp4 has reported 48000 frames and has 48000 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T143120.mp4\n",
      "left_20230621T143120.mp4\n",
      "right_20230621T143120.mp4\n",
      "top_20230621T143120.mp4\n",
      "running parse_open_ephys_events...\n",
      "events.csv file already exists\n",
      "arena first frame timestamp: 406842\n",
      "arena end frame timestamp: 16706258\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n",
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072\\oe_files\\2023-06-21_14-31-03\\parsed_events.csv\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "loaded chunked saccade data from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_073\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim2.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_073\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim2.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\eye_videos\\RE\\230621_pv62_audiostim2_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim2.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim2_LE.mp4 has reported 68629 frames and has 68629 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim2.mp4 has reported 68588 frames and has 68588 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T144553.mp4\n",
      "left_20230621T144553.mp4\n",
      "right_20230621T144553.mp4\n",
      "top_20230621T144553.mp4\n",
      "running parse_open_ephys_events...\n",
      "events.csv file already exists\n",
      "the arena TTLs are signaling start and stop positions at [  773 68208]\n",
      "arena first frame timestamp: 17873426\n",
      "arena end frame timestamp: 40784393\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n",
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\oe_files\\2023-06-21_14-45-37\\parsed_events.csv\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "automatic ON, Going ahead with the baseline threshold\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_074\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim3_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim3.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_074\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim3_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim3.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_074\\eye_videos\\RE\\230621_pv62_audiostim3_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim3.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim3_LE.mp4 has reported 33079 frames and has 33079 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim3.mp4 has reported 33080 frames and has 33080 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T150602.mp4\n",
      "left_20230621T150602.mp4\n",
      "right_20230621T150602.mp4\n",
      "top_20230621T150602.mp4\n",
      "running parse_open_ephys_events...\n",
      "events.csv file already exists\n",
      "the arena TTLs are signaling start and stop positions at [ 1207 33506]\n",
      "arena first frame timestamp: 42041651\n",
      "arena end frame timestamp: 53014323\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n",
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_074\\oe_files\\2023-06-21_15-05-38\\parsed_events.csv\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "automatic ON, Going ahead with the baseline threshold\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_075\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim4.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_075\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim4.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\eye_videos\\RE\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim4.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim4_LE.mp4 has reported 31934 frames and has 31934 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim4.mp4 has reported 31933 frames and has 31933 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T152553.mp4\n",
      "left_20230621T152553.mp4\n",
      "right_20230621T152553.mp4\n",
      "top_20230621T152553.mp4\n",
      "running parse_open_ephys_events...\n",
      "events.csv file already exists\n",
      "the arena TTLs are signaling start and stop positions at [  364 31720]\n",
      "arena first frame timestamp: 317800\n",
      "arena end frame timestamp: 10968158\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n",
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\oe_files\\2023-06-21_15-25-44\\parsed_events.csv\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "automatic ON, Going ahead with the baseline threshold\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for block in block_collection:\n",
    "    analyzed_block_automated_pipe(block)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "        Arena_TTL  Arena_frame  L_eye_frame  R_eye_frame  L_values  R_values\n0        855018.0       1319.0          6.0         11.0 -0.913598  1.884156\n1        855358.0       1320.0          7.0         12.0 -0.913155  1.885686\n2        855698.0       1321.0          8.0         13.0 -0.912993  1.885833\n3        856037.0       1322.0          9.0         14.0 -0.912866  1.884999\n4        856377.0       1323.0         10.0         15.0 -0.913932  1.886211\n...           ...          ...          ...          ...       ...       ...\n46570  16704559.0      47889.0      47562.0          NaN  0.992427       NaN\n46571  16704899.0      47890.0      47563.0          NaN  0.992530       NaN\n46572  16705239.0      47891.0      47564.0          NaN  0.991791       NaN\n46573  16705578.0      47892.0      47565.0          NaN  0.992694       NaN\n46574  16705918.0      47893.0      47566.0          NaN  0.991805       NaN\n\n[46575 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Arena_TTL</th>\n      <th>Arena_frame</th>\n      <th>L_eye_frame</th>\n      <th>R_eye_frame</th>\n      <th>L_values</th>\n      <th>R_values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>855018.0</td>\n      <td>1319.0</td>\n      <td>6.0</td>\n      <td>11.0</td>\n      <td>-0.913598</td>\n      <td>1.884156</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>855358.0</td>\n      <td>1320.0</td>\n      <td>7.0</td>\n      <td>12.0</td>\n      <td>-0.913155</td>\n      <td>1.885686</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>855698.0</td>\n      <td>1321.0</td>\n      <td>8.0</td>\n      <td>13.0</td>\n      <td>-0.912993</td>\n      <td>1.885833</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>856037.0</td>\n      <td>1322.0</td>\n      <td>9.0</td>\n      <td>14.0</td>\n      <td>-0.912866</td>\n      <td>1.884999</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>856377.0</td>\n      <td>1323.0</td>\n      <td>10.0</td>\n      <td>15.0</td>\n      <td>-0.913932</td>\n      <td>1.886211</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>46570</th>\n      <td>16704559.0</td>\n      <td>47889.0</td>\n      <td>47562.0</td>\n      <td>NaN</td>\n      <td>0.992427</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>46571</th>\n      <td>16704899.0</td>\n      <td>47890.0</td>\n      <td>47563.0</td>\n      <td>NaN</td>\n      <td>0.992530</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>46572</th>\n      <td>16705239.0</td>\n      <td>47891.0</td>\n      <td>47564.0</td>\n      <td>NaN</td>\n      <td>0.991791</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>46573</th>\n      <td>16705578.0</td>\n      <td>47892.0</td>\n      <td>47565.0</td>\n      <td>NaN</td>\n      <td>0.992694</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>46574</th>\n      <td>16705918.0</td>\n      <td>47893.0</td>\n      <td>47566.0</td>\n      <td>NaN</td>\n      <td>0.991805</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>46575 rows  6 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = block_collection[0]\n",
    "block.final_sync_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "TODO LIST:\n",
    "1. get the hang of how to parse the .mat OEMetaData files generated by Mark's code == V\n",
    "2. create a class object which initializes through BlockSync and allows the get_data method as written in MATLAB (that is, faster) == V\n",
    "3. rewrite the class to get its own metadata based on what is actually needed == V\n",
    "4. integrate with video outputs on a joint timeline\n",
    "5. go through with analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# initialize some things\n",
    "#block definition\n",
    "experiments_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "animal = \"PV_62\"\n",
    "date = \"2023_06_21\"\n",
    "block_n = \"072\"\n",
    "\n",
    "block = BlockSync(animal_call=animal,\n",
    "                  experiment_date=date,block_num=block_n,\n",
    "                  path_to_animal_folder=str(experiments_path),regev=True)\n",
    "\n",
    "# oe session definition (maybe redundent? do I really use their classes?)\n",
    "\n",
    "oe_metadata_file_path = block.oe_metadata_file_path\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 072 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072, new OE version\n",
      "Found the sample rate for block 072 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_073/oe_files/2023-06-21_14-45-37/Record Node 108/OE_metaData.mat')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.oe_metadata_file_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/OE_metaData.mat')"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe_metadata_file_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analyzed_block_automated_pipe(block)\n",
    "block.calibrate_pixel_size(10,overwrite=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/OE_metaData.mat')"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect saccade events within block\n",
    "block.saccade_event_analayzer(threshold=2, automatic=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "block.l_saccades_chunked"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/OE_metaData.mat')"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.calibrate_pixel_size(10,overwrite=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class OERecording:\n",
    "    \"\"\"\n",
    "    This is a class designed to get the metadata of an open-ephys format recording that was first analyzed by Mark's matlab code -\n",
    "    I should probably make an independent function sometime in the future but for now this class reads the produced metadata file to allow efficient access to the recording\n",
    "    \"\"\"\n",
    "    # define a helper function to get a group out of an hdf5 file (without resolving internal references!)\n",
    "\n",
    "    def group_to_dict(self, group):\n",
    "        result = {}\n",
    "        for key, item in group.items():\n",
    "            if isinstance(item, h5py.Group):\n",
    "                result[key] = self.group_to_dict(item)\n",
    "            else:\n",
    "\n",
    "                result[key] = item[()]  # Convert dataset to NumPy array and assign its value\n",
    "        return result\n",
    "\n",
    "    def __init__(self, oe_metadata_file_path):\n",
    "        # create the metadata_dict object:\n",
    "        # open the mat file:\n",
    "        mat_file = h5py.File(str(oe_metadata_file_path), 'r')\n",
    "\n",
    "        #implement on the metaData group:\n",
    "        meta_dict = self.group_to_dict(mat_file['metaData'])\n",
    "\n",
    "        # resolve internal references of blkCont object:\n",
    "        # get to the blkCont mat and reform it from reference instances\n",
    "        blkCont_dict = {\n",
    "            'Repeat':[],\n",
    "            'Types':[],\n",
    "            'Str':[]\n",
    "        }\n",
    "        blkCont_group = mat_file['metaData/blkCont']\n",
    "        for i in blkCont_group['Repeat']:\n",
    "            res = np.array(mat_file[i[0]][0])\n",
    "            blkCont_dict['Repeat'].append(res[0])\n",
    "\n",
    "        for i in blkCont_group['Types']:\n",
    "            res = np.array((mat_file[i[0]]))\n",
    "            str_array = np.vectorize(chr)(res).flatten()\n",
    "            str_value = ''.join(str_array.flatten())\n",
    "            blkCont_dict['Types'].append(str_value)\n",
    "\n",
    "        for i in blkCont_group['Str']:\n",
    "            res = np.array(mat_file[i[0]])\n",
    "            str_array = np.vectorize(chr)(res).flatten()\n",
    "            str_value = ''.join(str_array.flatten())\n",
    "            blkCont_dict['Str'].append(str_value)\n",
    "\n",
    "        #close the file\n",
    "        mat_file.close()\n",
    "\n",
    "        # switch out the dictionary blkCont attribute\n",
    "        meta_dict['blkCont'] = blkCont_dict\n",
    "        # parse a dictionary into attributes of the class\n",
    "        for key, value in meta_dict.items():\n",
    "            setattr(self, key, value)\n",
    "        # add some stuff from Mark's class that's not in the metadata\n",
    "        self.headerSizeByte = 1024\n",
    "        self.fileExtension = 'continuous'\n",
    "        self.eventFileExtension = 'events'\n",
    "        self.signalBits = 16 # the quantization of the sampling card\n",
    "        self.dataSamplesPerRecord = 1024\n",
    "        self.maxTTLBit = 9\n",
    "        self.oe_file_path = oe_metadata_file_path.parent\n",
    "        def extract_number_from_file(filename, suffix):\n",
    "            match = re.search(r'(\\d+)\\.' + suffix + '$', filename)\n",
    "            if match:\n",
    "                return int(match.group(1))\n",
    "            else:\n",
    "                return None\n",
    "        self.channel_files = sorted([i.name for i in oe_metadata_file_path.parent.iterdir() if ('.continuous' in str(i)) & ('AUX' not in str(i)) & ('ADC' not in str(i)) ],\n",
    "                                    key=lambda x: extract_number_from_file(x, suffix='continuous'))\n",
    "        self.analog_files = sorted([i.name for i in oe_metadata_file_path.parent.iterdir() if ('AUX' in str(i)) or ('ADC' in str(i))],\n",
    "                                   key=lambda x: extract_number_from_file(x, suffix='continuous'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "oe_metadata_file_path = pathlib.Path(r'Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072\\oe_files\\2023-06-21_14-31-03\\Record Node 108\\OE_metaData.mat')\n",
    "#oe_metadata_file_path = pathlib.Path(r'Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_073\\oe_files\\2023-06-21_14-45-37\\Record Node 108\\OE_metaData.mat')\n",
    "oe = OERecording(oe_metadata_file_path=oe_metadata_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "oe.analog_files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# TODO: deal with end-of-file errors (right now when encountering the end of a datafile I get numpy broadcasting errors,\n",
    "#  should be dealt with exceptions and try steps instead.\n",
    "def get_data_current(oe, channels, startTime_ms, window_ms, convert_to_mV=True):\n",
    "    \"\"\"\n",
    "    This is a translated matlab function that efficiently retrieves data from Open-Ephys format neural recordings\n",
    "    :param oe: an OERecording class obj. with a metadata file created by the matlab class with the same name\n",
    "    :param channels: a vector of channel numbers to sample from [1XN channels]\n",
    "    :param startTime_ms: a vector of window start times [1XN] in ms\n",
    "    :param window_ms: a single value, the length of the sampling window from each startTime [ms_value]\n",
    "    :param convert_to_mV: when True, turns the output into the mV representation of the sampled data\n",
    "    :return: V_uV - an array with the shape [nChannels, nWindows, nSamples] and either the int16 / mV values\n",
    "    \"\"\"\n",
    "    windowSamples = int(np.round(window_ms / oe.sample_ms)) # round the time in ms to the nearest whole sample count\n",
    "    nWindows = len(startTime_ms) # get the number of start times provided\n",
    "    startTime_ms = np.round(startTime_ms / oe.sample_ms) * oe.sample_ms # round the start times to the nearest whole sample multiple\n",
    "    window_ms = windowSamples*oe.sample_ms # get the ms based length of the rounded window\n",
    "\n",
    "    # deal with the channel numbers:\n",
    "    if len(channels) == 0 or channels is None: #if no channels were provided\n",
    "        channels = oe.channelNumbers\n",
    "\n",
    "    if not all([c in oe.channelNumbers for c in channels]): #if requested channels do not exist in the file\n",
    "        raise ValueError('one or more of the entered channels does not exist in the recording!')\n",
    "    nCh = len(channels)\n",
    "\n",
    "    #initialize some variables for the data extraction:\n",
    "    V_uV = np.zeros(shape=(int(windowSamples),nWindows,nCh),\n",
    "                    dtype=oe.blkCont['Types'][3],\n",
    "                    order='F') #initialize the waveform matrix\n",
    "    # List to store the record indices for waveform extraction\n",
    "    p_rec_idx = []\n",
    "    # List to store the indices where reading from the file should start (one per reading window)\n",
    "    read_start_indices = []\n",
    "    records_per_trial_list = []\n",
    "    for i in range(nWindows):\n",
    "        # find the relevant record blocks in the block list:\n",
    "        p_single_trial_time_stamps = np.where((oe.allTimeStamps[0] >= (startTime_ms[0][i] - oe.recordLength)) &\n",
    "                                              (oe.allTimeStamps[0] < (startTime_ms[0][i] + window_ms)))[1]\n",
    "        read_start_indices.append(p_single_trial_time_stamps[0]) # this collects the indices to start reading from\n",
    "        single_trial_time_stamps = np.round(oe.allTimeStamps[0][p_single_trial_time_stamps] / oe.sample_ms) * oe.sample_ms  # Calculate time stamps in milliseconds based on sampling freq & record block length\n",
    "        records_per_trial = len(single_trial_time_stamps[0])  # Get the number of records per trial\n",
    "        records_per_trial_list.append(records_per_trial)\n",
    "        # This is problematic, should give me the right time index selections consistently\n",
    "        time_idx = np.tile((np.arange(oe.dataSamplesPerRecord) * oe.sample_ms).reshape(-1, 1), (1, records_per_trial)) + single_trial_time_stamps.reshape(1, -1)\n",
    "        if i==0:\n",
    "            p_rec_idx.append((time_idx >= startTime_ms[0][i]) & (time_idx < (startTime_ms[0][i] + window_ms)))  # Find time indices within the requested time window (chunks are 1024 in size so they are usually cut for most time windows, this is saved as a boolean matrix)\n",
    "        else:\n",
    "            p_rec_idx.append((time_idx >= startTime_ms[0][i]) & (time_idx < (startTime_ms[0][i] + window_ms)))\n",
    "\n",
    "        if np.sum(p_rec_idx[i]) == windowSamples + 1:  # Due to rounding issues, there may be an error when there is one sample too much - in this case the last sample is removed\n",
    "            print(f'sample removed {i}')\n",
    "            p_rec_idx[i][0, np.where(p_rec_idx[i][0, :] == 1)[0][0]] = False\n",
    "\n",
    "    p_rec_idx = np.hstack(p_rec_idx)  # Concatenate record indices into a single array\n",
    "\n",
    "    # now for the data extraction itself:\n",
    "    for i in range(nCh): # iterate over channels\n",
    "        data = np.zeros(p_rec_idx.shape, dtype=np.dtype('>i2'))  # Initialize the data array for a specific channel\n",
    "        curr_rec = 0 # for this channel, initialize the record counter\n",
    "        c_file = oe.oe_file_path / oe.channel_files[channels[i]-1] # get the path to the relevant channel file\n",
    "        with open(c_file,'rb') as fid: #open the file such that it will close when left alone\n",
    "            for j in range(nWindows): # Iterate over sampling windows\n",
    "                # use seek to go to the appropriate position in the file\n",
    "                fid.seek(int(oe.headerSizeByte + (read_start_indices[j] * oe.bytesPerRecCont) + np.sum(oe.blkBytesCont[0:3])), 0)\n",
    "                # calculate the skip size, cut in half because each int16 is 2 bytes and the matlab function takes bytes as skip\n",
    "                # (which fromfile does not, uniform datatype)\n",
    "                skip_size = int(oe.bytesPerRecCont[0][0] - oe.blkBytesCont[3][0]) // 2\n",
    "                read_size = oe.dataSamplesPerRecord\n",
    "                total_bytes = (read_size + skip_size) * records_per_trial_list[j] # calculate total element count to read\n",
    "                # read data from file in a single vector, including skip_data (Notice datatype is non-flexible in this version of the function!!!)\n",
    "                data_plus_breaks = np.fromfile(fid, dtype=np.dtype('>i2'), count=total_bytes, sep='')\n",
    "                data_plus_breaks = data_plus_breaks.reshape(int(records_per_trial_list[j]), read_size + skip_size) # reshape into an array with a column-per-record shape\n",
    "                clean_data = data_plus_breaks[:, :read_size] # slice the array to get rid of the skip_data at the end of each column (record)\n",
    "                data[:, curr_rec : curr_rec + records_per_trial_list[j]] = clean_data.T # transpose and store the current_rec data\n",
    "                curr_rec = curr_rec + records_per_trial_list[j] # move forward to the next reading window\n",
    "        # this loop exit closes the current channel file\n",
    "        data_vec = data.T[p_rec_idx.T] # vectorize the data from the channel and perform a boolean snipping of non-window samples\n",
    "        V_uV[:,:,i] = data_vec.reshape(int(windowSamples), nWindows, order='F') # put the data in the final V_uV waveform matrix\n",
    "\n",
    "    V_uV = np.transpose(V_uV,[2,1,0])\n",
    "\n",
    "    if convert_to_mV:\n",
    "        V_uV = V_uV* oe.MicrovoltsPerAD[0]\n",
    "        return V_uV\n",
    "    else:\n",
    "        return V_uV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/OE_metaData.mat')"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recursive_printer(element):\n",
    "    txt = ET.tostring(element, pretty_print=True)\n",
    "    print(str(txt))\n",
    "    print('#####')\n",
    "    if len(element) > 1:\n",
    "        for i in range(len(element)):\n",
    "            recursive_printer(element[i])\n",
    "\n",
    "tree = ET.parse(str(xml_path))\n",
    "root = tree.getroot()\n",
    "for element in root:\n",
    "    recursive_printer(element)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 29920173 into shape (10000000,3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-117-ae8b7feca7a6>\u001B[0m in \u001B[0;36mget_data_current\u001B[1;34m(oe, channels, startTime_ms, window_ms, convert_to_mV)\u001B[0m\n\u001B[0;32m     76\u001B[0m         \u001B[1;31m# this loop exit closes the current channel file\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m         \u001B[0mdata_vec\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mp_rec_idx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;31m# vectorize the data from the channel and perform a boolean snipping of non-window samples\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 78\u001B[1;33m         \u001B[0mV_uV\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata_vec\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwindowSamples\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnWindows\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'F'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# put the data in the final V_uV waveform matrix\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     79\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m     \u001B[0mV_uV\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mV_uV\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 29920173 into shape (10000000,3)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_array = get_data_current(oe,[1],[10000, 20000, 30000],[500000],True)\n",
    "data_vec = np.concatenate([data_array[0,0,:],data_array[0,1,:],data_array[0,2,:]])\n",
    "mat_vec = scipy.io.loadmat('Z:/Nimrod/HelperFiles/c_vec.mat')\n",
    "c_vec = mat_vec['comp_vec'][:,0]\n",
    "np.array_equal(c_vec,data_vec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 0.0001 s\n",
      "\n",
      "Total time: 0.0816057 s\n",
      "File: <ipython-input-16-f63137aa0b36>\n",
      "Function: get_data_current at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def get_data_current(oe, channels, startTime_ms, window_ms, convert_to_mV=True):\n",
      "     2                                               \"\"\"\n",
      "     3                                               This is a translated matlab function that efficiently retrieves data from Open-Ephys format neural recordings\n",
      "     4                                               :param oe: an OERecording class obj. with a metadata file created by the matlab class with the same name\n",
      "     5                                               :param channels: a vector of channel numbers to sample from [1XN channels]\n",
      "     6                                               :param startTime_ms: a vector of window start times [1XN] in ms\n",
      "     7                                               :param window_ms: a single value, the length of the sampling window from each startTime [ms_value]\n",
      "     8                                               :param convert_to_mV: when True, turns the output into the mV representation of the sampled data\n",
      "     9                                               :return: V_uV - an array with the shape [nChannels, nWindows, nSamples] and either the int16 / mV values\n",
      "    10                                               \"\"\"\n",
      "    11         1          0.7      0.7      0.1      windowSamples = int(np.round(window_ms/oe.sample_ms)) # round the time in ms to the nearest whole sample count\n",
      "    12         1          0.0      0.0      0.0      nWindows = len(startTime_ms) # get the number of start times provided\n",
      "    13         1          0.2      0.2      0.0      startTime_ms = np.round(startTime_ms / oe.sample_ms) * oe.sample_ms # round the start times to the nearest whole sample multiple\n",
      "    14         1          0.0      0.0      0.0      window_ms = windowSamples*oe.sample_ms # get the ms based length of the rounded window\n",
      "    15                                           \n",
      "    16                                               # deal with the channel numbers:\n",
      "    17         1          0.0      0.0      0.0      if len(channels) == 0 or channels is None: #if no channels were provided\n",
      "    18                                                   channels = oe.channelNumbers\n",
      "    19                                           \n",
      "    20         1          0.3      0.3      0.0      if not all([c in oe.channelNumbers for c in channels]): #if requested channels do not exist in the file\n",
      "    21                                                   raise ValueError('one or more of the entered channels does not exist in the recording!')\n",
      "    22         1          0.0      0.0      0.0      nCh = len(channels)\n",
      "    23                                           \n",
      "    24                                               #initialize some variables for the data extraction:\n",
      "    25         1          3.0      3.0      0.4      V_uV = np.zeros(shape=(int(windowSamples),nWindows,nCh), dtype=oe.blkCont['Types'][3], order='F') #initialize the waveform matrix\n",
      "    26                                           \n",
      "    27         1          0.0      0.0      0.0      p_rec_idx = []  # List to store the record indices for waveform extraction\n",
      "    28         1          0.0      0.0      0.0      read_start_indices = [] # List to store the indices where reading from the file should start (one per reading window)\n",
      "    29         1          0.0      0.0      0.0      records_per_trial_list = []\n",
      "    30         1          0.0      0.0      0.0      for i in range(nWindows):\n",
      "    31                                                   # find the relevant record blocks in the block list:\n",
      "    32         1          4.3      4.3      0.5          p_single_trial_time_stamps = np.where((oe.allTimeStamps[0] >= (startTime_ms[0][i] - oe.recordLength)) & (oe.allTimeStamps[0] < (startTime_ms[0][i] + window_ms)))[1]\n",
      "    33         1          0.0      0.0      0.0          read_start_indices.append(p_single_trial_time_stamps[0]) # this collects the indices to start reading from\n",
      "    34         1          0.3      0.3      0.0          single_trial_time_stamps = np.round(oe.allTimeStamps[0][p_single_trial_time_stamps] / oe.sample_ms) * oe.sample_ms  # Calculate time stamps in milliseconds based on sampling freq & record block length\n",
      "    35         1          0.0      0.0      0.0          records_per_trial = len(single_trial_time_stamps[0])  # Get the number of records per trial\n",
      "    36         1          0.0      0.0      0.0          records_per_trial_list.append(records_per_trial)\n",
      "    37                                                   # This is problematic, should give me the right time index selections consistently\n",
      "    38         1          6.7      6.7      0.8          time_idx = np.tile((np.arange(oe.dataSamplesPerRecord) * oe.sample_ms).reshape(-1, 1), (1, records_per_trial)) + single_trial_time_stamps.reshape(1, -1)\n",
      "    39         1          0.0      0.0      0.0          if i==0:\n",
      "    40         1          1.3      1.3      0.2              p_rec_idx.append((time_idx >= startTime_ms[0][i]) & (time_idx < (startTime_ms[0][i] + window_ms)))  # Find time indices within the requested time window (chunks are 1024 in size so they are usually cut for most time windows, this is saved as a boolean matrix)\n",
      "    41                                                   else:\n",
      "    42                                                       p_rec_idx.append((time_idx >= startTime_ms[0][i]) & (time_idx < (startTime_ms[0][i] + window_ms)))\n",
      "    43                                           \n",
      "    44         1          1.2      1.2      0.1          if np.sum(p_rec_idx[i]) == windowSamples + 1:  # Due to rounding issues, there may be an error when there is one sample too much - in this case the last sample is removed\n",
      "    45                                                       print(f'sample removed {i}')\n",
      "    46                                                       p_rec_idx[i][0, np.where(p_rec_idx[i][0, :] == 1)[0][0]] = False\n",
      "    47                                           \n",
      "    48         1          0.0      0.0      0.0          time_idx = time_idx.T\n",
      "    49                                                   #p_out_idx.append(np.round((time_idx[p_rec_idx[i].T] - startTime_ms[0][i]) / oe.sample_ms) + windowSamples * i)  # Calculate the output indices for waveform extraction\n",
      "    50                                           \n",
      "    51                                               # if p_out_idx[0][0][0] == -1:  # Special case handling where the first index is 0 (due to rounding) -> might be redundent with python\n",
      "    52                                               #     p_out_idx[0] += 1\n",
      "    53                                           \n",
      "    54         1          0.4      0.4      0.0      p_rec_idx = np.hstack(p_rec_idx)  # Concatenate record indices into a single array\n",
      "    55                                               # p_out_idx = np.hstack(p_out_idx)  # Concatenate output indices into a single array\n",
      "    56                                           \n",
      "    57                                           \n",
      "    58                                               # now for the data extraction itself:\n",
      "    59         4          0.0      0.0      0.0      for i in range(nCh): # iterate over channels\n",
      "    60         4          0.7      0.2      0.1          data = np.zeros(p_rec_idx.shape, dtype=np.dtype('>i2'))  # Initialize the data array for a specific channel\n",
      "    61         4          0.0      0.0      0.0          curr_rec = 0 # for this channel, initialize the record counter\n",
      "    62         4          2.0      0.5      0.2          c_file = oe.oe_file_path / oe.channel_files[channels[i]-1] # get the path to the relevant channel file\n",
      "    63         4        104.9     26.2     12.9          with open(c_file,'rb') as fid: #open the file such that it will close when left alone\n",
      "    64         4          4.6      1.2      0.6              for j in range(nWindows): # Iterate over sampling windows\n",
      "    65         4          2.4      0.6      0.3                  fid.seek(int(oe.headerSizeByte + (read_start_indices[j] * oe.bytesPerRecCont) + np.sum(oe.blkBytesCont[0:3])), 0) # use seek to go to the appropriate position in the file\n",
      "    66         4          0.2      0.0      0.0                  skip_size = int(oe.bytesPerRecCont[0][0] - oe.blkBytesCont[3][0]) // 2 # calculate the skip size, cut in half because each int16 is 2 bytes and the matlab function takes bytes as skip\n",
      "    67                                                           # (which fromfile does not, uniform datatype)\n",
      "    68         4          0.0      0.0      0.0                  read_size = oe.dataSamplesPerRecord\n",
      "    69         4          0.0      0.0      0.0                  total_bytes = (read_size + skip_size) * records_per_trial_list[j] # calculate total element count to read\n",
      "    70         4        639.7    159.9     78.4                  data_plus_breaks = np.fromfile(fid, dtype=np.dtype('>i2'), count=total_bytes, sep='') # read data from file in a single vector, including skip_data\n",
      "    71         4          0.3      0.1      0.0                  data_plus_breaks = data_plus_breaks.reshape(int(records_per_trial_list[j]), read_size + skip_size) # reshape into an array with a column-per-record shape\n",
      "    72         4          0.2      0.0      0.0                  clean_data = data_plus_breaks[:, :read_size] # slice the array to get rid of the skip_data at the end of each column (record)\n",
      "    73         4         13.8      3.5      1.7                  data[:, curr_rec : curr_rec + records_per_trial_list[j]] = clean_data.T # transpose and store the current_rec data\n",
      "    74         4          0.0      0.0      0.0                  curr_rec = curr_rec + records_per_trial_list[j] # move forward to the next reading window\n",
      "    75                                                   # this loop exit closes the current channel file\n",
      "    76         4         17.4      4.3      2.1          data_vec = data.T[p_rec_idx.T] # vectorize the data from the channel and perform a boolean snipping of non-window samples\n",
      "    77         4          2.3      0.6      0.3          V_uV[:,:,i] = data_vec.reshape(int(windowSamples), nWindows, order='F') # put the data in the final V_uV waveform matrix\n",
      "    78                                           \n",
      "    79         1          0.2      0.2      0.0      V_uV = np.transpose(V_uV,[2,1,0])\n",
      "    80                                           \n",
      "    81         1          0.0      0.0      0.0      if convert_to_mV:\n",
      "    82         1          8.9      8.9      1.1          V_uV = V_uV* oe.MicrovoltsPerAD[0]\n",
      "    83         1          0.0      0.0      0.0          return V_uV\n",
      "    84                                               else:\n",
      "    85                                                   return V_uV\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "None"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import line_profiler\n",
    "from IPython.display import display\n",
    "profiler = line_profiler.LineProfiler()\n",
    "profiler.add_function(get_data_current)\n",
    "profiler.run(\"get_data_current(oe,[1,5,10,20],[10000],[5000],True)\")\n",
    "display(profiler.print_stats(output_unit=1e-4))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(c_vec[:,0],data_vec)\n",
    "#np.shape(c_vec[:,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# check stuff here:\n",
    "# rounding the inputs to clean multiples of the sample timestep:\n",
    "channels=[1]\n",
    "startTime_ms = [10000, 20000]\n",
    "window_ms = 5000\n",
    "\n",
    "windowSamples = int(np.round(window_ms/oe.sample_ms)) # round the time in ms to the nearest whole sample count\n",
    "nWindows = len(startTime_ms) # get the number of start times provided\n",
    "startTime_ms = np.round(startTime_ms / oe.sample_ms) * oe.sample_ms # round the start times to the nearest whole sample multiple\n",
    "window_ms = windowSamples*oe.sample_ms # get the ms based length of the rounded window\n",
    "\n",
    "# deal with the channel numbers:\n",
    "if len(channels) == 0 or channels is None: #if no channels were provided\n",
    "    channels = oe.channelNumbers\n",
    "\n",
    "if not all([c in oe.channelNumbers for c in channels]): #if requested channels do not exist in the file\n",
    "    raise ValueError('one or more of the entered channels does not exist in the recording!')\n",
    "nCh = len(channels)\n",
    "\n",
    "#initialize some variables for the data extraction:\n",
    "V_uV = np.zeros(shape=(int(windowSamples),nWindows,nCh), dtype=oe.blkCont['Types'][3], order='F') #initialize the waveform matrix\n",
    "\n",
    "p_out_idx = []  # List to store the output indices for waveform extraction\n",
    "p_rec_idx = []  # List to store the record indices for waveform extraction\n",
    "read_start_indices = [] # List to store the indices where reading from the file should start (one per reading window)\n",
    "records_per_trial_list = []\n",
    "for i in range(nWindows):\n",
    "    # find the relevant blocks in the block list:\n",
    "    p_single_trial_time_stamps = np.where((oe.allTimeStamps[0] >= (startTime_ms[0][i] - oe.recordLength)) & (oe.allTimeStamps[0] < (startTime_ms[0][i] + window_ms)))[1]\n",
    "    read_start_indices.append(p_single_trial_time_stamps[0])\n",
    "    # TODO: deal with the edge case where the start index is at 0\n",
    "    #\n",
    "    # if p_single_trial_time_stamps[0] == 0:\n",
    "    #     read_start_indices.append(p_single_trial_time_stamps[0])\n",
    "    # else:\n",
    "    #     read_start_indices.append(p_single_trial_time_stamps[0])\n",
    "\n",
    "    single_trial_time_stamps = np.round(oe.allTimeStamps[0][p_single_trial_time_stamps] / oe.sample_ms) * oe.sample_ms  # Calculate time stamps in milliseconds\n",
    "    records_per_trial = len(single_trial_time_stamps[0])  # Get the number of records per trial\n",
    "    records_per_trial_list.append(records_per_trial)\n",
    "    # This is problematic, should give me the right time index selections consistently\n",
    "    time_idx = np.tile((np.arange(oe.dataSamplesPerRecord) * oe.sample_ms).reshape(-1, 1), (1, records_per_trial)) + single_trial_time_stamps.reshape(1, -1)\n",
    "    if i==0:\n",
    "        p_rec_idx.append((time_idx >= startTime_ms[0][i]) & (time_idx < (startTime_ms[0][i] + window_ms)))  # Find time indices within the requested time window (chunks are 1024 in size so they are usually cut for most time windows, this is saved as a boolean matrix)\n",
    "    else:\n",
    "        p_rec_idx.append((time_idx >= startTime_ms[0][i]) & (time_idx < (startTime_ms[0][i] + window_ms)))\n",
    "\n",
    "    if np.sum(p_rec_idx[i]) == windowSamples + 1:  # Due to rounding issues, there may be an error when there is one sample too much - in this case the last sample is removed\n",
    "        print(f'sample removed {i}')\n",
    "        p_rec_idx[i][0, np.where(p_rec_idx[i][0, :] == 1)[0][0]] = False\n",
    "\n",
    "    time_idx = time_idx.T\n",
    "    #p_out_idx.append(np.round((time_idx[p_rec_idx[i].T] - startTime_ms[0][i]) / oe.sample_ms) + windowSamples * i)  # Calculate the output indices for waveform extraction\n",
    "\n",
    "# if p_out_idx[0][0][0] == -1:  # Special case handling where the first index is 0 (due to rounding) -> might be redundent with python\n",
    "#     p_out_idx[0] += 1\n",
    "\n",
    "p_rec_idx = np.hstack(p_rec_idx)  # Concatenate record indices into a single array\n",
    "# p_out_idx = np.hstack(p_out_idx)  # Concatenate output indices into a single array\n",
    "\n",
    "\n",
    "# now for the data extraction itself:\n",
    "# first, iterate over channels:\n",
    "for i in range(nCh):\n",
    "    data = np.zeros(p_rec_idx.shape, dtype=np.dtype('>i2'))  # Initialize the data array for a specific channel\n",
    "    curr_rec = 0\n",
    "    c_file = oe.oe_file_path / oe.channel_files[channels[i]-1] # get the channel file to read from\n",
    "    with open(c_file,'rb') as fid: #open the file such that it will close when left alone\n",
    "        for j in range(nWindows):\n",
    "            fid.seek(int(oe.headerSizeByte + (read_start_indices[j] * oe.bytesPerRecCont) + np.sum(oe.blkBytesCont[0:3])), 0) # use seek to go to the appropriate position in the file\n",
    "            skip_size = int(oe.bytesPerRecCont[0][0] - oe.blkBytesCont[3][0]) // 2 # calculate the skip size, cut in half because each int16 is 2 bytes and the matlab function takes bytes as skip\n",
    "            # (which fromfile does not, uniform datatype)\n",
    "            read_size = oe.dataSamplesPerRecord\n",
    "            total_bytes = (read_size + skip_size) * records_per_trial_list[j] # calculate total element count to read\n",
    "            data_plus_breaks = np.fromfile(fid, dtype=np.dtype('>i2'), count=total_bytes, sep='') # read data from file in a single vector, including skip_data\n",
    "            data_plus_breaks = data_plus_breaks.reshape(int(records_per_trial_list[j]), read_size + skip_size) # reshape into an array with a column per-record\n",
    "            clean_data = data_plus_breaks[:, :read_size] # slice the array to get rid of the skip_data\n",
    "            data[:, curr_rec : curr_rec + records_per_trial_list[j]] = clean_data.T\n",
    "            curr_rec = curr_rec + records_per_trial_list[j]\n",
    "    data_vec = data.T[p_rec_idx.T] # vectorize the data and perform a boolean snipping of non-window samples\n",
    "    if len(data_vec) < int(windowSamples) * nWindows:\n",
    "        print(f'The requested data segment between {read_start_indices [j]} ms and {read_start_indices[j] + window_ms[0][0]} ms '\n",
    "              f'exceeds the recording length, and will be 0-padded to fit the other windows')\n",
    "        num_zeros = (int(windowSamples) * nWindows) - len(data_vec)\n",
    "        data_vec = np.pad(data_vec,(0, num_zeros), mode='constant')\n",
    "    V_uV[:,:,i] = data_vec.reshape(int(windowSamples), nWindows, order='F') # put the data in the final V_uV waveform matrix\n",
    "\n",
    "V_uV = np.transpose(V_uV,[2,1,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "array([180, 172, 132, ...,   0,   0,   0], dtype=int16)"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_zeros = int(windowSamples)*nWindows - len(data_vec)\n",
    "padded_data_vec = np.pad(data_vec,(0,num_zeros),mode='constant')\n",
    "padded_data_vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[10000.  , 10000.05, 10000.1 , ..., 14999.85, 14999.9 , 14999.95],\n       [20000.  , 20000.05, 20000.1 , ..., 24999.85, 24999.9 , 24999.95]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "timestamps = np.tile(np.arange(windowSamples) * oe.sample_ms,(nWindows,1))\n",
    "start_times = np.tile(startTime_ms.T,windowSamples)\n",
    "timestamps = timestamps+start_times\n",
    "timestamps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[10000., 20000.]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startTime_ms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [5.000e-02, 5.000e-02, 5.000e-02, ..., 5.000e-02, 5.000e-02,\n        5.000e-02],\n       [1.000e-01, 1.000e-01, 1.000e-01, ..., 1.000e-01, 1.000e-01,\n        1.000e-01],\n       ...,\n       [5.105e+01, 5.105e+01, 5.105e+01, ..., 5.105e+01, 5.105e+01,\n        5.105e+01],\n       [5.110e+01, 5.110e+01, 5.110e+01, ..., 5.110e+01, 5.110e+01,\n        5.110e+01],\n       [5.115e+01, 5.115e+01, 5.115e+01, ..., 5.115e+01, 5.115e+01,\n        5.115e+01]])"
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector comparison\n",
    "py_vec = data_vec * oe.MicrovoltsPerAD[0]\n",
    "mat_vec = scipy.io.loadmat(pathlib.Path('Z:/Nimrod/HelperFiles/c_vec.mat'))\n",
    "c_vec = mat_vec['c_vec']\n",
    "c_vec = c_vec[:,0]\n",
    "#c_vec[0] = 111\n",
    "mat_vec = np.vstack((py_vec,c_vec))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['100_RhythmData_ADC1.continuous',\n '100_RhythmData_ADC2.continuous',\n '100_RhythmData_ADC3.continuous',\n '100_RhythmData_ADC4.continuous',\n '100_RhythmData_ADC5.continuous',\n '100_RhythmData_ADC6.continuous',\n '100_RhythmData_ADC7.continuous',\n '100_RhythmData_ADC8.continuous',\n '100_RhythmData_C1-AUX1.continuous',\n '100_RhythmData_C1-AUX2.continuous',\n '100_RhythmData_C1-AUX3.continuous']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_vec.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [5.000e-02, 5.000e-02, 5.000e-02, ..., 5.000e-02, 5.000e-02,\n        5.000e-02],\n       [1.000e-01, 1.000e-01, 1.000e-01, ..., 1.000e-01, 1.000e-01,\n        1.000e-01],\n       ...,\n       [5.105e+01, 5.105e+01, 5.105e+01, ..., 5.105e+01, 5.105e+01,\n        5.105e+01],\n       [5.110e+01, 5.110e+01, 5.110e+01, ..., 5.110e+01, 5.110e+01,\n        5.110e+01],\n       [5.115e+01, 5.115e+01, 5.115e+01, ..., 5.115e+01, 5.115e+01,\n        5.115e+01]])"
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p_rec_idx.append((time_idx >= startTime_ms[0][i]) & (time_idx < (startTime_ms[0][i] + window_ms)))\n",
    "mat_vec.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['100_RhythmData_ADC1.continuous',\n '100_RhythmData_ADC2.continuous',\n '100_RhythmData_ADC3.continuous',\n '100_RhythmData_ADC4.continuous',\n '100_RhythmData_ADC5.continuous',\n '100_RhythmData_ADC6.continuous',\n '100_RhythmData_ADC7.continuous',\n '100_RhythmData_ADC8.continuous',\n '100_RhythmData_C1-AUX1.continuous',\n '100_RhythmData_C1-AUX2.continuous',\n '100_RhythmData_C1-AUX3.continuous']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_idx.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [5.000e-02, 5.000e-02, 5.000e-02, ..., 5.000e-02, 5.000e-02,\n        5.000e-02],\n       [1.000e-01, 1.000e-01, 1.000e-01, ..., 1.000e-01, 1.000e-01,\n        1.000e-01],\n       ...,\n       [5.105e+01, 5.105e+01, 5.105e+01, ..., 5.105e+01, 5.105e+01,\n        5.105e+01],\n       [5.110e+01, 5.110e+01, 5.110e+01, ..., 5.110e+01, 5.110e+01,\n        5.110e+01],\n       [5.115e+01, 5.115e+01, 5.115e+01, ..., 5.115e+01, 5.115e+01,\n        5.115e+01]])"
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_start_indices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['100_RhythmData_ADC1.continuous',\n '100_RhythmData_ADC2.continuous',\n '100_RhythmData_ADC3.continuous',\n '100_RhythmData_ADC4.continuous',\n '100_RhythmData_ADC5.continuous',\n '100_RhythmData_ADC6.continuous',\n '100_RhythmData_ADC7.continuous',\n '100_RhythmData_ADC8.continuous',\n '100_RhythmData_C1-AUX1.continuous',\n '100_RhythmData_C1-AUX2.continuous',\n '100_RhythmData_C1-AUX3.continuous']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = V_uV * oe.MicrovoltsPerAD[0]\n",
    "a[0,0,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [5.000e-02, 5.000e-02, 5.000e-02, ..., 5.000e-02, 5.000e-02,\n        5.000e-02],\n       [1.000e-01, 1.000e-01, 1.000e-01, ..., 1.000e-01, 1.000e-01,\n        1.000e-01],\n       ...,\n       [5.105e+01, 5.105e+01, 5.105e+01, ..., 5.105e+01, 5.105e+01,\n        5.105e+01],\n       [5.110e+01, 5.110e+01, 5.110e+01, ..., 5.110e+01, 5.110e+01,\n        5.110e+01],\n       [5.115e+01, 5.115e+01, 5.115e+01, ..., 5.115e+01, 5.115e+01,\n        5.115e+01]])"
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_rec_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['100_RhythmData_ADC1.continuous',\n '100_RhythmData_ADC2.continuous',\n '100_RhythmData_ADC3.continuous',\n '100_RhythmData_ADC4.continuous',\n '100_RhythmData_ADC5.continuous',\n '100_RhythmData_ADC6.continuous',\n '100_RhythmData_ADC7.continuous',\n '100_RhythmData_ADC8.continuous',\n '100_RhythmData_C1-AUX1.continuous',\n '100_RhythmData_C1-AUX2.continuous',\n '100_RhythmData_C1-AUX3.continuous']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [5.000e-02, 5.000e-02, 5.000e-02, ..., 5.000e-02, 5.000e-02,\n        5.000e-02],\n       [1.000e-01, 1.000e-01, 1.000e-01, ..., 1.000e-01, 1.000e-01,\n        1.000e-01],\n       ...,\n       [5.105e+01, 5.105e+01, 5.105e+01, ..., 5.105e+01, 5.105e+01,\n        5.105e+01],\n       [5.110e+01, 5.110e+01, 5.110e+01, ..., 5.110e+01, 5.110e+01,\n        5.110e+01],\n       [5.115e+01, 5.115e+01, 5.115e+01, ..., 5.115e+01, 5.115e+01,\n        5.115e+01]])"
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "d = get_data_current(oe, [1,5], [0, 10000, 20000], 500)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['100_RhythmData_ADC1.continuous',\n '100_RhythmData_ADC2.continuous',\n '100_RhythmData_ADC3.continuous',\n '100_RhythmData_ADC4.continuous',\n '100_RhythmData_ADC5.continuous',\n '100_RhythmData_ADC6.continuous',\n '100_RhythmData_ADC7.continuous',\n '100_RhythmData_ADC8.continuous',\n '100_RhythmData_C1-AUX1.continuous',\n '100_RhythmData_C1-AUX2.continuous',\n '100_RhythmData_C1-AUX3.continuous']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tester = V_uV * oe.MicrovoltsPerAD[0]\n",
    "prec_tester = p_rec_idx\n",
    "p = pathlib.Path(r'Z:/Nimrod/HelperFiles/dataTester.mat')\n",
    "scipy.io.savemat(p,{'data':data_tester, 'prec':prec_tester})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [5.000e-02, 5.000e-02, 5.000e-02, ..., 5.000e-02, 5.000e-02,\n        5.000e-02],\n       [1.000e-01, 1.000e-01, 1.000e-01, ..., 1.000e-01, 1.000e-01,\n        1.000e-01],\n       ...,\n       [5.105e+01, 5.105e+01, 5.105e+01, ..., 5.105e+01, 5.105e+01,\n        5.105e+01],\n       [5.110e+01, 5.110e+01, 5.110e+01, ..., 5.110e+01, 5.110e+01,\n        5.110e+01],\n       [5.115e+01, 5.115e+01, 5.115e+01, ..., 5.115e+01, 5.115e+01,\n        5.115e+01]])"
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_uV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n        0.000e+00],\n       [5.000e-02, 5.000e-02, 5.000e-02, ..., 5.000e-02, 5.000e-02,\n        5.000e-02],\n       [1.000e-01, 1.000e-01, 1.000e-01, ..., 1.000e-01, 1.000e-01,\n        1.000e-01],\n       ...,\n       [5.105e+01, 5.105e+01, 5.105e+01, ..., 5.105e+01, 5.105e+01,\n        5.105e+01],\n       [5.110e+01, 5.110e+01, 5.110e+01, ..., 5.110e+01, 5.110e+01,\n        5.110e+01],\n       [5.115e+01, 5.115e+01, 5.115e+01, ..., 5.115e+01, 5.115e+01,\n        5.115e+01]])"
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_rec_idx.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['100_RhythmData_ADC1.continuous',\n '100_RhythmData_ADC2.continuous',\n '100_RhythmData_ADC3.continuous',\n '100_RhythmData_ADC4.continuous',\n '100_RhythmData_ADC5.continuous',\n '100_RhythmData_ADC6.continuous',\n '100_RhythmData_ADC7.continuous',\n '100_RhythmData_ADC8.continuous',\n '100_RhythmData_C1-AUX1.continuous',\n '100_RhythmData_C1-AUX2.continuous',\n '100_RhythmData_C1-AUX3.continuous']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data[np.where(p_rec_idx)]\n",
    "data_vec = data.flatten('F')[p_rec_idx.flatten('F')]\n",
    "data_vec.reshape(np.shape(V_uV)[:2],order='F')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  42,  180,  -47],\n       [  71,  172,  -27],\n       [ 118,  132,    3],\n       ...,\n       [-205,   76,  154],\n       [-234,  224,  154],\n       [-193,  266,  258]], dtype=int16)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['100_RhythmData_ADC1.continuous',\n '100_RhythmData_ADC2.continuous',\n '100_RhythmData_ADC3.continuous',\n '100_RhythmData_ADC4.continuous',\n '100_RhythmData_ADC5.continuous',\n '100_RhythmData_ADC6.continuous',\n '100_RhythmData_ADC7.continuous',\n '100_RhythmData_ADC8.continuous',\n '100_RhythmData_C1-AUX1.continuous',\n '100_RhythmData_C1-AUX2.continuous',\n '100_RhythmData_C1-AUX3.continuous']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(p_rec_idx.shape)\n",
    "print(V_uV.shape)\n",
    "print(data.shape)\n",
    "print(records_per_trial_list)\n",
    "a = V_uV.flatten()\n",
    "a = np.zeros(60000)\n",
    "int(oe.bytesPerRecCont[0][0] - oe.blkBytesCont[3][0])\n",
    "oe.headerSizeByte + (read_start_indices[1] * oe.bytesPerRecCont) + np.sum(oe.blkBytesCont[0:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  42,  180,  -47],\n       [  71,  172,  -27],\n       [ 118,  132,    3],\n       ...,\n       [-205,   76,  154],\n       [-234,  224,  154],\n       [-193,  266,  258]], dtype=int16)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "Original function:\n",
    "function [V_uV,t_ms]=getData(obj,channels,startTime_ms,window_ms)\n",
    "            %Extract Neuralynx recording data from file to memory\n",
    "            %Usage: [V_uV,t_ms]=obj.getData(channels,startTime_ms,window_ms);\n",
    "            %Input : channels - [1xN] a vector with channel numbers as appearing in the data folder files\n",
    "            %        startTime_ms - a vector [1xN] of start times [ms]. If Inf, returns all time stamps in recording (startTime_ms is not considered)\n",
    "            %        window_ms - a scalar [1x1] with the window duration [ms].\n",
    "            %Output: V_us - A 3D matrix [nChannels x nTrials x nSamples] with voltage waveforms across specified channels and trials\n",
    "            %        t_ms - A time vector relative to recording start (t=0 at start)\n",
    "\n",
    "            windowSamples=round(window_ms/obj.sample_ms);\n",
    "            nWindows=numel(startTime_ms);\n",
    "            startTime_ms=round(startTime_ms/obj.sample_ms)*obj.sample_ms;\n",
    "            window_ms=windowSamples*obj.sample_ms;\n",
    "\n",
    "            if isempty(channels) %if no channels are entered, get all channels\n",
    "                channels=obj.channelNumbers;\n",
    "            end\n",
    "            if ~all(ismember(channels,obj.channelNumbers))\n",
    "                error('The entered channel number does not exist in the recording!');\n",
    "            end\n",
    "            nCh=numel(channels);\n",
    "\n",
    "            V_uV=zeros(windowSamples,nWindows,nCh,obj.blkCont(4).Types); %initialize waveform matrix\n",
    "            pOutIdx=cell(nWindows,1);\n",
    "            pRecIdx=cell(nWindows,1);\n",
    "            %generate time stamps for block waveform extraction and extract waveforms from file\n",
    "            %clear pOutIdx\n",
    "            for i=1:nWindows\n",
    "                pSingleTrialTimeStamps{i}=find(obj.allTimeStamps>=startTime_ms(i)-obj.recordLength & obj.allTimeStamps<(startTime_ms(i)+window_ms)); %find relevant blocks in block list\n",
    "                singleTrialTimeStamps=round(obj.allTimeStamps(pSingleTrialTimeStamps{i})/obj.sample_ms)*obj.sample_ms; %calculate time stamps in milliseconds\n",
    "                recordsPerTrial(i)=numel(singleTrialTimeStamps);\n",
    "                timeIdx=bsxfun(@plus,(0:obj.dataSamplesPerRecord-1)*obj.sample_ms,singleTrialTimeStamps); % create a matrix for the times of every sample in ms\n",
    "                pRecIdx{i,:}=(timeIdx>=startTime_ms(i)) & timeIdx<(startTime_ms(i)+window_ms); %find time indices within the requested time window (chuncks are 1024 in size so they are usually cut for most time windows)\n",
    "\n",
    "                %maybe better to replace with \"if pOutIdx{i,1}==0\"\n",
    "                if sum(sum(pRecIdx{i,:}(:)))==windowSamples+1 %due to rounding issues, there may be an error when there is one sample too much - in this case the last sample is removed\n",
    "                    pRecIdx{i,:}(1,find(pRecIdx{i,:}(1,:)==1,1,'first'))=false;\n",
    "                end\n",
    "\n",
    "                timeIdx=timeIdx';\n",
    "                pOutIdx{i,1}=round((timeIdx(pRecIdx{i,:}')-startTime_ms(i))/obj.sample_ms)+windowSamples*(i-1); %round should not be changed to floor or ceil - it creates a weird artifact\n",
    "            end\n",
    "            %this solved a special case that may not be needed anymore - check if the future if can be removed\n",
    "            if pOutIdx{1}(1)==0\n",
    "                pOutIdx{1}=pOutIdx{1}+1;\n",
    "            end\n",
    "            pRecIdx=cell2mat(pRecIdx);\n",
    "            pOutIdx=cell2mat(pOutIdx);\n",
    "\n",
    "            %}\n",
    "\n",
    "            for i=1:nCh\n",
    "                data=zeros(size(pRecIdx),'int16')';currRec=1;\n",
    "                for j=1:nWindows\n",
    "                    if ~isempty(pSingleTrialTimeStamps{j})\n",
    "                        fseek(obj.fid(obj.n2s(channels(i))),obj.headerSizeByte+(pSingleTrialTimeStamps{j}(1)-1)*obj.bytesPerRecCont+sum(obj.blkBytesCont(1:3)),'bof'); %(64+32+32+32)/8=20\n",
    "                        data(:,(1:recordsPerTrial(j))+currRec-1)=fread(obj.fid(obj.n2s(channels(i))), [obj.dataSamplesPerRecord recordsPerTrial(j)], '1024*int16',obj.bytesPerRecCont - obj.blkBytesCont(4),'b');\n",
    "                        currRec=currRec+recordsPerTrial(j);\n",
    "                    else\n",
    "                        disp('requested time stamp outside recording range!');\n",
    "                    end\n",
    "                end\n",
    "                V_uV(pOutIdx+(i-1)*nWindows*windowSamples)=data(pRecIdx');\n",
    "            end\n",
    "\n",
    "            if obj.convertData2Double\n",
    "                V_uV = permute(double(V_uV) * obj.MicrovoltsPerAD(1) ,[3 2 1]);\n",
    "            else\n",
    "                V_uV = permute(V_uV,[3 2 1]);\n",
    "            end\n",
    "\n",
    "            if nargout==2\n",
    "                t_ms=(1:windowSamples)*(1e3/obj.samplingFrequency(1));\n",
    "            end\n",
    "        end\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# get to the blkCont mat and reform it from reference instances\n",
    "blkCont_dict = {\n",
    "    'Repeat':[],\n",
    "    'Types':[],\n",
    "    'Str':[]\n",
    "}\n",
    "mat_file = h5py.File(oe_metadata_file_path)\n",
    "blkCont_group = mat_file['metaData/blkCont']\n",
    "for i in blkCont_group['Repeat']:\n",
    "    res = np.array(mat_file[i[0]][0])\n",
    "    blkCont_dict['Repeat'].append(res[0])\n",
    "\n",
    "for i in blkCont_group['Types']:\n",
    "    res = np.array((mat_file[i[0]]))\n",
    "    str_array = np.vectorize(chr)(res).flatten()\n",
    "    str_value = ''.join(str_array.flatten())\n",
    "    blkCont_dict['Types'].append(str_value)\n",
    "\n",
    "for i in blkCont_group['Str']:\n",
    "    res = np.array(mat_file[i[0]])\n",
    "    str_array = np.vectorize(chr)(res).flatten()\n",
    "    str_value = ''.join(str_array.flatten())\n",
    "    blkCont_dict['Str'].append(str_value)\n",
    "\n",
    "mat_file.close()\n",
    "print(blkCont_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "pd.DataFrame(data=blkCont_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# necessary attributes for get_data:\n",
    "channelNumbers - V\n",
    "blkCont - V\n",
    "allTimeStamps - V\n",
    "recordLength - V\n",
    "sample_ms - V\n",
    "dataSamplesPerRecord - V\n",
    "n2s - V\n",
    "headerSizeByte - V\n",
    "bytesPerRecCont - V\n",
    "blkBytesCont - V\n",
    "MicrovoltsPerAD - V\n",
    "samplingFrequency - V"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def parse_hdf5_file(filename):\n",
    "    def parse_group(group):\n",
    "        result = {}\n",
    "        for key, value in group.items():\n",
    "            if isinstance(value, h5py.Dataset):\n",
    "                result[key] = value[()]  # Convert dataset to numpy array\n",
    "            elif isinstance(value, h5py.Group):\n",
    "                result[key] = parse_group(value)  # Recursively parse nested group\n",
    "            else:\n",
    "                result[key] = value  # For other types, include them as-is\n",
    "        return result\n",
    "\n",
    "    def resolve_reference(file, reference):\n",
    "        obj = file[reference]\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            return parse_group(obj)\n",
    "        elif isinstance(obj, h5py.Dataset):\n",
    "            return obj[()]\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def resolve_references(file, dataset):\n",
    "        if h5py.check_dtype(ref=dataset.dtype):\n",
    "            return np.array([resolve_reference(file, ref) for ref in dataset])\n",
    "        else:\n",
    "            return dataset\n",
    "\n",
    "    with h5py.File(filename, 'r') as file:\n",
    "        result = parse_group(file)\n",
    "        for key, value in result.items():\n",
    "            if isinstance(value, np.ndarray):\n",
    "                result[key] = resolve_references(file, value)\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['100_RhythmData_ADC1.continuous',\n '100_RhythmData_ADC2.continuous',\n '100_RhythmData_ADC3.continuous',\n '100_RhythmData_ADC4.continuous',\n '100_RhythmData_ADC5.continuous',\n '100_RhythmData_ADC6.continuous',\n '100_RhythmData_ADC7.continuous',\n '100_RhythmData_ADC8.continuous',\n '100_RhythmData_C1-AUX1.continuous',\n '100_RhythmData_C1-AUX2.continuous',\n '100_RhythmData_C1-AUX3.continuous']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[i.name for i in oe_metadata_file_path.parent.iterdir() if ('AUX' in str(i)) or ('ADC' in str(i)) ]\n",
    "sorted([i.name for i in oe_metadata_file_path.parent.iterdir() if ('AUX' in str(i)) or ('ADC' in str(i))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "result = parse_hdf5_file(oe_metadata_file_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ADBitVolts': array([0, 0], dtype=uint64),\n 'MicrovoltsPerAD': array([[0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195],\n        [0.195]]),\n 'MicrovoltsPerADAnalog': array([[ 37.4  ],\n        [ 37.4  ],\n        [ 37.4  ],\n        [152.588],\n        [152.588],\n        [152.588],\n        [152.588],\n        [152.588],\n        [152.588],\n        [152.588],\n        [152.588]]),\n 'ZeroADValue': array([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]]),\n 'ZeroADValueAnalog': array([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]]),\n 'allTimeStamps': array([[0.0000000e+00, 5.1200000e+01, 1.0240000e+02, ..., 8.4822965e+05,\n         8.4828085e+05, 8.4833205e+05]]),\n 'analogChannelNames': array([[<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>]], dtype=object),\n 'analogChannelNumbers': array([[ 1.],\n        [ 2.],\n        [ 3.],\n        [ 4.],\n        [ 5.],\n        [ 6.],\n        [ 7.],\n        [ 8.],\n        [ 9.],\n        [10.],\n        [11.]]),\n 'blkBytesCont': array([[8.000e+00],\n        [2.000e+00],\n        [2.000e+00],\n        [2.048e+03],\n        [1.000e+01]]),\n 'blkBytesEvnt': array([[8.],\n        [2.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [2.]]),\n 'blkCont': {'Repeat': array([[<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>]], dtype=object),\n  'Str': array([[<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>]], dtype=object),\n  'Types': array([[<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>]], dtype=object)},\n 'blkEvnt': {'Repeat': array([[<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>]], dtype=object),\n  'Str': array([[<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>]], dtype=object),\n  'Types': array([[<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>],\n         [<HDF5 object reference>]], dtype=object)},\n 'blockLength': array([[1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.]]),\n 'blockLengthAnalog': array([[1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.],\n        [1024.]]),\n 'bufferSize': array([0, 0], dtype=uint64),\n 'bufferSizeAnalog': array([0, 0], dtype=uint64),\n 'bytesPerRecCont': array([[2070.]]),\n 'bytesPerRecEvnt': array([[16.]]),\n 'chLayoutNames': array([0, 0], dtype=uint64),\n 'chLayoutNumbers': array([0, 0], dtype=uint64),\n 'chLayoutPositions': array([0, 0], dtype=uint64),\n 'channelFiles': array([[<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>]], dtype=object),\n 'channelFilesAnalog': array([[<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>]], dtype=object),\n 'channelNames': array([[<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>]], dtype=object),\n 'channelNumbers': array([[ 1.],\n        [ 2.],\n        [ 3.],\n        [ 4.],\n        [ 5.],\n        [ 6.],\n        [ 7.],\n        [ 8.],\n        [ 9.],\n        [10.],\n        [11.],\n        [12.],\n        [13.],\n        [14.],\n        [15.],\n        [16.],\n        [17.],\n        [18.],\n        [19.],\n        [20.],\n        [21.],\n        [22.],\n        [23.],\n        [24.],\n        [25.],\n        [26.],\n        [27.],\n        [28.],\n        [29.],\n        [30.],\n        [31.],\n        [32.]]),\n 'channelNumbersOrignal': array([0, 0], dtype=uint64),\n 'convertData2Double': array([[1.]]),\n 'dataDescriptionCont': array([[<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>]], dtype=object),\n 'dataDescriptionContAnalog': array([[<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>]], dtype=object),\n 'dataDescriptionEvnt': array([0, 0], dtype=uint64),\n 'dataFileNames': array([[ 47],\n        [109],\n        [101],\n        [100],\n        [105],\n        [ 97],\n        [ 47],\n        [115],\n        [105],\n        [108],\n        [ 50],\n        [ 47],\n        [ 68],\n        [ 97],\n        [116],\n        [ 97],\n        [ 47],\n        [ 78],\n        [105],\n        [109],\n        [114],\n        [111],\n        [100],\n        [ 47],\n        [101],\n        [120],\n        [112],\n        [101],\n        [114],\n        [105],\n        [109],\n        [101],\n        [110],\n        [116],\n        [115],\n        [ 47],\n        [ 80],\n        [ 86],\n        [ 95],\n        [ 54],\n        [ 50],\n        [ 47],\n        [ 50],\n        [ 48],\n        [ 50],\n        [ 51],\n        [ 95],\n        [ 48],\n        [ 54],\n        [ 95],\n        [ 50],\n        [ 49],\n        [ 47],\n        [ 98],\n        [108],\n        [111],\n        [ 99],\n        [107],\n        [ 95],\n        [ 48],\n        [ 55],\n        [ 50],\n        [ 47],\n        [111],\n        [101],\n        [ 95],\n        [102],\n        [105],\n        [108],\n        [101],\n        [115],\n        [ 47],\n        [ 50],\n        [ 48],\n        [ 50],\n        [ 51],\n        [ 45],\n        [ 48],\n        [ 54],\n        [ 45],\n        [ 50],\n        [ 49],\n        [ 95],\n        [ 49],\n        [ 52],\n        [ 45],\n        [ 51],\n        [ 49],\n        [ 45],\n        [ 48],\n        [ 51],\n        [ 47],\n        [ 82],\n        [101],\n        [ 99],\n        [111],\n        [114],\n        [100],\n        [ 32],\n        [ 78],\n        [111],\n        [100],\n        [101],\n        [ 32],\n        [ 49],\n        [ 48],\n        [ 56],\n        [ 47]], dtype=uint16),\n 'datatype': array([[105],\n        [110],\n        [116],\n        [ 49],\n        [ 54]], dtype=uint16),\n 'dspHighCutFrequency': array([0, 0], dtype=uint64),\n 'dspLowCutFrequency': array([0, 0], dtype=uint64),\n 'electrodePitch': array([0, 0], dtype=uint64),\n 'endDate': array([0, 0], dtype=uint64),\n 'eventFileName': array([[ 49],\n        [ 48],\n        [ 48],\n        [ 95],\n        [ 82],\n        [104],\n        [121],\n        [116],\n        [104],\n        [109],\n        [ 68],\n        [ 97],\n        [116],\n        [ 97],\n        [ 46],\n        [101],\n        [118],\n        [101],\n        [110],\n        [116],\n        [115]], dtype=uint16),\n 'eventFiles': array([0, 0], dtype=uint64),\n 'evntFileSize': array([[4652208.]]),\n 'fileHeaders': array([[<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>]], dtype=object),\n 'fileHeadersAnalog': array([[<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>]], dtype=object),\n 'fileSize': array([[34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.]]),\n 'fileSizeAnalog': array([[34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.],\n        [34247104.]]),\n 'globalStartTime_ms': array([[4019.2]]),\n 'includeOnlyDigitalDataInTriggers': array([[0]], dtype=uint8),\n 'layoutName': array([0, 0], dtype=uint64),\n 'metaDataFile': array([[ 47],\n        [109],\n        [101],\n        [100],\n        [105],\n        [ 97],\n        [ 47],\n        [115],\n        [105],\n        [108],\n        [ 50],\n        [ 47],\n        [ 68],\n        [ 97],\n        [116],\n        [ 97],\n        [ 47],\n        [ 78],\n        [105],\n        [109],\n        [114],\n        [111],\n        [100],\n        [ 47],\n        [101],\n        [120],\n        [112],\n        [101],\n        [114],\n        [105],\n        [109],\n        [101],\n        [110],\n        [116],\n        [115],\n        [ 47],\n        [ 80],\n        [ 86],\n        [ 95],\n        [ 54],\n        [ 50],\n        [ 47],\n        [ 50],\n        [ 48],\n        [ 50],\n        [ 51],\n        [ 95],\n        [ 48],\n        [ 54],\n        [ 95],\n        [ 50],\n        [ 49],\n        [ 47],\n        [ 98],\n        [108],\n        [111],\n        [ 99],\n        [107],\n        [ 95],\n        [ 48],\n        [ 55],\n        [ 50],\n        [ 47],\n        [111],\n        [101],\n        [ 95],\n        [102],\n        [105],\n        [108],\n        [101],\n        [115],\n        [ 47],\n        [ 50],\n        [ 48],\n        [ 50],\n        [ 51],\n        [ 45],\n        [ 48],\n        [ 54],\n        [ 45],\n        [ 50],\n        [ 49],\n        [ 95],\n        [ 49],\n        [ 52],\n        [ 45],\n        [ 51],\n        [ 49],\n        [ 45],\n        [ 48],\n        [ 51],\n        [ 47],\n        [ 82],\n        [101],\n        [ 99],\n        [111],\n        [114],\n        [100],\n        [ 32],\n        [ 78],\n        [111],\n        [100],\n        [101],\n        [ 32],\n        [ 49],\n        [ 48],\n        [ 56],\n        [ 47],\n        [ 47],\n        [ 79],\n        [ 69],\n        [ 95],\n        [109],\n        [101],\n        [116],\n        [ 97],\n        [ 68],\n        [ 97],\n        [116],\n        [ 97],\n        [ 46],\n        [109],\n        [ 97],\n        [116]], dtype=uint16),\n 'n2s': array([[ 1.],\n        [ 2.],\n        [ 3.],\n        [ 4.],\n        [ 5.],\n        [ 6.],\n        [ 7.],\n        [ 8.],\n        [ 9.],\n        [10.],\n        [11.],\n        [12.],\n        [13.],\n        [14.],\n        [15.],\n        [16.],\n        [17.],\n        [18.],\n        [19.],\n        [20.],\n        [21.],\n        [22.],\n        [23.],\n        [24.],\n        [25.],\n        [26.],\n        [27.],\n        [28.],\n        [29.],\n        [30.],\n        [31.],\n        [32.]]),\n 'n2sA': array([[ 1.],\n        [ 2.],\n        [ 3.],\n        [ 4.],\n        [ 5.],\n        [ 6.],\n        [ 7.],\n        [ 8.],\n        [ 9.],\n        [10.],\n        [11.]]),\n 'nRecordings': array([0, 0], dtype=uint64),\n 'nRecordsCont': array([[16544.]]),\n 'nRecordsEvnt': array([[290699.]]),\n 'openEphyXMLData': {'AUDIO': {'DEVICESETUP': {'audioDeviceBufferSizeAttribute': array([[1024.]]),\n    'audioDeviceRateAttribute': array([[48000.]]),\n    'audioInputDeviceNameAttribute': array([[3707764736,          2,          1,          1,         87,\n                     1]], dtype=uint32),\n    'audioOutputDeviceNameAttribute': array([[3707764736,          2,          1,          1,         86,\n                     1]], dtype=uint32),\n    'deviceTypeAttribute': array([[3707764736,          2,          1,          1,         85,\n                     1]], dtype=uint32)},\n   'bufferSizeAttribute': array([[1024.]]),\n   'deviceTypeAttribute': array([[3707764736,          2,          1,          1,         84,\n                    1]], dtype=uint32),\n   'sampleRateAttribute': array([[48000.]])},\n  'AUDIOEDITOR': {'isMutedAttribute': array([[0.]]),\n   'noiseGateAttribute': array([[10.]]),\n   'volumeAttribute': array([[42.]])},\n  'CONTROLPANEL': {'isOpenAttribute': array([[1.]]),\n   'recordEngineAttribute': array([[3707764736,          2,          1,          1,         89,\n                    1]], dtype=uint32),\n   'recordPathAttribute': array([[3707764736,          2,          1,          1,         88,\n                    1]], dtype=uint32)},\n  'DATAVIEWPORT': {'selectedTabAttribute': array([[3.]])},\n  'EDITORVIEWPORT': {'ACQUISITION_BOARD': {'IDAttribute': array([[100.]])},\n   'BANDPASS_FILTER': {'IDAttribute': array([[111.]])},\n   'LFP_VIEWER': {'IDAttribute': array([[112.]])},\n   'RECORD_NODE': {'IDAttribute': array([[108.]])},\n   'SPLITTER': {'IDAttribute': array([[110.]])},\n   'scrollAttribute': array([[0.]])},\n  'FILENAMECONFIG': {'APPEND': {'stateAttribute': array([[0.]]),\n    'valueAttribute': array([[3707764736,          2,          1,          1,         92,\n                     1]], dtype=uint32)},\n   'MAIN': {'stateAttribute': array([[1.]]),\n    'valueAttribute': array([[3707764736,          2,          1,          1,         91,\n                     1]], dtype=uint32)},\n   'PREPEND': {'stateAttribute': array([[0.]]),\n    'valueAttribute': array([[3707764736,          2,          1,          1,         90,\n                     1]], dtype=uint32)}},\n  'INFO': {'DATE': array([[3707764736,          2,          1,          1,          2,\n                    1]], dtype=uint32),\n   'MACHINE': {'cpu_modelAttribute': array([[3707764736,          2,          1,          1,          5,\n                     1]], dtype=uint32),\n    'cpu_num_coresAttribute': array([[8.]]),\n    'nameAttribute': array([[3707764736,          2,          1,          1,          4,\n                     1]], dtype=uint32)},\n   'OS': array([[3707764736,          2,          1,          1,          3,\n                    1]], dtype=uint32),\n   'PLUGIN_API_VERSION': array([[8.]]),\n   'VERSION': array([[3707764736,          2,          1,          1,          1,\n                    1]], dtype=uint32)},\n  'PROCESSORLIST': {'COLOR': {'BAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'GAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'IDAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'RAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object)}},\n  'SIGNALCHAIN': {'PROCESSOR': {'CUSTOM_PARAMETERS': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'EDITOR': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'GLOBAL_PARAMETERS': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'STREAM': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'indexAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'insertionPointAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'libraryNameAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'libraryVersionAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'nameAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'nodeIdAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'pluginNameAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'processorTypeAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object),\n    'typeAttribute': array([[<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>],\n           [<HDF5 object reference>]], dtype=object)},\n   'SWITCH': {'numberAttribute': array([[2.]])}},\n  'UICOMPONENT': {'isEditorViewportOpenAttribute': array([[1.]]),\n   'isProcessorListOpenAttribute': array([[1.]])}},\n 'openEphyXMLStructureData': {'RECORDING': {'STREAM': {'CHANNEL': {'bitVoltsAttribute': array([[<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>]], dtype=object),\n     'filenameAttribute': array([[<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>]], dtype=object),\n     'nameAttribute': array([[<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>]], dtype=object),\n     'positionAttribute': array([[<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>],\n            [<HDF5 object reference>]], dtype=object)},\n    'EVENTS': {'filenameAttribute': array([[3707764736,          2,          1,          1,        181,\n                      1]], dtype=uint32)},\n    'TIMESTAMPS': {'filenameAttribute': array([[3707764736,          2,          1,          1,        182,\n                      1]], dtype=uint32)},\n    'nameAttribute': array([[3707764736,          2,          1,          1,         93,\n                     1]], dtype=uint32),\n    'sample_rateAttribute': array([[20000.]]),\n    'source_node_idAttribute': array([[100.]]),\n    'source_node_nameAttribute': array([[3707764736,          2,          1,          1,         94,\n                     1]], dtype=uint32)},\n   'numberAttribute': array([[1.]])},\n  'format_versionAttribute': array([[0.6]]),\n  'numberAttribute': array([[1.]])},\n 'overwriteMetaData': array([[0]], dtype=uint8),\n 'recordLength': array([[51.2]]),\n 'recordSize': array([0, 0], dtype=uint64),\n 'recordingDir': array([[ 47],\n        [109],\n        [101],\n        [100],\n        [105],\n        [ 97],\n        [ 47],\n        [115],\n        [105],\n        [108],\n        [ 50],\n        [ 47],\n        [ 68],\n        [ 97],\n        [116],\n        [ 97],\n        [ 47],\n        [ 78],\n        [105],\n        [109],\n        [114],\n        [111],\n        [100],\n        [ 47],\n        [101],\n        [120],\n        [112],\n        [101],\n        [114],\n        [105],\n        [109],\n        [101],\n        [110],\n        [116],\n        [115],\n        [ 47],\n        [ 80],\n        [ 86],\n        [ 95],\n        [ 54],\n        [ 50],\n        [ 47],\n        [ 50],\n        [ 48],\n        [ 50],\n        [ 51],\n        [ 95],\n        [ 48],\n        [ 54],\n        [ 95],\n        [ 50],\n        [ 49],\n        [ 47],\n        [ 98],\n        [108],\n        [111],\n        [ 99],\n        [107],\n        [ 95],\n        [ 48],\n        [ 55],\n        [ 50],\n        [ 47],\n        [111],\n        [101],\n        [ 95],\n        [102],\n        [105],\n        [108],\n        [101],\n        [115],\n        [ 47],\n        [ 50],\n        [ 48],\n        [ 50],\n        [ 51],\n        [ 45],\n        [ 48],\n        [ 54],\n        [ 45],\n        [ 50],\n        [ 49],\n        [ 95],\n        [ 49],\n        [ 52],\n        [ 45],\n        [ 51],\n        [ 49],\n        [ 45],\n        [ 48],\n        [ 51],\n        [ 47],\n        [ 82],\n        [101],\n        [ 99],\n        [111],\n        [114],\n        [100],\n        [ 32],\n        [ 78],\n        [111],\n        [100],\n        [101],\n        [ 32],\n        [ 49],\n        [ 48],\n        [ 56],\n        [ 47]], dtype=uint16),\n 'recordingDuration_ms': array([[848332.05]]),\n 'recordingName': array([1, 0], dtype=uint64),\n 'sample_ms': array([[0.05]]),\n 'samplingFrequency': array([[20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.]]),\n 'samplingFrequencyAnalog': array([[20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.],\n        [20000.]]),\n 'softwareVersion': array([[0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6],\n        [0.6]]),\n 'startDate': array([[<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>]], dtype=object),\n 'startDateA': array([[<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>],\n        [<HDF5 object reference>]], dtype=object),\n 'triggerNames': array([0, 0], dtype=uint64)}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result['metaData']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "# get data from a mat file into a dictionary:\n",
    "# define the funciton that reads an HDF5 file group and converts it into a dictionary in python:\n",
    "\n",
    "def group_to_dict(group):\n",
    "    result = {}\n",
    "    for key, item in group.items():\n",
    "        if isinstance(item, h5py.Group):\n",
    "            result[key] = group_to_dict(item)\n",
    "        else:\n",
    "\n",
    "            result[key] = item[()]  # Convert dataset to NumPy array and assign its value\n",
    "    return result\n",
    "\n",
    "# open the mat file:\n",
    "mat_file = h5py.File(oe_metadata_file_path, 'r')\n",
    "\n",
    "#implement on the metaData group:\n",
    "meta_dict = group_to_dict(mat_file['metaData'])\n",
    "\n",
    "#close the file\n",
    "mat_file.close()\n",
    "\n",
    "# I now have the dictionary - I should create the recording class and assign the different keys to internal properties of the recording\n",
    "oeRec = OERecording(metadata_dict=meta_dict)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found references: [[<HDF5 object reference> <HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference> <HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference> <HDF5 object reference>\n",
      "  <HDF5 object reference> <HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n",
      "Found references: [[<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]\n",
      " [<HDF5 object reference>]]\n"
     ]
    }
   ],
   "source": [
    "def find_references_recursive(obj):\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        if h5py.check_dtype(ref=obj.dtype):\n",
    "            references = obj[...]\n",
    "            print(f\"Found references: {references}\")\n",
    "    elif isinstance(obj, h5py.Group):\n",
    "        for key in obj.keys():\n",
    "            find_references_recursive(obj[key])\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        for item in obj:\n",
    "            find_references_recursive(item)\n",
    "\n",
    "def find_hdf5_references(filename):\n",
    "    with h5py.File(filename, 'r') as file:\n",
    "        find_references_recursive(file)\n",
    "\n",
    "# Usage example:\n",
    "filename = oe_metadata_file_path\n",
    "find_hdf5_references(filename)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "# Over here I converted a reference object into data for the first time\n",
    "\n",
    "mat_file = h5py.File(oe_metadata_file_path, 'r')\n",
    "ref = mat_file['metaData/blkCont/Repeat'][3][0]\n",
    "res = np.array(mat_file[ref])\n",
    "\n",
    "mat_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-209-0218c68f387c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;31m# Usage example:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[0mfilename\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moe_metadata_file_path\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconstruct_dict_with_references\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-209-0218c68f387c>\u001B[0m in \u001B[0;36mconstruct_dict_with_references\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mh5py\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 37\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mconstruct_dict_recursive\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;31m# Usage example:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-209-0218c68f387c>\u001B[0m in \u001B[0;36mconstruct_dict_recursive\u001B[1;34m(obj)\u001B[0m\n\u001B[0;32m     10\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m                 \u001B[0mresult\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconstruct_dict_recursive\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-209-0218c68f387c>\u001B[0m in \u001B[0;36mconstruct_dict_recursive\u001B[1;34m(obj)\u001B[0m\n\u001B[0;32m     10\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m                 \u001B[0mresult\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconstruct_dict_recursive\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-209-0218c68f387c>\u001B[0m in \u001B[0;36mconstruct_dict_recursive\u001B[1;34m(obj)\u001B[0m\n\u001B[0;32m     10\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m                 \u001B[0mresult\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconstruct_dict_recursive\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "def construct_dict_with_references(filename):\n",
    "    def construct_dict_recursive(obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            if h5py.check_dtype(ref=obj.dtype):\n",
    "                references = obj[...]\n",
    "                return resolve_references(references)\n",
    "            else:\n",
    "                return obj[()]  # Convert dataset to numpy array\n",
    "        elif isinstance(obj, h5py.Group):\n",
    "            result = {}\n",
    "            for key in obj.keys():\n",
    "                result[key.decode()] = construct_dict_recursive(obj[key])\n",
    "            return result\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [construct_dict_recursive(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def resolve_references(references):\n",
    "        if isinstance(references, list):\n",
    "            return [resolve_reference(ref) for ref in references]\n",
    "        elif isinstance(references, np.ndarray):\n",
    "            return np.array([resolve_reference(ref) for ref in references])\n",
    "        else:\n",
    "            return resolve_reference(references)\n",
    "\n",
    "    def resolve_reference(reference):\n",
    "        obj = file[reference.decode()]\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            return construct_dict_recursive(obj)\n",
    "        elif isinstance(obj, h5py.Dataset):\n",
    "            return obj[()]\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    with h5py.File(filename, 'r') as file:\n",
    "        return construct_dict_recursive(file)\n",
    "\n",
    "# Usage example:\n",
    "filename = oe_metadata_file_path\n",
    "result = construct_dict_with_references(filename)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File structure:\n",
      "<HDF5 file \"OE_metaData.mat\" (mode r)>\n",
      "Keys in the root group:\n",
      "['#refs#', '#subsystem#', 'metaData']\n",
      "Keys in group 'group_name':\n",
      "['ADBitVolts', 'MicrovoltsPerAD', 'MicrovoltsPerADAnalog', 'ZeroADValue', 'ZeroADValueAnalog', 'allTimeStamps', 'analogChannelNames', 'analogChannelNumbers', 'blkBytesCont', 'blkBytesEvnt', 'blkCont', 'blkEvnt', 'blockLength', 'blockLengthAnalog', 'bufferSize', 'bufferSizeAnalog', 'bytesPerRecCont', 'bytesPerRecEvnt', 'chLayoutNames', 'chLayoutNumbers', 'chLayoutPositions', 'channelFiles', 'channelFilesAnalog', 'channelNames', 'channelNumbers', 'channelNumbersOrignal', 'convertData2Double', 'dataDescriptionCont', 'dataDescriptionContAnalog', 'dataDescriptionEvnt', 'dataFileNames', 'datatype', 'dspHighCutFrequency', 'dspLowCutFrequency', 'electrodePitch', 'endDate', 'eventFileName', 'eventFiles', 'evntFileSize', 'fileHeaders', 'fileHeadersAnalog', 'fileSize', 'fileSizeAnalog', 'globalStartTime_ms', 'includeOnlyDigitalDataInTriggers', 'layoutName', 'metaDataFile', 'n2s', 'n2sA', 'nRecordings', 'nRecordsCont', 'nRecordsEvnt', 'openEphyXMLData', 'openEphyXMLStructureData', 'overwriteMetaData', 'recordLength', 'recordSize', 'recordingDir', 'recordingDuration_ms', 'recordingName', 'sample_ms', 'samplingFrequency', 'samplingFrequencyAnalog', 'softwareVersion', 'startDate', 'startDateA', 'triggerNames']\n",
      "Dataset 'dataset_name' within 'group_name':\n",
      "<HDF5 dataset \"allTimeStamps\": shape (1, 16544), type \"<f8\">\n",
      "Data within 'dataset_name':\n",
      "[[0.0000000e+00 5.1200000e+01 1.0240000e+02 ... 8.4822965e+05\n",
      "  8.4828085e+05 8.4833205e+05]]\n"
     ]
    }
   ],
   "source": [
    "### 1. get the metadata into a dictionary with\n",
    "\n",
    "# Open the .mat file\n",
    "mat_file = h5py.File(oe_metadata_file_path, 'r')\n",
    "\n",
    "# Explore the file structure\n",
    "print(\"File structure:\")\n",
    "print(mat_file)\n",
    "\n",
    "# List all the keys (group and dataset names) in the root group\n",
    "print(\"Keys in the root group:\")\n",
    "print(list(mat_file.keys()))\n",
    "\n",
    "# Access a specific group within the root group\n",
    "group1 = mat_file['metaData']\n",
    "print(\"Keys in group 'metaData':\")\n",
    "print(list(group1.keys()))\n",
    "\n",
    "# Access a specific dataset within a group\n",
    "dataset1 = group1['allTimeStamps']\n",
    "print(\"Dataset 'dataset_name' within 'group_name':\")\n",
    "print(dataset1)\n",
    "\n",
    "# Access the data within the dataset\n",
    "data1 = dataset1[:]\n",
    "print(\"Data within 'dataset_name':\")\n",
    "print(data1)\n",
    "\n",
    "# Close the .mat file\n",
    "mat_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData.events'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData.timestamps'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_ADC1.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_ADC2.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_ADC3.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_ADC4.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_ADC5.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_ADC6.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_ADC7.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_ADC8.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_C1-AUX1.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_C1-AUX2.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_C1-AUX3.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH1.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH10.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH11.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH12.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH13.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH14.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH15.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH16.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH17.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH18.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH19.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH2.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH20.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH21.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH22.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH23.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH24.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH25.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH26.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH27.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH28.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH29.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH3.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH30.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH31.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH32.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH4.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH5.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH6.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH7.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH8.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/100_RhythmData_CH9.continuous'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/messages.events'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/OE_metaData.mat'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/settings.xml'),\n WindowsPath('Z:/Nimrod/experiments/PV_62/2023_06_21/block_072/oe_files/2023-06-21_14-31-03/Record Node 108/structure.openephys')]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I try to use the open-ephys-toolkit object up until the point where it gets sluggish and pick up from there:\n",
    "\n",
    "\n",
    "# here, I'll try and build a class call LightContinuous, which mirrors the class in the oe-py-toolkit but"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "session = oea.analysis.Session(str(block.oe_path.parent))\n",
    "cont_obj = session.recordnodes[0].recordings[0].continuous[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['#refs#', '#subsystem#', 'metaData']>\n"
     ]
    }
   ],
   "source": [
    "#read the matlab oe_metadata file\n",
    "oe_metadata = h5py.File(oe_metadata_file_path,'r')\n",
    "print(oe_metadata.keys())\n",
    "MetaData = oe_metadata['metaData']\n",
    "oe_metadata.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n",
      "Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072\\oe_files\\2023-06-21_14-31-03\\Record Node 108\\100_RhythmData.timestamps\n"
     ]
    }
   ],
   "source": [
    "continuous_files, stream_indexes, unique_stream_indexes, stream_info = recording.find_continuous_files()\n",
    "print(len(stream_info[0]['channel_names']))\n",
    "print(len(stream_info[0]['bit_volts']))\n",
    "print(stream_info[0]['timestamps_file'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def block_generator(block_list,experiment_path,animal, bad_blocks=[],regev=False):\n",
    "    \"\"\"\n",
    "    creates a block_collection to iterate over with multi-block functions\n",
    "    :param block_list: list of block numbers to loop over\n",
    "    :param experiment_path: pathlib.Path instance to the experiment folder\n",
    "    :param animal: string\n",
    "    :param bad_blocks: blocks to ignore\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    p = pathlib.Path(experiment_path) / animal\n",
    "    date_folder_list = [i for i in p.iterdir() if 'block' not in str(i).lower() and i.is_dir()]\n",
    "    block_collection = []\n",
    "    for date_path in date_folder_list:\n",
    "        date = date_path.name\n",
    "        # list all the blocks in the folder:\n",
    "        folder_list = [i for i in date_path.iterdir()]\n",
    "        for block in folder_list:\n",
    "            if 'block' in str(block):\n",
    "                block_number = block.name[-3:]\n",
    "                if int(block_number) in block_list and int(block_number) not in bad_blocks:\n",
    "                    #block definition\n",
    "                    block = BlockSync(animal_call=animal,\n",
    "                                      experiment_date=date,block_num=block_number,\n",
    "                                      path_to_animal_folder=str(experiment_path),regev=regev)\n",
    "                    block_collection.append(block)\n",
    "    return block_collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This bit gets a plot of pupil diameter Vs volume at the arena"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 072 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072, new OE version\n",
      "Found the sample rate for block 072 in the xml file, it is 20000 Hz\n"
     ]
    }
   ],
   "source": [
    "#block definition\n",
    "experiments_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "animal = \"PV_62\"\n",
    "date = \"2023_06_21\"\n",
    "block_n = \"072\"\n",
    "\n",
    "block = BlockSync(animal_call=animal,\n",
    "                  experiment_date=date,block_num=block_n,\n",
    "                  path_to_animal_folder=str(experiments_path),regev=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_072\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim1_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim1.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_072\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim1_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim1.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072\\eye_videos\\RE\\230621_pv62_audiostim1_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim1.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim1_LE.mp4 has reported 47995 frames and has 47995 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim1.mp4 has reported 48000 frames and has 48000 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T143120.mp4\n",
      "left_20230621T143120.mp4\n",
      "right_20230621T143120.mp4\n",
      "top_20230621T143120.mp4\n",
      "running parse_open_ephys_events...\n",
      "events.csv file already exists\n",
      "arena first frame timestamp: 406842\n",
      "arena end frame timestamp: 16706258\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n",
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_072\\oe_files\\2023-06-21_14-31-03\\parsed_events.csv\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n"
     ]
    }
   ],
   "source": [
    "analyzed_block_automated_pipe(block)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# get the volume trace with sample timestamps:\n",
    "session = oea.Session(str(block.oe_path.parent))\n",
    "timestamps = session.recordnodes[0].recordings[0].continuous[0].timestamps\n",
    "data = session.recordnodes[0].recordings[0].continuous[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "session = oea.Session(str(block.oe_path.parent))\n",
    "rec = session.recordnodes[0].recordings[0]\n",
    "cont_class = rec.continuous"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.64245605],\n       [1.64306641],\n       [1.64382935],\n       ...,\n       [0.        ],\n       [0.        ],\n       [0.        ]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_class[0].get_samples(0,100000000,selected_channels=[39])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "vol_channel_num = data.metadata['channel_names'].index('ADC5')\n",
    "volume_trace = data.samples[:,39]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x2130bc2ed30>]"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x216 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(15,3))\n",
    "axs.plot(timestamps,vol_z)\n",
    "axs.plot(block.final_sync_df['Arena_TTL'].values/20000,re_el_z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "re_el_z = (block.re_df.ellipse_size - block.re_df.ellipse_size.mean()) / block.re_df.ellipse_size.std()\n",
    "vol_z = (volume_trace - np.mean(volume_trace)) / np.std(volume_trace)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "#def block_eye_plot(self, export=False, ms_x_axis=True, plot_saccade_locs=False,\n",
    "#                  saccade_frames_l=None, saccade_frames_r=None):\n",
    "# setup\n",
    "ms_x_axis = True\n",
    "export = True\n",
    "plot_saccade_locs = False\n",
    "saccade_frames_l = None\n",
    "saccade_frames_r = None\n",
    "\n",
    "# normalize values:\n",
    "le_el_z = (block.le_df.ellipse_size - block.le_df.ellipse_size.mean()) / block.le_df.ellipse_size.std()\n",
    "le_x_z = (block.le_df.center_x - np.mean(block.le_df.center_x)) / block.le_df.center_x.std()\n",
    "le_y_z = (block.le_df.center_y - np.mean(block.le_df.center_y)) / block.le_df.center_y.std()\n",
    "re_el_z = (block.re_df.ellipse_size - block.re_df.ellipse_size.mean()) / block.re_df.ellipse_size.std()\n",
    "re_x_z = (block.re_df.center_x - np.mean(block.re_df.center_x)) / block.re_df.center_x.std()\n",
    "re_y_z = (block.re_df.center_y - np.mean(block.re_df.center_y)) / block.re_df.center_y.std()\n",
    "vol_z = (volume_trace - np.mean(volume_trace)) / np.std(volume_trace)\n",
    "\n",
    "if ms_x_axis is False:\n",
    "    x_axis = block.final_sync_df['Arena_TTL'].values\n",
    "    b_fig = figure(title=f'Pupil combined metrics block {block.block_num}',\n",
    "                   x_axis_label='OE Timestamps',\n",
    "                   y_axis_label='Z score',\n",
    "                   plot_width=1500,\n",
    "                   plot_height=700)\n",
    "else:\n",
    "    x_axis = (block.final_sync_df['Arena_TTL'].values -\n",
    "              block.final_sync_df['Arena_TTL'].values[0]) / (block.sample_rate / 1000)\n",
    "    b_fig = figure(title=f'Pupil combined metrics block {block.block_num}',\n",
    "                   x_axis_label='[Milliseconds]',\n",
    "                   y_axis_label='[Z score]',\n",
    "                   plot_width=1500,\n",
    "                   plot_height=700)\n",
    "b_fig.add_tools(HoverTool())\n",
    "b_fig.line(x_axis, le_el_z+7, legend_label='Left Eye Diameter', line_width=1.5, line_color='blue')\n",
    "#b_fig.line(x_axis, le_x_z+14, legend_label='Left Eye X Position', line_width=1, line_color='cyan')\n",
    "#b_fig.line(x_axis, le_y_z, legend_label='Left Eye Y position', line_width=1, line_color='green')\n",
    "b_fig.line(x_axis, re_el_z+7, legend_label='Right Eye Diameter', line_width=1.5, line_color='red')\n",
    "#b_fig.line(x_axis, re_x_z+14, legend_label='Right Eye X Position', line_width=1, line_color='orange')\n",
    "#b_fig.line(x_axis, re_y_z, legend_label='Right Eye Y position', line_width=1, line_color='pink')\n",
    "b_fig.line(timestamps * 2000, vol_z)\n",
    "if plot_saccade_locs:\n",
    "    b_fig.vbar(x=saccade_frames_l, width=1, bottom=-4, top=-1,\n",
    "               alpha=0.8, color='purple', legend_label='Left saccades')\n",
    "    b_fig.vbar(x=saccade_frames_r, width=1, bottom=-4, top=-1,\n",
    "               alpha=0.8, color='brown', legend_label='Right saccades')\n",
    "if export:\n",
    "    b_output.output_file(filename=str(block.analysis_path / f'pupillometry_block_{block.block_num}.html'),\n",
    "                         title=f'block {block.block_num} pupillometry')\n",
    "show(b_fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To generate the blocks:\n",
    "block_numbers = [i for i in range(72,76)]\n",
    "bad_blocks = []\n",
    "blocklist = block_generator(block_numbers,pathlib.Path(r\"Z:\\Nimrod\\experiments\"),'PV_62',bad_blocks=bad_blocks, regev=True)\n",
    "for block in blocklist:\n",
    "    analyzed_block_automated_pipe(block)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 075 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075, new OE version\n",
      "Found the sample rate for block 075 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 075\n",
      "got it!\n"
     ]
    }
   ],
   "source": [
    "#block definition\n",
    "experiments_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "animal = \"PV_62\"\n",
    "date = \"2023_06_21\"\n",
    "block_n = \"075\"\n",
    "\n",
    "block = BlockSync(animal_call=animal,\n",
    "                  experiment_date=date,block_num=block_n,\n",
    "                  path_to_animal_folder=str(experiments_path),regev=True)\n",
    "#analyzed_block_automated_pipe(block)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_075\\\\eye_videos\\\\LE\\\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim4.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_06_21\\\\block_075\\\\eye_videos\\\\RE\\\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\\\230621_pv62_audiostim4.h264']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\eye_videos\\RE\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim4.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230621_pv62_audiostim4_LE.mp4 has reported 31934 frames and has 31934 frames, it has dropped 0 frames\n",
      "The video named 230621_pv62_audiostim4.mp4 has reported 31933 frames and has 31933 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "no arena timestamps folder found\n",
      "Arena video Names:\n",
      "back_20230621T152553.mp4\n",
      "left_20230621T152553.mp4\n",
      "right_20230621T152553.mp4\n",
      "top_20230621T152553.mp4\n",
      "running parse_open_ephys_events...\n",
      "aligning to zero with 132096\n",
      "open ephys events aligned to zero & exported to csv file at Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\oe_files\\2023-06-21_15-25-44\\events.csv\n",
      "the arena TTLs are signaling start and stop positions at [  364 31720]\n",
      "arena first frame timestamp: 185704\n",
      "arena end frame timestamp: 10836062\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n",
      "created Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\oe_files\\2023-06-21_15-25-44\\parsed_events.csv\n"
     ]
    }
   ],
   "source": [
    "block.handle_eye_videos()\n",
    "block.handle_arena_files()\n",
    "block.parse_open_ephys_events()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no arena synchronization step performed - running it now...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-27-186483ea9479>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_arena_brightness_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthreshold_value\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m240\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mexport\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\PycharmProjects\\pythonProject3\\BlockSync_current.py\u001B[0m in \u001B[0;36mcreate_arena_brightness_df\u001B[1;34m(self, threshold_value, export)\u001B[0m\n\u001B[0;32m    728\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marena_sync_df\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    729\u001B[0m             \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'no arena synchronization step performed - running it now...'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 730\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msynchronize_arena_timestamps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    731\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marena_frame_val_list\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    732\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marena_frame_val_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBlockSync\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mproduce_frame_val_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marena_videos\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthreshold_value\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\pythonProject3\\BlockSync_current.py\u001B[0m in \u001B[0;36msynchronize_arena_timestamps\u001B[1;34m(self, return_dfs, export_sync_df, get_only_anchor_vid)\u001B[0m\n\u001B[0;32m    670\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    671\u001B[0m         \u001B[1;31m# pick the longest as an anchor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 672\u001B[1;33m         \u001B[0manchor_ind\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen_list\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    673\u001B[0m         \u001B[0manchor_vid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0manchor_ind\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    674\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0manchor_vid_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marena_vidnames\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0manchor_ind\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "block.create_arena_brightness_df(threshold_value=240,export=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 557/30900 [00:00<00:05, 5568.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating blocksync_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30900/30900 [00:07<00:00, 4171.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created blocksync_df\n",
      "exported blocksync_df to Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\analysis/ blocksync_df.csv\n"
     ]
    }
   ],
   "source": [
    "block.synchronize_block()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on video Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\eye_videos\\LE\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim4_LE.mp4\n",
      "done, frame_val_list contains 1 objects\n",
      "working on video Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\eye_videos\\RE\\230621_pv62_audiostim4_640x480_60hz_experiment_1_recording_0\\230621_pv62_audiostim4.mp4\n",
      "done, frame_val_list contains 1 objects\n",
      "creating Z:\\Nimrod\\experiments\\PV_62\\2023_06_21\\block_075\\analysis/eye_brightness_df.csv\n"
     ]
    }
   ],
   "source": [
    "block.create_eye_brightness_df(threshold_value=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index error on position 19 out of 20\n",
      "index error on position 17 out of 18\n",
      "The suspected lag between eye cameras is 0.0 with the direction ['right', 'late']\n"
     ]
    }
   ],
   "source": [
    "block.get_eyes_diff_list(threshold=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created manual_sync_df attribute for the block\n"
     ]
    }
   ],
   "source": [
    "block.fix_eye_synchronization()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index error on position 19 out of 20\n",
      "index error on position 17 out of 18\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'left': [244.0, 3853.0, 7461.0, 11070.0, 14678.0, 18287.0, 21896.0, 25504.0],\n 'right': [244.0, 3853.0, 7461.0, 11070.0, 14678.0, 18287.0, 21895.0, 25504.0]}"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.get_blink_frames_manual(threshold=2.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "           Arena_frame L_eye_frame R_eye_frame  L_values  R_values\nArena_TTL                                                         \n340282.0           455           1           1  1.250082 -0.671022\n340622.0           456           2           2  1.259298 -0.679236\n340962.0           457           3           4  1.259431 -0.670280\n341302.0           458           4           5  1.265670 -0.663590\n341641.0           459           5           6  1.262512 -0.657213\n...                ...         ...         ...       ...       ...\n10834363.0       31350       31541       31541  0.100973  1.061795\n10834703.0       31351       31542       31542  0.098376  1.074197\n10835043.0       31352       31543       31543  0.104797  1.081912\n10835382.0       31353       31544       31544  0.098626  1.076260\n10835722.0       31354       31545       31545  0.098863  1.066402\n\n[30900 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Arena_frame</th>\n      <th>L_eye_frame</th>\n      <th>R_eye_frame</th>\n      <th>L_values</th>\n      <th>R_values</th>\n    </tr>\n    <tr>\n      <th>Arena_TTL</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>340282.0</th>\n      <td>455</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.250082</td>\n      <td>-0.671022</td>\n    </tr>\n    <tr>\n      <th>340622.0</th>\n      <td>456</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.259298</td>\n      <td>-0.679236</td>\n    </tr>\n    <tr>\n      <th>340962.0</th>\n      <td>457</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1.259431</td>\n      <td>-0.670280</td>\n    </tr>\n    <tr>\n      <th>341302.0</th>\n      <td>458</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1.265670</td>\n      <td>-0.663590</td>\n    </tr>\n    <tr>\n      <th>341641.0</th>\n      <td>459</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1.262512</td>\n      <td>-0.657213</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10834363.0</th>\n      <td>31350</td>\n      <td>31541</td>\n      <td>31541</td>\n      <td>0.100973</td>\n      <td>1.061795</td>\n    </tr>\n    <tr>\n      <th>10834703.0</th>\n      <td>31351</td>\n      <td>31542</td>\n      <td>31542</td>\n      <td>0.098376</td>\n      <td>1.074197</td>\n    </tr>\n    <tr>\n      <th>10835043.0</th>\n      <td>31352</td>\n      <td>31543</td>\n      <td>31543</td>\n      <td>0.104797</td>\n      <td>1.081912</td>\n    </tr>\n    <tr>\n      <th>10835382.0</th>\n      <td>31353</td>\n      <td>31544</td>\n      <td>31544</td>\n      <td>0.098626</td>\n      <td>1.076260</td>\n    </tr>\n    <tr>\n      <th>10835722.0</th>\n      <td>31354</td>\n      <td>31545</td>\n      <td>31545</td>\n      <td>0.098863</td>\n      <td>1.066402</td>\n    </tr>\n  </tbody>\n</table>\n<p>30900 rows  5 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.manual_sync_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# use this to manually shift L\\R eye synchronization\n",
    "eye_to_move = 'R'\n",
    "block.move_eye_sync_manual(cols_to_move=[f'{eye_to_move}_eye_frame',f'{eye_to_move}_values'],step=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "block.full_sync_verification(with_arena=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "block.export_manual_sync_df()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "block.import_manual_sync_df()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31932/31932 [00:17<00:00, 1788.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31931/31931 [00:18<00:00, 1773.17it/s]\n",
      "  0%|          | 75/30900 [00:00<01:22, 375.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Done\n",
      "populating le_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30900/30900 [01:39<00:00, 310.29it/s]\n",
      "  0%|          | 39/30900 [00:00<01:20, 382.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "populating re_video_sync_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30900/30900 [01:40<00:00, 307.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "exporting to analysis folder\n"
     ]
    }
   ],
   "source": [
    "block.read_dlc_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "block.block_eye_plot(ms_x_axis=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x2295ba2d310>]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots()\n",
    "#axs.plot(np.diff(block.eye_brightness_df.R_values.values))\n",
    "axs.plot(block.eye_brightness_df.R_values.values)\n",
    "#axs.set_ylim(-1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arena_sync_df already exists, loading from file...\n"
     ]
    }
   ],
   "source": [
    "block.synchronize_arena_timestamps()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index error on position 122 out of 123\n"
     ]
    },
    {
     "data": {
      "text/plain": "[631.0,\n 3050.0,\n 3131.0,\n 5955.0,\n 6739.0,\n 10348.0,\n 10421.0,\n 12752.0,\n 13956.0,\n 15541.0,\n 17565.0,\n 17728.0,\n 21174.0,\n 22643.0,\n 24782.0,\n 26873.0,\n 28391.0,\n 28412.0,\n 29880.0,\n 31999.0,\n 32344.0,\n 34322.0,\n 35608.0,\n 36829.0,\n 37478.0,\n 39216.0,\n 39564.0,\n 40480.0,\n 42825.0,\n 43102.0,\n 45899.0,\n 46434.0,\n 47936.0,\n 47940.0,\n 49513.0,\n 50042.0,\n 51423.0,\n 53651.0]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_rising = block.blink_rising_edges_detector(block.eye_brightness_df['L_values'].values,\n",
    "                                            block.eye_brightness_df['L_eye_frame'], threshold=-4)\n",
    "b_series = pd.Series(data=block.eye_brightness_df['R_values'].values, index=block.eye_brightness_df['R_eye_frame'])\n",
    "blink_indexes = b_series[b_series < -4].index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the arena TTLs are signaling start and stop positions at [ 1661 24692]\n",
      "arena first frame timestamp: 1074086\n",
      "arena end frame timestamp: 8896453\n",
      "LED_driver was not identified as Arena_TTL\n",
      "L_eye_TTL was not identified as Arena_TTL\n",
      "R_eye_TTL was not identified as Arena_TTL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-2685f8107403>:41: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
      "  s_counter = pd.Series(data=np.arange(len(s), dtype='Int32'), index=s.index.values, name=sname+'_frame')\n",
      "<ipython-input-16-2685f8107403>:41: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
      "  s_counter = pd.Series(data=np.arange(len(s), dtype='Int32'), index=s.index.values, name=sname+'_frame')\n",
      "<ipython-input-16-2685f8107403>:41: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
      "  s_counter = pd.Series(data=np.arange(len(s), dtype='Int32'), index=s.index.values, name=sname+'_frame')\n",
      "<ipython-input-16-2685f8107403>:41: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
      "  s_counter = pd.Series(data=np.arange(len(s), dtype='Int32'), index=s.index.values, name=sname+'_frame')\n"
     ]
    }
   ],
   "source": [
    "#Test oe_events_parser:\n",
    "# initialize variables\n",
    "open_ephys_csv_path = block.block_path / rf'oe_files' / block.exp_date_time / 'events.csv'\n",
    "channel_names = block.channeldict\n",
    "arena_channel_name='Arena_TTL'\n",
    "export_path=None\n",
    "\n",
    "# infer the active channels:\n",
    "df = pd.read_csv(open_ephys_csv_path)\n",
    "channels = np.unique(df['line'].to_numpy(copy=True))\n",
    "df_onstate = df[df['state'] == 1]  # cut the df to represent only rising edges\n",
    "ls = []\n",
    "for chan in channels:  # extract a pandas series of the ON stats timestamps for each channel\n",
    "    if chan in channel_names.keys():\n",
    "        sname = channel_names[chan]\n",
    "        s = pd.Series(df_onstate['sample_number'][df_onstate['line'] == chan], name=sname)\n",
    "        # If this is the arena channel we need to collect the first and last frames which correspond with\n",
    "        # the video itsef (as TTLs are always being transmitted and a pause is expected before the video starts\n",
    "        if sname == arena_channel_name:\n",
    "            diff_series = np.diff(s)\n",
    "            diff_mode = stats.mode(diff_series)[0][0]\n",
    "            arena_start_stop = np.where(diff_series > 10 * diff_mode)[0]\n",
    "            if len(arena_start_stop) != 2:\n",
    "                start_ind = input(f'there is some kind of problem because there should be 2 breaks in the arena TTLs'\n",
    "                        f'and there are {len(arena_start_stop)}, those indices are: {[s.iloc[i] for i in arena_start_stop]}... '\n",
    "                                  f'choose the index to use as startpoint:')\n",
    "                end_ind = input('choose the index to use as endpoint:')\n",
    "                arena_start_timestamp = s.iloc[arena_start_stop[int(start_ind)] + 1]\n",
    "                print(f'arena first frame timestamp: {arena_start_timestamp}')\n",
    "                arena_end_timestamp = s.iloc[arena_start_stop[int(end_ind)]]\n",
    "                print(f'arena end frame timestamp: {arena_end_timestamp}')\n",
    "            else:\n",
    "                print(f'the arena TTLs are signaling start and stop positions at {arena_start_stop}')\n",
    "                arena_start_timestamp = s.iloc[arena_start_stop[0] + 1]\n",
    "                print(f'arena first frame timestamp: {arena_start_timestamp}')\n",
    "                arena_end_timestamp = s.iloc[arena_start_stop[1]]\n",
    "                print(f'arena end frame timestamp: {arena_end_timestamp}')\n",
    "        else:\n",
    "            print(f'{sname} was not identified as {arena_channel_name}')\n",
    "        # create a counter for every rising edge - these should match video frames\n",
    "        s_counter = pd.Series(data=np.arange(len(s), dtype='Int32'), index=s.index.values, name=sname+'_frame')\n",
    "        ls.append(s)\n",
    "        ls.append(s_counter)\n",
    "# concatenate all channels into a dataframe with open-ephys compatible timestamps\n",
    "open_ephys_events = pd.concat(ls, axis=1)\n",
    "# use arena start_stop to clean TTLs counted before video starts and after video ends\n",
    "open_ephys_events[f'{arena_channel_name}_frame'] = open_ephys_events[f'{arena_channel_name}_frame'] - (\n",
    "            arena_start_stop[0] + 1)\n",
    "open_ephys_events[f'{arena_channel_name}_frame'][open_ephys_events[f'{arena_channel_name}_frame'] < 0] = np.nan\n",
    "open_ephys_events[f'{arena_channel_name}_frame'][\n",
    "open_ephys_events[f'{arena_channel_name}'] > arena_end_timestamp] = np.nan\n",
    "\n",
    "if export_path is not None:\n",
    "    if export_path not in os.listdir(str(open_ephys_csv_path).split('events.csv')[0][:-1]):\n",
    "        open_ephys_events.to_csv(export_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video named back_20230502T134223.mp4 has 53936 frames\n",
      "The video named left_20230502T134223.mp4 has 53935 frames\n",
      "The video named right_20230502T134223.mp4 has 53936 frames\n",
      "The video named top_20230502T134223.mp4 has 53933 frames\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for vid in block.arena_videos:\n",
    "    cap = cv2.VideoCapture(str(vid))\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f'The video named {os.path.split(vid)[1]} has {length} frames')\n",
    "    cap.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "# synchronize arena timestamps with the new system:\n",
    "# The problem = number of frames does not align with number of ttls transmitted by the arduino + different cameras take different number of frames\n",
    "# solution:\n",
    "# 1. go through the csv files to see real frame-counts vs actual frames gathered\n",
    "#arena_timestamps = [i for i in glob.glob(block.arena_files[0].parent / 'frame_timestamps')]\n",
    "#arena_timestamps\n",
    "arena_timestamp_files = [i for i in (block.arena_files[0].parent / 'frames_timestamps').iterdir()]\n",
    "# read the timestamp files\n",
    "len_list = []\n",
    "df_list = []\n",
    "for p in arena_timestamp_files:\n",
    "    if p.name != 'events.csv':\n",
    "        df = pd.read_csv(p, index_col=0)\n",
    "        df  = df.rename(columns={'0':'timestamp'})\n",
    "        df_list.append(df)\n",
    "        len_list.append(len(df))\n",
    "\n",
    "# pick the longest as anchor\n",
    "anchor_ind = len_list.index(max(len_list))\n",
    "anchor_vid = df_list[anchor_ind]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 46/91552 [00:00<06:41, 228.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronizing the different arena videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 91552/91552 [07:10<00:00, 212.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The anchor video used was \"None\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "anchor_vid_name = block.arena_vidnames[anchor_ind]\n",
    "block.arena_sync_df = pd.DataFrame(data=[],\n",
    "                                  columns=block.arena_vidnames,\n",
    "                                  index=range(len(anchor_vid)))\n",
    "block.arena_sync_df[block.arena_sync_df.columns[anchor_ind]] = range(len(anchor_vid))\n",
    "vids_to_sync = list(block.arena_sync_df.drop(axis=1, labels=anchor_vid_name).columns)\n",
    "anchor_vid_df = df_list.pop(anchor_ind)\n",
    "df_to_sync = df_list\n",
    "print('Synchronizing the different arena videos')\n",
    "for row in tqdm(block.arena_sync_df.index):\n",
    "    anchor = anchor_vid.timestamp[row]\n",
    "    for vid in range(len(df_to_sync)):\n",
    "        frame_num = block.get_closest_frame(anchor, df_to_sync[vid])\n",
    "        block.arena_sync_df.loc[row, vids_to_sync[vid]] = frame_num\n",
    "print(f'The anchor video used was \"{block.anchor_vid_name}\"')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}