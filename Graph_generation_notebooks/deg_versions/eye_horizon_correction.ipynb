{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This notebook needs to solve the re-calculation of image rotations to a common frame of reference where the nostril-ear axis is defined as the horizon (rather than the tear-ducts axis)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50b965ddab6ca545"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import cycle\n",
    "import pickle\n",
    "import pathlib\n",
    "import math\n",
    "import tqdm\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import re\n",
    "from lxml import etree as ET\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "from scipy.stats import kde\n",
    "from BlockSync_current import BlockSync\n",
    "import UtilityFunctions_newOE as uf\n",
    "from scipy import signal\n",
    "import bokeh\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "rcParams['pdf.fonttype'] = 42  # Ensure fonts are embedded and editable\n",
    "rcParams['ps.fonttype'] = 42  # Ensure compatibility with vector outputs\n",
    "\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import cycle\n",
    "import pickle\n",
    "import pathlib\n",
    "import math\n",
    "import tqdm\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import re\n",
    "from lxml import etree as ET\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "from scipy.stats import kde\n",
    "from BlockSync_current import BlockSync\n",
    "import UtilityFunctions_newOE as uf\n",
    "from scipy import signal\n",
    "import bokeh\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "rcParams['pdf.fonttype'] = 42  # Ensure fonts are embedded and editable\n",
    "rcParams['ps.fonttype'] = 42  # Ensure compatibility with vector outputs\n",
    "\n",
    "\n",
    "def bokeh_plotter(data_list, x_axis_list=None, label_list=None, \n",
    "                  plot_name='default',\n",
    "                  x_axis_label='X', y_axis_label='Y',\n",
    "                  peaks=None, peaks_list=False, export_path=False):\n",
    "    \"\"\"Generates an interactive Bokeh plot for the given data vector.\n",
    "    Args:\n",
    "        data_list (list or array): The data to be plotted.\n",
    "        label_list (list of str): The labels of the data vectors\n",
    "        plot_name (str, optional): The title of the plot. Defaults to 'default'.\n",
    "        x_axis (str, optional): The label for the x-axis. Defaults to 'X'.\n",
    "        y_axis (str, optional): The label for the y-axis. Defaults to 'Y'.\n",
    "        peaks (list or array, optional): Indices of peaks to highlight on the plot. Defaults to None.\n",
    "        export_path (False or str): when set to str, will output the resulting html fig\n",
    "    \"\"\"\n",
    "    color_cycle = cycle(bokeh.palettes.Category10_10)\n",
    "    fig = bokeh.plotting.figure(title=f'bokeh explorer: {plot_name}',\n",
    "                                x_axis_label=x_axis_label,\n",
    "                                y_axis_label=y_axis_label,\n",
    "                                plot_width=1500,\n",
    "                                plot_height=700)\n",
    "\n",
    "    for i, data_vector in enumerate(data_list):\n",
    "        \n",
    "        color = next(color_cycle)\n",
    "        \n",
    "        if x_axis_list is None:\n",
    "            x_axis = range(len(data_vector))\n",
    "        elif len(x_axis_list) == len(data_list):\n",
    "            print('x_axis manually set')\n",
    "            x_axis = x_axis_list[i]\n",
    "        else:\n",
    "            raise Exception('problem with x_axis_list input - should be either None, or a list with the same length as data_list')\n",
    "        if label_list is None:\n",
    "            fig.line(x_axis, data_vector, line_color=color, legend_label=f\"Line {i+1}\")\n",
    "        elif len(label_list) == len(data_list):\n",
    "            fig.line(range(len(data_vector)), data_vector, line_color=color, legend_label=f\"{label_list[i]}\")\n",
    "        if peaks is not None and peaks_list is True:\n",
    "            fig.circle(peaks[i], data_vector[peaks[i]], size=10, color=color)\n",
    "\n",
    "    if peaks is not None and peaks_list is False:\n",
    "        fig.circle(peaks, data_vector[peaks], size=10, color='red')\n",
    "\n",
    "    if export_path is not False:\n",
    "        print(f'exporting to {export_path}')\n",
    "        bokeh.io.output.output_file(filename=str(export_path / f'{plot_name}.html'), title=f'{plot_name}')\n",
    "    bokeh.plotting.show(fig)\n",
    "    \n",
    "\n",
    "def load_eye_data_2d_w_rotation_matrix(block):\n",
    "    \"\"\"\n",
    "    This function checks if the eye dataframes and rotation dict object exist, then imports them\n",
    "    :param block: The current blocksync class with verifiec re/le dfs\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data.csv', index_col=0, engine='python')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data.csv', index_col=0, engine='python')\n",
    "    except FileNotFoundError:\n",
    "        print('eye_data files not found, run the pipeline!')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with open(block.analysis_path / 'rotate_eye_data_params.pkl', 'rb') as file:\n",
    "            rotation_dict = pickle.load(file)\n",
    "            block.left_rotation_matrix = rotation_dict['left_rotation_matrix']\n",
    "            block.right_rotation_matrix = rotation_dict['right_rotation_matrix']\n",
    "            block.left_rotation_angle = rotation_dict['left_rotation_angle']\n",
    "            block.right_rotation_angle = rotation_dict['right_rotation_angle']\n",
    "    except FileNotFoundError:\n",
    "        print('No rotation matrix file, create it')\n",
    "    \n",
    "    \n",
    "def create_saccade_events_df(eye_data_df, speed_threshold, bokeh_verify_threshold=False, magnitude_calib=1, speed_profile=True):    \n",
    "    \"\"\"\n",
    "    Detects saccade events in eye tracking data and computes relevant metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - eye_data_df (pd.DataFrame): Input DataFrame containing eye tracking data.\n",
    "    - speed_threshold (float): Threshold for saccade detection based on speed.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): Modified input DataFrame with added columns for speed and saccade detection.\n",
    "    - saccade_events_df (pd.DataFrame): DataFrame containing information about detected saccade events.\n",
    "\n",
    "    Steps:\n",
    "    1. Calculate speed components ('speed_x', 'speed_y') based on differences in 'center_x' and 'center_y'.\n",
    "    2. Compute the magnitude of the velocity vector ('speed_r').\n",
    "    3. Create a binary column ('is_saccade') indicating saccade events based on the speed threshold.\n",
    "    4. Determine saccade onset and offset indices and timestamps.\n",
    "    5. Create a DataFrame ('saccade_events_df') with columns:\n",
    "        - 'saccade_start_ind': Indices of saccade onset.\n",
    "        - 'saccade_start_timestamp': Timestamps corresponding to saccade onset.\n",
    "        - 'saccade_end_ind': Indices of saccade offset.\n",
    "        - 'saccade_end_timestamp': Timestamps corresponding to saccade offset.\n",
    "        - 'length': Duration of each saccade event.\n",
    "    6. Calculate distance traveled and angles for each saccade event.\n",
    "    7. Append additional columns to 'saccade_events_df':\n",
    "        - 'magnitude': Magnitude of the distance traveled during each saccade.\n",
    "        - 'angle': Angle of the saccade vector in degrees.\n",
    "        - 'initial_x', 'initial_y': Initial coordinates of the saccade.\n",
    "        - 'end_x', 'end_y': End coordinates of the saccade.\n",
    "\n",
    "    Note: The original 'eye_data_df' is not modified; modified data is returned as 'df'.\n",
    "    \"\"\"\n",
    "    df = eye_data_df\n",
    "    df['speed_x'] = df['center_x'].diff()  # Difference between consecutive 'center_x' values\n",
    "    df['speed_y'] = df['center_y'].diff()  # Difference between consecutive 'center_y' values\n",
    "    \n",
    "    # Step 2: Calculate magnitude of the velocity vector (R vector speed)\n",
    "    df['speed_r'] = (df['speed_x']**2 + df['speed_y']**2)**0.5\n",
    "    \n",
    "    # Create a column for saccade detection\n",
    "    df['is_saccade'] = df['speed_r'] > speed_threshold\n",
    "    \n",
    "    # create a saccade_on_off indicator where 1 is rising edge and -1 is falling edge by subtracting a shifted binary mask\n",
    "    saccade_on_off = df.is_saccade.astype(int) - df.is_saccade.shift(periods=1,fill_value=False).astype(int)\n",
    "    saccade_on_inds = np.where(saccade_on_off == 1)[0] - 1 # notice the manual shift here, chosen to include the first (sometimes slower) eye frame, just before saccade threshold crossing\n",
    "    saccade_on_ms = df['ms_axis'].iloc[saccade_on_inds]\n",
    "    saccade_on_timestamps = df['OE_timestamp'].iloc[saccade_on_inds]\n",
    "    saccade_off_inds = np.where(saccade_on_off == -1)[0]\n",
    "    saccade_off_timestamps = df['OE_timestamp'].iloc[saccade_off_inds]\n",
    "    saccade_off_ms = df['ms_axis'].iloc[saccade_off_inds]\n",
    "    \n",
    "    saccade_dict = {'saccade_start_ind' :  saccade_on_inds ,\n",
    "                    'saccade_start_timestamp': saccade_on_timestamps.values,\n",
    "                    'saccade_end_ind':      saccade_off_inds,\n",
    "                    'saccade_end_timestamp':saccade_off_timestamps.values,\n",
    "                    'saccade_on_ms': saccade_on_ms.values,\n",
    "                    'saccade_off_ms': saccade_off_ms.values}\n",
    "    \n",
    "    saccade_events_df = pd.DataFrame.from_dict(saccade_dict)\n",
    "    saccade_events_df['length'] = saccade_events_df['saccade_end_ind'] - saccade_events_df['saccade_start_ind']\n",
    "    # Drop columns used for intermediate steps\n",
    "    df = df.drop(['is_saccade'], axis=1)\n",
    "    \n",
    "    distances = []\n",
    "    angles = []\n",
    "    speed_list = []\n",
    "    speed_list_calib = []\n",
    "    diameter_list = []\n",
    "    for index, row in tqdm.tqdm(saccade_events_df.iterrows()):\n",
    "        saccade_samples = df.loc[(df['OE_timestamp'] >= row['saccade_start_timestamp']) & \n",
    "                                 (df['OE_timestamp'] <= row['saccade_end_timestamp'])]\n",
    "        distance_traveled = saccade_samples['speed_r'].sum()\n",
    "        if speed_profile:\n",
    "            saccade_speed_profile = saccade_samples['speed_r'].values\n",
    "            saccade_calib_speed_profile = saccade_samples['speed_r'].values * magnitude_calib \n",
    "            speed_list.append(saccade_speed_profile)\n",
    "            speed_list_calib.append(saccade_calib_speed_profile)\n",
    "        saccade_diameter_profile = saccade_samples['pupil_diameter'].values\n",
    "        diameter_list.append(saccade_diameter_profile)\n",
    "        # Calculate angle from initial position to endpoint\n",
    "        initial_position = saccade_samples.iloc[0][['center_x', 'center_y']]\n",
    "        endpoint = saccade_samples.iloc[-1][['center_x', 'center_y']]\n",
    "        overall_angle = np.arctan2(endpoint['center_y'] - initial_position['center_y'],\n",
    "                           endpoint['center_x'] - initial_position['center_x'])\n",
    "        \n",
    "        angles.append(overall_angle)  \n",
    "        distances.append(distance_traveled)\n",
    "        \n",
    "        \n",
    "    \n",
    "    saccade_events_df['magnitude_raw'] = np.array(distances)\n",
    "    saccade_events_df['magnitude'] = np.array(distances) * magnitude_calib\n",
    "    saccade_events_df['angle'] = np.where(np.isnan(angles), angles, np.rad2deg(angles) % 360) # Convert radians to degrees and ensure result is in [0, 360)\n",
    "    start_ts = saccade_events_df['saccade_start_timestamp'].values\n",
    "    end_ts = saccade_events_df['saccade_end_timestamp'].values\n",
    "    saccade_start_df = df[df['OE_timestamp'].isin(start_ts)]\n",
    "    saccade_end_df = df[df['OE_timestamp'].isin(end_ts)]\n",
    "    start_x_coord = saccade_start_df['center_x']\n",
    "    start_y_coord = saccade_start_df['center_y']\n",
    "    end_x_coord = saccade_end_df['center_x']\n",
    "    end_y_coord = saccade_end_df['center_y']\n",
    "    saccade_events_df['initial_x'] = start_x_coord.values\n",
    "    saccade_events_df['initial_y'] = start_y_coord.values\n",
    "    saccade_events_df['end_x'] = end_x_coord.values\n",
    "    saccade_events_df['end_y'] = end_y_coord.values\n",
    "    saccade_events_df['calib_dx'] = (saccade_events_df['end_x'].values - saccade_events_df['initial_x'].values) * magnitude_calib\n",
    "    saccade_events_df['calib_dy'] = (saccade_events_df['end_y'].values - saccade_events_df['initial_y'].values) * magnitude_calib\n",
    "    if speed_profile:\n",
    "        saccade_events_df['speed_profile'] = speed_list\n",
    "        saccade_events_df['speed_profile_calib'] = speed_list_calib\n",
    "    saccade_events_df['diameter_profile'] = diameter_list\n",
    "    if bokeh_verify_threshold:\n",
    "        bokeh_plotter(data_list=[df.speed_r], label_list=['Pupil Velocity'], peaks=saccade_on_inds)\n",
    "        \n",
    "    return df, saccade_events_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T09:03:51.697067500Z",
     "start_time": "2025-03-27T09:03:50.243322200Z"
    }
   },
   "id": "4acf9d59675659ad",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# create a multi-animal block_collection:\n",
    "\n",
    "def create_block_collections(animals, block_lists, experiment_path, bad_blocks=None):\n",
    "    \"\"\"\n",
    "    Create block collections and a block dictionary from multiple animals and their respective block lists.\n",
    "\n",
    "    Parameters:\n",
    "    - animals: list of str, names of the animals.\n",
    "    - block_lists: list of lists of int, block numbers corresponding to each animal.\n",
    "    - experiment_path: pathlib.Path, path to the experiment directory.\n",
    "    - bad_blocks: list of int, blocks to exclude. Default is an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - block_collection: list of BlockSync objects for all specified blocks.\n",
    "    - block_dict: dictionary where keys are block numbers as strings and values are BlockSync objects.\n",
    "    \"\"\"\n",
    "    import UtilityFunctions_newOE as uf\n",
    "\n",
    "    if bad_blocks is None:\n",
    "        bad_blocks = []\n",
    "\n",
    "    block_collection = []\n",
    "    block_dict = {}\n",
    "\n",
    "    for animal, blocks in zip(animals, block_lists):\n",
    "        # Generate blocks for the current animal\n",
    "        current_blocks = uf.block_generator(\n",
    "            block_numbers=blocks,\n",
    "            experiment_path=experiment_path,\n",
    "            animal=animal,\n",
    "            bad_blocks=bad_blocks\n",
    "        )\n",
    "        # Add to collection and dictionary\n",
    "        block_collection.extend(current_blocks)\n",
    "        for b in current_blocks:\n",
    "            block_dict[f\"{animal}_block_{b.block_num}\"] = b\n",
    "\n",
    "    return block_collection, block_dict\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T09:03:51.711447500Z",
     "start_time": "2025-03-27T09:03:51.698107200Z"
    }
   },
   "id": "8bbe20226992b8b1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 023 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_023, new OE version\n",
      "Found the sample rate for block 023 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 023\n",
      "got it!\n",
      "instantiated block number 024 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_024, new OE version\n",
      "Found the sample rate for block 024 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 024\n",
      "got it!\n",
      "instantiated block number 026 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_026, new OE version\n",
      "Found the sample rate for block 026 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 026\n",
      "got it!\n",
      "instantiated block number 038 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_05_01\\block_038, new OE version\n",
      "Found the sample rate for block 038 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 038\n",
      "got it!\n",
      "instantiated block number 007 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007, new OE version\n",
      "Found the sample rate for block 007 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 007\n",
      "got it!\n",
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_008, new OE version\n",
      "could not find the sample rate in the xml file due to error, will look in the cont file of the first recording...\n",
      "found the sample rate, it is 20000\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 010 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_010, new OE version\n",
      "Found the sample rate for block 010 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 010\n",
      "got it!\n",
      "instantiated block number 011 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_011, new OE version\n",
      "Found the sample rate for block 011 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 011\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 007 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_007, new OE version\n",
      "Found the sample rate for block 007 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 007\n",
      "got it!\n",
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_008, new OE version\n",
      "Found the sample rate for block 008 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 011 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_011, new OE version\n",
      "Found the sample rate for block 011 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 011\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 013 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013, new OE version\n",
      "Found the sample rate for block 013 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 013\n",
      "got it!\n"
     ]
    }
   ],
   "source": [
    "animals = ['PV_62','PV_126','PV_57']\n",
    "block_lists = [[23,24,26,38],[7,8,9,10,11,12],[7,8,9,11,12,13]]\n",
    "experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "bad_blocks = [0]  # Example of bad blocks\n",
    "\n",
    "block_collection, block_dict = create_block_collections(\n",
    "    animals=animals,\n",
    "    block_lists=block_lists,\n",
    "    experiment_path=experiment_path,\n",
    "    bad_blocks=bad_blocks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T09:03:59.859500700Z",
     "start_time": "2025-03-27T09:03:57.574830800Z"
    }
   },
   "id": "16b93d5d7b1649cf",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parse_open_ephys_events...\n",
      "block 023 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 023...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 024 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 024...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 026 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 026...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 038 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 038...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 007 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 007...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 010 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 010...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 011 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 011...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 007 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 007...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 011 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 011...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 013 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 013...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n"
     ]
    }
   ],
   "source": [
    "for block in block_collection:\n",
    "    block.parse_open_ephys_events()\n",
    "    block.get_eye_brightness_vectors()\n",
    "    block.synchronize_block()\n",
    "    block.create_eye_brightness_df(threshold_value=20)\n",
    "\n",
    "    # if the code fails here, go to manual synchronization\n",
    "    block.import_manual_sync_df()\n",
    "    block.read_dlc_data()\n",
    "    block.calibrate_pixel_size(10)\n",
    "    load_eye_data_2d_w_rotation_matrix(block) #should be integrated again... later\n",
    "    \n",
    "    # calibrate pupil diameter:\n",
    "    if 'pupil_diameter' not in block.left_eye_data.columns:\n",
    "        block.left_eye_data['pupil_diameter_pixels'] = block.left_eye_data.major_ax \n",
    "        block.right_eye_data['pupil_diameter_pixels'] = block.right_eye_data.major_ax\n",
    "        block.left_eye_data['pupil_diameter'] = block.left_eye_data['pupil_diameter_pixels'] * block.L_pix_size\n",
    "        block.right_eye_data['pupil_diameter'] = block.right_eye_data['pupil_diameter_pixels'] * block.R_pix_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T09:06:16.918153300Z",
     "start_time": "2025-03-27T09:05:19.099277200Z"
    }
   },
   "id": "75d1d41f64d24593",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# over here, I will re-orient the original \n",
    "# first step is to return to the original orientation by reversing the rotation matrix: \n",
    "\n",
    "\n",
    "# second is using the algorithm's output to re-orient:\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4468bcec06df570f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def kerr(df, aEC = np.nan, bEC = np.nan):\n",
    "    if aEC != aEC:\n",
    "        idx = find_roundest_ellipse_in_df(df)\n",
    "        dx = df.loc[df.index[idx],'center_x']\n",
    "        dy = df.loc[df.index[idx],'center_y']\n",
    "        if not isinstance(dx, numbers.Number):\n",
    "            dx = dx.iloc[0]\n",
    "        if not isinstance(dy, numbers.Number):\n",
    "            dy = dy.iloc[0]\n",
    "        aEC = int(dx)\n",
    "        bEC = int(dy)\n",
    "\n",
    "    theta_values = np.full(len(df), np.nan)  # Initialize theta column with NaNs\n",
    "    phi_values = np.full(len(df), np.nan)  # Initialize phi column with NaNs\n",
    "    r_values = np.full(len(df), np.nan)  # Initialize r column with NaNs\n",
    "\n",
    "    # Convert columns to NumPy arrays for faster access\n",
    "    hw_values = df['ratio2'].values\n",
    "    aPC_values = df['center_x'].values\n",
    "    bPC_values = df['center_y'].values\n",
    "\n",
    "    # Mask for valid `hw` values (to ignore NaNs)\n",
    "    valid_mask = ~np.isnan(hw_values)\n",
    "\n",
    "    # Vectorized computation for `top` and `bot`\n",
    "    sqrt_component = np.sqrt(1 - hw_values[valid_mask]**2)\n",
    "    distances = np.sqrt((aPC_values[valid_mask] - aEC)**2 + (bPC_values[valid_mask] - bEC)**2)\n",
    "\n",
    "    top_values = sqrt_component * distances\n",
    "    bot_values = (1 - hw_values[valid_mask]**2)\n",
    "\n",
    "    top = np.sum(top_values)\n",
    "    bot = np.sum(bot_values)\n",
    "\n",
    "    f_z = top / bot\n",
    "\n",
    "    # Compute `r` for all rows where `major_ax` is valid\n",
    "    valid_major_ax = ~np.isnan(df['major_ax'].values)\n",
    "    max_axes = np.maximum(df['major_ax'].values, df['minor_ax'].values)\n",
    "    r_values[valid_major_ax]  = (2 * max_axes[valid_major_ax]) / f_z\n",
    "\n",
    "    # Compute `theta` and `phi` in a vectorized way\n",
    "    valid_positions = ~np.isnan(aPC_values) & ~np.isnan(bPC_values)\n",
    "\n",
    "    comp_p = np.arcsin((aPC_values[valid_positions] - aEC) / f_z)\n",
    "    comp_t = np.arcsin((bPC_values[valid_positions] - bEC) / (np.cos(comp_p) * f_z))\n",
    "\n",
    "    theta_values[valid_positions] = np.degrees(comp_t)\n",
    "    phi_values[valid_positions] = np.degrees(comp_p)\n",
    "\n",
    "    # Create output DataFrame\n",
    "    output_df = pd.DataFrame({'r': r_values, 'theta': theta_values, 'phi': phi_values}, index=df.index)\n",
    "    output_df = pd.concat([df[['OE_timestamp', 'eye_frame', 'ms_axis']],output_df], axis=1)\n",
    "    return f_z, output_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ef4c731abd89036"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def kerr_block(block,ref_points):\n",
    "    time = datetime.datetime.now()\n",
    "    print(f'working on Block {block.block_num}')\n",
    "    print('Left eye')\n",
    "    df = block.left_eye_data\n",
    "    df['ratio2'] = df.minor_ax / df.major_ax\n",
    "    df['phi_ellipse'] = df.phi\n",
    "    try:\n",
    "        ref_row = ref_points[(ref_points.eye == 'L') & (ref_points.animal == int(block.animal_call.replace('PV_',''))) & (ref_points.block == int(block.block_num))]\n",
    "        aEC, bEC = ref_row.x0.iloc[0] , ref_row.y0.iloc[0]\n",
    "    except:\n",
    "        idx = find_roundest_ellipse_in_df(df)\n",
    "        dx = df.loc[df.index[idx],'center_x']\n",
    "        dy = df.loc[df.index[idx],'center_y']\n",
    "        if not isinstance(dx, numbers.Number):\n",
    "            dx = dx.iloc[0]\n",
    "        if not isinstance(dy, numbers.Number):\n",
    "            dy = dy.iloc[0]\n",
    "        aEC = int(dx)\n",
    "        bEC = int(dy)\n",
    "    f_z, output_df = kerr(df, aEC=aEC, bEC=bEC)\n",
    "\n",
    "    block.left_eye_kerr_ang = output_df\n",
    "    output_path = block.analysis_path /'left_kerr_angles.pkl'\n",
    "    res_dict = {'aEC':aEC, 'bEC':bEC, 'data':output_df}\n",
    "    with open(output_path, 'wb') as file:\n",
    "        pickle.dump(res_dict, file)\n",
    "\n",
    "\n",
    "    print('Right eye')\n",
    "    df = block.right_eye_data\n",
    "    df['ratio2'] = df.minor_ax / df.major_ax\n",
    "    df['phi_ellipse'] = df.phi\n",
    "    try:\n",
    "        ref_row = ref_points[(ref_points.eye == 'R') & (ref_points.animal == int(block.animal_call.replace('PV_',''))) & (ref_points.block == int(block.block_num))]\n",
    "        aEC, bEC = ref_row.x0.iloc[0] , ref_row.y0.iloc[0]\n",
    "    except:\n",
    "        idx = find_roundest_ellipse_in_df(df)\n",
    "        dx = df.loc[df.index[idx],'center_x']\n",
    "        dy = df.loc[df.index[idx],'center_y']\n",
    "        if not isinstance(dx, numbers.Number):\n",
    "            dx = dx.iloc[0]\n",
    "        if not isinstance(dy, numbers.Number):\n",
    "            dy = dy.iloc[0]\n",
    "        aEC = int(dx)\n",
    "        bEC = int(dy)\n",
    "    f_z, output_df = kerr(df, aEC, bEC)\n",
    "\n",
    "    block.right_eye_kerr_ang = output_df\n",
    "    output_path = block.analysis_path /'right_kerr_angles.pkl'\n",
    "    res_dict = {'aEC':aEC, 'bEC':bEC, 'data':output_df}\n",
    "    with open(output_path, 'wb') as file:\n",
    "        pickle.dump(res_dict, file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "723373d7e7ce7c2b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
