{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import cycle\n",
    "import pickle\n",
    "import pathlib\n",
    "import math\n",
    "import tqdm\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import re\n",
    "from lxml import etree as ET\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "from scipy.stats import kde\n",
    "from BlockSync_current import BlockSync\n",
    "import UtilityFunctions_newOE as uf\n",
    "from scipy import signal\n",
    "import bokeh\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42  # Ensure fonts are embedded and editable\n",
    "rcParams['ps.fonttype'] = 42  # Ensure compatibility with vector outputs\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def bokeh_plotter(data_list, x_axis_list=None, label_list=None, \n",
    "                  plot_name='default',\n",
    "                  x_axis_label='X', y_axis_label='Y',\n",
    "                  peaks=None, peaks_list=False, export_path=False):\n",
    "    \"\"\"Generates an interactive Bokeh plot for the given data vector.\n",
    "    Args:\n",
    "        data_list (list or array): The data to be plotted.\n",
    "        label_list (list of str): The labels of the data vectors\n",
    "        plot_name (str, optional): The title of the plot. Defaults to 'default'.\n",
    "        x_axis (str, optional): The label for the x-axis. Defaults to 'X'.\n",
    "        y_axis (str, optional): The label for the y-axis. Defaults to 'Y'.\n",
    "        peaks (list or array, optional): Indices of peaks to highlight on the plot. Defaults to None.\n",
    "        export_path (False or str): when set to str, will output the resulting html fig\n",
    "    \"\"\"\n",
    "    color_cycle = cycle(bokeh.palettes.Category10_10)\n",
    "    fig = bokeh.plotting.figure(title=f'bokeh explorer: {plot_name}',\n",
    "                                x_axis_label=x_axis_label,\n",
    "                                y_axis_label=y_axis_label,\n",
    "                                plot_width=1500,\n",
    "                                plot_height=700)\n",
    "\n",
    "    for i, data_vector in enumerate(data_list):\n",
    "        \n",
    "        color = next(color_cycle)\n",
    "        \n",
    "        if x_axis_list is None:\n",
    "            x_axis = range(len(data_vector))\n",
    "        elif len(x_axis_list) == len(data_list):\n",
    "            print('x_axis manually set')\n",
    "            x_axis = x_axis_list[i]\n",
    "        else:\n",
    "            raise Exception('problem with x_axis_list input - should be either None, or a list with the same length as data_list')\n",
    "        if label_list is None:\n",
    "            fig.line(x_axis, data_vector, line_color=color, legend_label=f\"Line {i+1}\")\n",
    "        elif len(label_list) == len(data_list):\n",
    "            fig.line(range(len(data_vector)), data_vector, line_color=color, legend_label=f\"{label_list[i]}\")\n",
    "        if peaks is not None and peaks_list is True:\n",
    "            fig.circle(peaks[i], data_vector[peaks[i]], size=10, color=color)\n",
    "\n",
    "    if peaks is not None and peaks_list is False:\n",
    "        fig.circle(peaks, data_vector[peaks], size=10, color='red')\n",
    "\n",
    "    if export_path is not False:\n",
    "        print(f'exporting to {export_path}')\n",
    "        bokeh.io.output.output_file(filename=str(export_path / f'{plot_name}.html'), title=f'{plot_name}')\n",
    "    bokeh.plotting.show(fig)\n",
    "    \n",
    "\n",
    "def load_eye_data_2d_w_rotation_matrix(block):\n",
    "    \"\"\"\n",
    "    This function checks if the eye dataframes and rotation dict object exist, then imports them\n",
    "    :param block: The current blocksync class with verifiec re/le dfs\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data.csv', index_col=0, engine='python')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data.csv', index_col=0, engine='python')\n",
    "    except FileNotFoundError:\n",
    "        print('eye_data files not found, run the pipeline!')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with open(block.analysis_path / 'rotate_eye_data_params.pkl', 'rb') as file:\n",
    "            rotation_dict = pickle.load(file)\n",
    "            block.left_rotation_matrix = rotation_dict['left_rotation_matrix']\n",
    "            block.right_rotation_matrix = rotation_dict['right_rotation_matrix']\n",
    "            block.left_rotation_angle = rotation_dict['left_rotation_angle']\n",
    "            block.right_rotation_angle = rotation_dict['right_rotation_angle']\n",
    "    except FileNotFoundError:\n",
    "        print('No rotation matrix file, create it')\n",
    "    \n",
    "    \n",
    "def create_saccade_events_df(eye_data_df, speed_threshold, bokeh_verify_threshold=False, magnitude_calib=1, speed_profile=True):    \n",
    "    \"\"\"\n",
    "    Detects saccade events in eye tracking data and computes relevant metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - eye_data_df (pd.DataFrame): Input DataFrame containing eye tracking data.\n",
    "    - speed_threshold (float): Threshold for saccade detection based on speed.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): Modified input DataFrame with added columns for speed and saccade detection.\n",
    "    - saccade_events_df (pd.DataFrame): DataFrame containing information about detected saccade events.\n",
    "\n",
    "    Steps:\n",
    "    1. Calculate speed components ('speed_x', 'speed_y') based on differences in 'center_x' and 'center_y'.\n",
    "    2. Compute the magnitude of the velocity vector ('speed_r').\n",
    "    3. Create a binary column ('is_saccade') indicating saccade events based on the speed threshold.\n",
    "    4. Determine saccade onset and offset indices and timestamps.\n",
    "    5. Create a DataFrame ('saccade_events_df') with columns:\n",
    "        - 'saccade_start_ind': Indices of saccade onset.\n",
    "        - 'saccade_start_timestamp': Timestamps corresponding to saccade onset.\n",
    "        - 'saccade_end_ind': Indices of saccade offset.\n",
    "        - 'saccade_end_timestamp': Timestamps corresponding to saccade offset.\n",
    "        - 'length': Duration of each saccade event.\n",
    "    6. Calculate distance traveled and angles for each saccade event.\n",
    "    7. Append additional columns to 'saccade_events_df':\n",
    "        - 'magnitude': Magnitude of the distance traveled during each saccade.\n",
    "        - 'angle': Angle of the saccade vector in degrees.\n",
    "        - 'initial_x', 'initial_y': Initial coordinates of the saccade.\n",
    "        - 'end_x', 'end_y': End coordinates of the saccade.\n",
    "\n",
    "    Note: The original 'eye_data_df' is not modified; modified data is returned as 'df'.\n",
    "    \"\"\"\n",
    "    df = eye_data_df\n",
    "    df['speed_x'] = df['center_x'].diff()  # Difference between consecutive 'center_x' values\n",
    "    df['speed_y'] = df['center_y'].diff()  # Difference between consecutive 'center_y' values\n",
    "    \n",
    "    # Step 2: Calculate magnitude of the velocity vector (R vector speed)\n",
    "    df['speed_r'] = (df['speed_x']**2 + df['speed_y']**2)**0.5\n",
    "    \n",
    "    # Create a column for saccade detection\n",
    "    df['is_saccade'] = df['speed_r'] > speed_threshold\n",
    "    \n",
    "    # create a saccade_on_off indicator where 1 is rising edge and -1 is falling edge by subtracting a shifted binary mask\n",
    "    saccade_on_off = df.is_saccade.astype(int) - df.is_saccade.shift(periods=1,fill_value=False).astype(int)\n",
    "    saccade_on_inds = np.where(saccade_on_off == 1)[0] - 1 # notice the manual shift here, chosen to include the first (sometimes slower) eye frame, just before saccade threshold crossing\n",
    "    saccade_on_ms = df['ms_axis'].iloc[saccade_on_inds]\n",
    "    saccade_on_timestamps = df['OE_timestamp'].iloc[saccade_on_inds]\n",
    "    saccade_off_inds = np.where(saccade_on_off == -1)[0]\n",
    "    saccade_off_timestamps = df['OE_timestamp'].iloc[saccade_off_inds]\n",
    "    saccade_off_ms = df['ms_axis'].iloc[saccade_off_inds]\n",
    "    \n",
    "    saccade_dict = {'saccade_start_ind' :  saccade_on_inds ,\n",
    "                    'saccade_start_timestamp': saccade_on_timestamps.values,\n",
    "                    'saccade_end_ind':      saccade_off_inds,\n",
    "                    'saccade_end_timestamp':saccade_off_timestamps.values,\n",
    "                    'saccade_on_ms': saccade_on_ms.values,\n",
    "                    'saccade_off_ms': saccade_off_ms.values}\n",
    "    \n",
    "    saccade_events_df = pd.DataFrame.from_dict(saccade_dict)\n",
    "    saccade_events_df['length'] = saccade_events_df['saccade_end_ind'] - saccade_events_df['saccade_start_ind']\n",
    "    # Drop columns used for intermediate steps\n",
    "    df = df.drop(['is_saccade'], axis=1)\n",
    "    \n",
    "    distances = []\n",
    "    angles = []\n",
    "    speed_list = []\n",
    "    diameter_list = []\n",
    "    for index, row in tqdm.tqdm(saccade_events_df.iterrows()):\n",
    "        saccade_samples = df.loc[(df['OE_timestamp'] >= row['saccade_start_timestamp']) & \n",
    "                                 (df['OE_timestamp'] <= row['saccade_end_timestamp'])]\n",
    "        distance_traveled = saccade_samples['speed_r'].sum()\n",
    "        if speed_profile:\n",
    "            saccade_speed_profile = saccade_samples['speed_r'].values\n",
    "            speed_list.append(saccade_speed_profile)\n",
    "        saccade_diameter_profile = saccade_samples['pupil_diameter'].values\n",
    "        diameter_list.append(saccade_diameter_profile)\n",
    "        # Calculate angle from initial position to endpoint\n",
    "        initial_position = saccade_samples.iloc[0][['center_x', 'center_y']]\n",
    "        endpoint = saccade_samples.iloc[-1][['center_x', 'center_y']]\n",
    "        overall_angle = np.arctan2(endpoint['center_y'] - initial_position['center_y'],\n",
    "                           endpoint['center_x'] - initial_position['center_x'])\n",
    "        \n",
    "        angles.append(overall_angle)  \n",
    "        distances.append(distance_traveled)\n",
    "        \n",
    "        \n",
    "    \n",
    "    saccade_events_df['magnitude_raw'] = np.array(distances)\n",
    "    saccade_events_df['magnitude'] = np.array(distances) * magnitude_calib\n",
    "    saccade_events_df['angle'] = np.where(np.isnan(angles), angles, np.rad2deg(angles) % 360) # Convert radians to degrees and ensure result is in [0, 360)\n",
    "    start_ts = saccade_events_df['saccade_start_timestamp'].values\n",
    "    end_ts = saccade_events_df['saccade_end_timestamp'].values\n",
    "    saccade_start_df = df[df['OE_timestamp'].isin(start_ts)]\n",
    "    saccade_end_df = df[df['OE_timestamp'].isin(end_ts)]\n",
    "    start_x_coord = saccade_start_df['center_x']\n",
    "    start_y_coord = saccade_start_df['center_y']\n",
    "    end_x_coord = saccade_end_df['center_x']\n",
    "    end_y_coord = saccade_end_df['center_y']\n",
    "    saccade_events_df['initial_x'] = start_x_coord.values\n",
    "    saccade_events_df['initial_y'] = start_y_coord.values\n",
    "    saccade_events_df['end_x'] = end_x_coord.values\n",
    "    saccade_events_df['end_y'] = end_y_coord.values\n",
    "    saccade_events_df['calib_dx'] = (saccade_events_df['end_x'].values - saccade_events_df['initial_x'].values) * magnitude_calib\n",
    "    saccade_events_df['calib_dy'] = (saccade_events_df['end_y'].values - saccade_events_df['initial_y'].values) * magnitude_calib\n",
    "    if speed_profile:\n",
    "        saccade_events_df['speed_profile'] = speed_list\n",
    "    saccade_events_df['diameter_profile'] = diameter_list\n",
    "    if bokeh_verify_threshold:\n",
    "        bokeh_plotter(data_list=[df.speed_r], label_list=['Pupil Velocity'], peaks=saccade_on_inds)\n",
    "        \n",
    "    return df, saccade_events_df\n",
    "\n",
    "# create a multi-animal block_collection:\n",
    "\n",
    "def create_block_collections(animals, block_lists, experiment_path, bad_blocks=None):\n",
    "    \"\"\"\n",
    "    Create block collections and a block dictionary from multiple animals and their respective block lists.\n",
    "\n",
    "    Parameters:\n",
    "    - animals: list of str, names of the animals.\n",
    "    - block_lists: list of lists of int, block numbers corresponding to each animal.\n",
    "    - experiment_path: pathlib.Path, path to the experiment directory.\n",
    "    - bad_blocks: list of int, blocks to exclude. Default is an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - block_collection: list of BlockSync objects for all specified blocks.\n",
    "    - block_dict: dictionary where keys are block numbers as strings and values are BlockSync objects.\n",
    "    \"\"\"\n",
    "    import UtilityFunctions_newOE as uf\n",
    "\n",
    "    if bad_blocks is None:\n",
    "        bad_blocks = []\n",
    "\n",
    "    block_collection = []\n",
    "    block_dict = {}\n",
    "\n",
    "    for animal, blocks in zip(animals, block_lists):\n",
    "        # Generate blocks for the current animal\n",
    "        current_blocks = uf.block_generator(\n",
    "            block_numbers=blocks,\n",
    "            experiment_path=experiment_path,\n",
    "            animal=animal,\n",
    "            bad_blocks=bad_blocks\n",
    "        )\n",
    "        # Add to collection and dictionary\n",
    "        block_collection.extend(current_blocks)\n",
    "        for b in current_blocks:\n",
    "            block_dict[f\"{animal}_block_{b.block_num}\"] = b\n",
    "    \n",
    "    return block_collection, block_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T15:33:05.065841200Z",
     "start_time": "2025-04-08T15:33:02.427781800Z"
    }
   },
   "id": "709e85a3c82a3ee7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 023 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_023, new OE version\n",
      "Found the sample rate for block 023 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 023\n",
      "got it!\n",
      "instantiated block number 024 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_024, new OE version\n",
      "Found the sample rate for block 024 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 024\n",
      "got it!\n",
      "instantiated block number 026 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_026, new OE version\n",
      "Found the sample rate for block 026 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 026\n",
      "got it!\n",
      "instantiated block number 038 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_05_01\\block_038, new OE version\n",
      "Found the sample rate for block 038 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 038\n",
      "got it!\n",
      "instantiated block number 007 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007, new OE version\n",
      "Found the sample rate for block 007 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 007\n",
      "got it!\n",
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_008, new OE version\n",
      "could not find the sample rate in the xml file due to error, will look in the cont file of the first recording...\n",
      "found the sample rate, it is 20000\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 010 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_010, new OE version\n",
      "Found the sample rate for block 010 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 010\n",
      "got it!\n",
      "instantiated block number 011 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_011, new OE version\n",
      "Found the sample rate for block 011 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 011\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 007 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_007, new OE version\n",
      "Found the sample rate for block 007 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 007\n",
      "got it!\n",
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_008, new OE version\n",
      "Found the sample rate for block 008 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 011 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_011, new OE version\n",
      "Found the sample rate for block 011 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 011\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 013 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013, new OE version\n",
      "Found the sample rate for block 013 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 013\n",
      "got it!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "animals = ['PV_62','PV_126','PV_57']\n",
    "block_lists = [[23,24,26,38],[7,8,9,10,11,12],[7,8,9,11,12,13]]\n",
    "experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "bad_blocks = [0]  # Example of bad blocks\n",
    "\n",
    "block_collection, block_dict = create_block_collections(\n",
    "    animals=animals, \n",
    "    block_lists=block_lists, \n",
    "    experiment_path=experiment_path, \n",
    "    bad_blocks=bad_blocks\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T15:33:08.094307700Z",
     "start_time": "2025-04-08T15:33:05.068726800Z"
    }
   },
   "id": "65ade2ee05680ec7",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parse_open_ephys_events...\n",
      "block 023 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 023...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 024 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 024...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 026 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 026...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 038 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 038...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 007 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 007...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 010 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 010...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 011 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 011...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 007 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 007...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 011 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 011...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 013 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 013...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n"
     ]
    }
   ],
   "source": [
    "for block in block_collection:\n",
    "    block.parse_open_ephys_events()\n",
    "    block.get_eye_brightness_vectors()\n",
    "    block.synchronize_block()\n",
    "    block.create_eye_brightness_df(threshold_value=20)\n",
    "\n",
    "    # if the code fails here, go to manual synchronization\n",
    "    block.import_manual_sync_df()\n",
    "    block.read_dlc_data()\n",
    "    block.calibrate_pixel_size(10)\n",
    "    #load_eye_data_2d_w_rotation_matrix(block) #should be integrated again... later\n",
    "    block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data_degrees_raw.csv', index_col=0, engine='python')\n",
    "    block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_raw.csv', index_col=0, engine='python')\n",
    "    \n",
    "    # calibrate pupil diameter:\n",
    "    if 'pupil_diameter' not in block.left_eye_data.columns:\n",
    "        block.left_eye_data['pupil_diameter_pixels'] = block.left_eye_data.major_ax \n",
    "        block.right_eye_data['pupil_diameter_pixels'] = block.right_eye_data.major_ax\n",
    "        block.left_eye_data['pupil_diameter'] = block.left_eye_data['pupil_diameter_pixels'] * block.L_pix_size\n",
    "        block.right_eye_data['pupil_diameter'] = block.right_eye_data['pupil_diameter_pixels'] * block.R_pix_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T15:35:03.320349600Z",
     "start_time": "2025-04-08T15:33:47.713825800Z"
    }
   },
   "id": "f44e98728b4d6d9d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Unnamed: 0.1', 'OE_timestamp', 'eye_frame', 'ms_axis', 'center_x',\n       'center_y', 'phi', 'width', 'height', 'major_ax', 'minor_ax', 'ratio',\n       'pupil_diameter_pixels', 'pupil_diameter', 'ratio2', 'phi_ellipse',\n       'k_phi', 'k_theta'],\n      dtype='object')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.left_eye_data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T15:35:13.973812200Z",
     "start_time": "2025-04-08T15:35:13.948785100Z"
    }
   },
   "id": "d4a2b9a730bc925c",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# over here, I am creating the new rotation function for the eye_data dfs - this should be integrated into the blocksync class later: \n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def rotate_single_eye_data(block, eye, new_rotation_angle):\n",
    "    \"\"\"\n",
    "    Rotate the eye data for a single eye by counter-rotating the current rotation and applying an additional rotation.\n",
    "    \n",
    "    This function:\n",
    "      1. Determines the center of the frame by reading the first frame of the corresponding eye video.\n",
    "      2. Computes the net rotation as: net_rotation = new_rotation_angle - current_rotation_angle.\n",
    "      3. Applies the net rotation to the 'center_x' and 'center_y' coordinates of the eye data.\n",
    "      4. Updates the 'phi' (ellipse orientation) by subtracting the net rotation.\n",
    "      5. Updates the BlockSync object with the newly rotated data and new rotation angle.\n",
    "    \n",
    "    Parameters:\n",
    "        block : BlockSync object\n",
    "            The BlockSync instance containing the eye data and rotation parameters.\n",
    "        eye : str\n",
    "            Either \"left\" or \"right\", indicating which eye's data to rotate.\n",
    "        new_rotation_angle : float\n",
    "            The desired new rotation angle (in degrees) after applying the transformation.\n",
    "    \n",
    "    Returns:\n",
    "        None. The function updates the block.left_eye_data or block.right_eye_data and the corresponding rotation angle in-place.\n",
    "    \"\"\"\n",
    "    # Select the appropriate data and video list based on the eye.\n",
    "    if eye.lower() == 'left':\n",
    "        eye_data = block.left_eye_data\n",
    "        current_angle = block.left_rotation_angle\n",
    "        video_list = block.le_videos\n",
    "    elif eye.lower() == 'right':\n",
    "        eye_data = block.right_eye_data\n",
    "        current_angle = block.right_rotation_angle\n",
    "        video_list = block.re_videos\n",
    "    else:\n",
    "        raise ValueError(\"Eye must be 'left' or 'right'\")\n",
    "    \n",
    "    # Ensure that there is at least one video available.\n",
    "    if not video_list:\n",
    "        raise ValueError(f\"No video available for {eye} eye.\")\n",
    "    \n",
    "    # Open the first video to determine frame dimensions and compute the center.\n",
    "    video_path = video_list[0]\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    center = (frame_width / 2, frame_height / 2)\n",
    "    cap.release()\n",
    "    \n",
    "    # Compute the net rotation angle: first counter-rotate (undo current) then apply new rotation.\n",
    "    net_rotation = new_rotation_angle - current_angle\n",
    "    \n",
    "    # Compute the affine transformation matrix for the net rotation.\n",
    "    M = cv2.getRotationMatrix2D(center, net_rotation, 1.0)\n",
    "    \n",
    "    # Extract (center_x, center_y) from the DataFrame and convert to float32.\n",
    "    coords = eye_data[['center_x', 'center_y']].values.astype(np.float32)\n",
    "    # Convert coordinates to homogeneous form by adding a column of ones.\n",
    "    ones = np.ones((coords.shape[0], 1), dtype=np.float32)\n",
    "    coords_homogeneous = np.hstack([coords, ones])\n",
    "    # Apply the rotation matrix.\n",
    "    rotated_coords = np.dot(M, coords_homogeneous.T).T\n",
    "    # Update the DataFrame with the new coordinates.\n",
    "    eye_data['center_x'] = rotated_coords[:, 0]\n",
    "    eye_data['center_y'] = rotated_coords[:, 1]\n",
    "    \n",
    "    # Update the ellipse orientation (phi) by subtracting the net rotation.\n",
    "    eye_data['phi'] = (eye_data['phi'] - net_rotation) % 360\n",
    "    \n",
    "    # Update the BlockSync object with the rotated data and new rotation angle.\n",
    "    if eye.lower() == 'left':\n",
    "        block.left_eye_data = eye_data\n",
    "        block.left_rotation_angle = new_rotation_angle\n",
    "    else:\n",
    "        block.right_eye_data = eye_data\n",
    "        block.right_rotation_angle = new_rotation_angle\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f3629d50b74993b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rotate_single_eye_data(block,'left',new_rotation_angle=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "223a9ef426e89fa5",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def verify_frame_alignment_scroll(block, eye, path_to_video=False, xflip=False, phi_in_radians=False):\n",
    "    \"\"\"\n",
    "    Allows interactive scrolling through video frames via a trackbar to verify that the rotated \n",
    "    video frames and the corresponding rotated eye data (ellipse overlay) are correctly aligned.\n",
    "    \n",
    "    The function:\n",
    "      - Opens the video for the specified eye (using block.le_videos or block.re_videos).\n",
    "      - Creates an OpenCV window with a \"Frame\" trackbar to select the frame index.\n",
    "      - For each selected frame, it reads the raw frame, applies the stored rotation (using the \n",
    "        stored rotation angle for that eye to compute a transformation matrix based on the frame's center),\n",
    "        - Retrieves the corresponding ellipse data (center_x, center_y, phi, width, height) for that frame,\n",
    "        - Draws the ellipse on the rotated frame, and displays the result.\n",
    "    \n",
    "    Parameters:\n",
    "        block : BlockSync object\n",
    "            Contains the video lists and rotated eye data DataFrames (left_eye_data/right_eye_data),\n",
    "            as well as the stored rotation angles (left_rotation_angle/right_rotation_angle).\n",
    "        eye : str\n",
    "            Either \"left\" or \"right\", specifying which eyeâ€™s video and data to use.\n",
    "        path_to_video : str or False, optional\n",
    "            If provided, overrides the video path stored in the block.\n",
    "        xflip : bool, optional\n",
    "            If True, the frame is flipped horizontally.\n",
    "        phi_in_radians : bool, optional\n",
    "            If True, converts the ellipse orientation to radians before drawing.\n",
    "    \n",
    "    Returns:\n",
    "        None. The function only displays the video; press 'q' to exit.\n",
    "    \"\"\"\n",
    "    # Select the appropriate video and ellipse data based on the eye.\n",
    "    if eye.lower() == 'left':\n",
    "        video_path = block.le_videos[0]\n",
    "        ellipse_dataframe = block.left_eye_data\n",
    "        stored_angle = block.left_rotation_angle\n",
    "    elif eye.lower() == 'right':\n",
    "        video_path = block.re_videos[0]\n",
    "        ellipse_dataframe = block.right_eye_data\n",
    "        stored_angle = block.right_rotation_angle\n",
    "    else:\n",
    "        raise ValueError(\"eye must be 'left' or 'right'\")\n",
    "    \n",
    "    if path_to_video:\n",
    "        video_path = path_to_video\n",
    "\n",
    "    # Open the video.\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file.\")\n",
    "        return\n",
    "\n",
    "    # Get video frame count and dimensions.\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    ret, temp_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading first frame.\")\n",
    "        cap.release()\n",
    "        return\n",
    "    frame_height, frame_width = temp_frame.shape[:2]\n",
    "    center = (frame_width / 2, frame_height / 2)\n",
    "    \n",
    "    # Create window and trackbar.\n",
    "    window_name = \"Frame Alignment Verification\"\n",
    "    cv2.namedWindow(window_name)\n",
    "    cv2.createTrackbar(\"Frame\", window_name, 0, frame_count - 1, lambda x: None)\n",
    "\n",
    "    while True:\n",
    "        # Read current frame index from trackbar.\n",
    "        frame_idx = cv2.getTrackbarPos(\"Frame\", window_name)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        if xflip:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Compute the transformation matrix using the stored rotation angle.\n",
    "        # (This rotates the raw video frame so that its orientation matches the rotated eye data.)\n",
    "        M = cv2.getRotationMatrix2D(center, stored_angle, 1.0)\n",
    "        rotated_frame = cv2.warpAffine(frame, M, (frame_width, frame_height))\n",
    "        \n",
    "        # Retrieve the ellipse data for the current frame.\n",
    "        current_frame_num = frame_idx\n",
    "        try:\n",
    "            # Assumes the eye_data DataFrame has an \"eye_frame\" column matching the frame number.\n",
    "            idx = ellipse_dataframe.query(\"eye_frame == @current_frame_num\").index[0]\n",
    "            ellipse_data = ellipse_dataframe.loc[idx]\n",
    "            \n",
    "            # Use the rotated coordinates as stored in the DataFrame.\n",
    "            ell_center = (int(ellipse_data['center_x']), int(ellipse_data['center_y']))\n",
    "            ell_width = int(ellipse_data['width'])\n",
    "            ell_height = int(ellipse_data['height'])\n",
    "            ell_phi = float(ellipse_data['phi'])\n",
    "            if phi_in_radians:\n",
    "                ell_phi = np.deg2rad(ell_phi)\n",
    "            \n",
    "            # Draw the ellipse on the rotated frame.\n",
    "            cv2.ellipse(rotated_frame, ell_center, (ell_width, ell_height), ell_phi, 0, 360, (0, 255, 0), 2)\n",
    "        except IndexError:\n",
    "            # If no ellipse data exists for this frame, simply continue.\n",
    "            pass\n",
    "\n",
    "        # Display the frame along with an overlay of the current frame index.\n",
    "        cv2.putText(rotated_frame, f'Frame: {frame_idx}', (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(window_name, rotated_frame)\n",
    "\n",
    "        # Wait a short moment and break if 'q' is pressed.\n",
    "        if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "verify_frame_alignment_scroll(block, 'left', path_to_video=False, xflip=True, phi_in_radians=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T13:20:35.043183300Z",
     "start_time": "2025-04-06T13:20:30.895857Z"
    }
   },
   "id": "89e90e65f6b769b9",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T13:20:24.854532800Z",
     "start_time": "2025-04-06T13:20:24.834051200Z"
    }
   },
   "id": "e964de1483c71a77",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This function zeros the previous iteration of rotation-correction - we do this to create a new paradigm where we load data raw, and rotate it subsequently according to pre-defined angles for each eye. \n",
    "# first step is to check this works\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def restore_original_eye_data(block, save_to_disk=True):\n",
    "    \"\"\"\n",
    "    Restores the original orientation of the rotated eye data CSV files by counter-rotating \n",
    "    the data using the stored rotation parameters. The function:\n",
    "    \n",
    "      1. Loads the left and right eye data CSV files (if not already loaded).\n",
    "      2. Loads the rotation parameters (left/right rotation angles and matrices) from the \n",
    "         'rotate_eye_data_params.pkl' file.\n",
    "      3. For each eye, determines the frame center using the first frame of the corresponding video.\n",
    "      4. Computes the inverse transformation matrix using the negative stored rotation angle.\n",
    "      5. Applies this transformation to the 'center_x' and 'center_y' columns.\n",
    "      6. Updates the ellipse orientation ('phi') by adding the stored rotation angle.\n",
    "      7. Updates the BlockSync object in memory and (optionally) saves the restored data to new CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "        block : BlockSync object\n",
    "            The BlockSync object containing:\n",
    "              - analysis_path (a pathlib.Path)\n",
    "              - le_videos and re_videos (lists of video paths)\n",
    "              - left_eye_data and right_eye_data attributes (if not, they will be loaded)\n",
    "        save_to_disk : bool, optional\n",
    "            If True, the restored data is saved as 'left_eye_data_original.csv' and \n",
    "            'right_eye_data_original.csv' in the analysis folder.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Load eye data CSV files if not already loaded.\n",
    "    try:\n",
    "        if block.left_eye_data is None:\n",
    "            block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data.csv', index_col=0, engine='python')\n",
    "        if block.right_eye_data is None:\n",
    "            block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data.csv', index_col=0, engine='python')\n",
    "    except Exception as e:\n",
    "        print(\"Error loading eye data CSV files:\", e)\n",
    "        return\n",
    "    \n",
    "    # Step 2: Load rotation parameters.\n",
    "    try:\n",
    "        with open(block.analysis_path / 'rotate_eye_data_params.pkl', 'rb') as f:\n",
    "            rotation_dict = pickle.load(f)\n",
    "            block.left_rotation_angle = rotation_dict.get('left_rotation_angle', 0)\n",
    "            block.right_rotation_angle = rotation_dict.get('right_rotation_angle', 0)\n",
    "            block.left_rotation_matrix = rotation_dict.get('left_rotation_matrix', None)\n",
    "            block.right_rotation_matrix = rotation_dict.get('right_rotation_matrix', None)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Rotation parameters file not found. Cannot restore original orientation.\")\n",
    "        return\n",
    "    \n",
    "    # Helper function to restore eye data.\n",
    "    def restore_eye_data(eye_data, video_path, stored_angle):\n",
    "        # Open the video to determine frame dimensions.\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            raise ValueError(f\"Cannot read first frame from video: {video_path}\")\n",
    "        frame_height, frame_width = frame.shape[:2]\n",
    "        center = (frame_width / 2, frame_height / 2)\n",
    "        cap.release()\n",
    "        \n",
    "        # Compute the inverse rotation:\n",
    "        # To restore the original orientation, apply a rotation of -stored_angle.\n",
    "        net_rotation = -stored_angle\n",
    "        \n",
    "        # Compute the inverse transformation matrix.\n",
    "        M_inv = cv2.getRotationMatrix2D(center, net_rotation, 1.0)\n",
    "        \n",
    "        # Apply the transformation to the (center_x, center_y) coordinates.\n",
    "        coords = eye_data[['center_x', 'center_y']].values.astype(np.float32)\n",
    "        ones = np.ones((coords.shape[0], 1), dtype=np.float32)\n",
    "        coords_hom = np.hstack([coords, ones])\n",
    "        restored_coords = np.dot(M_inv, coords_hom.T).T\n",
    "        \n",
    "        # Update the DataFrame with restored coordinates.\n",
    "        eye_data['center_x'] = restored_coords[:, 0]\n",
    "        eye_data['center_y'] = restored_coords[:, 1]\n",
    "        \n",
    "        # Update the ellipse orientation (phi) by adding the stored angle.\n",
    "        # (If the data were rotated by 'stored_angle', restoring means: original_phi = rotated_phi + stored_angle.)\n",
    "        eye_data['phi'] = (eye_data['phi'] + stored_angle) % 360\n",
    "        \n",
    "        return eye_data\n",
    "\n",
    "    # Step 3: Restore left and right eye data.\n",
    "    try:\n",
    "        left_video_path = block.le_videos[0]\n",
    "        right_video_path = block.re_videos[0]\n",
    "    except Exception as e:\n",
    "        print(\"Error accessing video paths from block:\", e)\n",
    "        return\n",
    "    \n",
    "    restored_left = restore_eye_data(block.left_eye_data, left_video_path, block.left_rotation_angle)\n",
    "    restored_right = restore_eye_data(block.right_eye_data, right_video_path, block.right_rotation_angle)\n",
    "    \n",
    "    block.left_eye_data = restored_left\n",
    "    block.right_eye_data = restored_right\n",
    "\n",
    "    # Step 4: Optionally, save the restored data to new CSV files.\n",
    "    if save_to_disk:\n",
    "        left_save_path = block.analysis_path / 'left_eye_data_original.csv'\n",
    "        right_save_path = block.analysis_path / 'right_eye_data_original.csv'\n",
    "        restored_left.to_csv(left_save_path)\n",
    "        restored_right.to_csv(right_save_path)\n",
    "        print(f\"Restored left eye data saved to {left_save_path}\")\n",
    "        print(f\"Restored right eye data saved to {right_save_path}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T13:14:20.704588Z",
     "start_time": "2025-04-06T13:14:20.689777600Z"
    }
   },
   "id": "37442c900e449ec0",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_023\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_023\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_024\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_024\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_026\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_026\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_62\\2023_05_01\\block_038\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_62\\2023_05_01\\block_038\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_008\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_008\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_009\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_009\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_010\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_010\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_011\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_011\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_012\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_012\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_007\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_007\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_008\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_008\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_009\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_009\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_011\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_011\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_012\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_012\\analysis\\right_eye_data_original.csv\n",
      "Restored left eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013\\analysis\\left_eye_data_original.csv\n",
      "Restored right eye data saved to Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013\\analysis\\right_eye_data_original.csv\n"
     ]
    }
   ],
   "source": [
    "for block in block_collection:\n",
    "    restore_original_eye_data(block,save_to_disk=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T13:16:32.336527900Z",
     "start_time": "2025-04-06T13:14:57.000254100Z"
    }
   },
   "id": "a14568cd29d6609d",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded original eye data from:\n",
      "  Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013\\analysis\\left_eye_data_original.csv\n",
      "  Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013\\analysis\\right_eye_data_original.csv\n",
      "Rotation parameters reset: angles set to 0 and rotation matrices set to identity.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_original_eye_data_and_reset_rotation(block):\n",
    "    \"\"\"\n",
    "    Loads the original eye data CSV files ('left_eye_data_original.csv' and 'right_eye_data_original.csv')\n",
    "    and assigns them to block.left_eye_data and block.right_eye_data. Then resets the rotation parameters\n",
    "    by setting block.left_rotation_angle and block.right_rotation_angle to 0 and assigning identity\n",
    "    matrices to block.left_rotation_matrix and block.right_rotation_matrix.\n",
    "    \n",
    "    This does not modify the original files; it only updates the attributes of the BlockSync object.\n",
    "    \n",
    "    Parameters:\n",
    "        block : BlockSync object\n",
    "            The BlockSync instance, which must have an 'analysis_path' attribute.\n",
    "    \n",
    "    Returns:\n",
    "        None. The function updates block.left_eye_data, block.right_eye_data, \n",
    "              block.left_rotation_angle, block.right_rotation_angle,\n",
    "              block.left_rotation_matrix, and block.right_rotation_matrix.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        left_path = block.analysis_path / 'left_eye_data_original.csv'\n",
    "        right_path = block.analysis_path / 'right_eye_data_original.csv'\n",
    "        \n",
    "        block.left_eye_data = pd.read_csv(left_path, index_col=0, engine='python')\n",
    "        block.right_eye_data = pd.read_csv(right_path, index_col=0, engine='python')\n",
    "        \n",
    "        print(f\"Successfully loaded original eye data from:\\n  {left_path}\\n  {right_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading original eye data:\", e)\n",
    "        return\n",
    "    \n",
    "    # Reset the stored rotation angles to zero.\n",
    "    block.left_rotation_angle = 0\n",
    "    block.right_rotation_angle = 0\n",
    "    \n",
    "    # Reset the rotation matrices to identity.\n",
    "    # For an affine transformation (used by cv2.warpAffine), the identity matrix is:\n",
    "    # [[1, 0, 0],\n",
    "    #  [0, 1, 0]]\n",
    "    identity_matrix = np.array([[1, 0, 0],\n",
    "                                [0, 1, 0]], dtype=float)\n",
    "    \n",
    "    block.left_rotation_matrix = identity_matrix.copy()\n",
    "    block.right_rotation_matrix = identity_matrix.copy()\n",
    "    \n",
    "    print(\"Rotation parameters reset: angles set to 0 and rotation matrices set to identity.\")\n",
    "load_original_eye_data_and_reset_rotation(block)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T13:20:09.024245500Z",
     "start_time": "2025-04-06T13:20:07.786391700Z"
    }
   },
   "id": "be7b85dec5e271c1",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'block_collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-96cd15c3e0a3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mblock\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mblock_collection\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mleft_eye_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0manalysis_path\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;34m'left_eye_data_original.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mright_eye_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0manalysis_path\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;34m'right_eye_data_original.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'block_collection' is not defined"
     ]
    }
   ],
   "source": [
    "def append_angle_data(eye_df, new_df):\n",
    "    \"\"\"\n",
    "    Appends the kinematics columns (phi and theta) from new_df to eye_df.\n",
    "    The function renames 'phi' to 'k_phi' and 'theta' to 'k_theta', then merges\n",
    "    on the shared 'OE_timestamp' column.\n",
    "    \n",
    "    Parameters:\n",
    "    - eye_df: pandas DataFrame containing the eye tracking data.\n",
    "    - new_df: pandas DataFrame containing the new kinematics data with columns\n",
    "              'phi' and 'theta' along with 'OE_timestamp' (and possibly others).\n",
    "    \n",
    "    Returns:\n",
    "    - merged_df: pandas DataFrame resulting from merging the new kinematics data\n",
    "                 into eye_df.\n",
    "    \"\"\"\n",
    "    # Select the necessary columns and rename them\n",
    "    angle_data = new_df[['OE_timestamp', 'phi', 'theta']].rename(\n",
    "        columns={'phi': 'k_phi', 'theta': 'k_theta'}\n",
    "    )\n",
    "    \n",
    "    # Merge on OE_timestamp using a left join to preserve all rows in eye_df\n",
    "    merged_df = pd.merge(eye_df, angle_data, on='OE_timestamp', how='left')\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "for block in block_collection:\n",
    "    print(block)\n",
    "    try:\n",
    "        left_angles = pd.read_csv([i for i in block.analysis_path.iterdir() if ('left_kerr_angles_current.csv' in str(i)) ][0])\n",
    "        right_angles = pd.read_csv([i for i in block.analysis_path.iterdir() if ('right_kerr_angles_current.csv' in str(i)) ][0])\n",
    "    except IndexError:\n",
    "        print(f'{block} has a problem')\n",
    "    \n",
    "    block.left_eye_data = append_angle_data(block.left_eye_data,left_angles)\n",
    "    block.right_eye_data = append_angle_data(block.right_eye_data,right_angles)\n",
    "\n",
    "for block in block_collection:\n",
    "    block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data_original.csv')\n",
    "    block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_original.csv')\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dacb20880005a9",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c6d83d55bc5973b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
