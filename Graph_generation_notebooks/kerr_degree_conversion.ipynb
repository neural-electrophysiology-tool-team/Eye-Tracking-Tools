{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#TODO\n",
    "1. use the verification tools on all relevant blocks and check for synchronized data, proper rotation matrices and data chirality\n",
    "2. create the polar histogram for xy-coordinates with/ without tear duct rotation\n",
    "3. create the polar histograms for degree coordinates with / without 3D correction\n",
    "4."
   ],
   "id": "632235045b9c5ff7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T19:25:58.350135Z",
     "start_time": "2025-08-09T19:25:31.717458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# notice this function is here if reference errors need to be corrects:\n",
    "def pick_reference_opencv(self, eye):\n",
    "    \"\"\"\n",
    "    Display an image with candidate points overlaid as a continuous gradient\n",
    "    (using COLORMAP_TURBO) according to their ellipse ratio (major_ax/minor_ax)\n",
    "    from the rotated eye data. A background frame is shown (using a slider to\n",
    "    change the frame), candidate points are overlaid, and an extrapolated\n",
    "    reference is drawn. The user may click on the main image (excluding the\n",
    "    colorbar) to select a final reference point.\n",
    "\n",
    "    :param eye: 'left' or 'right'\n",
    "    :return: Tuple (ref_x, ref_y) representing the selected reference coordinates,\n",
    "             or None if canceled.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scipy.optimize import minimize\n",
    "    from scipy.interpolate import Rbf\n",
    "\n",
    "    # --- 1. Select and clean the data ---\n",
    "    if eye == 'left':\n",
    "        df = self.left_eye_data.copy()\n",
    "    elif eye == 'right':\n",
    "        df = self.right_eye_data.copy()\n",
    "    else:\n",
    "        print(\"Eye not recognized. Choose 'left' or 'right'.\")\n",
    "        return None\n",
    "\n",
    "    # Drop rows with missing center coordinates.\n",
    "    df = df.dropna(subset=['center_x', 'center_y'])\n",
    "\n",
    "    # Ensure the 'ratio' column exists (ratio = major_ax / minor_ax).\n",
    "    if 'ratio' not in df.columns:\n",
    "        df['ratio'] = df['major_ax'] / df['minor_ax']\n",
    "\n",
    "    # Determine ratio range.\n",
    "    min_ratio = df['ratio'].min()\n",
    "    max_ratio = df['ratio'].max()\n",
    "\n",
    "    # --- 2. Extrapolate the ideal reference point via RBF regression on a stratified subset ---\n",
    "    x_data = df['center_x'].values\n",
    "    y_data = df['center_y'].values\n",
    "    ratio_data = df['ratio'].values\n",
    "\n",
    "    # Stratified sampling: split the ratio range into bins and sample up to n_per_bin points.\n",
    "    n_bins = 10\n",
    "    n_per_bin = 50\n",
    "    subset_indices = []\n",
    "    bin_edges = np.linspace(min_ratio, max_ratio, n_bins + 1)\n",
    "    for i in range(n_bins):\n",
    "        indices = np.where((ratio_data >= bin_edges[i]) & (ratio_data < bin_edges[i + 1]))[0]\n",
    "        if len(indices) > 0:\n",
    "            n_select = min(n_per_bin, len(indices))\n",
    "            selected = np.random.choice(indices, n_select, replace=False)\n",
    "            subset_indices.extend(selected)\n",
    "    subset_indices = np.array(subset_indices)\n",
    "\n",
    "    if len(subset_indices) == 0:\n",
    "        print(\"No data available for regression.\")\n",
    "        return None\n",
    "\n",
    "    # Build the subset.\n",
    "    x_subset = x_data[subset_indices]\n",
    "    y_subset = y_data[subset_indices]\n",
    "    ratio_subset = ratio_data[subset_indices]\n",
    "\n",
    "    # Create the RBF interpolator.\n",
    "    rbf = Rbf(x_subset, y_subset, ratio_subset, function='multiquadric', smooth=1)\n",
    "\n",
    "    # Define an objective function: squared difference from 1.\n",
    "    def objective(p):\n",
    "        return (rbf(p[0], p[1]) - 1) ** 2\n",
    "\n",
    "    # Use the candidate with ratio closest to 1 as an initial guess.\n",
    "    idx_closest = np.argmin(np.abs(ratio_data - 1))\n",
    "    init_guess = np.array([x_data[idx_closest], y_data[idx_closest]])\n",
    "\n",
    "    res = minimize(objective, init_guess, method='Nelder-Mead')\n",
    "    extrapolated_ref = (int(round(res.x[0])), int(round(res.x[1])))\n",
    "\n",
    "    # --- 3. Determine frame range and initial frame ---\n",
    "    # We derive the frame range from the 'eye_frame' column.\n",
    "    min_frame = int(df['eye_frame'].min())\n",
    "    max_frame = int(df['eye_frame'].max())\n",
    "    best_frame_num = int(df.iloc[idx_closest]['eye_frame'])\n",
    "    current_frame_num = best_frame_num\n",
    "\n",
    "    # Create window and prepare a container for display images.\n",
    "    window_name = \"Select Reference\"\n",
    "    cv2.namedWindow(window_name)\n",
    "    display_images = {\"combined\": None, \"blended\": None}\n",
    "\n",
    "    # --- 4. Function to update the display given a frame number ---\n",
    "    def update_display(frame_num):\n",
    "        # Retrieve and process the new frame.\n",
    "        frame = self.get_rotated_frame(frame_num, eye)\n",
    "        print('hi')\n",
    "        if frame is None:\n",
    "            print(\"Error retrieving frame number {}\".format(frame_num))\n",
    "            return\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        background = cv2.cvtColor(frame_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Overlay candidate points.\n",
    "        overlay = background.copy()\n",
    "        for _, row in df.iterrows():\n",
    "            x = int(round(row['center_x']))\n",
    "            y = int(round(row['center_y']))\n",
    "            ratio = row['ratio']\n",
    "            norm = (ratio - min_ratio) / (max_ratio - min_ratio) if max_ratio > min_ratio else 0.5\n",
    "            value = int(norm * 255)\n",
    "            dummy = np.uint8([[value]])\n",
    "            color = cv2.applyColorMap(dummy, cv2.COLORMAP_TURBO)[0, 0].tolist()\n",
    "            cv2.circle(overlay, (x, y), radius=4, color=color, thickness=-1)\n",
    "\n",
    "        alpha = 0.5  # transparency for candidate points\n",
    "        blended = cv2.addWeighted(overlay, alpha, background, 1 - alpha, 0)\n",
    "\n",
    "        # Mark the extrapolated best reference point.\n",
    "        cv2.drawMarker(blended, extrapolated_ref, color=(0, 0, 255),\n",
    "                       markerType=cv2.MARKER_TILTED_CROSS, markerSize=30, thickness=3)\n",
    "        cv2.putText(blended, \"Extrapolated Best Ref\", (extrapolated_ref[0] + 10, extrapolated_ref[1] + 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        # Create a vertical colorbar.\n",
    "        bar_width = 50\n",
    "        bar_height = blended.shape[0]\n",
    "        gradient = np.linspace(0, 255, bar_height, dtype=np.uint8).reshape(bar_height, 1)\n",
    "        gradient = np.repeat(gradient, bar_width, axis=1)\n",
    "        colorbar = cv2.applyColorMap(gradient, cv2.COLORMAP_TURBO)\n",
    "        cv2.putText(colorbar, f\"{min_ratio:.2f}\", (5, 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(colorbar, f\"{max_ratio:.2f}\", (5, bar_height - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Combine the blended image and the colorbar.\n",
    "        combined = np.hstack([blended, colorbar])\n",
    "        cv2.putText(combined, \"Click on main image to select ref (ESC to cancel)\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        # Save the updated images in our container.\n",
    "        display_images[\"combined\"] = combined\n",
    "        display_images[\"blended\"] = blended\n",
    "        cv2.imshow(window_name, combined)\n",
    "\n",
    "    # Initial display update.\n",
    "    update_display(current_frame_num)\n",
    "\n",
    "    # --- 5. Create the slider (trackbar) ---\n",
    "    def on_trackbar(val):\n",
    "        # Convert trackbar value back to the actual frame number.\n",
    "        new_frame_num = val + min_frame\n",
    "        update_display(new_frame_num)\n",
    "\n",
    "    # The trackbar range is set from 0 to (max_frame - min_frame)\n",
    "    cv2.createTrackbar(\"Frame\", window_name, best_frame_num - min_frame, max_frame - min_frame, on_trackbar)\n",
    "\n",
    "    # --- 6. Interactive selection via mouse callback ---\n",
    "    ref_point = []\n",
    "\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        nonlocal ref_point\n",
    "        # Only register clicks in the main image area (exclude the colorbar).\n",
    "        if event == cv2.EVENT_LBUTTONDOWN and display_images[\"blended\"] is not None and x < \\\n",
    "                display_images[\"blended\"].shape[1]:\n",
    "            ref_point = [x, y]\n",
    "            cv2.drawMarker(display_images[\"combined\"], (x, y), color=(0, 255, 255),\n",
    "                           markerType=cv2.MARKER_STAR, markerSize=30, thickness=3)\n",
    "            cv2.imshow(window_name, display_images[\"combined\"])\n",
    "\n",
    "    cv2.setMouseCallback(window_name, mouse_callback)\n",
    "\n",
    "    # --- 7. Wait for selection or cancel ---\n",
    "    while True:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if ref_point:\n",
    "            break\n",
    "        if key == 27:  # ESC key to cancel.\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if ref_point:\n",
    "        print(block, eye)\n",
    "        print(\"Selected reference point: X = {}, Y = {}\".format(ref_point[0], ref_point[1]))\n",
    "        return ref_point[0], ref_point[1]\n",
    "    else:\n",
    "        print(\"No reference point selected.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "block = block_dict['PV_106_block_008']\n",
    "pick_reference_opencv(block, ''\n",
    "                             '')\n",
    "block_dict.keys()\n",
    "\n"
   ],
   "id": "2c67cdbc598f2ae8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19 right\n",
      "Selected reference point: X = 342, Y = 273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['PV_106_block_008'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T19:25:23.661743Z",
     "start_time": "2025-08-09T19:25:23.648714Z"
    }
   },
   "cell_type": "code",
   "source": "block_dict",
   "id": "dbbbddc9254c8a9c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PV_106_block_008': BlockSync object for animal PV_106 with \n",
       " block_num 008 at date PV106_ET_d3t12025-08-06_11-52-19}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T15:29:30.235055Z",
     "start_time": "2025-08-15T15:29:30.141496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import cycle\n",
    "import pickle\n",
    "import pathlib\n",
    "import math\n",
    "import tqdm\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import re\n",
    "from lxml import etree as ET\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "from scipy.stats import kde\n",
    "from BlockSync_current import BlockSync\n",
    "import UtilityFunctions_newOE as uf\n",
    "from scipy import signal\n",
    "import bokeh\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42  # Ensure fonts are embedded and editable\n",
    "rcParams['ps.fonttype'] = 42  # Ensure compatibility with vector outputs\n",
    "%matplotlib inline\n",
    "\n",
    "def horizontal_flip_eye_data(df: pd.DataFrame, frame_width: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Horizontally flip eye-tracking data across the vertical (y) axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns 'center_x', 'center_y', and 'phi' (in degrees).\n",
    "    frame_width : int\n",
    "        Width of the video/frame in pixels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A copy of df where:\n",
    "          - center_x → frame_width − center_x\n",
    "          - center_y unchanged\n",
    "          - phi      → (phi + 90) % 360\n",
    "    \"\"\"\n",
    "    df_flipped = df.copy()\n",
    "    # mirror x\n",
    "    df_flipped['center_x'] = frame_width - df_flipped['center_x']\n",
    "    # phi shift by +90°\n",
    "    df_flipped['phi'] = (df_flipped['phi'] + 90) % 360\n",
    "    return df_flipped\n",
    "\n",
    "def bokeh_plotter(data_list, x_axis_list=None, label_list=None,\n",
    "                  plot_name='default',\n",
    "                  x_axis_label='X', y_axis_label='Y',\n",
    "                  peaks=None, peaks_list=False, export_path=False):\n",
    "    \"\"\"Generates an interactive Bokeh plot for the given data vector.\n",
    "    Args:\n",
    "        data_list (list or array): The data to be plotted.\n",
    "        label_list (list of str): The labels of the data vectors\n",
    "        plot_name (str, optional): The title of the plot. Defaults to 'default'.\n",
    "        x_axis (str, optional): The label for the x-axis. Defaults to 'X'.\n",
    "        y_axis (str, optional): The label for the y-axis. Defaults to 'Y'.\n",
    "        peaks (list or array, optional): Indices of peaks to highlight on the plot. Defaults to None.\n",
    "        export_path (False or str): when set to str, will output the resulting html fig\n",
    "    \"\"\"\n",
    "    color_cycle = cycle(bokeh.palettes.Category10_10)\n",
    "    fig = bokeh.plotting.figure(title=f'bokeh explorer: {plot_name}',\n",
    "                                x_axis_label=x_axis_label,\n",
    "                                y_axis_label=y_axis_label,\n",
    "                                plot_width=1500,\n",
    "                                plot_height=700)\n",
    "\n",
    "    for i, data_vector in enumerate(data_list):\n",
    "\n",
    "        color = next(color_cycle)\n",
    "\n",
    "        if x_axis_list is None:\n",
    "            x_axis = range(len(data_vector))\n",
    "        elif len(x_axis_list) == len(data_list):\n",
    "            print('x_axis manually set')\n",
    "            x_axis = x_axis_list[i]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                'problem with x_axis_list input - should be either None, or a list with the same length as data_list')\n",
    "        if label_list is None:\n",
    "            fig.line(x_axis, data_vector, line_color=color, legend_label=f\"Line {i + 1}\")\n",
    "        elif len(label_list) == len(data_list):\n",
    "            fig.line(range(len(data_vector)), data_vector, line_color=color, legend_label=f\"{label_list[i]}\")\n",
    "        if peaks is not None and peaks_list is True:\n",
    "            fig.circle(peaks[i], data_vector[peaks[i]], size=10, color=color)\n",
    "\n",
    "    if peaks is not None and peaks_list is False:\n",
    "        fig.circle(peaks, data_vector[peaks], size=10, color='red')\n",
    "\n",
    "    if export_path is not False:\n",
    "        print(f'exporting to {export_path}')\n",
    "        bokeh.io.output.output_file(filename=str(export_path / f'{plot_name}.html'), title=f'{plot_name}')\n",
    "    bokeh.plotting.show(fig)\n",
    "\n",
    "\n",
    "def load_eye_data_2d_w_rotation_matrix(block):\n",
    "    \"\"\"\n",
    "    This function checks if the eye dataframes and rotation dict object exist, then imports them\n",
    "    :param block: The current blocksync class with verifiec re/le dfs\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data.csv', index_col=0, engine='python')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data.csv', index_col=0, engine='python')\n",
    "    except FileNotFoundError:\n",
    "        print('eye_data files not found, run the pipeline!')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(block.analysis_path / 'rotate_eye_data_params.pkl', 'rb') as file:\n",
    "            rotation_dict = pickle.load(file)\n",
    "            block.left_rotation_matrix = rotation_dict['left_rotation_matrix']\n",
    "            block.right_rotation_matrix = rotation_dict['right_rotation_matrix']\n",
    "            block.left_rotation_angle = rotation_dict['left_rotation_angle']\n",
    "            block.right_rotation_angle = rotation_dict['right_rotation_angle']\n",
    "    except FileNotFoundError:\n",
    "        print('No rotation matrix file, create it')\n",
    "\n",
    "\n",
    "def create_saccade_events_df(eye_data_df, speed_threshold, bokeh_verify_threshold=False, magnitude_calib=1,\n",
    "                             speed_profile=True):\n",
    "    \"\"\"\n",
    "    Detects saccade events in eye tracking data and computes relevant metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - eye_data_df (pd.DataFrame): Input DataFrame containing eye tracking data.\n",
    "    - speed_threshold (float): Threshold for saccade detection based on speed.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): Modified input DataFrame with added columns for speed and saccade detection.\n",
    "    - saccade_events_df (pd.DataFrame): DataFrame containing information about detected saccade events.\n",
    "\n",
    "    Steps:\n",
    "    1. Calculate speed components ('speed_x', 'speed_y') based on differences in 'center_x' and 'center_y'.\n",
    "    2. Compute the magnitude of the velocity vector ('speed_r').\n",
    "    3. Create a binary column ('is_saccade') indicating saccade events based on the speed threshold.\n",
    "    4. Determine saccade onset and offset indices and timestamps.\n",
    "    5. Create a DataFrame ('saccade_events_df') with columns:\n",
    "        - 'saccade_start_ind': Indices of saccade onset.\n",
    "        - 'saccade_start_timestamp': Timestamps corresponding to saccade onset.\n",
    "        - 'saccade_end_ind': Indices of saccade offset.\n",
    "        - 'saccade_end_timestamp': Timestamps corresponding to saccade offset.\n",
    "        - 'length': Duration of each saccade event.\n",
    "    6. Calculate distance traveled and angles for each saccade event.\n",
    "    7. Append additional columns to 'saccade_events_df':\n",
    "        - 'magnitude': Magnitude of the distance traveled during each saccade.\n",
    "        - 'angle': Angle of the saccade vector in degrees.\n",
    "        - 'initial_x', 'initial_y': Initial coordinates of the saccade.\n",
    "        - 'end_x', 'end_y': End coordinates of the saccade.\n",
    "\n",
    "    Note: The original 'eye_data_df' is not modified; modified data is returned as 'df'.\n",
    "    \"\"\"\n",
    "    df = eye_data_df\n",
    "    df['speed_x'] = df['center_x'].diff()  # Difference between consecutive 'center_x' values\n",
    "    df['speed_y'] = df['center_y'].diff()  # Difference between consecutive 'center_y' values\n",
    "\n",
    "    # Step 2: Calculate magnitude of the velocity vector (R vector speed)\n",
    "    df['speed_r'] = (df['speed_x'] ** 2 + df['speed_y'] ** 2) ** 0.5\n",
    "\n",
    "    # Create a column for saccade detection\n",
    "    df['is_saccade'] = df['speed_r'] > speed_threshold\n",
    "\n",
    "    # create a saccade_on_off indicator where 1 is rising edge and -1 is falling edge by subtracting a shifted binary mask\n",
    "    saccade_on_off = df.is_saccade.astype(int) - df.is_saccade.shift(periods=1, fill_value=False).astype(int)\n",
    "    saccade_on_inds = np.where(saccade_on_off == 1)[\n",
    "                          0] - 1  # notice the manual shift here, chosen to include the first (sometimes slower) eye frame, just before saccade threshold crossing\n",
    "    saccade_on_ms = df['ms_axis'].iloc[saccade_on_inds]\n",
    "    saccade_on_timestamps = df['OE_timestamp'].iloc[saccade_on_inds]\n",
    "    saccade_off_inds = np.where(saccade_on_off == -1)[0]\n",
    "    saccade_off_timestamps = df['OE_timestamp'].iloc[saccade_off_inds]\n",
    "    saccade_off_ms = df['ms_axis'].iloc[saccade_off_inds]\n",
    "\n",
    "    saccade_dict = {'saccade_start_ind': saccade_on_inds,\n",
    "                    'saccade_start_timestamp': saccade_on_timestamps.values,\n",
    "                    'saccade_end_ind': saccade_off_inds,\n",
    "                    'saccade_end_timestamp': saccade_off_timestamps.values,\n",
    "                    'saccade_on_ms': saccade_on_ms.values,\n",
    "                    'saccade_off_ms': saccade_off_ms.values}\n",
    "\n",
    "    saccade_events_df = pd.DataFrame.from_dict(saccade_dict)\n",
    "    saccade_events_df['length'] = saccade_events_df['saccade_end_ind'] - saccade_events_df['saccade_start_ind']\n",
    "    # Drop columns used for intermediate steps\n",
    "    df = df.drop(['is_saccade'], axis=1)\n",
    "\n",
    "    distances = []\n",
    "    angles = []\n",
    "    speed_list = []\n",
    "    diameter_list = []\n",
    "    for index, row in tqdm.tqdm(saccade_events_df.iterrows()):\n",
    "        saccade_samples = df.loc[(df['OE_timestamp'] >= row['saccade_start_timestamp']) &\n",
    "                                 (df['OE_timestamp'] <= row['saccade_end_timestamp'])]\n",
    "        distance_traveled = saccade_samples['speed_r'].sum()\n",
    "        if speed_profile:\n",
    "            saccade_speed_profile = saccade_samples['speed_r'].values\n",
    "            speed_list.append(saccade_speed_profile)\n",
    "        saccade_diameter_profile = saccade_samples['pupil_diameter'].values\n",
    "        diameter_list.append(saccade_diameter_profile)\n",
    "        # Calculate angle from initial position to endpoint\n",
    "        initial_position = saccade_samples.iloc[0][['center_x', 'center_y']]\n",
    "        endpoint = saccade_samples.iloc[-1][['center_x', 'center_y']]\n",
    "        overall_angle = np.arctan2(endpoint['center_y'] - initial_position['center_y'],\n",
    "                                   endpoint['center_x'] - initial_position['center_x'])\n",
    "\n",
    "        angles.append(overall_angle)\n",
    "        distances.append(distance_traveled)\n",
    "\n",
    "    saccade_events_df['magnitude_raw'] = np.array(distances)\n",
    "    saccade_events_df['magnitude'] = np.array(distances) * magnitude_calib\n",
    "    saccade_events_df['angle'] = np.where(np.isnan(angles), angles, np.rad2deg(\n",
    "        angles) % 360)  # Convert radians to degrees and ensure result is in [0, 360)\n",
    "    start_ts = saccade_events_df['saccade_start_timestamp'].values\n",
    "    end_ts = saccade_events_df['saccade_end_timestamp'].values\n",
    "    saccade_start_df = df[df['OE_timestamp'].isin(start_ts)]\n",
    "    saccade_end_df = df[df['OE_timestamp'].isin(end_ts)]\n",
    "    start_x_coord = saccade_start_df['center_x']\n",
    "    start_y_coord = saccade_start_df['center_y']\n",
    "    end_x_coord = saccade_end_df['center_x']\n",
    "    end_y_coord = saccade_end_df['center_y']\n",
    "    saccade_events_df['initial_x'] = start_x_coord.values\n",
    "    saccade_events_df['initial_y'] = start_y_coord.values\n",
    "    saccade_events_df['end_x'] = end_x_coord.values\n",
    "    saccade_events_df['end_y'] = end_y_coord.values\n",
    "    saccade_events_df['calib_dx'] = (saccade_events_df['end_x'].values - saccade_events_df[\n",
    "        'initial_x'].values) * magnitude_calib\n",
    "    saccade_events_df['calib_dy'] = (saccade_events_df['end_y'].values - saccade_events_df[\n",
    "        'initial_y'].values) * magnitude_calib\n",
    "    if speed_profile:\n",
    "        saccade_events_df['speed_profile'] = speed_list\n",
    "    saccade_events_df['diameter_profile'] = diameter_list\n",
    "    if bokeh_verify_threshold:\n",
    "        bokeh_plotter(data_list=[df.speed_r], label_list=['Pupil Velocity'], peaks=saccade_on_inds)\n",
    "\n",
    "    return df, saccade_events_df\n",
    "\n",
    "\n",
    "# create a multi-animal block_collection:\n",
    "\n",
    "def create_block_collections(animals, block_lists, experiment_path, bad_blocks=None):\n",
    "    \"\"\"\n",
    "    Create block collections and a block dictionary from multiple animals and their respective block lists.\n",
    "\n",
    "    Parameters:\n",
    "    - animals: list of str, names of the animals.\n",
    "    - block_lists: list of lists of int, block numbers corresponding to each animal.\n",
    "    - experiment_path: pathlib.Path, path to the experiment directory.\n",
    "    - bad_blocks: list of int, blocks to exclude. Default is an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - block_collection: list of BlockSync objects for all specified blocks.\n",
    "    - block_dict: dictionary where keys are block numbers as strings and values are BlockSync objects.\n",
    "    \"\"\"\n",
    "    import UtilityFunctions_newOE as uf\n",
    "\n",
    "    if bad_blocks is None:\n",
    "        bad_blocks = []\n",
    "\n",
    "    block_collection = []\n",
    "    block_dict = {}\n",
    "\n",
    "    for animal, blocks in zip(animals, block_lists):\n",
    "        # Generate blocks for the current animal\n",
    "        current_blocks = uf.block_generator(\n",
    "            block_numbers=blocks,\n",
    "            experiment_path=experiment_path,\n",
    "            animal=animal,\n",
    "            bad_blocks=bad_blocks\n",
    "        )\n",
    "        # Add to collection and dictionary\n",
    "        block_collection.extend(current_blocks)\n",
    "        for b in current_blocks:\n",
    "            block_dict[f\"{animal}_block_{b.block_num}\"] = b\n",
    "\n",
    "    return block_collection, block_dict\n",
    "def load_self_kerr_refs(block, filename: str = \"self_kerr_refs.csv\") -> bool:\n",
    "    \"\"\"\n",
    "    Load Kerr reference coordinates from the analysis folder CSV and set them on `block`.\n",
    "\n",
    "    Reads a single-row CSV with columns:\n",
    "        kerr_ref_r_x, kerr_ref_r_y, kerr_ref_l_x, kerr_ref_l_y\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if refs were loaded and applied, False if the file was missing or empty.\n",
    "    \"\"\"\n",
    "    path = pathlib.Path(block.analysis_path) / filename\n",
    "    if not path.exists():\n",
    "        print(f\"No Kerr refs file found at: {path}\")\n",
    "        return False\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    if df.empty:\n",
    "        print(f\"Kerr refs file is empty: {path}\")\n",
    "        return False\n",
    "\n",
    "    row = df.iloc[0]\n",
    "\n",
    "    # Helper to safely set attribute if value is finite\n",
    "    def _set_attr(name):\n",
    "        if name in row and pd.notna(row[name]):\n",
    "            try:\n",
    "                setattr(block, name, int(round(float(row[name]))))\n",
    "            except (ValueError, TypeError):\n",
    "                # keep existing value if conversion fails\n",
    "                pass\n",
    "\n",
    "    for col in (\"kerr_ref_r_x\", \"kerr_ref_r_y\", \"kerr_ref_l_x\", \"kerr_ref_l_y\"):\n",
    "        _set_attr(col)\n",
    "\n",
    "    print(f\"Kerr refs loaded from: {path}\")\n",
    "    return True"
   ],
   "id": "b4550ac9ba2a4237",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T15:36:27.512158Z",
     "start_time": "2025-08-15T15:36:26.635134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#animals = ['PV_62', 'PV_126', 'PV_57']\n",
    "#block_lists = [[24, 26, 38], [7, 8, 9, 10, 11, 12], [7, 8, 9, 12, 13]]\n",
    "#experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "animals = ['PV_106','PV_143']\n",
    "block_lists = [[8,9,10,11,12],[1,2,3,4]]\n",
    "experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "\n",
    "bad_blocks = [0]  # Example of bad blocks\n",
    "\n",
    "block_collection, block_dict = create_block_collections(\n",
    "    animals=animals,\n",
    "    block_lists=block_lists,\n",
    "    experiment_path=experiment_path,\n",
    "    bad_blocks=bad_blocks\n",
    ")"
   ],
   "id": "f4bce4b3d9f0075e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_008, new OE version\n",
      "Found the sample rate for block 008 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 010 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_010, new OE version\n",
      "Found the sample rate for block 010 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 010\n",
      "got it!\n",
      "instantiated block number 011 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_011, new OE version\n",
      "Found the sample rate for block 011 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 011\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 001 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_001, new OE version\n",
      "Found the sample rate for block 001 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 001\n",
      "got it!\n",
      "instantiated block number 002 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_002, new OE version\n",
      "Found the sample rate for block 002 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 002\n",
      "got it!\n",
      "instantiated block number 003 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_003, new OE version\n",
      "Found the sample rate for block 003 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 003\n",
      "got it!\n",
      "instantiated block number 004 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_004, new OE version\n",
      "Found the sample rate for block 004 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 004\n",
      "got it!\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "for block in block_collection:\n",
    "\n",
    "    block.parse_open_ephys_events()\n",
    "    block.get_eye_brightness_vectors()\n",
    "    block.synchronize_block()\n",
    "    block.create_eye_brightness_df(threshold_value=20)\n",
    "    block.handle_eye_videos()\n",
    "    # if the code fails here, go to manual synchronization\n",
    "    block.import_manual_sync_df()\n",
    "    #block.read_dlc_data()\n",
    "    block.calibrate_pixel_size(10)\n",
    "    load_eye_data_2d_w_rotation_matrix(block)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-15T15:36:50.402324Z",
     "start_time": "2025-08-15T15:36:28.317326Z"
    }
   },
   "id": "bad31ff9fa2c7da8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_008\\\\eye_videos\\\\LE\\\\pv_106_d3_t1\\\\pv_106_d3_t1.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_008\\\\eye_videos\\\\RE\\\\pv_106_d3_t1\\\\pv_106_d3_t1.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_008\\\\eye_videos\\\\LE\\\\pv_106_d3_t1\\\\pv_106_d3_t1_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_008\\\\eye_videos\\\\RE\\\\pv_106_d3_t1\\\\pv_106_d3_t1.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_008\\eye_videos\\RE\\pv_106_d3_t1\\pv_106_d3_t1.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named pv_106_d3_t1_LE.mp4 has reported 59074 frames and has 59074 frames, it has dropped 0 frames\n",
      "The video named pv_106_d3_t1.mp4 has reported 59233 frames and has 59233 frames, it has dropped 0 frames\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_009\\\\eye_videos\\\\LE\\\\pv_106_d3_t2\\\\pv_106_d3_t2.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_009\\\\eye_videos\\\\RE\\\\pv_106_d3_t2\\\\pv_106_d3_t2.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_009\\\\eye_videos\\\\LE\\\\pv_106_d3_t2\\\\pv_106_d3_t2_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_009\\\\eye_videos\\\\RE\\\\pv_106_d3_t2\\\\pv_106_d3_t2.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_009\\eye_videos\\RE\\pv_106_d3_t2\\pv_106_d3_t2.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named pv_106_d3_t2_LE.mp4 has reported 58843 frames and has 58843 frames, it has dropped 0 frames\n",
      "The video named pv_106_d3_t2.mp4 has reported 59027 frames and has 59027 frames, it has dropped 0 frames\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 010 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 010...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_010\\\\eye_videos\\\\LE\\\\pv_106_d3_t3\\\\pv_106_d3_t3.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_010\\\\eye_videos\\\\RE\\\\pv_106_d3_t3\\\\pv_106_d3_t3.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_010\\\\eye_videos\\\\LE\\\\pv_106_d3_t3\\\\pv_106_d3_t3_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_010\\\\eye_videos\\\\RE\\\\pv_106_d3_t3\\\\pv_106_d3_t3.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_010\\eye_videos\\RE\\pv_106_d3_t3\\pv_106_d3_t3.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named pv_106_d3_t3_LE.mp4 has reported 58278 frames and has 58278 frames, it has dropped 0 frames\n",
      "The video named pv_106_d3_t3.mp4 has reported 58439 frames and has 58439 frames, it has dropped 0 frames\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 011 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 011...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_011\\\\eye_videos\\\\LE\\\\pv_106_d3_t4\\\\pv_106_d3_t4.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_011\\\\eye_videos\\\\RE\\\\pv_106_d3_t4\\\\pv_106_d3_t4.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_011\\\\eye_videos\\\\LE\\\\pv_106_d3_t4\\\\pv_106_d3_t4_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_011\\\\eye_videos\\\\RE\\\\pv_106_d3_t4\\\\pv_106_d3_t4.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_011\\eye_videos\\RE\\pv_106_d3_t4\\pv_106_d3_t4.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named pv_106_d3_t4_LE.mp4 has reported 133269 frames and has 133269 frames, it has dropped 0 frames\n",
      "The video named pv_106_d3_t4.mp4 has reported 133281 frames and has 133281 frames, it has dropped 0 frames\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_012\\\\eye_videos\\\\LE\\\\pv_106_d3_t5\\\\pv_106_d3_t5.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_012\\\\eye_videos\\\\RE\\\\pv_106_d3_t5\\\\pv_106_d3_t5.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_012\\\\eye_videos\\\\LE\\\\pv_106_d3_t5\\\\pv_106_d3_t5_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_106\\\\2025_08_06\\\\block_012\\\\eye_videos\\\\RE\\\\pv_106_d3_t5\\\\pv_106_d3_t5.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_012\\eye_videos\\RE\\pv_106_d3_t5\\pv_106_d3_t5.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named pv_106_d3_t5_LE.mp4 has reported 114914 frames and has 114914 frames, it has dropped 0 frames\n",
      "The video named pv_106_d3_t5.mp4 has reported 115195 frames and has 115195 frames, it has dropped 0 frames\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 001 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 001...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_001\\\\eye_videos\\\\LE\\\\pv_143_d1t1\\\\pv_143_d1t1.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_001\\\\eye_videos\\\\RE\\\\pv_143_d1t1\\\\pv_143_d1t1.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_001\\\\eye_videos\\\\LE\\\\pv_143_d1t1\\\\pv_143_d1t1_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_001\\\\eye_videos\\\\RE\\\\pv_143_d1t1\\\\pv_143_d1t1.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_001\\eye_videos\\RE\\pv_143_d1t1\\pv_143_d1t1.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named pv_143_d1t1_LE.mp4 has reported 75162 frames and has 75162 frames, it has dropped 0 frames\n",
      "The video named pv_143_d1t1.mp4 has reported 74966 frames and has 74966 frames, it has dropped 0 frames\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 002 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 002...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_002\\\\eye_videos\\\\LE\\\\pv_143_d1t2\\\\pv_143_d1t2.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_002\\\\eye_videos\\\\RE\\\\pv_143_d1t2\\\\pv_143_d1t2.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_002\\\\eye_videos\\\\LE\\\\pv_143_d1t2\\\\pv_143_d1t2_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_002\\\\eye_videos\\\\RE\\\\pv_143_d1t2\\\\pv_143_d1t2.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_002\\eye_videos\\RE\\pv_143_d1t2\\pv_143_d1t2.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named pv_143_d1t2_LE.mp4 has reported 82573 frames and has 82572 frames, it has dropped 1 frames\n",
      "The video named pv_143_d1t2.mp4 has reported 82151 frames and has 82151 frames, it has dropped 0 frames\n",
      "there is no manual sync file for block 002, manually sync the block\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 003 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 003...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_003\\\\eye_videos\\\\LE\\\\pv_143_d1t3\\\\pv_143_d1t3.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_003\\\\eye_videos\\\\RE\\\\pv_143_d1t3\\\\pv_143_d1t3.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_003\\\\eye_videos\\\\LE\\\\pv_143_d1t3\\\\pv_143_d1t3_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_003\\\\eye_videos\\\\RE\\\\pv_143_d1t3\\\\pv_143_d1t3.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_003\\eye_videos\\RE\\pv_143_d1t3\\pv_143_d1t3.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named pv_143_d1t3_LE.mp4 has reported 87431 frames and has 87430 frames, it has dropped 1 frames\n",
      "The video named pv_143_d1t3.mp4 has reported 87481 frames and has 87481 frames, it has dropped 0 frames\n",
      "got the calibration values from the analysis folder\n",
      "running parse_open_ephys_events...\n",
      "block 004 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 004...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_004\\\\eye_videos\\\\LE\\\\pv_143_d1t4\\\\pv_143_d1t4.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_004\\\\eye_videos\\\\RE\\\\pv_143_d1t4\\\\pv_143_d1t4.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_004\\\\eye_videos\\\\LE\\\\pv_143_d1t4\\\\pv_143_d1t4_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_143\\\\2025_08_25\\\\block_004\\\\eye_videos\\\\RE\\\\pv_143_d1t4\\\\pv_143_d1t4.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_004\\eye_videos\\RE\\pv_143_d1t4\\pv_143_d1t4.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named pv_143_d1t4_LE.mp4 has reported 75008 frames and has 75007 frames, it has dropped 1 frames\n",
      "The video named pv_143_d1t4.mp4 has reported 74968 frames and has 74968 frames, it has dropped 0 frames\n",
      "there is no manual sync file for block 004, manually sync the block\n",
      "got the calibration values from the analysis folder\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:05:00.552204Z",
     "start_time": "2025-06-07T16:05:00.542206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CAREFUL! THIS CELL HORIZONTALLY FLIPS THE REFERENCES FILE AND OVERWRITES IT\n",
    "print('read before running!')\n",
    "#df = pd.read_csv(r'Z:\\Nimrod\\experiments\\cross_animals_data\\kerr_reference_all_animals_current_25_05_12.csv')\n",
    "# Flip x0 across the vertical axis\n",
    "#print(df.head())\n",
    "#frame_width = 640\n",
    "#df['x0'] = frame_width - df['x0']\n",
    "#df.to_csv(r'Z:\\Nimrod\\experiments\\cross_animals_data\\kerr_reference_all_animals_current_25_05_12.csv')\n",
    "#print(df.head())"
   ],
   "id": "2817ea7ec509c079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read before running!\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T12:27:06.322933Z",
     "start_time": "2025-08-14T12:27:06.135575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CAREFUL! THIS CELL USES THE ROTATION MATRICES TO ROTATE THE DATA AND REFERENCE POINTS TOGETHER BEFORE DEGREE CONVERSION:\n",
    "\n",
    "def apply_rotation(df: pd.DataFrame, rot_mat: np.ndarray, rot_angle: float) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    pts = df2[['center_x', 'center_y']].values.reshape(-1, 1, 2).astype(np.float32)\n",
    "    pts2 = cv2.transform(pts, rot_mat.astype(np.float32))\n",
    "    df2['center_x'] = pts2[:, 0, 0]\n",
    "    df2['center_y'] = pts2[:, 0, 1]\n",
    "    df2['phi'] = (df2['phi'] + rot_angle) % 360\n",
    "    return df2\n",
    "\n",
    "for block in block_collection:\n",
    "    # Rotate left eye data in memory\n",
    "    if hasattr(block, 'left_eye_data') and block.left_eye_data is not None:\n",
    "        R_L = np.array(block.left_rotation_matrix, dtype=np.float32)\n",
    "        ang_L = float(block.left_rotation_angle)\n",
    "        block.left_eye_data = apply_rotation(block.left_eye_data, R_L, ang_L)\n",
    "\n",
    "    # Rotate right eye data in memory\n",
    "    if hasattr(block, 'right_eye_data') and block.right_eye_data is not None:\n",
    "        R_R = np.array(block.right_rotation_matrix, dtype=np.float32)\n",
    "        ang_R = float(block.right_rotation_angle)\n",
    "        block.right_eye_data = apply_rotation(block.right_eye_data, R_R, ang_R)\n",
    "\n",
    "    print(f\"Applied rotation to block {block.animal_call}-{block.block_num}\")"
   ],
   "id": "b22cbe4a9b603ccf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied rotation to block PV_106-008\n",
      "Applied rotation to block PV_106-009\n",
      "Applied rotation to block PV_106-010\n",
      "Applied rotation to block PV_106-011\n",
      "Applied rotation to block PV_106-012\n",
      "Applied rotation to block PV_143-001\n",
      "Applied rotation to block PV_143-002\n",
      "Applied rotation to block PV_143-003\n",
      "Applied rotation to block PV_143-004\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T15:36:50.480351Z",
     "start_time": "2025-08-15T15:36:50.419325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for block in block_collection:\n",
    "    #block.load_best_reference(r'Z:\\Nimrod\\experiments\\cross_animals_data\\kerr_reference_all_animals_current_25_05_12.csv')\n",
    "    load_self_kerr_refs(block)"
   ],
   "id": "d64add87b5abaa66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kerr refs loaded from: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_008\\analysis\\self_kerr_refs.csv\n",
      "Kerr refs loaded from: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_009\\analysis\\self_kerr_refs.csv\n",
      "Kerr refs loaded from: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_010\\analysis\\self_kerr_refs.csv\n",
      "Kerr refs loaded from: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_011\\analysis\\self_kerr_refs.csv\n",
      "Kerr refs loaded from: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_012\\analysis\\self_kerr_refs.csv\n",
      "Kerr refs loaded from: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_001\\analysis\\self_kerr_refs.csv\n",
      "Kerr refs loaded from: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_002\\analysis\\self_kerr_refs.csv\n",
      "Kerr refs loaded from: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_003\\analysis\\self_kerr_refs.csv\n",
      "Kerr refs loaded from: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_004\\analysis\\self_kerr_refs.csv\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T12:27:41.244892Z",
     "start_time": "2025-08-14T12:27:41.229278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This one rotates the reference points\n",
    "for block in block_collection:\n",
    "    # Rotate left reference point\n",
    "    if hasattr(block, 'kerr_ref_l_x') and block.kerr_ref_l_x is not None:\n",
    "        x0, y0 = block.kerr_ref_l_x, block.kerr_ref_l_y\n",
    "        pt = np.array([[[x0, y0]]], dtype=np.float32)\n",
    "        R_L = np.array(block.left_rotation_matrix, dtype=np.float32)\n",
    "        pt_rot = cv2.transform(pt, R_L)\n",
    "        # Update in-place\n",
    "        block.kerr_ref_l_x = float(pt_rot[0, 0, 0])\n",
    "        block.kerr_ref_l_y = float(pt_rot[0, 0, 1])\n",
    "\n",
    "    # Rotate right reference point\n",
    "    if hasattr(block, 'kerr_ref_r_x') and block.kerr_ref_r_x is not None:\n",
    "        x0, y0 = block.kerr_ref_r_x, block.kerr_ref_r_y\n",
    "        pt = np.array([[[x0, y0]]], dtype=np.float32)\n",
    "        R_R = np.array(block.right_rotation_matrix, dtype=np.float32)\n",
    "        pt_rot = cv2.transform(pt, R_R)\n",
    "        block.kerr_ref_r_x = float(pt_rot[0, 0, 0])\n",
    "        block.kerr_ref_r_y = float(pt_rot[0, 0, 1])\n",
    "\n",
    "    print(f\"Block {block.animal_call}-{block.block_num}:\")\n",
    "    print(f\"  Rotated left ref -> ({block.kerr_ref_l_x:.2f}, {block.kerr_ref_l_y:.2f})\")\n",
    "    print(f\"  Rotated right ref-> ({block.kerr_ref_r_x:.2f}, {block.kerr_ref_r_y:.2f})\")\n"
   ],
   "id": "1b04873ef2f9bdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block PV_106-008:\n",
      "  Rotated left ref -> (376.69, 347.42)\n",
      "  Rotated right ref-> (334.91, 322.23)\n",
      "Block PV_106-009:\n",
      "  Rotated left ref -> (387.94, 357.55)\n",
      "  Rotated right ref-> (291.07, 287.55)\n",
      "Block PV_106-010:\n",
      "  Rotated left ref -> (373.52, 358.80)\n",
      "  Rotated right ref-> (307.04, 304.72)\n",
      "Block PV_106-011:\n",
      "  Rotated left ref -> (403.38, 361.46)\n",
      "  Rotated right ref-> (292.73, 310.33)\n",
      "Block PV_106-012:\n",
      "  Rotated left ref -> (388.51, 358.05)\n",
      "  Rotated right ref-> (296.78, 294.57)\n",
      "Block PV_143-001:\n",
      "  Rotated left ref -> (366.64, 291.02)\n",
      "  Rotated right ref-> (358.12, 253.25)\n",
      "Block PV_143-002:\n",
      "  Rotated left ref -> (388.01, 289.06)\n",
      "  Rotated right ref-> (351.62, 248.14)\n",
      "Block PV_143-003:\n",
      "  Rotated left ref -> (377.78, 278.77)\n",
      "  Rotated right ref-> (350.87, 239.74)\n",
      "Block PV_143-004:\n",
      "  Rotated left ref -> (353.33, 291.13)\n",
      "  Rotated right ref-> (336.45, 250.87)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T15:37:09.471708Z",
     "start_time": "2025-08-15T15:36:50.555353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name_tag = 'raw_verified'\n",
    "for block in block_collection:\n",
    "    # Here is where the conversion happens:\n",
    "    block.calculate_kerr_angles(name_tag=name_tag)\n"
   ],
   "id": "a7bfe70529d673ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on Block 008\n",
      "Left eye\n",
      "Left eye\n",
      "finished successfully and saved to Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_008\\analysis with tag= raw_verified\n",
      "working on Block 009\n",
      "Left eye\n",
      "Left eye\n",
      "finished successfully and saved to Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_009\\analysis with tag= raw_verified\n",
      "working on Block 010\n",
      "Left eye\n",
      "Left eye\n",
      "finished successfully and saved to Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_010\\analysis with tag= raw_verified\n",
      "working on Block 011\n",
      "Left eye\n",
      "Left eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MarkS3\\PycharmProjects\\pythonProject3\\BlockSync_current.py:3002: RuntimeWarning: invalid value encountered in arcsin\n",
      "  comp_t = np.arcsin((bPC_values[valid_positions] - bEC) / (np.cos(comp_p) * f_z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished successfully and saved to Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_011\\analysis with tag= raw_verified\n",
      "working on Block 012\n",
      "Left eye\n",
      "Left eye\n",
      "finished successfully and saved to Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_012\\analysis with tag= raw_verified\n",
      "working on Block 001\n",
      "Left eye\n",
      "Left eye\n",
      "finished successfully and saved to Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_001\\analysis with tag= raw_verified\n",
      "working on Block 002\n",
      "Left eye\n",
      "Left eye\n",
      "finished successfully and saved to Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_002\\analysis with tag= raw_verified\n",
      "working on Block 003\n",
      "Left eye\n",
      "Left eye\n",
      "finished successfully and saved to Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_003\\analysis with tag= raw_verified\n",
      "working on Block 004\n",
      "Left eye\n",
      "Left eye\n",
      "finished successfully and saved to Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_004\\analysis with tag= raw_verified\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "# load and combine the eye data with the angle calculation\n",
    "name_tag = 'rotated_verified'\n",
    "def append_angle_data(eye_df, new_df):\n",
    "    \"\"\"\n",
    "    Appends the angle columns (phi and theta) from new_df to eye_df.\n",
    "    The function renames 'phi' to 'k_phi' and 'theta' to 'k_theta', then merges\n",
    "    on the shared 'OE_timestamp' column.\n",
    "\n",
    "    Parameters:\n",
    "    - eye_df: pandas DataFrame containing the eye tracking data.\n",
    "    - new_df: pandas DataFrame containing the new kinematics data with columns\n",
    "              'phi' and 'theta' along with 'OE_timestamp' (and possibly others).\n",
    "\n",
    "    Returns:\n",
    "    - merged_df: pandas DataFrame resulting from merging the new kinematics data\n",
    "                 into eye_df.\n",
    "    \"\"\"\n",
    "    # Select the necessary columns and rename them\n",
    "    angle_data = new_df[['OE_timestamp', 'phi', 'theta']].rename(\n",
    "        columns={'phi': 'k_phi', 'theta': 'k_theta'}\n",
    "    )\n",
    "\n",
    "    # Merge on OE_timestamp using a left join to preserve all rows in eye_df\n",
    "    merged_df = pd.merge(eye_df, angle_data, on='OE_timestamp', how='left')\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\n",
    "for block in block_collection:\n",
    "    print(block)\n",
    "    try:\n",
    "        left_angles = pd.read_csv([i for i in block.analysis_path.iterdir() if (f'left_kerr_angle_{name_tag}.csv' in str(i))][0])\n",
    "        right_angles = pd.read_csv([i for i in block.analysis_path.iterdir() if (f'right_kerr_angle_{name_tag}.csv' in str(i))][0])\n",
    "    except IndexError:\n",
    "        print(f'{block} has a problem, files missing')\n",
    "        \n",
    "    block.left_eye_data = append_angle_data(block.left_eye_data,left_angles)\n",
    "    block.right_eye_data = append_angle_data(block.right_eye_data,right_angles)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-15T16:02:49.252407Z",
     "start_time": "2025-08-15T16:02:46.456211Z"
    }
   },
   "id": "11193b1f3cf9916",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19\n",
      "PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43\n",
      "PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43\n",
      "PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30\n",
      "PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30\n",
      "PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08\n",
      "PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11\n",
      "PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35\n",
      "PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "def export_eye_data_w_angles(block, name_tag='0'):\n",
    "    block.right_eye_data.to_csv(block.analysis_path / f'right_eye_data_{name_tag}.csv')\n",
    "    block.left_eye_data.to_csv(block.analysis_path / f'left_eye_data_{name_tag}.csv')\n",
    "\n",
    "for block in block_collection:\n",
    "    export_eye_data_w_angles(block, name_tag='degrees_raw_verified')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-15T16:03:56.016159Z",
     "start_time": "2025-08-15T16:03:13.403764Z"
    }
   },
   "id": "bc1aac6190490bc9",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T16:03:07.797272Z",
     "start_time": "2025-08-15T16:03:07.777250Z"
    }
   },
   "cell_type": "code",
   "source": "block.left_eye_data",
   "id": "9d1a4162db0e7c03",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       OE_timestamp  eye_frame     ms_axis  center_x  center_y  phi  width  \\\n",
       "0          385197.0        NaN    19259.85       NaN       NaN  NaN    NaN   \n",
       "1          385530.0        NaN    19276.50       NaN       NaN  NaN    NaN   \n",
       "2          385863.0        NaN    19293.15       NaN       NaN  NaN    NaN   \n",
       "3          386196.0        NaN    19309.80       NaN       NaN  NaN    NaN   \n",
       "4          386529.0        NaN    19326.45       NaN       NaN  NaN    NaN   \n",
       "...             ...        ...         ...       ...       ...  ...    ...   \n",
       "73196    24759465.0        NaN  1237973.25       NaN       NaN  NaN    NaN   \n",
       "73197    24759798.0        NaN  1237989.90       NaN       NaN  NaN    NaN   \n",
       "73198    24760131.0        NaN  1238006.55       NaN       NaN  NaN    NaN   \n",
       "73199    24760464.0        NaN  1238023.20       NaN       NaN  NaN    NaN   \n",
       "73200    24760797.0        NaN  1238039.85       NaN       NaN  NaN    NaN   \n",
       "\n",
       "       height  major_ax  minor_ax  ratio  ratio2  phi_ellipse  k_phi  k_theta  \n",
       "0         NaN       NaN       NaN    NaN     NaN          NaN    NaN      NaN  \n",
       "1         NaN       NaN       NaN    NaN     NaN          NaN    NaN      NaN  \n",
       "2         NaN       NaN       NaN    NaN     NaN          NaN    NaN      NaN  \n",
       "3         NaN       NaN       NaN    NaN     NaN          NaN    NaN      NaN  \n",
       "4         NaN       NaN       NaN    NaN     NaN          NaN    NaN      NaN  \n",
       "...       ...       ...       ...    ...     ...          ...    ...      ...  \n",
       "73196     NaN       NaN       NaN    NaN     NaN          NaN    NaN      NaN  \n",
       "73197     NaN       NaN       NaN    NaN     NaN          NaN    NaN      NaN  \n",
       "73198     NaN       NaN       NaN    NaN     NaN          NaN    NaN      NaN  \n",
       "73199     NaN       NaN       NaN    NaN     NaN          NaN    NaN      NaN  \n",
       "73200     NaN       NaN       NaN    NaN     NaN          NaN    NaN      NaN  \n",
       "\n",
       "[73201 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OE_timestamp</th>\n",
       "      <th>eye_frame</th>\n",
       "      <th>ms_axis</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "      <th>phi</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>major_ax</th>\n",
       "      <th>minor_ax</th>\n",
       "      <th>ratio</th>\n",
       "      <th>ratio2</th>\n",
       "      <th>phi_ellipse</th>\n",
       "      <th>k_phi</th>\n",
       "      <th>k_theta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385197.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19259.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>385530.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19276.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>385863.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19293.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386196.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19309.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>386529.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19326.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73196</th>\n",
       "      <td>24759465.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1237973.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73197</th>\n",
       "      <td>24759798.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1237989.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73198</th>\n",
       "      <td>24760131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1238006.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73199</th>\n",
       "      <td>24760464.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1238023.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73200</th>\n",
       "      <td>24760797.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1238039.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73201 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T16:04:54.578594Z",
     "start_time": "2025-08-15T16:04:54.562967Z"
    }
   },
   "cell_type": "code",
   "source": "block.left_eye_data.columns",
   "id": "7048433c03715ee4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OE_timestamp', 'eye_frame', 'ms_axis', 'center_x', 'center_y', 'phi',\n",
       "       'width', 'height', 'major_ax', 'minor_ax', 'ratio', 'ratio2',\n",
       "       'phi_ellipse', 'k_phi', 'k_theta'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PV_62, block 023, on 2023-04-27_10-52-42\n",
      "found reference file and loaded points 325.0 243.0 296.0 348.0\n",
      "PV_62, block 024, on 2023-04-27_11-22-56\n",
      "found reference file and loaded points 351.0 261.0 324.0 385.0\n",
      "PV_62, block 026, on 2023-04-27_12-21-41\n",
      "found reference file and loaded points 352.0 282.0 314.0 368.0\n",
      "PV_62, block 038, on 2023-05-01_13-57-45\n",
      "found reference file and loaded points 354.0 298.0 341.0 388.0\n",
      "PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12\n",
      "found reference file and loaded points 311.0 326.0 304.0 382.0\n",
      "PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41\n",
      "found reference file and loaded points 366.0 313.0 311.0 337.0\n",
      "PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15\n",
      "found reference file and loaded points 404.0 324.0 300.0 360.0\n",
      "PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57\n",
      "found reference file and loaded points 387.0 367.0 321.0 350.0\n",
      "PV_126, block 011, on PV126_Trial115_eyeTracking_w7\n",
      "found reference file and loaded points 388.0 349.0 287.0 354.0\n",
      "PV_126, block 012, on PV126_Trial116_eyeTracking_h8\n",
      "found reference file and loaded points 393.0 349.0 290.0 365.0\n",
      "PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31\n",
      "found reference file and loaded points 436.0 339.0 214.0 340.0\n",
      "PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18\n",
      "found reference file and loaded points 428.0 318.0 220.0 377.0\n",
      "PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35\n",
      "found reference file and loaded points 418.0 314.0 221.0 375.0\n",
      "PV_57, block 011, on PV_57_hunter_2_2024-12-01_15-43-28\n",
      "found reference file and loaded points 415.0 320.0 247.0 380.0\n",
      "PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39\n",
      "found reference file and loaded points 410.0 345.0 247.0 380.0\n",
      "PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43\n",
      "found reference file and loaded points 421.0 365.0 265.0 369.0\n"
     ]
    }
   ],
   "execution_count": 55,
   "source": [
    "for block in block_collection:\n",
    "    print(block)\n",
    "    block.load_best_reference(r'Z:\\Nimrod\\experiments\\cross_animals_data\\kerr_reference_all_animals_current_25_05_12.csv')"
   ],
   "id": "fb3ec30b70102678"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# verification here:\n",
    "# first, I want to see the data superimposed on a single block's eye frames as it is now\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_first_frame_with_reference(block, eye, apply_rotation=True, xflip=True):\n",
    "    \"\"\"\n",
    "    For the given BlockSync instance and eye ('left' or 'right'), loads the first video frame,\n",
    "    optionally flips & rotates it to match your data basis, and then overlays:\n",
    "      • all center_x, center_y points (yellow dots, semi-transparent)\n",
    "      • the best reference point (large red 'X')\n",
    "    \"\"\"\n",
    "    # pick the right attributes\n",
    "    if eye == 'left':\n",
    "        video_path = block.le_videos[0]\n",
    "        df = block.left_eye_data\n",
    "        M = block.left_rotation_matrix\n",
    "        ref_x = block.kerr_ref_l_x\n",
    "        ref_y = block.kerr_ref_l_y\n",
    "        print(ref_x,ref_y)\n",
    "    elif eye == 'right':\n",
    "        print('hi')\n",
    "        video_path = block.re_videos[0]\n",
    "        df = block.right_eye_data\n",
    "        M = block.right_rotation_matrix\n",
    "        ref_x = block.kerr_ref_r_x\n",
    "        ref_y = block.kerr_ref_r_y\n",
    "        print(ref_x,ref_y)\n",
    "    else:\n",
    "        raise ValueError(\"eye must be 'left' or 'right'\")\n",
    "\n",
    "    # read first frame\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ret:\n",
    "        print(f\"⚠️  Could not read first frame of {eye} eye video at {video_path}\")\n",
    "        return\n",
    "\n",
    "    # flip if needed\n",
    "    if xflip:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # apply your rotation matrix if you want the same basis as the data\n",
    "    if apply_rotation and (M is not None):\n",
    "        frame = cv2.warpAffine(frame, M, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "    # compute “best reference” exactly as BlockSync.get_best_reference does\n",
    "    if {'major_ax','minor_ax'}.issubset(df.columns):\n",
    "        ratio = df['major_ax'] / df['minor_ax']\n",
    "        anchor_idx = np.argmin(np.abs(ratio - 1))\n",
    "    else:\n",
    "        # fallback to midpoint of your measured centers\n",
    "        anchor_idx = len(df) // 2\n",
    "\n",
    "    # ref_x = df['center_x'].iloc[anchor_idx]\n",
    "    # ref_y = df['center_y'].iloc[anchor_idx]\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    ax.scatter(df['center_x'], df['center_y'],\n",
    "               s=6, c='yellow', alpha=0.3, label='all center points')\n",
    "    ax.scatter([ref_x], [ref_y],\n",
    "               s=80, c='red', marker='x', lw=2, label='reference')\n",
    "    ax.set_title(f\"Block {block.block_num} — {eye.title()} Eye\")\n",
    "    ax.set_xlim(0, frame.shape[1])\n",
    "    ax.set_ylim(frame.shape[0], 0)          # invert y to match image coords\n",
    "    ax.axis('off')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# === usage: right before your final export cell ===\n",
    "# for block in block_collection:\n",
    "#     show_first_frame_with_reference(block, 'left',  apply_rotation=True, xflip=True)\n",
    "#     show_first_frame_with_reference(block, 'right', apply_rotation=True, xflip=True)\n",
    "\n",
    "block = block_dict['PV_126_block_007']\n",
    "block.load_best_reference(r'Z:\\Nimrod\\experiments\\cross_animals_data\\kerr_reference_all_animals.csv')\n",
    "show_first_frame_with_reference(block,'left',apply_rotation=False, xflip=True)"
   ],
   "id": "e013c67ecea9c667"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "block.load_best_reference(r'Z:\\Nimrod\\experiments\\cross_animals_data\\kerr_reference_all_animals.csv')\n",
    "block.calculate_kerr_angles(name_tag='raw')"
   ],
   "id": "6a7ff5735c295ec5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(ref_points)",
   "id": "d6ae6905304c41e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numbers\n",
    "\n",
    "def find_roundest_ellipse_in_df(df):\n",
    "    s = df.ratio2\n",
    "    closest_ind = np.nanargmin(np.abs(s - 1))  # find the index of the value closest to 1\n",
    "    return int(closest_ind)\n",
    "\n",
    "def kerr(df, aEC = np.nan, bEC = np.nan):\n",
    "    if aEC != aEC:\n",
    "        idx = find_roundest_ellipse_in_df(df)\n",
    "        dx = df.loc[df.index[idx],'center_x']\n",
    "        dy = df.loc[df.index[idx],'center_y']\n",
    "        if not isinstance(dx, numbers.Number):\n",
    "            dx = dx.iloc[0]\n",
    "        if not isinstance(dy, numbers.Number):\n",
    "            dy = dy.iloc[0]\n",
    "        aEC = int(dx)\n",
    "        bEC = int(dy)\n",
    "\n",
    "    theta_values = np.full(len(df), np.nan)  # Initialize theta column with NaNs\n",
    "    phi_values = np.full(len(df), np.nan)  # Initialize phi column with NaNs\n",
    "    r_values = np.full(len(df), np.nan)  # Initialize r column with NaNs\n",
    "\n",
    "    # Convert columns to NumPy arrays for faster access\n",
    "    hw_values = df['ratio2'].values\n",
    "    aPC_values = df['center_x'].values\n",
    "    bPC_values = df['center_y'].values\n",
    "\n",
    "    # Mask for valid `hw` values (to ignore NaNs)\n",
    "    valid_mask = ~np.isnan(hw_values)\n",
    "\n",
    "    # Vectorized computation for `top` and `bot`\n",
    "    sqrt_component = np.sqrt(1 - hw_values[valid_mask]**2)\n",
    "    distances = np.sqrt((aPC_values[valid_mask] - aEC)**2 + (bPC_values[valid_mask] - bEC)**2)\n",
    "\n",
    "    top_values = sqrt_component * distances\n",
    "    bot_values = (1 - hw_values[valid_mask]**2)\n",
    "\n",
    "    top = np.sum(top_values)\n",
    "    bot = np.sum(bot_values)\n",
    "\n",
    "    f_z = top / bot\n",
    "\n",
    "    # Compute `r` for all rows where `major_ax` is valid\n",
    "    valid_major_ax = ~np.isnan(df['major_ax'].values)\n",
    "    max_axes = np.maximum(df['major_ax'].values, df['minor_ax'].values)\n",
    "    r_values[valid_major_ax]  = (2 * max_axes[valid_major_ax]) / f_z\n",
    "\n",
    "    # Compute `theta` and `phi` in a vectorized way\n",
    "    valid_positions = ~np.isnan(aPC_values) & ~np.isnan(bPC_values)\n",
    "\n",
    "    # p1 = (aPC_values[valid_positions] - aEC)\n",
    "    # p = p1/f_z\n",
    "    comp_p = np.arcsin((aPC_values[valid_positions] - aEC) / f_z)\n",
    "\n",
    "    # t1 = (bPC_values[valid_positions] - bEC)\n",
    "    # t2 =  (np.cos(comp_p) * f_z)\n",
    "    # t = t1/t2\n",
    "    comp_t = np.arcsin((bPC_values[valid_positions] - bEC) / (np.cos(comp_p) * f_z))\n",
    "\n",
    "    theta_values[valid_positions] = np.degrees(comp_t)\n",
    "    phi_values[valid_positions] = np.degrees(comp_p)\n",
    "\n",
    "    # Create output DataFrame\n",
    "    output_df = pd.DataFrame({'r': r_values, 'theta': theta_values, 'phi': phi_values}, index=df.index)\n",
    "    output_df = pd.concat([df[['OE_timestamp', 'eye_frame', 'ms_axis']],output_df], axis=1)\n",
    "    return f_z, output_df #, valid_mask, valid_major_ax, valid_positions"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "def kerr_block2(block,ref_points, name_tag='0'):\n",
    "    time = datetime.datetime.now()\n",
    "    print(f'working on Block {block.block_num}')\n",
    "    print('Left eye')\n",
    "\n",
    "    df = block.left_eye_data\n",
    "    df['ratio2'] = df.minor_ax / df.major_ax\n",
    "    df['phi_ellipse'] = df.phi\n",
    "    try:\n",
    "        ref_row = ref_points[(ref_points.eye == 'L') & (ref_points.animal == int(block.animal_call.replace('PV_',''))) & (ref_points.block == int(block.block_num))]\n",
    "        aEC, bEC = ref_row.x0.iloc[0] , ref_row.y0.iloc[0]\n",
    "    except:\n",
    "        idx = find_roundest_ellipse_in_df(df)\n",
    "        dx = df.loc[df.index[idx],'center_x']\n",
    "        dy = df.loc[df.index[idx],'center_y']\n",
    "        if not isinstance(dx, numbers.Number):\n",
    "            dx = dx.iloc[0]\n",
    "        if not isinstance(dy, numbers.Number):\n",
    "            dy = dy.iloc[0]\n",
    "        aEC = int(dx)\n",
    "        bEC = int(dy)\n",
    "    f_z, output_df_l = kerr(df, aEC=aEC, bEC=bEC)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Right eye')\n",
    "    df = block.right_eye_data\n",
    "    df['ratio2'] = df.minor_ax / df.major_ax\n",
    "    df['phi_ellipse'] = df.phi\n",
    "\n",
    "    try:\n",
    "        ref_row = ref_points[(ref_points.eye == 'R') & (ref_points.animal == int(block.animal_call.replace('PV_',''))) & (ref_points.block == int(block.block_num))]\n",
    "        aEC, bEC = ref_row.x0.iloc[0] , ref_row.y0.iloc[0]\n",
    "    except:\n",
    "        idx = find_roundest_ellipse_in_df(df)\n",
    "        dx = df.loc[df.index[idx],'center_x']\n",
    "        dy = df.loc[df.index[idx],'center_y']\n",
    "        if not isinstance(dx, numbers.Number):\n",
    "            dx = dx.iloc[0]\n",
    "        if not isinstance(dy, numbers.Number):\n",
    "            dy = dy.iloc[0]\n",
    "        aEC = int(dx)\n",
    "        bEC = int(dy)\n",
    "    f_z, output_df_r = kerr(df, aEC=aEC, bEC=bEC)\n",
    "\n",
    "\n",
    "    block.left_eye_kerr_ang = output_df_l\n",
    "    block.left_eye_kerr_ang.to_csv(block.analysis_path / f'left_kerr_angle_{name_tag}.csv')\n",
    "\n",
    "    block.right_eye_kerr_ang = output_df_r\n",
    "    block.right_eye_kerr_ang.to_csv(block.analysis_path / f'right_kerr_angle_{name_tag}.csv')\n",
    "    print(f'finished successfully and saved to {block.analysis_path} with tag= {name_tag}')"
   ],
   "id": "48487557a6f2d4cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "name_tag = 'raw'\n",
    "for block in block_collection:\n",
    "    kerr_block2(block,ref_points=ref_points,name_tag=name_tag)"
   ],
   "id": "75ac4710119abc41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for block in block_collection:\n",
    "    block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data_original.csv')\n",
    "    block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_original.csv')\n"
   ],
   "id": "a1330817cc019e75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for block in block_collection:\n",
    "    print(block)\n",
    "    print([i.name for i in block.analysis_path.iterdir() if 'raw' in str(i)])"
   ],
   "id": "260433061c39bb0b"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def load_rotation_matrix(filepath):\n",
    "    \"\"\"Load a 3x3 rotation matrix (stored in JSON) as a NumPy array.\"\"\"\n",
    "    with open(filepath, \"r\") as f:\n",
    "        matrix = json.load(f)\n",
    "    return np.array(matrix)\n",
    "\n",
    "def angles_to_vectors(phis, thetas):\n",
    "    \"\"\"\n",
    "    Vectorized conversion of gaze angles (in degrees) to 3D unit vectors.\n",
    "    Assumes:\n",
    "      - phis: azimuth angles (degrees)\n",
    "      - thetas: elevation angles (degrees)\n",
    "    Conversion (using spherical coordinates):\n",
    "      x = cos(theta) * cos(phi)\n",
    "      y = cos(theta) * sin(phi)\n",
    "      z = sin(theta)\n",
    "    \"\"\"\n",
    "    # Convert degrees to radians.\n",
    "    p = np.deg2rad(phis)\n",
    "    t = np.deg2rad(thetas)\n",
    "    x = np.cos(t) * np.cos(p)\n",
    "    y = np.cos(t) * np.sin(p)\n",
    "    z = np.sin(t)\n",
    "    return np.column_stack((x, y, z))  # (n, 3) array\n",
    "\n",
    "def vectors_to_angles(vectors):\n",
    "    \"\"\"\n",
    "    Vectorized conversion of 3D vectors to gaze angles (in degrees).\n",
    "    Returns:\n",
    "      - phis: azimuth angles computed via arctan2(y, x)\n",
    "      - thetas: elevation angles computed via arcsin(z/norm)\n",
    "    \"\"\"\n",
    "    x = vectors[:, 0]\n",
    "    y = vectors[:, 1]\n",
    "    z = vectors[:, 2]\n",
    "    phis = np.rad2deg(np.arctan2(y, x))\n",
    "    norms = np.linalg.norm(vectors, axis=1)\n",
    "    # Clip the ratio for numerical stability.\n",
    "    thetas = np.rad2deg(np.arcsin(np.clip(z / norms, -1.0, 1.0)))\n",
    "    return phis, thetas\n",
    "\n",
    "def correct_gaze_angles_vectorized(df, rot_matrix):\n",
    "    \"\"\"\n",
    "    Correct gaze angles in a dataframe using the composite rotation matrix.\n",
    "    This function:\n",
    "      1. Converts all (k_phi, k_theta) values to 3D vectors.\n",
    "      2. Applies the rotation to all vectors at once.\n",
    "      3. Converts the rotated vectors back into (k_phi, k_theta).\n",
    "    Returns:\n",
    "      Two NumPy arrays: corrected azimuths and elevations.\n",
    "    \"\"\"\n",
    "    # Extract arrays of angles.\n",
    "    phis = df[\"k_phi\"].values\n",
    "    thetas = df[\"k_theta\"].values\n",
    "    # Convert to 3D vectors.\n",
    "    vectors = angles_to_vectors(phis, thetas)\n",
    "    # Apply rotation; note: using the transpose so that each row is rotated.\n",
    "    vectors_corr = np.dot(vectors, rot_matrix.T)\n",
    "    # Convert corrected vectors back to angles.\n",
    "    k_phi_corr, k_theta_corr = vectors_to_angles(vectors_corr)\n",
    "    return k_phi_corr, k_theta_corr\n",
    "\n",
    "def correct_block_sync_data(block, left_json_path, right_json_path):\n",
    "    \"\"\"\n",
    "    Correct the eye tracking angles stored in block.left_eye_data and block.right_eye_data.\n",
    "    \n",
    "    Parameters:\n",
    "      block           : Object with attributes left_eye_data and right_eye_data (Pandas dataframes).\n",
    "      left_json_path  : Path to the JSON file storing the left eye 3x3 rotation matrix.\n",
    "      right_json_path : Path to the JSON file storing the right eye 3x3 rotation matrix.\n",
    "    \n",
    "    Process:\n",
    "      1. Load the rotation matrices from the provided JSON files.\n",
    "      2. Convert the raw angles in left/right eye dataframes from (k_phi, k_theta) into 3D unit vectors.\n",
    "      3. Apply the composite rotation to bring them into the common anatomical frame.\n",
    "      4. Convert the rotated vectors back into (k_phi, k_theta).\n",
    "      5. Append the corrected angles as new columns (\"k_phi_corr\" and \"k_theta_corr\").\n",
    "    \n",
    "    Returns:\n",
    "      (corrected_left_eye_data, corrected_right_eye_data)\n",
    "      where each is a Pandas dataframe containing both the original and corrected angles.\n",
    "    \"\"\"\n",
    "    # Load rotation matrices.\n",
    "    rot_matrix_left = load_rotation_matrix(left_json_path)\n",
    "    rot_matrix_right = load_rotation_matrix(right_json_path)\n",
    "    \n",
    "    # Process left eye dataframe.\n",
    "    left_df = block.left_eye_data.copy()\n",
    "    left_phi_corr, left_theta_corr = correct_gaze_angles_vectorized(left_df, rot_matrix_left)\n",
    "    left_df[\"k_phi_corr\"] = left_phi_corr\n",
    "    left_df[\"k_theta_corr\"] = left_theta_corr\n",
    "    \n",
    "    # Process right eye dataframe.\n",
    "    right_df = block.right_eye_data.copy()\n",
    "    right_phi_corr, right_theta_corr = correct_gaze_angles_vectorized(right_df, rot_matrix_right)\n",
    "    right_df[\"k_phi_corr\"] = right_phi_corr\n",
    "    right_df[\"k_theta_corr\"] = right_theta_corr\n",
    "    \n",
    "    # Return the corrected dataframes for inspection.\n",
    "    return left_df, right_df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56ea65df4b6f30a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "block_dict.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4f90da9d3be96fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ecfa3cf775ee1bd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# This is the new version of what happens below"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bab3e4429fe64565"
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "def load_rotation_matrix(path):\n",
    "    \"\"\"Load 3×3 rotation matrix (JSON) into an ndarray.\"\"\"\n",
    "    return np.array(json.load(open(path,'r')))\n",
    "\n",
    "def angles_to_vecs(phis, thetas):\n",
    "    \"\"\"(N,) arrays → Nx3 unit vectors.\"\"\"\n",
    "    p = np.deg2rad(phis); t = np.deg2rad(thetas)\n",
    "    x = np.cos(t)*np.cos(p)\n",
    "    y = np.cos(t)*np.sin(p)\n",
    "    z = np.sin(t)\n",
    "    return np.vstack((x,y,z)).T\n",
    "\n",
    "def vecs_to_angles(v):\n",
    "    \"\"\"Nx3 vector array → (phis, thetas) in degrees.\"\"\"\n",
    "    x,y,z = v[:,0], v[:,1], v[:,2]\n",
    "    phis  = np.rad2deg(np.arctan2(y,x))\n",
    "    thetas= np.rad2deg(np.arcsin(np.clip(z, -1.0, 1.0)))\n",
    "    return phis, thetas\n",
    "\n",
    "def correct_eye_df(df, json_path):\n",
    "    \"\"\"\n",
    "    Correct a single eye DataFrame with columns k_phi,k_theta.\n",
    "    If flip_x is True (e.g. left eye post‑processing), flips horizontal sign.\n",
    "    \"\"\"\n",
    "    R   = load_rotation_matrix(json_path)    # use R directly (no .T!)\n",
    "    V   = angles_to_vecs(df.k_phi.values, df.k_theta.values)\n",
    "    # phi0, theta0 = 0.0, 0.0\n",
    "    # V_test = angles_to_vecs(np.array([phi0]), np.array([theta0]))\n",
    "    \n",
    "    #np.insert(V, 0, [1,0,0], axis=0)\n",
    "    V[0] = [.1,.0,.0]\n",
    "    Vc  = V @ R                               # image→anatomy\n",
    "    df2 = df.copy()\n",
    "    df2['k_phi_corr'], df2['k_theta_corr'] = vecs_to_angles(Vc)\n",
    "    return df2\n",
    "\n",
    "def visualize_correction_subset(df, subset=30, title=\"Eye: Orig vs Corr\"):\n",
    "    \"\"\"Interactive Plotly sphere of original vs corrected vectors.\"\"\"\n",
    "    V_o = angles_to_vecs(df.k_phi.values, df.k_theta.values)\n",
    "    V_c = angles_to_vecs(df.k_phi_corr.values, df.k_theta_corr.values)\n",
    "    idx = np.linspace(0, len(df)-1, min(subset,len(df))).astype(int)\n",
    "    idx[0] = 0\n",
    "    # sphere\n",
    "    u = np.linspace(0,2*np.pi,60); v = np.linspace(0,np.pi,30)\n",
    "    uu,vv = np.meshgrid(u,v)\n",
    "    xs = np.cos(uu)*np.sin(vv); ys = np.sin(uu)*np.sin(vv); zs = np.cos(vv)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Surface(\n",
    "        x=xs, y=ys, z=zs, opacity=0.2, showscale=False,\n",
    "        colorscale=[[0,'lightgray'],[1,'lightgray']],\n",
    "    ))\n",
    "    for i in idx:\n",
    "        xo,yo,zo = V_o[i]; xc,yc,zc = V_c[i]\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[xo], y=[yo], z=[zo],\n",
    "            mode='markers', marker=dict(size=4,color='blue'),\n",
    "            name='Orig' if i==idx[0] else None\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[xc], y=[yc], z=[zc],\n",
    "            mode='markers', marker=dict(size=4,color='red'),\n",
    "            name='Corr' if i==idx[0] else None\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[xo,xc], y=[yo,yc], z=[zo,zc],\n",
    "            mode='lines', line=dict(color='gray',width=2),\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "          aspectmode='cube',\n",
    "          xaxis=dict(title='X',range=[-1,1]),\n",
    "          yaxis=dict(title='Y',range=[-1,1]),\n",
    "          zaxis=dict(title='Z',range=[-1,1]),\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# assuming `block` already has left_eye_data / right_eye_data loaded\n",
    "blender_project_path = pathlib.Path(r\"D:\\MarkS3\\Documents\\BlenderFiles\\Camera_angle_registration\\PV_57_textured-20250325T102628Z-001\")\n",
    "left_json_path = blender_project_path / \"l_rot_matrix_v8.json\"\n",
    "right_json_path = blender_project_path / \"r_rot_matrix_v8.json\"\n",
    "left_df  = correct_eye_df(block.left_eye_data,  left_json_path)\n",
    "right_df = correct_eye_df(block.right_eye_data, right_json_path)\n",
    "\n",
    "visualize_correction_subset(left_df, subset=100, title='left')\n",
    "visualize_correction_subset(right_df, subset=100, title='right')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22202c611ede97e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def visualize_correction_with_zero(df, R, subset=30, eye='Eye'):\n",
    "    \"\"\"\n",
    "    Interactive Plotly 3D sphere showing:\n",
    "      - Original gaze (blue)\n",
    "      - Corrected gaze (red)\n",
    "      - Old zero‑gaze arrow (green)\n",
    "      - New zero‑gaze arrow (magenta)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # Sphere mesh\n",
    "    u = np.linspace(0,2*np.pi,60)\n",
    "    v = np.linspace(0,np.pi,30)\n",
    "    uu,vv = np.meshgrid(u,v)\n",
    "    xs = np.cos(uu)*np.sin(vv)\n",
    "    ys = np.sin(uu)*np.sin(vv)\n",
    "    zs = np.cos(vv)\n",
    "\n",
    "    # Gaze vectors\n",
    "    V_o = angles_to_vecs(df.k_phi.values, df.k_theta.values)\n",
    "    V_c = angles_to_vecs(df.k_phi_corr.values, df.k_theta_corr.values)\n",
    "    idx = np.linspace(0,len(df)-1,min(subset,len(df))).astype(int)\n",
    "\n",
    "    # Zero‑gaze arrows\n",
    "    orig_zero = np.array([1.0, 0.0, 0.0])\n",
    "    corr_zero = orig_zero @ R\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Eyeball\n",
    "    fig.add_trace(go.Surface(\n",
    "        x=xs, y=ys, z=zs, opacity=0.2, showscale=False,\n",
    "        colorscale=[[0,'lightgray'],[1,'lightgray']]\n",
    "    ))\n",
    "\n",
    "    # Zero‑gaze helpers\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[0, orig_zero[0]], y=[0, orig_zero[1]], z=[0, orig_zero[2]],\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='green', width=6),\n",
    "        marker=dict(size=4, color='green'),\n",
    "        name='Orig zero',\n",
    "        showlegend=True\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[0, corr_zero[0]], y=[0, corr_zero[1]], z=[0, corr_zero[2]],\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='magenta', width=6),\n",
    "        marker=dict(size=4, color='magenta'),\n",
    "        name='Corr zero',\n",
    "        showlegend=True\n",
    "    ))\n",
    "\n",
    "    # Plot gaze points & connectors\n",
    "    first = True\n",
    "    for i in idx:\n",
    "        xo,yo,zo = V_o[i]\n",
    "        xc,yc,zc = V_c[i]\n",
    "        # original gaze\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[xo], y=[yo], z=[zo],\n",
    "            mode='markers',\n",
    "            marker=dict(size=3, color='blue'),\n",
    "            name='Orig gaze' if first else None,\n",
    "            showlegend=bool(first)\n",
    "        ))\n",
    "        # corrected gaze\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[xc], y=[yc], z=[zc],\n",
    "            mode='markers',\n",
    "            marker=dict(size=3, color='red'),\n",
    "            name='Corr gaze' if first else None,\n",
    "            showlegend=False\n",
    "        ))\n",
    "        # connector\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[xo, xc], y=[yo, yc], z=[zo, zc],\n",
    "            mode='lines', line=dict(color='gray', width=1),\n",
    "            showlegend=False\n",
    "        ))\n",
    "        first = False\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"{eye} Eye: Orig vs Corr + Zero‑Gaze Helpers\",\n",
    "        scene=dict(\n",
    "            aspectmode='cube',\n",
    "            xaxis=dict(title='X', range=[-1,1]),\n",
    "            yaxis=dict(title='Y', range=[-1,1]),\n",
    "            zaxis=dict(title='Z', range=[-1,1]),\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dca90857f092e30",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Load your R matrix as before, e.g.:\n",
    "R_left = load_rotation_matrix(left_json_path)\n",
    "R_right = load_rotation_matrix(right_json_path)\n",
    "\n",
    "# Correct your DataFrame:\n",
    "left_df = correct_eye_df(block.left_eye_data, left_json_path)\n",
    "\n",
    "# Then visualize with zero helpers:\n",
    "visualize_correction_with_zero(left_df, R_left, subset=100, eye='Left')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4498d8e6b13d4a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# from here, There's an attempt to read and use the rotation matrices created in blender to correct the angles into an anatomically reasonable frame of reference. This is the older version:  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fa32fb7349ac0ae"
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_correction_with_zero(right_df, R_right, subset=100, eye='Right')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50862c71e27ccf9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(R_left)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b32b5f655f5eed3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(R_right)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f60f63d4687095c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_phi_theta_comparison(df, eye='left'):\n",
    "    \"\"\"\n",
    "    Scatter plot of (k_phi, k_theta) before and after correction.\n",
    "    \n",
    "    Parameters:\n",
    "      df  : DataFrame with 'k_phi','k_theta','k_phi_corr','k_theta_corr'\n",
    "      eye : 'left' or 'right' (for title)\n",
    "    \"\"\"\n",
    "    phi_orig   = df['k_phi']\n",
    "    theta_orig = df['k_theta']\n",
    "    phi_corr   = df['k_phi_corr']\n",
    "    theta_corr = df['k_theta_corr']\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(phi_orig, theta_orig, \n",
    "                s=5, alpha=0.5, label='Original', c='blue')\n",
    "    plt.scatter(phi_corr, theta_corr, \n",
    "                s=5, alpha=0.5, label='Corrected', c='red')\n",
    "    plt.xlabel(r'$\\phi$ (deg)')\n",
    "    plt.ylabel(r'$\\theta$ (deg)')\n",
    "    plt.title(f'{eye.capitalize()} Eye: φ–θ Before vs After Correction')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_phi_theta_comparison(left_df, eye='left')\n",
    "plot_phi_theta_comparison(right_df, eye='right')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0e4442985c10d4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "block = block_dict['PV_57_block_008']\n",
    "block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data_degrees_raw.csv')\n",
    "block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_raw.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a072de682899d391",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "k_phi = block.right_eye_data['k_phi']\n",
    "k_theta = block.right_eye_data['k_theta']\n",
    "plt.scatter(k_phi,k_theta)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea907578d9398efd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "k_phi = block.right_eye_data['k_phi_corr']\n",
    "k_theta = block.right_eye_data['k_theta_corr']\n",
    "plt.scatter(k_phi,k_theta)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de984cef22a0d4f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "k_phi = block.left_eye_data['k_phi']\n",
    "k_theta = block.left_eye_data['k_theta']\n",
    "plt.scatter(k_phi,k_theta)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d5629256d6d1cef",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_rotation_matrix(path):\n",
    "    \"\"\"Load a 3×3 rotation matrix from JSON into a NumPy array.\"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        mat = json.load(f)\n",
    "    return np.array(mat)\n",
    "\n",
    "\n",
    "def angles_to_vecs(phis, thetas):\n",
    "    \"\"\"Convert arrays of azimuth (phis) and elevation (thetas) in degrees to 3D unit vectors.\"\"\"\n",
    "    p = np.deg2rad(phis)\n",
    "    t = np.deg2rad(thetas)\n",
    "    x = np.cos(t) * np.cos(p)\n",
    "    y = np.cos(t) * np.sin(p)\n",
    "    z = np.sin(t)\n",
    "    return np.vstack((x, y, z)).T\n",
    "\n",
    "\n",
    "def vecs_to_angles(vecs):\n",
    "    \"\"\"Convert 3D unit vectors to azimuth (phis) and elevation (thetas) in degrees.\"\"\"\n",
    "    x, y, z = vecs[:,0], vecs[:,1], vecs[:,2]\n",
    "    phis = np.rad2deg(np.arctan2(y, x))\n",
    "    norms = np.linalg.norm(vecs, axis=1)\n",
    "    thetas = np.rad2deg(np.arcsin(np.clip(z / norms, -1.0, 1.0)))\n",
    "    return phis, thetas\n",
    "\n",
    "\n",
    "def correct_block_sync_data(block, left_json_path, right_json_path):\n",
    "    \"\"\"\n",
    "    Correct the gaze angles in block.left_eye_data and block.right_eye_data\n",
    "    using the rotation matrices exported from Blender.\n",
    "\n",
    "    Parameters:\n",
    "      block           : object with attributes left_eye_data and right_eye_data (Pandas DataFrames).\n",
    "      left_json_path  : file path to left eye rotation JSON (3×3 matrix).\n",
    "      right_json_path : file path to right eye rotation JSON.\n",
    "\n",
    "    Returns:\n",
    "      corrected_left, corrected_right : DataFrames with new columns 'k_phi_corr', 'k_theta_corr'.\n",
    "    \"\"\"\n",
    "    # Load rotation matrices\n",
    "    R_left  = load_rotation_matrix(left_json_path)\n",
    "    R_right = load_rotation_matrix(right_json_path)\n",
    "\n",
    "    # Process left eye\n",
    "    left_df = block.left_eye_data.copy()\n",
    "    V_left = angles_to_vecs(left_df['k_phi'], left_df['k_theta'])\n",
    "    V_left_rot = V_left @ R_left.T #This transpose could be a problem...\n",
    "    left_df['k_phi_corr'], left_df['k_theta_corr'] = vecs_to_angles(V_left_rot)\n",
    "\n",
    "    # Process right eye\n",
    "    right_df = block.right_eye_data.copy()\n",
    "    V_right = angles_to_vecs(right_df['k_phi'], right_df['k_theta'])\n",
    "    V_right_rot = V_right @ R_right.T # also this one... \n",
    "    right_df['k_phi_corr'], right_df['k_theta_corr'] = vecs_to_angles(V_right_rot)\n",
    "\n",
    "    return left_df, right_df\n",
    "\n",
    "# Example usage:\n",
    "# Provide paths to the rotation matrices (exported from Blender).\n",
    "blender_project_path = pathlib.Path(r\"D:\\MarkS3\\Documents\\BlenderFiles\\Camera_angle_registration\\PV_57_textured-20250325T102628Z-001\")\n",
    "left_json_path = blender_project_path / \"l_rot_matrix_v6.json\"\n",
    "right_json_path = blender_project_path / \"r_rot_matrix_v6.json\"\n",
    "corrected_left, corrected_right = correct_block_sync_data(block, left_json_path, right_json_path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6ad61f34bc22c36",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def visualize_correction_subset(left_df, right_df, subset=20, eye='left'):\n",
    "    \"\"\"\n",
    "    Interactive Plotly 3D visualization showing a subset of original vs corrected gaze\n",
    "    vectors for one eye on the unit sphere, with lines connecting each pair.\n",
    "\n",
    "    Parameters:\n",
    "      left_df, right_df : DataFrames returned by correct_block_sync_data\n",
    "      subset            : number of points to sample and display\n",
    "      eye               : 'left' or 'right' (select which DataFrame to plot)\n",
    "    \"\"\"\n",
    "    # Select correct DataFrame\n",
    "    df = left_df if eye.lower().startswith('l') else right_df\n",
    "\n",
    "    # Convert to vectors\n",
    "    V_orig = angles_to_vecs(df['k_phi'].values, df['k_theta'].values)\n",
    "    V_corr = angles_to_vecs(df['k_phi_corr'].values, df['k_theta_corr'].values)\n",
    "\n",
    "    # Sample indices\n",
    "    n = len(df)\n",
    "    idxs = np.linspace(0, n-1, min(subset, n)).astype(int)\n",
    "\n",
    "    # Build sphere mesh\n",
    "    u = np.linspace(0, 2*np.pi, 50)\n",
    "    v = np.linspace(0, np.pi, 25)\n",
    "    uu, vv = np.meshgrid(u, v)\n",
    "    xs = np.cos(uu)*np.sin(vv)\n",
    "    ys = np.sin(uu)*np.sin(vv)\n",
    "    zs = np.cos(vv)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    # Sphere\n",
    "    fig.add_trace(go.Surface(x=xs, y=ys, z=zs,\n",
    "                             opacity=0.2, showscale=False,\n",
    "                             colorscale=[[0,'lightgray'],[1,'lightgray']]))\n",
    "    # Points and connectors\n",
    "    for i in idxs:\n",
    "        xo, yo, zo = V_orig[i]\n",
    "        xc, yc, zc = V_corr[i]\n",
    "        # original in blue\n",
    "        fig.add_trace(go.Scatter3d(x=[xo], y=[yo], z=[zo],\n",
    "                                   mode='markers', marker=dict(size=4, color='blue'),\n",
    "                                   name='Original' if i==idxs[0] else None))\n",
    "        # corrected in red\n",
    "        fig.add_trace(go.Scatter3d(x=[xc], y=[yc], z=[zc],\n",
    "                                   mode='markers', marker=dict(size=4, color='red'),\n",
    "                                   name='Corrected' if i==idxs[0] else None))\n",
    "        # connector\n",
    "        fig.add_trace(go.Scatter3d(x=[xo, xc], y=[yo, yc], z=[zo, zc],\n",
    "                                   mode='lines', line=dict(color='gray', width=2),\n",
    "                                   showlegend=False))\n",
    "    fig.update_layout(scene=dict(aspectmode='cube',\n",
    "                                 xaxis=dict(range=[-1,1]),\n",
    "                                 yaxis=dict(range=[-1,1]),\n",
    "                                 zaxis=dict(range=[-1,1])),\n",
    "                      title=f\"{eye.capitalize()} Eye: Original (blue) vs Corrected (red)\")\n",
    "    fig.show()\n",
    "\n",
    "# Example usage:\n",
    "visualize_correction_subset(corrected_left, corrected_right, subset=300, eye='left')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5328b5205b9d4d65",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_correction_subset(corrected_left, corrected_right, subset=300, eye='right')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ecda3911c3ce0a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # registers the 3D projection\n",
    "\n",
    "def visualize_R(R, title=\"Rotation of Forward Vector\"):\n",
    "    \"\"\"\n",
    "    Given a 3×3 rotation matrix R, plot in 3D:\n",
    "      • the original forward vector v = (0,0,-1) in green\n",
    "      • the rotated vector R @ v            in red\n",
    "    \"\"\"\n",
    "    # 1) Define the original “forward” vector (Blender camera looks down -Z).\n",
    "    v = np.array([0.0, 0.0, -1.0])\n",
    "    # 2) Rotate it.\n",
    "    v_rot = R.dot(v)\n",
    "\n",
    "    # 3) Set up a 3D plot.\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # 4) Draw the two arrows from the origin.\n",
    "    # ‑ length=1 means draw them at their true length (they’re unit vectors).\n",
    "    ax.quiver(0, 0, 0, \n",
    "              v[0], v[1], v[2], \n",
    "              color='green', length=1, normalize=False, linewidth=2, label='orig')\n",
    "    ax.quiver(0, 0, 0, \n",
    "              v_rot[0], v_rot[1], v_rot[2], \n",
    "              color='red',   length=1, normalize=False, linewidth=2, label='rot')\n",
    "\n",
    "    # 5) Annotate the tips for clarity.\n",
    "    ax.text(   v[0],    v[1],    v[2],   ' orig (0,0,-1)', color='green')\n",
    "    ax.text(v_rot[0], v_rot[1], v_rot[2], ' rot = R⋅v',     color='red')\n",
    "\n",
    "    # 6) Make the axes equal‑scaled.\n",
    "    lim = 1.0\n",
    "    ax.set_xlim([-lim, lim])\n",
    "    ax.set_ylim([-lim, lim])\n",
    "    ax.set_zlim([-lim, lim])\n",
    "\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Usage example ---\n",
    "\n",
    "# 1) Load one of your rotation matrices:\n",
    "import json\n",
    "def load_rot_matrix(path):\n",
    "    with open(path) as f:\n",
    "        M = np.array(json.load(f))\n",
    "    return M\n",
    "\n",
    "blender_project_path = pathlib.Path(r\"D:\\MarkS3\\Documents\\BlenderFiles\\Camera_angle_registration\\PV_57_textured-20250325T102628Z-001\")\n",
    "left_json_path = blender_project_path / \"left_rot_matrix.json\"\n",
    "right_json_path = blender_project_path / \"right_rot_matrix.json\"\n",
    "\n",
    "R_left  = load_rot_matrix(left_json_path)\n",
    "R_right = load_rot_matrix(right_json_path)\n",
    "\n",
    "# 2) Visualize:\n",
    "visualize_R(R_left,  title=\"Left Eye: R ⋅ (0,0,-1)\")\n",
    "visualize_R(R_right, title=\"Right Eye: R ⋅ (0,0,-1)\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7cfff7895866e73",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def visualize_R_plotly_interactive(json_path, title=\"Rotation of Forward Vector\"):\n",
    "    \"\"\"\n",
    "    Load a 3x3 rotation matrix from JSON, then visualize:\n",
    "      • Original forward vector (0,0,-1) in green (line + marker)\n",
    "      • Rotated vector R @ (0,0,-1) in red\n",
    "      • Arc between them in blue, with angle annotation\n",
    "    using an interactive Plotly 3D scene.\n",
    "    \"\"\"\n",
    "    # Load rotation matrix\n",
    "    R = np.array(json.load(open(json_path, 'r')))\n",
    "    \n",
    "    # Define the original forward vector\n",
    "    v = np.array([0.0, 0.0, -1.0])\n",
    "    v_rot = R.dot(v)\n",
    "    \n",
    "    # Normalize for arc computation\n",
    "    v_norm = v / np.linalg.norm(v)\n",
    "    v_rot_norm = v_rot / np.linalg.norm(v_rot)\n",
    "    \n",
    "    # Compute angle between them\n",
    "    cosang = np.dot(v_norm, v_rot_norm)\n",
    "    cosang = np.clip(cosang, -1.0, 1.0)\n",
    "    angle = np.degrees(np.arccos(cosang))\n",
    "    \n",
    "    # Compute rotation axis for arc (unit)\n",
    "    axis = np.cross(v_norm, v_rot_norm)\n",
    "    if np.linalg.norm(axis) < 1e-6:\n",
    "        axis_unit = np.array([1,0,0])\n",
    "    else:\n",
    "        axis_unit = axis / np.linalg.norm(axis)\n",
    "    \n",
    "    # Generate points along the arc\n",
    "    steps = 50\n",
    "    thetas = np.linspace(0, np.radians(angle), steps)\n",
    "    arc_points = []\n",
    "    for t in thetas:\n",
    "        # Rodrigues' rotation formula around axis_unit\n",
    "        arc_vec = (v_norm * np.cos(t) +\n",
    "                   np.cross(axis_unit, v_norm) * np.sin(t))\n",
    "        arc_points.append(arc_vec)\n",
    "    arc_points = np.array(arc_points)\n",
    "    \n",
    "    # Midpoint index for annotation\n",
    "    mid = len(arc_points) // 2\n",
    "    \n",
    "    # Create Plotly figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Original vector line\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[0, v[0]], y=[0, v[1]], z=[0, v[2]],\n",
    "        mode='lines+markers',\n",
    "        marker=dict(size=4, color='green'),\n",
    "        line=dict(color='green', width=6),\n",
    "        name='Original'\n",
    "    ))\n",
    "    \n",
    "    # Rotated vector line\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[0, v_rot[0]], y=[0, v_rot[1]], z=[0, v_rot[2]],\n",
    "        mode='lines+markers',\n",
    "        marker=dict(size=4, color='red'),\n",
    "        line=dict(color='red', width=6),\n",
    "        name='Rotated'\n",
    "    ))\n",
    "    \n",
    "    # Angle arc\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=arc_points[:,0], y=arc_points[:,1], z=arc_points[:,2],\n",
    "        mode='lines',\n",
    "        line=dict(color='blue', width=4),\n",
    "        name='Angle Arc'\n",
    "    ))\n",
    "    \n",
    "    # Angle annotation at the midpoint\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[arc_points[mid,0]], y=[arc_points[mid,1]], z=[arc_points[mid,2]],\n",
    "        mode='text',\n",
    "        text=[f'{angle:.1f}°'],\n",
    "        textposition='middle right',\n",
    "        showlegend=False\n",
    "    ))\n",
    "    \n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(range=[-1,1], title='X'),\n",
    "            yaxis=dict(range=[-1,1], title='Y'),\n",
    "            zaxis=dict(range=[-1,1], title='Z'),\n",
    "            aspectmode='cube'\n",
    "        ),\n",
    "        title=f\"{title}<br>Rotation angle = {angle:.2f}°\",\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Example usage:\n",
    "visualize_R_plotly_interactive(left_json_path, title=\"Left Eye Rotation\")\n",
    "# visualize_R_plotly_interactive(\"r_rot_matrix.json\", title=\"Right Eye Rotation\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23fac70aea017c8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def visualize_with_horizon(df, R, subset=20, title=\"Gaze Vectors & Horizon on Eye Sphere\"):\n",
    "    \"\"\"\n",
    "    Visualize gaze vectors on the eye sphere, reference vector, and both\n",
    "    original and rotated horizon axes.\n",
    "    \n",
    "    Parameters:\n",
    "      df      : DataFrame with 'k_phi','k_theta','k_phi_corr','k_theta_corr'\n",
    "      R       : 3x3 rotation matrix (NumPy array)\n",
    "      subset  : number of gaze points to draw\n",
    "      title   : plot title\n",
    "    \"\"\"\n",
    "    # Convert angles to unit vectors\n",
    "    def angles_to_vecs(phis, thetas):\n",
    "        p = np.deg2rad(phis); t = np.deg2rad(thetas)\n",
    "        x = np.cos(t) * np.cos(p)\n",
    "        y = np.cos(t) * np.sin(p)\n",
    "        z = np.sin(t)\n",
    "        return np.vstack((x,y,z)).T\n",
    "\n",
    "    vecs_orig = angles_to_vecs(df['k_phi'], df['k_theta'])\n",
    "    vecs_corr = angles_to_vecs(df['k_phi_corr'], df['k_theta_corr'])\n",
    "\n",
    "    # Camera forward and horizon axes in camera space\n",
    "    v_cam = np.array([0,0,-1])\n",
    "    orig_x = np.array([1,0,0])\n",
    "    orig_y = np.array([0,1,0])\n",
    "\n",
    "    # Map to anatomical frame\n",
    "    v_ref   = R.dot(v_cam)\n",
    "    x_rot   = R.dot(orig_x)\n",
    "    y_rot   = R.dot(orig_y)\n",
    "\n",
    "    # Sphere mesh\n",
    "    u = np.linspace(0,2*np.pi,50)\n",
    "    v = np.linspace(0,np.pi,50)\n",
    "    uu, vv = np.meshgrid(u,v)\n",
    "    xs = np.cos(uu)*np.sin(vv)\n",
    "    ys = np.sin(uu)*np.sin(vv)\n",
    "    zs = np.cos(vv)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Sphere\n",
    "    fig.add_trace(go.Surface(x=xs, y=ys, z=zs, opacity=0.2,\n",
    "                             colorscale=[[0,'lightblue'],[1,'lightblue']], showscale=False,\n",
    "                             name='Eye Sphere'))\n",
    "\n",
    "    # Reference forward\n",
    "    fig.add_trace(go.Scatter3d(x=[0, v_ref[0]], y=[0, v_ref[1]], z=[0, v_ref[2]],\n",
    "                               mode='lines+markers', line=dict(color='blue', width=4),\n",
    "                               marker=dict(size=5, color='blue'),\n",
    "                               name='Ref Forward'))\n",
    "\n",
    "    # Original horizon axes\n",
    "    fig.add_trace(go.Scatter3d(x=[0, orig_x[0]], y=[0, orig_x[1]], z=[0, orig_x[2]],\n",
    "                               mode='lines+markers', line=dict(color='black', width=3, dash='dash'),\n",
    "                               marker=dict(size=4, color='black'),\n",
    "                               name='Orig X-axis'))\n",
    "    fig.add_trace(go.Scatter3d(x=[0, orig_y[0]], y=[0, orig_y[1]], z=[0, orig_y[2]],\n",
    "                               mode='lines+markers', line=dict(color='black', width=3, dash='dash'),\n",
    "                               marker=dict(size=4, color='black'),\n",
    "                               name='Orig Y-axis'))\n",
    "\n",
    "    # Rotated horizon axes\n",
    "    fig.add_trace(go.Scatter3d(x=[0, x_rot[0]], y=[0, x_rot[1]], z=[0, x_rot[2]],\n",
    "                               mode='lines+markers', line=dict(color='orange', width=4),\n",
    "                               marker=dict(size=5, color='orange'),\n",
    "                               name='Rot X-axis'))\n",
    "    fig.add_trace(go.Scatter3d(x=[0, y_rot[0]], y=[0, y_rot[1]], z=[0, y_rot[2]],\n",
    "                               mode='lines+markers', line=dict(color='purple', width=4),\n",
    "                               marker=dict(size=5, color='purple'),\n",
    "                               name='Rot Y-axis'))\n",
    "\n",
    "    # Sample gaze points\n",
    "    n = len(df); idxs = np.linspace(0, n-1, min(subset,n)).astype(int)\n",
    "    for i, col in enumerate(['Original','Corrected']):\n",
    "        pts = vecs_orig if col=='Original' else vecs_corr\n",
    "        color = 'green' if col=='Original' else 'red'\n",
    "        showleg = True if i==0 else False\n",
    "        # plot points\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=pts[idxs,0], y=pts[idxs,1], z=pts[idxs,2],\n",
    "            mode='markers', marker=dict(size=3, color=color),\n",
    "            name=col, showlegend=showleg\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        scene=dict(xaxis=dict(range=[-1,1]), yaxis=dict(range=[-1,1]), zaxis=dict(range=[-1,1]),\n",
    "                   aspectmode='cube'),\n",
    "        title=title\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Example usage:\n",
    "visualize_with_horizon(corrected_left, R_left, subset=30)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54b267699a91ddfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def visualize_full_interactive(df, R, subset=30, arc_steps=20):\n",
    "    \"\"\"\n",
    "    Interactive Plotly 3D visualization showing:\n",
    "      - Unit sphere representing the eye\n",
    "      - Two sets of reference axes:\n",
    "          * Unrotated camera frame: X_red, Y_green, Z_blue\n",
    "          * Rotated anatomical frame: X_purple, Y_yellow, Z_cyan\n",
    "      - A subset of gaze vectors: original endpoints (small red),\n",
    "        rotated endpoints (small green), and arcs (gray) between each pair.\n",
    "    \n",
    "    Parameters:\n",
    "      df        : DataFrame with 'k_phi','k_theta','k_phi_corr','k_theta_corr'\n",
    "      R         : 3x3 rotation matrix (NumPy array)\n",
    "      subset    : number of gaze points to sample and display\n",
    "      arc_steps : number of segments to draw each arc\n",
    "    \"\"\"\n",
    "    # Helper: spherical linear interpolation (slerp) between v1, v2\n",
    "    def compute_arc(v1, v2, steps):\n",
    "        # Ensure normalized\n",
    "        v1_u = v1 / np.linalg.norm(v1)\n",
    "        v2_u = v2 / np.linalg.norm(v2)\n",
    "        # angle between\n",
    "        dot = np.clip(np.dot(v1_u, v2_u), -1.0, 1.0)\n",
    "        omega = np.arccos(dot)\n",
    "        if omega < 1e-6:\n",
    "            return np.tile(v1_u, (steps,1))\n",
    "        axis = np.cross(v1_u, v2_u)\n",
    "        axis = axis / np.linalg.norm(axis)\n",
    "        arc = []\n",
    "        for t in np.linspace(0,1,steps):\n",
    "            # Rodrigues rotation of v1 by angle t*omega about axis\n",
    "            cos_t = np.cos(t*omega)\n",
    "            sin_t = np.sin(t*omega)\n",
    "            v = v1_u*cos_t + np.cross(axis, v1_u)*sin_t + axis*(axis.dot(v1_u))*(1-cos_t)\n",
    "            arc.append(v)\n",
    "        return np.array(arc)\n",
    "    \n",
    "    # Convert angles to vectors\n",
    "    def to_vecs(phis, thetas):\n",
    "        p = np.deg2rad(phis); t = np.deg2rad(thetas)\n",
    "        x = np.cos(t)*np.cos(p)\n",
    "        y = np.cos(t)*np.sin(p)\n",
    "        z = np.sin(t)\n",
    "        return np.vstack((x,y,z)).T\n",
    "\n",
    "    vec_orig = to_vecs(df['k_phi'].values, df['k_theta'].values)\n",
    "    vec_corr = to_vecs(df['k_phi_corr'].values, df['k_theta_corr'].values)\n",
    "    \n",
    "    # Reference axes in camera frame\n",
    "    axes_cam = np.eye(3)\n",
    "    # Rotated axes in anatomical frame\n",
    "    axes_rot = R.dot(axes_cam.T).T\n",
    "\n",
    "    # Sphere mesh\n",
    "    u = np.linspace(0,2*np.pi,60)\n",
    "    v = np.linspace(0,np.pi,30)\n",
    "    uu, vv = np.meshgrid(u,v)\n",
    "    xs = np.cos(uu)*np.sin(vv)\n",
    "    ys = np.sin(uu)*np.sin(vv)\n",
    "    zs = np.cos(vv)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Eye sphere\n",
    "    fig.add_trace(go.Surface(\n",
    "        x=xs, y=ys, z=zs, opacity=0.2,\n",
    "        colorscale=[[0,'lightgray'],[1,'lightgray']], showscale=False\n",
    "    ))\n",
    "\n",
    "    # Plot unrotated axes: X_red, Y_green, Z_blue\n",
    "    colors_orig = ['red','green','blue']\n",
    "    names_orig = ['Orig X','Orig Y','Orig Z']\n",
    "    for i, col in enumerate(colors_orig):\n",
    "        v = axes_cam[i]\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[0,v[0]], y=[0,v[1]], z=[0,v[2]],\n",
    "            mode='lines+markers', marker=dict(size=4,color=col),\n",
    "            line=dict(color=col,width=4), name=names_orig[i]\n",
    "        ))\n",
    "\n",
    "    # Plot rotated axes: X_purple, Y_yellow, Z_cyan\n",
    "    colors_rot = ['purple','yellow','cyan']\n",
    "    names_rot = ['Rot X','Rot Y','Rot Z']\n",
    "    for i, col in enumerate(colors_rot):\n",
    "        v = axes_rot[i]\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[0,v[0]], y=[0,v[1]], z=[0,v[2]],\n",
    "            mode='lines+markers', marker=dict(size=4,color=col),\n",
    "            line=dict(color=col,width=4), name=names_rot[i]\n",
    "        ))\n",
    "\n",
    "    # Subsample gaze points\n",
    "    n = len(df)\n",
    "    idxs = np.linspace(0,n-1,min(subset,n)).astype(int)\n",
    "    # Plot original and corrected endpoints, arcs\n",
    "    for idx in idxs:\n",
    "        vo = vec_orig[idx]\n",
    "        vc = vec_corr[idx]\n",
    "        # original endpoint small red\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[vo[0]], y=[vo[1]], z=[vo[2]],\n",
    "            mode='markers', marker=dict(size=3,color='red'),\n",
    "            showlegend=False\n",
    "        ))\n",
    "        # corrected endpoint small green\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[vc[0]], y=[vc[1]], z=[vc[2]],\n",
    "            mode='markers', marker=dict(size=3,color='green'),\n",
    "            showlegend=False\n",
    "        ))\n",
    "        # arc\n",
    "        arc = compute_arc(vo, vc, arc_steps)\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=arc[:,0], y=arc[:,1], z=arc[:,2],\n",
    "            mode='lines', line=dict(color='gray',width=2),\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(range=[-1,1],title='X'),\n",
    "            yaxis=dict(range=[-1,1],title='Y'),\n",
    "            zaxis=dict(range=[-1,1],title='Z'),\n",
    "            aspectmode='cube'\n",
    "        ),\n",
    "        title=\"Sphere & Axes: Original vs Rotated (R)\"\n",
    "    )\n",
    "    fig.update_layout(\n",
    "    scene_camera=dict(\n",
    "      eye=dict(x=1.5, y=1.5, z=1.5),\n",
    "      center=dict(x=0, y=0, z=0),\n",
    "      up=dict(x=0, y=0, z=1),\n",
    "    )\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Example usage:\n",
    "visualize_full_interactive(corrected_left, R_left, subset=300)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc11d5c1f7ae2756",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# when you have a specific block object to correct: \n",
    "\n",
    "# Provide paths to the rotation matrices (exported from Blender).\n",
    "blender_project_path = pathlib.Path(r\"D:\\MarkS3\\Documents\\BlenderFiles\\Camera_angle_registration\\PV_57_textured-20250325T102628Z-001\")\n",
    "left_json_path = blender_project_path / \"l_rot_matrix_v3.json\"\n",
    "right_json_path = blender_project_path / \"r_rot_matrix_v3.json\"\n",
    "\n",
    "# Correct the gaze data.\n",
    "corrected_left, corrected_right = correct_block_sync_data(block, left_json_path, right_json_path)\n",
    "\n",
    "# For downstream inspection, you can now examine the corrected DataFrames.\n",
    "print(corrected_left.head())\n",
    "print(corrected_right.head())\n",
    "\n",
    "# When you are satisfied, you may choose to update block.left_eye_data and block.right_eye_data:\n",
    "# block.left_eye_data = corrected_left\n",
    "# block.right_eye_data = corrected_right\n",
    "#\n",
    "# And, if desired, export the corrected dataframes to CSV:\n",
    "# corrected_left.to_csv(\"left_eye_data_corrected.csv\", index=False)\n",
    "# corrected_right.to_csv(\"right_eye_data_corrected.csv\", index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa43b72b9768550",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.scatter(corrected_right.k_phi_corr, corrected_right.k_theta_corr)\n",
    "ax.set_xlim(-60,60)\n",
    "ax.set_ylim(-60,60)\n",
    "ax.set_aspect('equal')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7b3ac1c93f91708",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.scatter(corrected_right.k_phi, corrected_right.k_theta)\n",
    "ax.set_xlim(-60,60)\n",
    "ax.set_ylim(-60,60)\n",
    "ax.set_aspect('equal')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a97bc31f02e9ae9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.scatter(corrected_left.k_phi, corrected_left.k_theta)\n",
    "ax.set_xlim(-60,60)\n",
    "ax.set_ylim(-60,60)\n",
    "ax.set_aspect('equal')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96eb24fe59aad938",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.scatter(corrected_left.k_phi_corr, corrected_left.k_theta_corr)\n",
    "#ax.set_xlim(-60,60)\n",
    "#ax.set_ylim(-60,60)\n",
    "ax.set_aspect('equal')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0896a6ca5bdd506",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# This ceates a verification plot for \n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "\n",
    "def plot_eye_comparison_over_time(eye_df):\n",
    "    \"\"\"\n",
    "    Creates two interactive Bokeh line plots arranged vertically to compare \n",
    "    the twin datasets over time.\n",
    "    \n",
    "    The first plot displays:\n",
    "      - center_x (pixel-based) and \n",
    "      - k_phi (angular, in degrees)\n",
    "    against ms_axis (time in milliseconds).\n",
    "    \n",
    "    The second plot displays:\n",
    "      - center_y (pixel-based) and \n",
    "      - k_theta (angular, in degrees)\n",
    "    against ms_axis.\n",
    "    \n",
    "    Both plots include interactive tools (pan, zoom, box zoom, reset, save) and \n",
    "    allow you to zoom and pan through time.\n",
    "    \n",
    "    Parameters:\n",
    "      eye_df : pandas.DataFrame\n",
    "          DataFrame with columns:\n",
    "            - 'ms_axis': Time in milliseconds.\n",
    "            - 'center_x': Pixel-based x-coordinate.\n",
    "            - 'center_y': Pixel-based y-coordinate.\n",
    "            - 'k_phi': Angular phi (in degrees), analogous to center_x.\n",
    "            - 'k_theta': Angular theta (in degrees), analogous to center_y.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a ColumnDataSource for efficient plotting\n",
    "    source = ColumnDataSource(eye_df)\n",
    "    tools = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "    # Plot 1: ms_axis vs. center_x and k_phi\n",
    "    p1 = figure(title=\"Time Series: center_x vs. k_phi\",\n",
    "                x_axis_label=\"Time (ms)\",\n",
    "                y_axis_label=\"center_x / k_phi\",\n",
    "                tools=tools, width=1500, height=1300)\n",
    "    p1.line(x='ms_axis', y='k_phi', source=source, color=\"blue\", legend_label=\"center_x\", line_width=2)\n",
    "    p1.line(x='ms_axis', y='k_phi_corr', source=source, color=\"red\", legend_label=\"k_phi\", line_width=2)\n",
    "    p1.legend.location = \"top_left\"\n",
    "\n",
    "    # Plot 2: ms_axis vs. center_y and k_theta\n",
    "    p2 = figure(title=\"Time Series: center_y vs. k_theta\",\n",
    "                x_axis_label=\"Time (ms)\",\n",
    "                y_axis_label=\"center_y / k_theta\",\n",
    "                tools=tools, width=1500, height=1300)\n",
    "    p2.line(x='ms_axis', y='k_theta', source=source, color=\"blue\", legend_label=\"center_y\", line_width=2)\n",
    "    p2.line(x='ms_axis', y='k_theta_corr', source=source, color=\"red\", legend_label=\"k_theta\", line_width=2)\n",
    "    p2.legend.location = \"top_left\"\n",
    "\n",
    "    # Layout the plots in a vertical column and display them\n",
    "    layout = column(p1, p2)\n",
    "    show(layout)\n",
    "\n",
    "\n",
    "plot_eye_comparison_over_time(corrected_right)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3069d42bfc628b5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "corrected_left.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b118098e7e98b8c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_gaze_vectors(before, after, title=\"Gaze Correction Verification\"):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(121, projection='3d')\n",
    "    ax.set_title(\"Original (Camera Frame)\")\n",
    "    ax.quiver(np.zeros(len(before)), np.zeros(len(before)), np.zeros(len(before)),\n",
    "              before[:, 0], before[:, 1], before[:, 2], color='r', alpha=0.5)\n",
    "    ax.set_xlim([-1, 1]); ax.set_ylim([-1, 1]); ax.set_zlim([-1, 1])\n",
    "\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.set_title(\"Corrected (Anatomical Frame)\")\n",
    "    ax2.quiver(np.zeros(len(after)), np.zeros(len(after)), np.zeros(len(after)),\n",
    "               after[:, 0], after[:, 1], after[:, 2], color='g', alpha=0.5)\n",
    "    ax2.set_xlim([-1, 1]); ax2.set_ylim([-1, 1]); ax2.set_zlim([-1, 1])\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_gaze_vectors(l_vectors, l_rotated, title=\"Left Eye Gaze Correction\")\n",
    "plot_gaze_vectors(r_vectors, r_rotated, title=\"Right Eye Gaze Correction\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed0fa95df03e008b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# from here, another attempt:\n",
    "\n",
    "# Jupyter Notebook Pipeline: Correct Gaze Vectors Using Rotation Matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Functions ---\n",
    "def spherical_to_cartesian(k_phi, k_theta):\n",
    "    phi = np.radians(k_phi)\n",
    "    theta = np.radians(k_theta)\n",
    "    x = np.cos(theta) * np.cos(phi)\n",
    "    y = np.cos(theta) * np.sin(phi)\n",
    "    z = np.sin(theta)\n",
    "    return np.stack((x, y, z), axis=-1)\n",
    "\n",
    "def apply_rotation(vectors, rotation_matrix):\n",
    "    return vectors @ rotation_matrix.T\n",
    "\n",
    "def cartesian_to_spherical(vectors):\n",
    "    x, y, z = vectors[:, 0], vectors[:, 1], vectors[:, 2]\n",
    "    r = np.linalg.norm(vectors, axis=1)\n",
    "    k_theta = np.arcsin(z / r)\n",
    "    k_phi = np.arctan2(y, x)\n",
    "    return np.degrees(k_phi), np.degrees(k_theta)\n",
    "\n",
    "# --- Load Data ---\n",
    "left_eye_data = pd.read_csv(\"left_eye_data.csv\")\n",
    "right_eye_data = pd.read_csv(\"right_eye_data.csv\")\n",
    "\n",
    "# --- Load Rotation Matrices ---\n",
    "l_rotation_matrix = np.loadtxt(\"left_eye_rotation_matrix.txt\")\n",
    "r_rotation_matrix = np.loadtxt(\"right_eye_rotation_matrix.txt\")\n",
    "\n",
    "# --- Process Left Eye ---\n",
    "l_vectors = spherical_to_cartesian(left_eye_data['k_phi'], left_eye_data['k_theta'])\n",
    "l_rotated = apply_rotation(l_vectors, l_rotation_matrix)\n",
    "l_phi_corr, l_theta_corr = cartesian_to_spherical(l_rotated)\n",
    "left_eye_data['k_phi_corrected'] = l_phi_corr\n",
    "left_eye_data['k_theta_corrected'] = l_theta_corr\n",
    "\n",
    "# --- Process Right Eye ---\n",
    "r_vectors = spherical_to_cartesian(right_eye_data['k_phi'], right_eye_data['k_theta'])\n",
    "r_rotated = apply_rotation(r_vectors, r_rotation_matrix)\n",
    "r_phi_corr, r_theta_corr = cartesian_to_spherical(r_rotated)\n",
    "right_eye_data['k_phi_corrected'] = r_phi_corr\n",
    "right_eye_data['k_theta_corrected'] = r_theta_corr\n",
    "\n",
    "# --- Save Updated Data ---\n",
    "left_eye_data.to_csv(\"left_eye_data_corrected.csv\", index=False)\n",
    "right_eye_data.to_csv(\"right_eye_data_corrected.csv\", index=False)\n",
    "\n",
    "print(\"Gaze correction complete.\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69f7d939c42e7e87",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# try again, 20/04\n",
    "\n",
    "# ==============================================================================\n",
    "# Python Analysis Functions: Apply and Visualize Correction\n",
    "# =====================================================================\n",
    "# These functions can be imported into your Jupyter pipeline.\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_rot_matrix(path):\n",
    "    with open(path,'r') as f: return np.array(json.load(f))\n",
    "\n",
    "\n",
    "def angles_to_vecs(phi, theta):\n",
    "    p = np.deg2rad(phi); t = np.deg2rad(theta)\n",
    "    x = np.cos(t)*np.cos(p)\n",
    "    y = np.cos(t)*np.sin(p)\n",
    "    z = np.sin(t)\n",
    "    return np.vstack((x,y,z)).T\n",
    "\n",
    "\n",
    "def vecs_to_angles(v):\n",
    "    x,y,z = v[:,0], v[:,1], v[:,2]\n",
    "    phi = np.rad2deg(np.arctan2(y,x))\n",
    "    r = np.linalg.norm(v,axis=1)\n",
    "    theta = np.rad2deg(np.arcsin(np.clip(z/r, -1,1)))\n",
    "    return phi, theta\n",
    "\n",
    "\n",
    "def apply_correction(df, mat, mirror=False):\n",
    "    \"\"\"\n",
    "    df: DataFrame with 'k_phi','k_theta'\n",
    "    mat: 3x3 rotation matrix\n",
    "    mirror: if True, flip phi sign (for left eye)\n",
    "    \"\"\"\n",
    "    V = angles_to_vecs(df['k_phi'], df['k_theta'])\n",
    "    Vc = V @ mat.T\n",
    "    phi_c, theta_c = vecs_to_angles(Vc)\n",
    "    if mirror:\n",
    "        phi_c = -phi_c\n",
    "    df['k_phi_corr'] = phi_c\n",
    "    df['k_theta_corr'] = theta_c\n",
    "    return df\n",
    "\n",
    "\n",
    "def visualize_average(df, title='Average Gaze'):\n",
    "    \"\"\"\n",
    "    Compute mean gaze vector and visualize original vs corrected axes.\n",
    "    \"\"\"\n",
    "    # Mean original\n",
    "    Vox = angles_to_vecs(df['k_phi'], df['k_theta'])\n",
    "    mean_orig = Vox.mean(axis=0)\n",
    "    # Mean corrected\n",
    "    Vc = angles_to_vecs(df['k_phi_corr'], df['k_theta_corr'])\n",
    "    mean_corr = Vc.mean(axis=0)\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # pick a small sample\n",
    "    sub = df.iloc[::len(df)//50]  # 50 points\n",
    "    Vox_sub = angles_to_vecs(sub['k_phi'], sub['k_theta'])\n",
    "    Voxc_sub = angles_to_vecs(sub['k_phi_corr'], sub['k_theta_corr'])\n",
    "    \n",
    "    plt.scatter(Vox_sub[:,0], Vox_sub[:,1], label='orig')\n",
    "    plt.scatter(Voxc_sub[:,0], Voxc_sub[:,1], label='corr')\n",
    "    plt.legend(); plt.axis('equal'); plt.show()\n",
    "\n",
    "    print(\"Mean original (φ, θ):\", df[[\"k_phi\",\"k_theta\"]].mean().values)\n",
    "    print(\"Mean corrected (φ, θ):\", df[[\"k_phi_corr\",\"k_theta_corr\"]].mean().values)\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.quiver(0,0, mean_orig[0], mean_orig[1], color='blue', label='Orig')\n",
    "    ax.quiver(0,0, mean_corr[0], mean_corr[1], color='red', label='Corr')\n",
    "    ax.set_xlim(-1,1); ax.set_ylim(-1,1)\n",
    "    ax.set_aspect('equal'); ax.grid(True)\n",
    "    ax.legend(); ax.set_title(title)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6bea03b6f359dfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Provide paths to the rotation matrices (exported from Blender).\n",
    "blender_project_path = pathlib.Path(r\"D:\\MarkS3\\Documents\\BlenderFiles\\Camera_angle_registration\\PV_57_textured-20250325T102628Z-001\")\n",
    "left_json_path = blender_project_path / \"l_rot_matrix.json\"\n",
    "right_json_path = blender_project_path / \"r_rot_matrix.json\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3155cb9f35d7bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "left_df = block.left_eye_data.copy()\n",
    "right_df = block.right_eye_data.copy()\n",
    "\n",
    "R_left = load_rot_matrix(left_json_path)\n",
    "R_right = load_rot_matrix(right_json_path)\n",
    "\n",
    "left_corr_df  = apply_correction(left_df.copy(),  R_left,  mirror=False)\n",
    "right_corr_df = apply_correction(right_df.copy(), R_right, mirror=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "457d8217d68babf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_average(left_corr_df,  title='Left Eye: Original vs Corrected')\n",
    "visualize_average(right_corr_df, title='Right Eye: Original vs Corrected')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70e8e31b699989a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4c6b4510946c1e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
