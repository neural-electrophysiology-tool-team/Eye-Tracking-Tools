{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def synchronize_and_display_videos_with_mapping(video_path1, video_path2, dataframe1, dataframe2, start_timestamp, stop_timestamp):\n",
    "    cap1 = cv2.VideoCapture(video_path1)\n",
    "    cap2 = cv2.VideoCapture(video_path2)\n",
    "\n",
    "    if not cap1.isOpened() or not cap2.isOpened():\n",
    "        print(\"Error opening video file.\")\n",
    "        return\n",
    "\n",
    "    # Find the starting frame numbers for each video based on the start timestamp\n",
    "    start_frame1 = dataframe1[dataframe1['OE_timestamp'] == start_timestamp]['frame_number'].values[0]\n",
    "    start_frame2 = dataframe2[dataframe2['OE_timestamp'] == start_timestamp]['frame_number'].values[0]\n",
    "\n",
    "    # Set the starting frames for each video\n",
    "    cap1.set(cv2.CAP_PROP_POS_FRAMES, start_frame1)\n",
    "    cap2.set(cv2.CAP_PROP_POS_FRAMES, start_frame2)\n",
    "\n",
    "    while True:\n",
    "        ret1, frame1 = cap1.read()\n",
    "        ret2, frame2 = cap2.read()\n",
    "\n",
    "        if not ret1 or not ret2:\n",
    "            break\n",
    "\n",
    "        # Resize frames if needed (adjust the dimensions based on your preference)\n",
    "        frame1 = cv2.resize(frame1, (640, 480))\n",
    "        frame2 = cv2.resize(frame2, (640, 480))\n",
    "\n",
    "        # Concatenate frames side by side\n",
    "        synchronized_frame = cv2.hconcat([frame1, frame2])\n",
    "\n",
    "        # Display the synchronized frame\n",
    "        cv2.imshow('Synchronized Videos', synchronized_frame)\n",
    "\n",
    "        # Check for the 'q' key to quit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Find the next frame numbers based on the current timestamps\n",
    "        current_timestamp = start_timestamp + (cap1.get(cv2.CAP_PROP_POS_FRAMES) - start_frame1) / cap1.get(cv2.CAP_PROP_FPS)\n",
    "        next_frame1 = dataframe1[dataframe1['OE_timestamp'] == current_timestamp]['frame_number'].values[0]\n",
    "        next_frame2 = dataframe2[dataframe2['OE_timestamp'] == current_timestamp]['frame_number'].values[0]\n",
    "\n",
    "        # Set the next frames for each video\n",
    "        cap1.set(cv2.CAP_PROP_POS_FRAMES, next_frame1)\n",
    "        cap2.set(cv2.CAP_PROP_POS_FRAMES, next_frame2)\n",
    "\n",
    "        # Update the start timestamp for the next iteration\n",
    "        start_timestamp = current_timestamp\n",
    "\n",
    "        # Break if the stop timestamp is reached\n",
    "        if current_timestamp >= stop_timestamp:\n",
    "            break\n",
    "\n",
    "    # Release video capture objects and close the window\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage:\n",
    "# synchronize_and_display_videos_with_mapping('path_to_video1.mp4', 'path_to_video2.mp4', dataframe1, dataframe2, start_timestamp, stop_timestamp)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "This notebook is used to create display a video file together with its ellipse fitting results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# define the path to the target block\n",
    "block_path = pathlib.Path(r'Z:\\Nimrod\\experiments\\PV_24\\2021_12_27\\block_12')\n",
    "\n",
    "# extract paths to objects of interest\n",
    "le_video = [vid for vid in glob.glob(str(block_path) + r'\\eye_videos\\LE\\**\\*.mp4') if\n",
    "                  \"DLC\" not in vid]\n",
    "re_video = [vid for vid in glob.glob(str(block_path) + r'\\eye_videos\\RE\\**\\*.mp4') if\n",
    "                  \"DLC\" not in vid]\n",
    "le_analysis_path = block_path / 'analysis' / 'le_df.csv'\n",
    "re_analysis_path = block_path / 'analysis' / 're_df.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# This cell reads the analysis file and gets it ready for ellipse fitting in the video\n",
    "r_df = pd.read_csv(re_analysis_path)\n",
    "r_width = np.floor(r_df.width.values)\n",
    "\n",
    "r_height = np.floor(r_df.height.values)\n",
    "\n",
    "MmAxes_r = []\n",
    "angle_r = np.floor(np.degrees(r_df.phi.values))\n",
    "\n",
    "center_coords_r = [np.floor(r_df.center_x.values), np.floor(r_df.center_y.values)]\n",
    "\n",
    "for i in range(len(r_width)):\n",
    "    if r_width[i] == r_width[i]:\n",
    "        if r_width[i] > r_height[i]:\n",
    "            MmAxes_r.append((int(r_width[i]),int(r_height[i])))\n",
    "        else:\n",
    "            MmAxes_r.append((int(r_height[i]), int(r_width[i])))\n",
    "    else:\n",
    "        MmAxes_r.append((np.nan, np.nan))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "### working ###\n",
    "# This cell runs a video of the right eye with overlaid ellipses\n",
    "\n",
    "re_cap = cv2.VideoCapture(re_video[0])\n",
    "frame_n = -1\n",
    "# go over frames of the video\n",
    "while re_cap.isOpened():\n",
    "    bad_flag = 0\n",
    "    # get a frame\n",
    "    re_ret, re_frame = re_cap.read()\n",
    "    if re_ret is True:\n",
    "        frame_n += 1\n",
    "        # find the row in the dataframe that corresponds with the frame_n\n",
    "        try:\n",
    "            i = np.where(r_df.R_eye_frame.values.astype(np.int32) == frame_n)[0][0]\n",
    "        except IndexError:\n",
    "            i = 0\n",
    "\n",
    "        re_frame = cv2.cvtColor(re_frame, cv2.COLOR_BGR2GRAY)\n",
    "        if MmAxes_r[i][0] == MmAxes_r[i][0]:\n",
    "            re_frame_with_ellipse = cv2.ellipse(re_frame,\n",
    "                                                (int(center_coords_r[0][i]),int(center_coords_r[1][i])),\n",
    "                                                (MmAxes_r[i][0], MmAxes_r[i][1]),\n",
    "                                                angle_r[i],\n",
    "                                                0,\n",
    "                                                360,\n",
    "                                                (0, 255, 0),\n",
    "                                                2)\n",
    "            cv2.imshow('Right eye frame', re_frame_with_ellipse)\n",
    "        else:\n",
    "            cv2.imshow('Right eye frame', re_frame)\n",
    "        if cv2.waitKey(5) & 0xFF==ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "re_cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
