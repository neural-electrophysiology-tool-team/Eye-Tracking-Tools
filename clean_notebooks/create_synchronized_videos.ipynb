{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T08:55:16.207213Z",
     "start_time": "2025-12-18T08:55:15.791233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import cycle\n",
    "import pickle\n",
    "import pathlib\n",
    "import math\n",
    "import tqdm\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import re\n",
    "from lxml import etree as ET\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "from scipy.stats import kde\n",
    "from BlockSync_current import BlockSync\n",
    "import UtilityFunctions_newOE as uf\n",
    "from scipy import signal\n",
    "import bokeh\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "rcParams['pdf.fonttype'] = 42  # Ensure fonts are embedded and editable\n",
    "rcParams['ps.fonttype'] = 42  # Ensure compatibility with vector outputs\n",
    "\n",
    "\n",
    "def bokeh_plotter(data_list, x_axis_list=None, label_list=None,\n",
    "                  plot_name='default',\n",
    "                  x_axis_label='X', y_axis_label='Y',\n",
    "                  peaks=None, peaks_list=False, export_path=False):\n",
    "    \"\"\"Generates an interactive Bokeh plot for the given data vector.\n",
    "    Args:\n",
    "        data_list (list or array): The data to be plotted.\n",
    "        label_list (list of str): The labels of the data vectors\n",
    "        plot_name (str, optional): The title of the plot. Defaults to 'default'.\n",
    "        x_axis (str, optional): The label for the x-axis. Defaults to 'X'.\n",
    "        y_axis (str, optional): The label for the y-axis. Defaults to 'Y'.\n",
    "        peaks (list or array, optional): Indices of peaks to highlight on the plot. Defaults to None.\n",
    "        export_path (False or str): when set to str, will output the resulting html fig\n",
    "    \"\"\"\n",
    "    color_cycle = cycle(bokeh.palettes.Category10_10)\n",
    "    fig = bokeh.plotting.figure(title=f'bokeh explorer: {plot_name}',\n",
    "                                x_axis_label=x_axis_label,\n",
    "                                y_axis_label=y_axis_label,\n",
    "                                plot_width=1500,\n",
    "                                plot_height=700)\n",
    "\n",
    "    for i, data_vector in enumerate(data_list):\n",
    "\n",
    "        color = next(color_cycle)\n",
    "\n",
    "        if x_axis_list is None:\n",
    "            x_axis = range(len(data_vector))\n",
    "        elif len(x_axis_list) == len(data_list):\n",
    "            print('x_axis manually set')\n",
    "            x_axis = x_axis_list[i]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                'problem with x_axis_list input - should be either None, or a list with the same length as data_list')\n",
    "        if label_list is None:\n",
    "            fig.line(x_axis, data_vector, line_color=color, legend_label=f\"Line {i + 1}\")\n",
    "        elif len(label_list) == len(data_list):\n",
    "            fig.line(range(len(data_vector)), data_vector, line_color=color, legend_label=f\"{label_list[i]}\")\n",
    "        if peaks is not None and peaks_list is True:\n",
    "            fig.circle(peaks[i], data_vector[peaks[i]], size=10, color=color)\n",
    "\n",
    "    if peaks is not None and peaks_list is False:\n",
    "        fig.circle(peaks, data_vector[peaks], size=10, color='red')\n",
    "\n",
    "    if export_path is not False:\n",
    "        print(f'exporting to {export_path}')\n",
    "        bokeh.io.output.output_file(filename=str(export_path / f'{plot_name}.html'), title=f'{plot_name}')\n",
    "    bokeh.plotting.show(fig)\n",
    "\n",
    "\n",
    "def load_eye_data_2d_w_rotation_matrix(block):\n",
    "    \"\"\"\n",
    "    This function checks if the eye dataframes and rotation dict object exist, then imports them\n",
    "    :param block: The current blocksync class with verifiec re/le dfs\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data.csv', index_col=0, engine='python')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data.csv', index_col=0, engine='python')\n",
    "    except FileNotFoundError:\n",
    "        print('eye_data files not found, run the pipeline!')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(block.analysis_path / 'rotate_eye_data_params.pkl', 'rb') as file:\n",
    "            rotation_dict = pickle.load(file)\n",
    "            block.left_rotation_matrix = rotation_dict['left_rotation_matrix']\n",
    "            block.right_rotation_matrix = rotation_dict['right_rotation_matrix']\n",
    "            block.left_rotation_angle = rotation_dict['left_rotation_angle']\n",
    "            block.right_rotation_angle = rotation_dict['right_rotation_angle']\n",
    "    except FileNotFoundError:\n",
    "        print('No rotation matrix file, create it')\n",
    "\n",
    "\n",
    "def create_saccade_events_df(eye_data_df, speed_threshold, bokeh_verify_threshold=False, magnitude_calib=1,\n",
    "                             speed_profile=True):\n",
    "    \"\"\"\n",
    "    Detects saccade events in eye tracking data and computes relevant metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - eye_data_df (pd.DataFrame): Input DataFrame containing eye tracking data.\n",
    "    - speed_threshold (float): Threshold for saccade detection based on speed.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): Modified input DataFrame with added columns for speed and saccade detection.\n",
    "    - saccade_events_df (pd.DataFrame): DataFrame containing information about detected saccade events.\n",
    "\n",
    "    Steps:\n",
    "    1. Calculate speed components ('speed_x', 'speed_y') based on differences in 'center_x' and 'center_y'.\n",
    "    2. Compute the magnitude of the velocity vector ('speed_r').\n",
    "    3. Create a binary column ('is_saccade') indicating saccade events based on the speed threshold.\n",
    "    4. Determine saccade onset and offset indices and timestamps.\n",
    "    5. Create a DataFrame ('saccade_events_df') with columns:\n",
    "        - 'saccade_start_ind': Indices of saccade onset.\n",
    "        - 'saccade_start_timestamp': Timestamps corresponding to saccade onset.\n",
    "        - 'saccade_end_ind': Indices of saccade offset.\n",
    "        - 'saccade_end_timestamp': Timestamps corresponding to saccade offset.\n",
    "        - 'length': Duration of each saccade event.\n",
    "    6. Calculate distance traveled and angles for each saccade event.\n",
    "    7. Append additional columns to 'saccade_events_df':\n",
    "        - 'magnitude': Magnitude of the distance traveled during each saccade.\n",
    "        - 'angle': Angle of the saccade vector in degrees.\n",
    "        - 'initial_x', 'initial_y': Initial coordinates of the saccade.\n",
    "        - 'end_x', 'end_y': End coordinates of the saccade.\n",
    "\n",
    "    Note: The original 'eye_data_df' is not modified; modified data is returned as 'df'.\n",
    "    \"\"\"\n",
    "    df = eye_data_df\n",
    "    df['speed_x'] = df['center_x'].diff()  # Difference between consecutive 'center_x' values\n",
    "    df['speed_y'] = df['center_y'].diff()  # Difference between consecutive 'center_y' values\n",
    "\n",
    "    # Step 2: Calculate magnitude of the velocity vector (R vector speed)\n",
    "    df['speed_r'] = (df['speed_x'] ** 2 + df['speed_y'] ** 2) ** 0.5\n",
    "\n",
    "    # Create a column for saccade detection\n",
    "    df['is_saccade'] = df['speed_r'] > speed_threshold\n",
    "\n",
    "    # create a saccade_on_off indicator where 1 is rising edge and -1 is falling edge by subtracting a shifted binary mask\n",
    "    saccade_on_off = df.is_saccade.astype(int) - df.is_saccade.shift(periods=1, fill_value=False).astype(int)\n",
    "    saccade_on_inds = np.where(saccade_on_off == 1)[\n",
    "                          0] - 1  # notice the manual shift here, chosen to include the first (sometimes slower) eye frame, just before saccade threshold crossing\n",
    "    saccade_on_ms = df['ms_axis'].iloc[saccade_on_inds]\n",
    "    saccade_on_timestamps = df['OE_timestamp'].iloc[saccade_on_inds]\n",
    "    saccade_off_inds = np.where(saccade_on_off == -1)[0]\n",
    "    saccade_off_timestamps = df['OE_timestamp'].iloc[saccade_off_inds]\n",
    "    saccade_off_ms = df['ms_axis'].iloc[saccade_off_inds]\n",
    "\n",
    "    saccade_dict = {'saccade_start_ind': saccade_on_inds,\n",
    "                    'saccade_start_timestamp': saccade_on_timestamps.values,\n",
    "                    'saccade_end_ind': saccade_off_inds,\n",
    "                    'saccade_end_timestamp': saccade_off_timestamps.values,\n",
    "                    'saccade_on_ms': saccade_on_ms.values,\n",
    "                    'saccade_off_ms': saccade_off_ms.values}\n",
    "\n",
    "    saccade_events_df = pd.DataFrame.from_dict(saccade_dict)\n",
    "    saccade_events_df['length'] = saccade_events_df['saccade_end_ind'] - saccade_events_df['saccade_start_ind']\n",
    "    # Drop columns used for intermediate steps\n",
    "    df = df.drop(['is_saccade'], axis=1)\n",
    "\n",
    "    distances = []\n",
    "    angles = []\n",
    "    speed_list = []\n",
    "    diameter_list = []\n",
    "    for index, row in tqdm.tqdm(saccade_events_df.iterrows()):\n",
    "        saccade_samples = df.loc[(df['OE_timestamp'] >= row['saccade_start_timestamp']) &\n",
    "                                 (df['OE_timestamp'] <= row['saccade_end_timestamp'])]\n",
    "        distance_traveled = saccade_samples['speed_r'].sum()\n",
    "        if speed_profile:\n",
    "            saccade_speed_profile = saccade_samples['speed_r'].values\n",
    "            speed_list.append(saccade_speed_profile)\n",
    "        saccade_diameter_profile = saccade_samples['pupil_diameter'].values\n",
    "        diameter_list.append(saccade_diameter_profile)\n",
    "        # Calculate angle from initial position to endpoint\n",
    "        initial_position = saccade_samples.iloc[0][['center_x', 'center_y']]\n",
    "        endpoint = saccade_samples.iloc[-1][['center_x', 'center_y']]\n",
    "        overall_angle = np.arctan2(endpoint['center_y'] - initial_position['center_y'],\n",
    "                                   endpoint['center_x'] - initial_position['center_x'])\n",
    "\n",
    "        angles.append(overall_angle)\n",
    "        distances.append(distance_traveled)\n",
    "\n",
    "    saccade_events_df['magnitude_raw'] = np.array(distances)\n",
    "    saccade_events_df['magnitude'] = np.array(distances) * magnitude_calib\n",
    "    saccade_events_df['angle'] = np.where(np.isnan(angles), angles, np.rad2deg(\n",
    "        angles) % 360)  # Convert radians to degrees and ensure result is in [0, 360)\n",
    "    start_ts = saccade_events_df['saccade_start_timestamp'].values\n",
    "    end_ts = saccade_events_df['saccade_end_timestamp'].values\n",
    "    saccade_start_df = df[df['OE_timestamp'].isin(start_ts)]\n",
    "    saccade_end_df = df[df['OE_timestamp'].isin(end_ts)]\n",
    "    start_x_coord = saccade_start_df['center_x']\n",
    "    start_y_coord = saccade_start_df['center_y']\n",
    "    end_x_coord = saccade_end_df['center_x']\n",
    "    end_y_coord = saccade_end_df['center_y']\n",
    "    saccade_events_df['initial_x'] = start_x_coord.values\n",
    "    saccade_events_df['initial_y'] = start_y_coord.values\n",
    "    saccade_events_df['end_x'] = end_x_coord.values\n",
    "    saccade_events_df['end_y'] = end_y_coord.values\n",
    "    saccade_events_df['calib_dx'] = (saccade_events_df['end_x'].values - saccade_events_df[\n",
    "        'initial_x'].values) * magnitude_calib\n",
    "    saccade_events_df['calib_dy'] = (saccade_events_df['end_y'].values - saccade_events_df[\n",
    "        'initial_y'].values) * magnitude_calib\n",
    "    if speed_profile:\n",
    "        saccade_events_df['speed_profile'] = speed_list\n",
    "    saccade_events_df['diameter_profile'] = diameter_list\n",
    "    if bokeh_verify_threshold:\n",
    "        bokeh_plotter(data_list=[df.speed_r], label_list=['Pupil Velocity'], peaks=saccade_on_inds)\n",
    "\n",
    "    return df, saccade_events_df\n",
    "\n",
    "\n",
    "# create a multi-animal block_collection:\n",
    "\n",
    "def create_block_collections(animals, block_lists, experiment_path, bad_blocks=None):\n",
    "    \"\"\"\n",
    "    Create block collections and a block dictionary from multiple animals and their respective block lists.\n",
    "\n",
    "    Parameters:\n",
    "    - animals: list of str, names of the animals.\n",
    "    - block_lists: list of lists of int, block numbers corresponding to each animal.\n",
    "    - experiment_path: pathlib.Path, path to the experiment directory.\n",
    "    - bad_blocks: list of int, blocks to exclude. Default is an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - block_collection: list of BlockSync objects for all specified blocks.\n",
    "    - block_dict: dictionary where keys are block numbers as strings and values are BlockSync objects.\n",
    "    \"\"\"\n",
    "    import UtilityFunctions_newOE as uf\n",
    "\n",
    "    if bad_blocks is None:\n",
    "        bad_blocks = []\n",
    "\n",
    "    block_collection = []\n",
    "    block_dict = {}\n",
    "\n",
    "    for animal, blocks in zip(animals, block_lists):\n",
    "        # Generate blocks for the current animal\n",
    "        current_blocks = uf.block_generator(\n",
    "            block_numbers=blocks,\n",
    "            experiment_path=experiment_path,\n",
    "            animal=animal,\n",
    "            bad_blocks=bad_blocks\n",
    "        )\n",
    "        # Add to collection and dictionary\n",
    "        block_collection.extend(current_blocks)\n",
    "        for b in current_blocks:\n",
    "            block_dict[f\"{animal}_block_{b.block_num}\"] = b\n",
    "\n",
    "    return block_collection, block_dict\n"
   ],
   "id": "701b2d22e0217f08",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T08:57:37.782082Z",
     "start_time": "2025-12-18T08:57:33.257813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# BLOCK DEFINITION #\n",
    "# This was the previous run\n",
    "#animals = ['PV_62', 'PV_126', 'PV_57']\n",
    "#block_lists = [[24, 26, 38], [7, 8, 9, 10, 11, 12], [7, 8, 9, 12, 13]]\n",
    "#This with new animals:\n",
    "animals = ['PV_126']\n",
    "block_lists = [[7]]\n",
    "experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "bad_blocks = [0]  # Example of bad blocks\n",
    "\n",
    "block_collection, block_dict = create_block_collections(\n",
    "    animals=animals,\n",
    "    block_lists=block_lists,\n",
    "    experiment_path=experiment_path,\n",
    "    bad_blocks=bad_blocks\n",
    ")\n",
    "for block in block_collection:\n",
    "    block.parse_open_ephys_events()\n",
    "    block.get_eye_brightness_vectors()\n",
    "    block.synchronize_block()\n",
    "    block.create_eye_brightness_df(threshold_value=20)\n",
    "\n",
    "    # if the code fails here, go to manual synchronization\n",
    "    block.import_manual_sync_df()\n",
    "    block.read_dlc_data()\n",
    "    block.calibrate_pixel_size(10)\n",
    "    #load_eye_data_2d_w_rotation_matrix(block) #should be integrated again... later\n",
    "\n",
    "    for block in block_collection:\n",
    "        # block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_corr_angles.csv')\n",
    "        # block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_corr_angles.csv')\n",
    "        #block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_raw_xflipped.csv')\n",
    "        #block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_raw_xflipped.csv')\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_raw_verified.csv')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_raw_verified.csv')\n",
    "        # block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_3d_corr_verified.csv')\n",
    "        # block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_3d_corr_verified.csv')\n",
    "        #block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_rotated_verified.csv')\n",
    "        #block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_rotated_verified.csv')\n",
    "\n",
    "    # calibrate pupil diameter:\n",
    "    # if 'pupil_diameter' not in block.left_eye_data.columns:\n",
    "    #     block.left_eye_data['pupil_diameter_pixels'] = block.left_eye_data.major_ax * 2 * np.pi\n",
    "    #     block.right_eye_data['pupil_diameter_pixels'] = block.right_eye_data.major_ax * 2 * np.pi\n",
    "    #     block.left_eye_data['pupil_diameter'] = block.left_eye_data['pupil_diameter_pixels'] * block.L_pix_size\n",
    "    #     block.right_eye_data['pupil_diameter'] = block.right_eye_data['pupil_diameter_pixels'] * block.R_pix_size"
   ],
   "id": "65f010acc4900a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 007 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007, new OE version\n",
      "Found the sample rate for block 007 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 007\n",
      "got it!\n",
      "running parse_open_ephys_events...\n",
      "block 007 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 007...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T09:07:49.094083Z",
     "start_time": "2025-12-18T09:07:48.899860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for block in block_collection:\n",
    "    block.handle_eye_videos()\n",
    "    block.handle_arena_files()\n",
    "    if 'pupil_diameter' not in block.left_eye_data.columns:\n",
    "        print(f'calculating pupil diameter for {block} ')\n",
    "        block.left_eye_data['pupil_diameter_pixels'] = block.left_eye_data.major_ax\n",
    "        block.right_eye_data['pupil_diameter_pixels'] = block.right_eye_data.major_ax\n",
    "        block.left_eye_data['pupil_diameter'] = block.left_eye_data['pupil_diameter_pixels'] * block.L_pix_size\n",
    "        block.right_eye_data['pupil_diameter'] = block.right_eye_data['pupil_diameter_pixels'] * block.R_pix_size"
   ],
   "id": "8f35595c817f2398",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_126\\\\2024_07_18\\\\block_007\\\\eye_videos\\\\LE\\\\wake3_640x480_60hz_experiment_1_recording_0\\\\wake3.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_126\\\\2024_07_18\\\\block_007\\\\eye_videos\\\\RE\\\\wake3_640x480_60hz_experiment_1_recording_0\\\\wake3.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_126\\\\2024_07_18\\\\block_007\\\\eye_videos\\\\LE\\\\wake3_640x480_60hz_experiment_1_recording_0\\\\wake3_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_126\\\\2024_07_18\\\\block_007\\\\eye_videos\\\\RE\\\\wake3_640x480_60hz_experiment_1_recording_0\\\\wake3.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\eye_videos\\RE\\wake3_640x480_60hz_experiment_1_recording_0\\wake3.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named wake3_LE.mp4 has reported 121804 frames and has 121805 frames, it has dropped -1 frames\n",
      "The video named wake3.mp4 has reported 121901 frames and has 121901 frames, it has dropped 0 frames\n",
      "handling arena files\n",
      "Arena video Names:\n",
      "front_20240718T124930.mp4\n",
      "left_20240718T124930.mp4\n",
      "right_20240718T124930.mp4\n",
      "top_20240718T124930.mp4\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T09:07:06.047631Z",
     "start_time": "2025-12-18T09:07:06.037632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if ms_axis is missing from final sync df:\n",
    "block.final_sync_df['ms_axis'] = block.final_sync_df['Arena_TTL'].values / (block.sample_rate / 1000)"
   ],
   "id": "db0bebf2e2cfd1f9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T12:58:02.229242Z",
     "start_time": "2025-12-22T12:58:02.133701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional, Sequence, Dict, Tuple, Union, Literal\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def export_block_synchronized_montage_video_v3(\n",
    "    block: object,\n",
    "    start_ms: float,\n",
    "    end_ms: float,\n",
    "    out_path: os.PathLike | str,\n",
    "    *,\n",
    "    fps: float = 60.0,\n",
    "\n",
    "    # Arena selection + manual patch\n",
    "    arena_video: Optional[Union[int, str]] = None,  # None => prompt; int => index; str => substring match\n",
    "    arena_frame_cols: Sequence[str] = (\n",
    "        \"Arena_frame\", \"arena_frame\", \"arena_frames\", \"arena_frame_idx\",\n",
    "        \"frame\", \"frame_idx\", \"video_frame\", \"arena_idx\"\n",
    "    ),\n",
    "    use_final_sync_df: bool = True,\n",
    "    arena_frame_shift: int = 0,  # + shifts arena later (uses later frames); - shifts earlier\n",
    "\n",
    "    # --- NEW: choose eye video source ---\n",
    "    eye_video_mode: Literal[\"auto\", \"raw\", \"dlc\"] = \"auto\",  # <-- requested flag\n",
    "    dlc_name_hint: str = \"DLC\",  # substring to identify DLC files (case-insensitive)\n",
    "\n",
    "    # Geometry / appearance\n",
    "    top_banner_h: int = 60,\n",
    "    trace_h: int = 220,\n",
    "    fit_eyes_to_arena_height: bool = False,  # scale eyes to arena height (preserve AR)\n",
    "    flip_eyes_vertical: bool = True,\n",
    "\n",
    "    # Trace controls\n",
    "    trace_window_ms: Optional[float] = None,\n",
    "    normalize_traces: bool = False,\n",
    "    robust_ylim_percentiles: Tuple[float, float] = (5.0, 95.0),\n",
    "    trace_signals: Sequence[str] = (\"pupil_diameter\", \"phi\", \"theta\"),\n",
    "    trace_col_map: Optional[Dict[str, str]] = None,  # e.g. {\"theta\":\"k_theta\",\"phi\":\"k_phi\"}\n",
    "\n",
    "    # Disqualification / missing frames\n",
    "    disqualify_cols: Sequence[str] = (\"center_x\", \"center_y\"),\n",
    "    show_disqualified_badge: bool = True,\n",
    "\n",
    "    # Output encoding\n",
    "    codec: str = \"mp4v\",\n",
    "    timestamp_precision_ms: int = 0,\n",
    "\n",
    "    show_debug_prints: bool = True,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Export synchronized montage video:\n",
    "        [Right eye | Arena | Left eye]\n",
    "      + top text banner\n",
    "      + bottom traces panel (pupil_diameter, phi, theta)\n",
    "\n",
    "    NEW: eye_video_mode controls whether to use raw eye mp4s or DLC-annotated mp4s.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------- helpers --------------------------\n",
    "    def _require_attr(obj: object, name: str):\n",
    "        if not hasattr(obj, name):\n",
    "            raise AttributeError(f\"block is missing required attribute '{name}'\")\n",
    "        return getattr(obj, name)\n",
    "\n",
    "    def _require_cols(df: pd.DataFrame, cols: Sequence[str], df_name: str):\n",
    "        missing = [c for c in cols if c not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"{df_name} is missing required columns: {missing}\")\n",
    "\n",
    "    def _pick_first_video(paths, name: str) -> Path:\n",
    "        if paths is None:\n",
    "            raise ValueError(f\"block.{name} is None\")\n",
    "        if isinstance(paths, (str, os.PathLike)):\n",
    "            p = Path(paths)\n",
    "            if not p.exists():\n",
    "                raise FileNotFoundError(p)\n",
    "            return p\n",
    "        if isinstance(paths, (list, tuple)) and len(paths) > 0:\n",
    "            p = Path(paths[0])\n",
    "            if not p.exists():\n",
    "                raise FileNotFoundError(p)\n",
    "            return p\n",
    "        raise ValueError(f\"block.{name} has no usable video path(s)\")\n",
    "\n",
    "    def _open_cap(p: Path, label: str) -> cv2.VideoCapture:\n",
    "        cap = cv2.VideoCapture(str(p))\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(f\"Cannot open {label} video: {p}\")\n",
    "        return cap\n",
    "\n",
    "    def _nearest_row_by_ms(df: pd.DataFrame, ms: float) -> pd.Series:\n",
    "        arr = df[\"ms_axis\"].to_numpy(dtype=float)\n",
    "        if arr.size == 0:\n",
    "            raise ValueError(\"ms_axis array is empty.\")\n",
    "        idx = int(np.nanargmin(np.abs(arr - float(ms))))\n",
    "        return df.iloc[idx]\n",
    "\n",
    "    def _resolve_arena_frame_col(fs: pd.DataFrame) -> str:\n",
    "        for c in arena_frame_cols:\n",
    "            if c in fs.columns:\n",
    "                return c\n",
    "        raise ValueError(f\"final_sync_df has no recognizable arena frame column. Tried: {list(arena_frame_cols)}\")\n",
    "\n",
    "    def _safe_put_text(img, text, org, color, scale=0.6, thickness=2):\n",
    "        x, y = org\n",
    "        cv2.putText(img, text, (x + 1, y + 1), cv2.FONT_HERSHEY_SIMPLEX, scale, (0, 0, 0),\n",
    "                    thickness + 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "    def _make_banner(W: int, lines: Sequence[str]) -> np.ndarray:\n",
    "        banner = np.zeros((top_banner_h, W, 3), dtype=np.uint8)\n",
    "        y = 24\n",
    "        for ln in lines:\n",
    "            _safe_put_text(banner, ln, (12, y), (255, 255, 255), scale=0.7, thickness=2)\n",
    "            y += 24\n",
    "            if y > top_banner_h - 8:\n",
    "                break\n",
    "        return banner\n",
    "\n",
    "    def _read_frame_at(cap: cv2.VideoCapture, frame_idx: int) -> Optional[np.ndarray]:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_idx))\n",
    "        ok, frame = cap.read()\n",
    "        return frame if ok else None\n",
    "\n",
    "    def _clamp_idx(idx: Optional[int], cap: cv2.VideoCapture) -> Optional[int]:\n",
    "        if idx is None:\n",
    "            return None\n",
    "        n = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "        if n > 0:\n",
    "            return int(np.clip(int(idx), 0, n - 1))\n",
    "        return max(0, int(idx))\n",
    "\n",
    "    def _resize_to_height(img: np.ndarray, target_h: int) -> np.ndarray:\n",
    "        h, w = img.shape[:2]\n",
    "        if h == target_h:\n",
    "            return img\n",
    "        new_w = max(1, int(round(w * (target_h / float(h)))))\n",
    "        return cv2.resize(img, (new_w, target_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def _robust_limits(x: np.ndarray, p_lo: float, p_hi: float) -> Tuple[float, float]:\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        x = x[np.isfinite(x)]\n",
    "        if x.size < 2:\n",
    "            return (-1.0, 1.0)\n",
    "        lo = np.percentile(x, p_lo)\n",
    "        hi = np.percentile(x, p_hi)\n",
    "        if not np.isfinite(lo) or not np.isfinite(hi) or abs(hi - lo) < 1e-12:\n",
    "            lo, hi = float(np.min(x)), float(np.max(x))\n",
    "        if abs(hi - lo) < 1e-12:\n",
    "            lo -= 1.0\n",
    "            hi += 1.0\n",
    "        return float(lo), float(hi)\n",
    "\n",
    "    def _map_to_axis(vals: np.ndarray, lo: float, hi: float) -> np.ndarray:\n",
    "        return (vals - lo) / (hi - lo + 1e-12)\n",
    "\n",
    "    def _draw_trace_panel(\n",
    "        W: int,\n",
    "        t_ms: float,\n",
    "        t_grid: np.ndarray,\n",
    "        Lsig: Dict[str, np.ndarray],\n",
    "        Rsig: Dict[str, np.ndarray],\n",
    "        t0: float,\n",
    "        t1: float,\n",
    "    ) -> np.ndarray:\n",
    "        panel = np.zeros((trace_h, W, 3), dtype=np.uint8)\n",
    "\n",
    "        if trace_window_ms is None:\n",
    "            w0, w1 = t0, t1\n",
    "        else:\n",
    "            half = float(trace_window_ms) / 2.0\n",
    "            w0, w1 = max(t0, t_ms - half), min(t1, t_ms + half)\n",
    "            if w1 <= w0:\n",
    "                w0, w1 = t0, t1\n",
    "\n",
    "        idx = np.where((t_grid >= w0) & (t_grid <= w1))[0]\n",
    "        if idx.size < 2:\n",
    "            return panel\n",
    "\n",
    "        tg = t_grid[idx]\n",
    "        x = (tg - w0) / (w1 - w0 + 1e-12)\n",
    "        xpix = (x * (W - 1)).astype(int)\n",
    "\n",
    "        n_axes = len(trace_signals)\n",
    "        pad_y = 10\n",
    "        axis_h = max(40, (trace_h - 2 * pad_y) // max(1, n_axes))\n",
    "        axes = []\n",
    "        for j, name in enumerate(trace_signals):\n",
    "            y0 = pad_y + j * axis_h\n",
    "            y1 = min(trace_h - pad_y, y0 + axis_h) - 8\n",
    "            axes.append((name, y0, y1))\n",
    "\n",
    "        cursor_x = int(round((np.clip(t_ms, w0, w1) - w0) / (w1 - w0 + 1e-12) * (W - 1)))\n",
    "        cv2.line(panel, (cursor_x, 0), (cursor_x, trace_h - 1), (120, 120, 120), 1)\n",
    "\n",
    "        _safe_put_text(panel, f\"t = {t_ms:.{timestamp_precision_ms}f} ms\", (12, 22),\n",
    "                       (255, 255, 255), scale=0.65, thickness=2)\n",
    "\n",
    "        color_L = (80, 220, 80)    # green\n",
    "        color_R = (220, 220, 80)   # yellow\n",
    "\n",
    "        for name, y0, y1 in axes:\n",
    "            cv2.rectangle(panel, (0, y0), (W - 1, y1), (20, 20, 20), 1)\n",
    "            L = Lsig.get(name, None)\n",
    "            R = Rsig.get(name, None)\n",
    "            if L is None or R is None:\n",
    "                continue\n",
    "\n",
    "            Lw = L[idx].astype(float)\n",
    "            Rw = R[idx].astype(float)\n",
    "\n",
    "            yy0, yy1 = int(y0 + 18), int(y1 - 8)\n",
    "            Hax = max(2, yy1 - yy0)\n",
    "\n",
    "            if normalize_traces:\n",
    "                # normalize per-window, per-eye\n",
    "                Llo, Lhi = np.nanmin(Lw), np.nanmax(Lw)\n",
    "                Rlo, Rhi = np.nanmin(Rw), np.nanmax(Rw)\n",
    "                Ln = np.full_like(Lw, 0.5) if (not np.isfinite(Llo) or not np.isfinite(Lhi) or abs(Lhi - Llo) < 1e-12) else _map_to_axis(Lw, Llo, Lhi)\n",
    "                Rn = np.full_like(Rw, 0.5) if (not np.isfinite(Rlo) or not np.isfinite(Rhi) or abs(Rhi - Rlo) < 1e-12) else _map_to_axis(Rw, Rlo, Rhi)\n",
    "                label = f\"{name} (norm)\"\n",
    "            else:\n",
    "                # shared robust limits (both eyes) in window\n",
    "                p_lo, p_hi = robust_ylim_percentiles\n",
    "                lo, hi = _robust_limits(np.concatenate([Lw, Rw]), p_lo, p_hi)\n",
    "                Ln = _map_to_axis(Lw, lo, hi)\n",
    "                Rn = _map_to_axis(Rw, lo, hi)\n",
    "                label = f\"{name} [{lo:.2f},{hi:.2f}]\"\n",
    "\n",
    "            yL = (yy0 + (1.0 - np.clip(Ln, 0, 1)) * (Hax - 1)).astype(int)\n",
    "            yR = (yy0 + (1.0 - np.clip(Rn, 0, 1)) * (Hax - 1)).astype(int)\n",
    "\n",
    "            for k in range(1, len(xpix)):\n",
    "                if np.isfinite(yL[k - 1]) and np.isfinite(yL[k]):\n",
    "                    cv2.line(panel, (xpix[k - 1], yL[k - 1]), (xpix[k], yL[k]), color_L, 1, cv2.LINE_AA)\n",
    "                if np.isfinite(yR[k - 1]) and np.isfinite(yR[k]):\n",
    "                    cv2.line(panel, (xpix[k - 1], yR[k - 1]), (xpix[k], yR[k]), color_R, 1, cv2.LINE_AA)\n",
    "\n",
    "            _safe_put_text(panel, label, (12, y0 + 16), (200, 200, 200), scale=0.55, thickness=1)\n",
    "            _safe_put_text(panel, \"L\", (W - 60, y0 + 16), color_L, scale=0.55, thickness=1)\n",
    "            _safe_put_text(panel, \"R\", (W - 35, y0 + 16), color_R, scale=0.55, thickness=1)\n",
    "\n",
    "        return panel\n",
    "\n",
    "    def _choose_arena_video(arena_list: Sequence[str], choice: Optional[Union[int, str]]) -> Path:\n",
    "        paths = [Path(p) for p in arena_list]\n",
    "        if not paths:\n",
    "            raise ValueError(\"block.arena_videos is empty.\")\n",
    "        if isinstance(choice, int):\n",
    "            if choice < 0 or choice >= len(paths):\n",
    "                raise ValueError(f\"arena_video index {choice} out of range (0..{len(paths)-1})\")\n",
    "            return paths[int(choice)]\n",
    "        if isinstance(choice, str) and choice.strip():\n",
    "            key = choice.strip().lower()\n",
    "            hits = [p for p in paths if key in p.name.lower()]\n",
    "            if not hits:\n",
    "                raise ValueError(f\"arena_video='{choice}' did not match any arena video name.\")\n",
    "            hits.sort(key=lambda p: len(p.name))\n",
    "            return hits[0]\n",
    "        # prompt\n",
    "        print(\"\\nSelect arena video:\")\n",
    "        for i, p in enumerate(paths):\n",
    "            print(f\"  [{i}] {p.name}\")\n",
    "        raw = \"\"\n",
    "        try:\n",
    "            raw = input(\"Enter arena index (default 0): \").strip()\n",
    "        except Exception:\n",
    "            raw = \"\"\n",
    "        idx = 0 if raw == \"\" else int(raw)\n",
    "        if idx < 0 or idx >= len(paths):\n",
    "            raise ValueError(f\"arena index {idx} out of range.\")\n",
    "        return paths[idx]\n",
    "\n",
    "    def _resolve_eye_video(raw_path: Path, mode: str) -> Path:\n",
    "        \"\"\"\n",
    "        raw_path: block.le_videos[0] or block.re_videos[0]\n",
    "        mode: 'raw' | 'dlc' | 'auto'\n",
    "        Finds DLC mp4s in the same folder if requested.\n",
    "        \"\"\"\n",
    "        raw_path = Path(raw_path)\n",
    "        if mode == \"raw\":\n",
    "            return raw_path\n",
    "\n",
    "        folder = raw_path.parent\n",
    "        if not folder.exists():\n",
    "            if mode == \"dlc\":\n",
    "                raise FileNotFoundError(f\"Eye video folder not found: {folder}\")\n",
    "            return raw_path\n",
    "\n",
    "        # all mp4 with DLC hint\n",
    "        hint = dlc_name_hint.lower()\n",
    "        dlc_candidates = [p for p in folder.glob(\"*.mp4\") if hint in p.name.lower()]\n",
    "\n",
    "        # prefer candidates that contain the raw stem\n",
    "        stem = raw_path.stem.lower()\n",
    "        stem_hits = [p for p in dlc_candidates if stem in p.stem.lower()]\n",
    "        candidates = stem_hits if stem_hits else dlc_candidates\n",
    "\n",
    "        if candidates:\n",
    "            # stable pick\n",
    "            candidates.sort(key=lambda p: p.name)\n",
    "            return candidates[0]\n",
    "\n",
    "        if mode == \"dlc\":\n",
    "            raise FileNotFoundError(\n",
    "                f\"eye_video_mode='dlc' but no DLC mp4 found in {folder} (hint='{dlc_name_hint}')\"\n",
    "            )\n",
    "        return raw_path\n",
    "\n",
    "    # -------------------------- validation --------------------------\n",
    "    start_ms = float(start_ms)\n",
    "    end_ms = float(end_ms)\n",
    "    if end_ms <= start_ms:\n",
    "        raise ValueError(f\"end_ms must be > start_ms (got start_ms={start_ms}, end_ms={end_ms})\")\n",
    "\n",
    "    left_df: pd.DataFrame = _require_attr(block, \"left_eye_data\")\n",
    "    right_df: pd.DataFrame = _require_attr(block, \"right_eye_data\")\n",
    "    _require_cols(left_df, [\"ms_axis\", \"eye_frame\"], \"left_eye_data\")\n",
    "    _require_cols(right_df, [\"ms_axis\", \"eye_frame\"], \"right_eye_data\")\n",
    "\n",
    "    fs = None\n",
    "    arena_fcol = None\n",
    "    if use_final_sync_df:\n",
    "        fs = _require_attr(block, \"final_sync_df\")\n",
    "        if not isinstance(fs, pd.DataFrame):\n",
    "            raise ValueError(\"block.final_sync_df is not a pandas DataFrame.\")\n",
    "        _require_cols(fs, [\"ms_axis\"], \"final_sync_df\")\n",
    "        arena_fcol = _resolve_arena_frame_col(fs)\n",
    "\n",
    "    # --- resolve chosen eye video files ---\n",
    "    rv_raw = _pick_first_video(_require_attr(block, \"re_videos\"), \"re_videos\")\n",
    "    lv_raw = _pick_first_video(_require_attr(block, \"le_videos\"), \"le_videos\")\n",
    "    rv = _resolve_eye_video(rv_raw, eye_video_mode)\n",
    "    lv = _resolve_eye_video(lv_raw, eye_video_mode)\n",
    "\n",
    "    # arena path\n",
    "    arena_list = _require_attr(block, \"arena_videos\")\n",
    "    arena_path = _choose_arena_video(arena_list, arena_video)\n",
    "\n",
    "    # open caps\n",
    "    capR = _open_cap(rv, \"right_eye\")\n",
    "    capL = _open_cap(lv, \"left_eye\")\n",
    "    capA = _open_cap(arena_path, \"arena\")\n",
    "\n",
    "    Wr, Hr = int(capR.get(cv2.CAP_PROP_FRAME_WIDTH)), int(capR.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    Wl, Hl = int(capL.get(cv2.CAP_PROP_FRAME_WIDTH)), int(capL.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    Wa, Ha = int(capA.get(cv2.CAP_PROP_FRAME_WIDTH)), int(capA.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    dt_ms = 1000.0 / float(fps)\n",
    "    t_grid = np.arange(start_ms, end_ms + 0.5 * dt_ms, dt_ms, dtype=float)\n",
    "\n",
    "    # -------------------------- trace mapping --------------------------\n",
    "    default_map = {\n",
    "        \"pupil_diameter\": \"pupil_diameter\",\n",
    "        \"phi\": \"phi\",\n",
    "        \"theta\": \"k_theta\" if (\"k_theta\" in left_df.columns and \"k_theta\" in right_df.columns) else \"theta\",\n",
    "    }\n",
    "    if trace_col_map is None:\n",
    "        trace_col_map = default_map\n",
    "    else:\n",
    "        tmp = default_map.copy()\n",
    "        tmp.update(trace_col_map)\n",
    "        trace_col_map = tmp\n",
    "\n",
    "    # Precompute trace arrays on the export timebase\n",
    "    Lsig: Dict[str, np.ndarray] = {}\n",
    "    Rsig: Dict[str, np.ndarray] = {}\n",
    "    for sig in trace_signals:\n",
    "        col = trace_col_map.get(sig, sig)\n",
    "        if col not in left_df.columns or col not in right_df.columns:\n",
    "            Lsig[sig] = np.full_like(t_grid, np.nan, dtype=float)\n",
    "            Rsig[sig] = np.full_like(t_grid, np.nan, dtype=float)\n",
    "            continue\n",
    "\n",
    "        Lvals = np.full_like(t_grid, np.nan, dtype=float)\n",
    "        Rvals = np.full_like(t_grid, np.nan, dtype=float)\n",
    "        for i, t in enumerate(t_grid):\n",
    "            rL = _nearest_row_by_ms(left_df, t)\n",
    "            rR = _nearest_row_by_ms(right_df, t)\n",
    "            vL = rL.get(col, np.nan)\n",
    "            vR = rR.get(col, np.nan)\n",
    "            Lvals[i] = float(vL) if pd.notna(vL) else np.nan\n",
    "            Rvals[i] = float(vR) if pd.notna(vR) else np.nan\n",
    "        Lsig[sig] = Lvals\n",
    "        Rsig[sig] = Rvals\n",
    "\n",
    "    # -------------------------- output geometry --------------------------\n",
    "    if fit_eyes_to_arena_height:\n",
    "        Wr_out = max(1, int(round(Wr * (Ha / float(Hr)))))\n",
    "        Wl_out = max(1, int(round(Wl * (Ha / float(Hl)))))\n",
    "        Wa_out = Wa\n",
    "        Hrow = Ha\n",
    "    else:\n",
    "        Wr_out, Wl_out, Wa_out = Wr, Wl, Wa\n",
    "        Hrow = max(Hr, Hl, Ha)\n",
    "\n",
    "    Wtotal = Wr_out + Wa_out + Wl_out\n",
    "    Htotal = top_banner_h + Hrow + trace_h\n",
    "\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    writer = cv2.VideoWriter(\n",
    "        str(out_path),\n",
    "        cv2.VideoWriter_fourcc(*codec),\n",
    "        float(fps),\n",
    "        (Wtotal, Htotal),\n",
    "    )\n",
    "    if not writer.isOpened():\n",
    "        for cap in (capR, capL, capA):\n",
    "            cap.release()\n",
    "        raise RuntimeError(f\"Could not open VideoWriter for: {out_path} (codec='{codec}')\")\n",
    "\n",
    "    # banner (include eye_video_mode for provenance)\n",
    "    animal = getattr(block, \"animal_call\", None) or getattr(block, \"animal\", None) or \"\"\n",
    "    blk = getattr(block, \"block\", None) or getattr(block, \"block_num\", None) or \"\"\n",
    "    banner_lines = [\n",
    "        f\"Synchronized montage | {animal} {('B'+str(blk)) if str(blk) else ''}\".strip(),\n",
    "        f\"eye_video_mode={eye_video_mode} | Right: {rv.name} | Arena: {arena_path.name} | Left: {lv.name} | arena_shift={int(arena_frame_shift)}\",\n",
    "    ]\n",
    "    banner = _make_banner(Wtotal, banner_lines)\n",
    "\n",
    "    if show_debug_prints:\n",
    "        print(f\"[export] output={Wtotal}x{Htotal} @ {fps} fps | frames={len(t_grid)}\")\n",
    "        print(f\"[eyes] mode={eye_video_mode} | R={rv.name} | L={lv.name}\")\n",
    "        print(f\"[arena] {arena_path.name} | arena_frame_shift={int(arena_frame_shift)}\")\n",
    "\n",
    "    # last-good frames for duplication on read failure\n",
    "    prev_R = np.zeros((Hr, Wr, 3), dtype=np.uint8)\n",
    "    prev_L = np.zeros((Hl, Wl, 3), dtype=np.uint8)\n",
    "    prev_A = np.zeros((Ha, Wa, 3), dtype=np.uint8)\n",
    "\n",
    "    try:\n",
    "        for t_ms in tqdm(t_grid, desc=\"Exporting montage\", unit=\"frame\", dynamic_ncols=True):\n",
    "            # nearest eye rows â†’ eye frames\n",
    "            rR = _nearest_row_by_ms(right_df, t_ms)\n",
    "            rL = _nearest_row_by_ms(left_df, t_ms)\n",
    "            idxR = int(rR[\"eye_frame\"]) if pd.notna(rR[\"eye_frame\"]) else None\n",
    "            idxL = int(rL[\"eye_frame\"]) if pd.notna(rL[\"eye_frame\"]) else None\n",
    "\n",
    "            # arena frame index\n",
    "            if use_final_sync_df:\n",
    "                rA = _nearest_row_by_ms(fs, t_ms)\n",
    "                vA = rA.get(arena_fcol, pd.NA)\n",
    "                idxA = int(vA) if pd.notna(vA) else None\n",
    "            else:\n",
    "                fpsA = capA.get(cv2.CAP_PROP_FPS) or fps\n",
    "                idxA = int(round((t_ms - start_ms) / 1000.0 * float(fpsA)))\n",
    "\n",
    "            # manual patch\n",
    "            if idxA is not None:\n",
    "                idxA = int(idxA) + int(arena_frame_shift)\n",
    "\n",
    "            # clamp\n",
    "            idxR = _clamp_idx(idxR, capR)\n",
    "            idxL = _clamp_idx(idxL, capL)\n",
    "            idxA = _clamp_idx(idxA, capA)\n",
    "\n",
    "            # read with fallback (duplicate previous if missing)\n",
    "            missingR = missingL = missingA = False\n",
    "\n",
    "            fR = _read_frame_at(capR, idxR) if idxR is not None else None\n",
    "            if fR is None:\n",
    "                fR = prev_R.copy()\n",
    "                missingR = True\n",
    "            else:\n",
    "                prev_R = fR.copy()\n",
    "\n",
    "            fL = _read_frame_at(capL, idxL) if idxL is not None else None\n",
    "            if fL is None:\n",
    "                fL = prev_L.copy()\n",
    "                missingL = True\n",
    "            else:\n",
    "                prev_L = fL.copy()\n",
    "\n",
    "            fA = _read_frame_at(capA, idxA) if idxA is not None else None\n",
    "            if fA is None:\n",
    "                fA = prev_A.copy()\n",
    "                missingA = True\n",
    "            else:\n",
    "                prev_A = fA.copy()\n",
    "\n",
    "            # flips\n",
    "            if flip_eyes_vertical:\n",
    "                fR = cv2.flip(fR, 0)\n",
    "                fL = cv2.flip(fL, 0)\n",
    "\n",
    "            # disqualified flags (show but keep frames)\n",
    "            disqR = any((c in right_df.columns and pd.isna(rR.get(c, np.nan))) for c in disqualify_cols)\n",
    "            disqL = any((c in left_df.columns and pd.isna(rL.get(c, np.nan))) for c in disqualify_cols)\n",
    "\n",
    "            # overlays\n",
    "            _safe_put_text(fR, \"RIGHT\", (12, 24), (255, 255, 255), scale=0.75, thickness=2)\n",
    "            _safe_put_text(fA, \"ARENA\", (12, 24), (255, 255, 255), scale=0.75, thickness=2)\n",
    "            _safe_put_text(fL, \"LEFT\",  (12, 24), (255, 255, 255), scale=0.75, thickness=2)\n",
    "\n",
    "            if show_disqualified_badge and disqR:\n",
    "                _safe_put_text(fR, \"disqualified\", (max(10, fR.shape[1] - 170), 24), (0, 0, 255), scale=0.65, thickness=2)\n",
    "            if show_disqualified_badge and disqL:\n",
    "                _safe_put_text(fL, \"disqualified\", (max(10, fL.shape[1] - 170), 24), (0, 0, 255), scale=0.65, thickness=2)\n",
    "\n",
    "            if missingR:\n",
    "                _safe_put_text(fR, \"missing frame\", (12, fR.shape[0] - 12), (255, 0, 0), scale=0.6, thickness=2)\n",
    "            if missingL:\n",
    "                _safe_put_text(fL, \"missing frame\", (12, fL.shape[0] - 12), (255, 0, 0), scale=0.6, thickness=2)\n",
    "            if missingA:\n",
    "                _safe_put_text(fA, \"missing frame\", (12, fA.shape[0] - 12), (255, 0, 0), scale=0.6, thickness=2)\n",
    "\n",
    "            # timestamp below arena (inside arena image bottom center)\n",
    "            ts_str = f\"{t_ms:.{timestamp_precision_ms}f} ms\"\n",
    "            ts_sz, _ = cv2.getTextSize(ts_str, cv2.FONT_HERSHEY_SIMPLEX, 0.85, 2)\n",
    "            tx = max(12, (fA.shape[1] - ts_sz[0]) // 2)\n",
    "            ty = max(28, fA.shape[0] - 12)\n",
    "            _safe_put_text(fA, ts_str, (tx, ty), (255, 255, 255), scale=0.85, thickness=2)\n",
    "\n",
    "            # resize/pad into row\n",
    "            if fit_eyes_to_arena_height:\n",
    "                fR = _resize_to_height(fR, Ha)\n",
    "                fL = _resize_to_height(fL, Ha)\n",
    "                # arena stays native height Ha\n",
    "            else:\n",
    "                def _pad(img: np.ndarray, H: int) -> np.ndarray:\n",
    "                    h, w = img.shape[:2]\n",
    "                    if h == H:\n",
    "                        return img\n",
    "                    return cv2.copyMakeBorder(img, 0, max(0, H - h), 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "\n",
    "                fR = _pad(fR, Hrow)\n",
    "                fA = _pad(fA, Hrow)\n",
    "                fL = _pad(fL, Hrow)\n",
    "\n",
    "            row_img = np.concatenate([fR, fA, fL], axis=1)\n",
    "\n",
    "            trace = _draw_trace_panel(\n",
    "                W=Wtotal,\n",
    "                t_ms=t_ms,\n",
    "                t_grid=t_grid,\n",
    "                Lsig=Lsig,\n",
    "                Rsig=Rsig,\n",
    "                t0=start_ms,\n",
    "                t1=end_ms,\n",
    "            )\n",
    "\n",
    "            frame = np.zeros((Htotal, Wtotal, 3), dtype=np.uint8)\n",
    "            frame[0:top_banner_h, :, :] = banner\n",
    "            frame[top_banner_h:top_banner_h + Hrow, :, :] = row_img\n",
    "            frame[top_banner_h + Hrow:top_banner_h + Hrow + trace_h, :, :] = trace\n",
    "\n",
    "            writer.write(frame)\n",
    "\n",
    "        return out_path\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            writer.release()\n",
    "        except Exception:\n",
    "            pass\n",
    "        for cap in (capR, capL, capA):\n",
    "            try:\n",
    "                cap.release()\n",
    "            except Exception:\n",
    "                pass\n"
   ],
   "id": "da3a6f1e6158916",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T13:08:29.718343Z",
     "start_time": "2025-12-22T12:58:02.274588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "export_block_synchronized_montage_video_v3(\n",
    "    block, 240_000, 300_000,\n",
    "    out_path = str(block.analysis_path / '240_300_montage_raw_synced.mp4'),\n",
    "    eye_video_mode=\"raw\",\n",
    "    arena_video=\"top\",\n",
    "    arena_frame_shift=-3,\n",
    "    fps=60\n",
    ")\n"
   ],
   "id": "4a7414b87a2f4c71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting montage:   0%|          | 0/3601 [00:00<?, ?frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[export] output=2720x1360 @ 60 fps | frames=3601\n",
      "[eyes] mode=raw | R=wake3.mp4 | L=wake3_LE.mp4\n",
      "[arena] top_20240718T124930.mp4 | arena_frame_shift=-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-e3eff2c31886>:237: RuntimeWarning: invalid value encountered in cast\n",
      "  yL = (yy0 + (1.0 - np.clip(Ln, 0, 1)) * (Hax - 1)).astype(int)\n",
      "<ipython-input-31-e3eff2c31886>:238: RuntimeWarning: invalid value encountered in cast\n",
      "  yR = (yy0 + (1.0 - np.clip(Rn, 0, 1)) * (Hax - 1)).astype(int)\n",
      "Exporting montage: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3601/3601 [10:18<00:00,  5.83frame/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('Z:/Nimrod/experiments/PV_126/2024_07_18/block_007/analysis/240_300_montage_raw_synced.mp4')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:25:07.771897Z",
     "start_time": "2025-12-18T12:25:07.701869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# export synchronized video montage:\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional, Sequence, Dict, Any, Tuple, Union\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def export_block_synchronized_montage_video_v2(\n",
    "    block: object,\n",
    "    start_ms: float,\n",
    "    end_ms: float,\n",
    "    out_path: os.PathLike | str,\n",
    "    *,\n",
    "    fps: float = 60.0,\n",
    "    use_final_sync_df: bool = True,\n",
    "\n",
    "    # --- NEW: manual band-aid sync patch ---\n",
    "    arena_frame_shift: int = 0,  # + shifts arena later (uses later frames); - shifts earlier\n",
    "\n",
    "    # Arena selection\n",
    "    arena_video: Optional[Union[int, str]] = None,  # None => prompt; int => index; str => substring match\n",
    "    arena_frame_cols: Sequence[str] = (\n",
    "        \"Arena_frame\", \"arena_frame\", \"arena_frames\", \"arena_frame_idx\",\n",
    "        \"frame\", \"frame_idx\", \"video_frame\", \"arena_idx\"\n",
    "    ),\n",
    "\n",
    "    # Eye video selection/transform\n",
    "    prefer_dlc_eye_videos: bool = True,\n",
    "    flip_eyes_vertical: bool = True,\n",
    "\n",
    "    # Layout sizing\n",
    "    top_banner_h: int = 60,\n",
    "    trace_h: int = 220,\n",
    "    fit_eyes_to_arena_height: bool = False,  # scales eye panels to arena height, preserve aspect ratio\n",
    "\n",
    "    # Trace controls\n",
    "    trace_window_ms: Optional[float] = None,   # None = full clip, else rolling window\n",
    "    normalize_traces: bool = False,            # default OFF (native units)\n",
    "    robust_ylim_percentiles: Tuple[float, float] = (5.0, 95.0),\n",
    "    trace_signals: Sequence[str] = (\"pupil_diameter\", \"phi\", \"theta\"),\n",
    "    trace_col_map: Optional[Dict[str, str]] = None,  # mapping display->df column\n",
    "\n",
    "    # Disqualification logic + missing frames\n",
    "    disqualify_cols: Sequence[str] = (\"center_x\", \"center_y\"),\n",
    "    show_disqualified_badge: bool = True,\n",
    "\n",
    "    timestamp_precision_ms: int = 0,\n",
    "    codec: str = \"mp4v\",\n",
    "    show_debug_prints: bool = True,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Export a synchronized montage video:\n",
    "\n",
    "      [Right eye | Arena | Left eye]\n",
    "      + top banner (text)\n",
    "      + bottom trace panel with pupil diameter + phi/theta (cursor at current t)\n",
    "\n",
    "    Manual sync patch:\n",
    "      - arena_frame_shift: constant integer offset applied to arena frame indices\n",
    "        before reading frames from the arena video file.\n",
    "\n",
    "        If LED appears EARLIER in arena vs eyes, you usually want arena_frame_shift=+N\n",
    "        (use later arena frames so the blink occurs later in arena).\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------- helpers --------------------------\n",
    "    def _require_attr(obj: object, name: str):\n",
    "        if not hasattr(obj, name):\n",
    "            raise AttributeError(f\"block is missing required attribute '{name}'\")\n",
    "        return getattr(obj, name)\n",
    "\n",
    "    def _require_cols(df: pd.DataFrame, cols: Sequence[str], df_name: str):\n",
    "        missing = [c for c in cols if c not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"{df_name} is missing required columns: {missing}\")\n",
    "\n",
    "    def _pick_first_video(paths: Any, name: str) -> Path:\n",
    "        if paths is None:\n",
    "            raise ValueError(f\"block.{name} is None\")\n",
    "        if isinstance(paths, (str, os.PathLike)):\n",
    "            p = Path(paths)\n",
    "            if not p.exists():\n",
    "                raise FileNotFoundError(f\"Video not found: {p}\")\n",
    "            return p\n",
    "        if isinstance(paths, (list, tuple)) and len(paths) > 0:\n",
    "            p = Path(paths[0])\n",
    "            if not p.exists():\n",
    "                raise FileNotFoundError(f\"Video not found: {p}\")\n",
    "            return p\n",
    "        raise ValueError(f\"block.{name} has no usable video path(s)\")\n",
    "\n",
    "    def _find_dlc_variant(original: Path) -> Optional[Path]:\n",
    "        \"\"\"Heuristic: same folder, *.mp4 with 'DLC' in name; prefer those containing original stem.\"\"\"\n",
    "        try:\n",
    "            folder = original.parent\n",
    "            if not folder.exists():\n",
    "                return None\n",
    "            cand = [p for p in folder.glob(\"*.mp4\") if \"dlc\" in p.name.lower()]\n",
    "            if not cand:\n",
    "                return None\n",
    "            stem = original.stem.lower()\n",
    "            cand2 = [p for p in cand if stem in p.stem.lower()]\n",
    "            best = cand2[0] if cand2 else cand[0]\n",
    "            return best if best.exists() else None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def _open_cap(p: Path, label: str) -> cv2.VideoCapture:\n",
    "        cap = cv2.VideoCapture(str(p))\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(f\"Cannot open {label} video: {p}\")\n",
    "        return cap\n",
    "\n",
    "    def _nearest_row_by_ms(df: pd.DataFrame, ms: float) -> pd.Series:\n",
    "        arr = df[\"ms_axis\"].to_numpy(dtype=float)\n",
    "        if arr.size == 0:\n",
    "            raise ValueError(\"ms_axis array is empty.\")\n",
    "        idx = int(np.nanargmin(np.abs(arr - float(ms))))\n",
    "        return df.iloc[idx]\n",
    "\n",
    "    def _resolve_arena_frame_col(fs: pd.DataFrame) -> str:\n",
    "        for c in arena_frame_cols:\n",
    "            if c in fs.columns:\n",
    "                return c\n",
    "        raise ValueError(\n",
    "            f\"final_sync_df has no recognizable arena frame column. Tried: {list(arena_frame_cols)}\"\n",
    "        )\n",
    "\n",
    "    def _safe_put_text(img, text, org, color, scale=0.6, thickness=2):\n",
    "        x, y = org\n",
    "        cv2.putText(img, text, (x + 1, y + 1), cv2.FONT_HERSHEY_SIMPLEX, scale, (0, 0, 0),\n",
    "                    thickness + 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "    def _read_frame_at(cap: cv2.VideoCapture, frame_idx: int) -> Optional[np.ndarray]:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_idx))\n",
    "        ok, frame = cap.read()\n",
    "        return frame if ok else None\n",
    "\n",
    "    def _make_banner(W: int, lines: Sequence[str]) -> np.ndarray:\n",
    "        banner = np.zeros((top_banner_h, W, 3), dtype=np.uint8)\n",
    "        y = 24\n",
    "        for ln in lines:\n",
    "            _safe_put_text(banner, ln, (12, y), (255, 255, 255), scale=0.7, thickness=2)\n",
    "            y += 24\n",
    "            if y > top_banner_h - 8:\n",
    "                break\n",
    "        return banner\n",
    "\n",
    "    def _choose_arena_video(arena_list: Sequence[str], choice: Optional[Union[int, str]]) -> Path:\n",
    "        paths = [Path(p) for p in arena_list]\n",
    "        if not paths:\n",
    "            raise ValueError(\"block.arena_videos is empty.\")\n",
    "\n",
    "        if isinstance(choice, int):\n",
    "            idx = int(choice)\n",
    "            if idx < 0 or idx >= len(paths):\n",
    "                raise ValueError(f\"arena_video index {idx} out of range (0..{len(paths)-1})\")\n",
    "            return paths[idx]\n",
    "\n",
    "        if isinstance(choice, str) and choice.strip():\n",
    "            key = choice.strip().lower()\n",
    "            hits = [p for p in paths if key in p.name.lower()]\n",
    "            if len(hits) == 1:\n",
    "                return hits[0]\n",
    "            if len(hits) > 1:\n",
    "                hits.sort(key=lambda p: len(p.name))\n",
    "                return hits[0]\n",
    "            raise ValueError(f\"arena_video='{choice}' did not match any arena video name.\")\n",
    "\n",
    "        print(\"\\nSelect arena video:\")\n",
    "        for i, p in enumerate(paths):\n",
    "            print(f\"  [{i}] {p.name}\")\n",
    "        try:\n",
    "            raw = input(\"Enter arena index (default 0): \").strip()\n",
    "        except Exception:\n",
    "            raw = \"\"\n",
    "        idx = 0 if raw == \"\" else int(raw)\n",
    "        if idx < 0 or idx >= len(paths):\n",
    "            raise ValueError(f\"arena index {idx} out of range.\")\n",
    "        return paths[idx]\n",
    "\n",
    "    def _resize_to_height(img: np.ndarray, target_h: int) -> np.ndarray:\n",
    "        h, w = img.shape[:2]\n",
    "        if h == target_h:\n",
    "            return img\n",
    "        new_w = max(1, int(round(w * (target_h / float(h)))))\n",
    "        return cv2.resize(img, (new_w, target_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def _robust_limits(x: np.ndarray, p_lo: float, p_hi: float) -> Tuple[float, float]:\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        x = x[np.isfinite(x)]\n",
    "        if x.size < 2:\n",
    "            return (-1.0, 1.0)\n",
    "        lo = np.percentile(x, p_lo)\n",
    "        hi = np.percentile(x, p_hi)\n",
    "        if not np.isfinite(lo) or not np.isfinite(hi) or abs(hi - lo) < 1e-12:\n",
    "            lo, hi = float(np.min(x)), float(np.max(x))\n",
    "        if abs(hi - lo) < 1e-12:\n",
    "            lo -= 1.0\n",
    "            hi += 1.0\n",
    "        return float(lo), float(hi)\n",
    "\n",
    "    def _map_to_axis(vals: np.ndarray, lo: float, hi: float) -> np.ndarray:\n",
    "        return (vals - lo) / (hi - lo + 1e-12)\n",
    "\n",
    "    def _draw_trace_panel(\n",
    "        W: int,\n",
    "        t_ms: float,\n",
    "        t_grid: np.ndarray,\n",
    "        Lsig: Dict[str, np.ndarray],\n",
    "        Rsig: Dict[str, np.ndarray],\n",
    "        t0: float,\n",
    "        t1: float,\n",
    "    ) -> np.ndarray:\n",
    "        panel = np.zeros((trace_h, W, 3), dtype=np.uint8)\n",
    "\n",
    "        if trace_window_ms is None:\n",
    "            w0, w1 = t0, t1\n",
    "        else:\n",
    "            half = float(trace_window_ms) / 2.0\n",
    "            w0, w1 = max(t0, t_ms - half), min(t1, t_ms + half)\n",
    "            if w1 <= w0:\n",
    "                w0, w1 = t0, t1\n",
    "\n",
    "        idx = np.where((t_grid >= w0) & (t_grid <= w1))[0]\n",
    "        if idx.size < 2:\n",
    "            return panel\n",
    "\n",
    "        tg = t_grid[idx]\n",
    "        x = (tg - w0) / (w1 - w0 + 1e-12)\n",
    "        xpix = (x * (W - 1)).astype(int)\n",
    "\n",
    "        n_axes = len(trace_signals)\n",
    "        pad_y = 10\n",
    "        axis_h = max(40, (trace_h - 2 * pad_y) // max(1, n_axes))\n",
    "        axes = []\n",
    "        for j, name in enumerate(trace_signals):\n",
    "            y0 = pad_y + j * axis_h\n",
    "            y1 = min(trace_h - pad_y, y0 + axis_h) - 8\n",
    "            axes.append((name, y0, y1))\n",
    "\n",
    "        cursor_x = int(round((np.clip(t_ms, w0, w1) - w0) / (w1 - w0 + 1e-12) * (W - 1)))\n",
    "        cv2.line(panel, (cursor_x, 0), (cursor_x, trace_h - 1), (120, 120, 120), 1)\n",
    "\n",
    "        _safe_put_text(panel, f\"t = {t_ms:.{timestamp_precision_ms}f} ms\", (12, 22),\n",
    "                       (255, 255, 255), scale=0.65, thickness=2)\n",
    "\n",
    "        color_L = (80, 220, 80)    # green\n",
    "        color_R = (220, 220, 80)   # yellow\n",
    "\n",
    "        for name, y0, y1 in axes:\n",
    "            cv2.rectangle(panel, (0, y0), (W - 1, y1), (20, 20, 20), 1)\n",
    "\n",
    "            L = Lsig.get(name, None)\n",
    "            R = Rsig.get(name, None)\n",
    "            if L is None or R is None:\n",
    "                continue\n",
    "\n",
    "            Lw = L[idx].astype(float)\n",
    "            Rw = R[idx].astype(float)\n",
    "\n",
    "            yy0, yy1 = int(y0 + 18), int(y1 - 8)\n",
    "            Hax = max(2, yy1 - yy0)\n",
    "\n",
    "            if normalize_traces:\n",
    "                Llo, Lhi = np.nanmin(Lw), np.nanmax(Lw)\n",
    "                Rlo, Rhi = np.nanmin(Rw), np.nanmax(Rw)\n",
    "                if not np.isfinite(Llo) or not np.isfinite(Lhi) or abs(Lhi - Llo) < 1e-12:\n",
    "                    Ln = np.full_like(Lw, 0.5)\n",
    "                else:\n",
    "                    Ln = _map_to_axis(Lw, Llo, Lhi)\n",
    "                if not np.isfinite(Rlo) or not np.isfinite(Rhi) or abs(Rhi - Rlo) < 1e-12:\n",
    "                    Rn = np.full_like(Rw, 0.5)\n",
    "                else:\n",
    "                    Rn = _map_to_axis(Rw, Rlo, Rhi)\n",
    "                label = f\"{name} (norm)\"\n",
    "            else:\n",
    "                p_lo, p_hi = robust_ylim_percentiles\n",
    "                lo, hi = _robust_limits(np.concatenate([Lw, Rw]), p_lo, p_hi)\n",
    "                Ln = _map_to_axis(Lw, lo, hi)\n",
    "                Rn = _map_to_axis(Rw, lo, hi)\n",
    "                label = f\"{name} [{lo:.2f},{hi:.2f}]\"\n",
    "\n",
    "            yL = (yy0 + (1.0 - np.clip(Ln, 0, 1)) * (Hax - 1)).astype(int)\n",
    "            yR = (yy0 + (1.0 - np.clip(Rn, 0, 1)) * (Hax - 1)).astype(int)\n",
    "\n",
    "            for k in range(1, len(xpix)):\n",
    "                if np.isfinite(yL[k - 1]) and np.isfinite(yL[k]):\n",
    "                    cv2.line(panel, (xpix[k - 1], yL[k - 1]), (xpix[k], yL[k]), color_L, 1, cv2.LINE_AA)\n",
    "                if np.isfinite(yR[k - 1]) and np.isfinite(yR[k]):\n",
    "                    cv2.line(panel, (xpix[k - 1], yR[k - 1]), (xpix[k], yR[k]), color_R, 1, cv2.LINE_AA)\n",
    "\n",
    "            _safe_put_text(panel, label, (12, y0 + 16), (200, 200, 200), scale=0.55, thickness=1)\n",
    "            _safe_put_text(panel, \"L\", (W - 60, y0 + 16), color_L, scale=0.55, thickness=1)\n",
    "            _safe_put_text(panel, \"R\", (W - 35, y0 + 16), color_R, scale=0.55, thickness=1)\n",
    "\n",
    "        return panel\n",
    "\n",
    "    def _clamp_idx(idx: Optional[int], cap: cv2.VideoCapture) -> Optional[int]:\n",
    "        if idx is None:\n",
    "            return None\n",
    "        n = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "        if n > 0:\n",
    "            return int(np.clip(int(idx), 0, n - 1))\n",
    "        return max(0, int(idx))\n",
    "\n",
    "    # -------------------------- validation --------------------------\n",
    "    start_ms = float(start_ms)\n",
    "    end_ms = float(end_ms)\n",
    "    if end_ms <= start_ms:\n",
    "        raise ValueError(f\"end_ms must be > start_ms (got start_ms={start_ms}, end_ms={end_ms})\")\n",
    "\n",
    "    left_df: pd.DataFrame = _require_attr(block, \"left_eye_data\")\n",
    "    right_df: pd.DataFrame = _require_attr(block, \"right_eye_data\")\n",
    "    _require_cols(left_df, [\"ms_axis\", \"eye_frame\"], \"left_eye_data\")\n",
    "    _require_cols(right_df, [\"ms_axis\", \"eye_frame\"], \"right_eye_data\")\n",
    "\n",
    "    fs = None\n",
    "    arena_fcol = None\n",
    "    if use_final_sync_df:\n",
    "        fs = _require_attr(block, \"final_sync_df\")\n",
    "        if not isinstance(fs, pd.DataFrame):\n",
    "            raise ValueError(\"block.final_sync_df is not a pandas DataFrame.\")\n",
    "        _require_cols(fs, [\"ms_axis\"], \"final_sync_df\")\n",
    "        arena_fcol = _resolve_arena_frame_col(fs)\n",
    "\n",
    "    rv = _pick_first_video(_require_attr(block, \"re_videos\"), \"re_videos\")\n",
    "    lv = _pick_first_video(_require_attr(block, \"le_videos\"), \"le_videos\")\n",
    "\n",
    "    if prefer_dlc_eye_videos:\n",
    "        rv_dlc = _find_dlc_variant(rv)\n",
    "        lv_dlc = _find_dlc_variant(lv)\n",
    "        if rv_dlc is not None:\n",
    "            if show_debug_prints:\n",
    "                print(f\"[video] Using RIGHT DLC: {rv_dlc.name}\")\n",
    "            rv = rv_dlc\n",
    "        if lv_dlc is not None:\n",
    "            if show_debug_prints:\n",
    "                print(f\"[video] Using LEFT DLC:  {lv_dlc.name}\")\n",
    "            lv = lv_dlc\n",
    "\n",
    "    arena_list = _require_attr(block, \"arena_videos\")\n",
    "    arena_path = _choose_arena_video(arena_list, arena_video)\n",
    "\n",
    "    capR = _open_cap(rv, \"right_eye\")\n",
    "    capL = _open_cap(lv, \"left_eye\")\n",
    "    capA = _open_cap(arena_path, \"arena\")\n",
    "\n",
    "    Wr, Hr = int(capR.get(cv2.CAP_PROP_FRAME_WIDTH)), int(capR.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    Wl, Hl = int(capL.get(cv2.CAP_PROP_FRAME_WIDTH)), int(capL.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    Wa, Ha = int(capA.get(cv2.CAP_PROP_FRAME_WIDTH)), int(capA.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    dt_ms = 1000.0 / float(fps)\n",
    "    t_grid = np.arange(start_ms, end_ms + 0.5 * dt_ms, dt_ms, dtype=float)\n",
    "\n",
    "    # -------------------------- trace column mapping --------------------------\n",
    "    default_map = {\n",
    "        \"pupil_diameter\": \"pupil_diameter\",\n",
    "        \"phi\": \"phi\",\n",
    "        \"theta\": \"k_theta\" if (\"k_theta\" in left_df.columns and \"k_theta\" in right_df.columns) else \"theta\",\n",
    "    }\n",
    "    if trace_col_map is None:\n",
    "        trace_col_map = default_map\n",
    "    else:\n",
    "        tmp = default_map.copy()\n",
    "        tmp.update(trace_col_map)\n",
    "        trace_col_map = tmp\n",
    "\n",
    "    # Precompute trace signals sampled on the same output timebase\n",
    "    Lsig: Dict[str, np.ndarray] = {}\n",
    "    Rsig: Dict[str, np.ndarray] = {}\n",
    "    for sig in trace_signals:\n",
    "        col = trace_col_map.get(sig, sig)\n",
    "        if col not in left_df.columns or col not in right_df.columns:\n",
    "            if show_debug_prints:\n",
    "                print(f\"[warn] Trace '{sig}' requested but column '{col}' not found in both eyes; trace will be blank.\")\n",
    "            Lsig[sig] = np.full_like(t_grid, np.nan, dtype=float)\n",
    "            Rsig[sig] = np.full_like(t_grid, np.nan, dtype=float)\n",
    "            continue\n",
    "\n",
    "        Lvals = np.full_like(t_grid, np.nan, dtype=float)\n",
    "        Rvals = np.full_like(t_grid, np.nan, dtype=float)\n",
    "        for i, t in enumerate(t_grid):\n",
    "            rL = _nearest_row_by_ms(left_df, t)\n",
    "            rR = _nearest_row_by_ms(right_df, t)\n",
    "            vL = rL.get(col, np.nan)\n",
    "            vR = rR.get(col, np.nan)\n",
    "            Lvals[i] = float(vL) if pd.notna(vL) else np.nan\n",
    "            Rvals[i] = float(vR) if pd.notna(vR) else np.nan\n",
    "        Lsig[sig] = Lvals\n",
    "        Rsig[sig] = Rvals\n",
    "\n",
    "    # -------------------------- output geometry --------------------------\n",
    "    if fit_eyes_to_arena_height:\n",
    "        Wr_out = max(1, int(round(Wr * (Ha / float(Hr)))))\n",
    "        Wl_out = max(1, int(round(Wl * (Ha / float(Hl)))))\n",
    "        Wa_out, Ha_out = Wa, Ha\n",
    "        Hrow = Ha\n",
    "    else:\n",
    "        Wr_out, Wl_out, Wa_out = Wr, Wl, Wa\n",
    "        Ha_out = Ha\n",
    "        Hrow = max(Hr, Hl, Ha)\n",
    "\n",
    "    Wtotal = Wr_out + Wa_out + Wl_out\n",
    "    Htotal = top_banner_h + Hrow + trace_h\n",
    "\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "    writer = cv2.VideoWriter(str(out_path), fourcc, float(fps), (Wtotal, Htotal))\n",
    "    if not writer.isOpened():\n",
    "        capR.release(); capL.release(); capA.release()\n",
    "        raise RuntimeError(f\"Could not open VideoWriter for: {out_path} (codec='{codec}')\")\n",
    "\n",
    "    animal = getattr(block, \"animal_call\", None) or getattr(block, \"animal\", None) or \"\"\n",
    "    blk = getattr(block, \"block\", None) or getattr(block, \"block_num\", None) or \"\"\n",
    "    banner_lines = [\n",
    "        f\"Synchronized montage | {animal} {('B'+str(blk)) if str(blk) else ''}\".strip(),\n",
    "        f\"Right: {rv.name} | Arena: {arena_path.name} | Left: {lv.name} | arena_frame_shift={int(arena_frame_shift)}\",\n",
    "    ]\n",
    "    banner = _make_banner(Wtotal, banner_lines)\n",
    "\n",
    "    if show_debug_prints:\n",
    "        print(f\"[export] frames={len(t_grid)} | fps={fps} | dt_ms={dt_ms:.3f}\")\n",
    "        print(f\"[export] output={Wtotal}x{Htotal} | rowH={Hrow} | fit_eyes_to_arena_height={fit_eyes_to_arena_height}\")\n",
    "        if use_final_sync_df:\n",
    "            print(f\"[arena] final_sync_df arena frame col='{arena_fcol}'\")\n",
    "        print(f\"[arena] arena_frame_shift={int(arena_frame_shift)}\")\n",
    "\n",
    "    prev_R = np.zeros((Hr, Wr, 3), dtype=np.uint8)\n",
    "    prev_L = np.zeros((Hl, Wl, 3), dtype=np.uint8)\n",
    "    prev_A = np.zeros((Ha, Wa, 3), dtype=np.uint8)\n",
    "\n",
    "    # -------------------------- main loop --------------------------\n",
    "    try:\n",
    "        for t_ms in tqdm(\n",
    "            t_grid,\n",
    "            desc=\"Exporting montage\",\n",
    "            unit=\"frame\",\n",
    "            total=len(t_grid),\n",
    "            dynamic_ncols=True,\n",
    "            smoothing=0.1,\n",
    "        ):\n",
    "            rR = _nearest_row_by_ms(right_df, t_ms)\n",
    "            rL = _nearest_row_by_ms(left_df, t_ms)\n",
    "\n",
    "            idxR = int(rR[\"eye_frame\"]) if pd.notna(rR[\"eye_frame\"]) else None\n",
    "            idxL = int(rL[\"eye_frame\"]) if pd.notna(rL[\"eye_frame\"]) else None\n",
    "\n",
    "            if use_final_sync_df:\n",
    "                rA = _nearest_row_by_ms(fs, t_ms)\n",
    "                vA = rA.get(arena_fcol, pd.NA)\n",
    "                idxA = int(vA) if pd.notna(vA) else None\n",
    "            else:\n",
    "                fpsA = capA.get(cv2.CAP_PROP_FPS) or fps\n",
    "                idxA = int(round((t_ms - start_ms) / 1000.0 * float(fpsA)))\n",
    "\n",
    "            # --- NEW: apply manual arena shift ---\n",
    "            if idxA is not None:\n",
    "                idxA = int(idxA) + int(arena_frame_shift)\n",
    "\n",
    "            # clamp indices so we don't seek negative / beyond end\n",
    "            idxR = _clamp_idx(idxR, capR)\n",
    "            idxL = _clamp_idx(idxL, capL)\n",
    "            idxA = _clamp_idx(idxA, capA)\n",
    "\n",
    "            missingR = missingL = missingA = False\n",
    "\n",
    "            fR = _read_frame_at(capR, idxR) if idxR is not None else None\n",
    "            if fR is None:\n",
    "                fR = prev_R.copy()\n",
    "                missingR = True\n",
    "            else:\n",
    "                prev_R = fR.copy()\n",
    "\n",
    "            fL = _read_frame_at(capL, idxL) if idxL is not None else None\n",
    "            if fL is None:\n",
    "                fL = prev_L.copy()\n",
    "                missingL = True\n",
    "            else:\n",
    "                prev_L = fL.copy()\n",
    "\n",
    "            fA = _read_frame_at(capA, idxA) if idxA is not None else None\n",
    "            if fA is None:\n",
    "                fA = prev_A.copy()\n",
    "                missingA = True\n",
    "            else:\n",
    "                prev_A = fA.copy()\n",
    "\n",
    "            if flip_eyes_vertical:\n",
    "                fR = cv2.flip(fR, 0)\n",
    "                fL = cv2.flip(fL, 0)\n",
    "\n",
    "            disqR = False\n",
    "            disqL = False\n",
    "            for c in disqualify_cols:\n",
    "                if c in right_df.columns and pd.isna(rR.get(c, np.nan)):\n",
    "                    disqR = True\n",
    "                if c in left_df.columns and pd.isna(rL.get(c, np.nan)):\n",
    "                    disqL = True\n",
    "\n",
    "            _safe_put_text(fR, \"RIGHT\", (12, 24), (255, 255, 255), scale=0.75, thickness=2)\n",
    "            _safe_put_text(fA, \"ARENA\", (12, 24), (255, 255, 255), scale=0.75, thickness=2)\n",
    "            _safe_put_text(fL, \"LEFT\",  (12, 24), (255, 255, 255), scale=0.75, thickness=2)\n",
    "\n",
    "            if show_disqualified_badge and disqR:\n",
    "                _safe_put_text(fR, \"disqualified\", (max(10, fR.shape[1] - 170), 24), (0, 0, 255), scale=0.65, thickness=2)\n",
    "            if show_disqualified_badge and disqL:\n",
    "                _safe_put_text(fL, \"disqualified\", (max(10, fL.shape[1] - 170), 24), (0, 0, 255), scale=0.65, thickness=2)\n",
    "\n",
    "            if missingR:\n",
    "                _safe_put_text(fR, \"missing frame\", (12, fR.shape[0] - 12), (255, 0, 0), scale=0.6, thickness=2)\n",
    "            if missingL:\n",
    "                _safe_put_text(fL, \"missing frame\", (12, fL.shape[0] - 12), (255, 0, 0), scale=0.6, thickness=2)\n",
    "            if missingA:\n",
    "                _safe_put_text(fA, \"missing frame\", (12, fA.shape[0] - 12), (255, 0, 0), scale=0.6, thickness=2)\n",
    "\n",
    "            ts_str = f\"{t_ms:.{timestamp_precision_ms}f} ms\"\n",
    "            ts_sz, _ = cv2.getTextSize(ts_str, cv2.FONT_HERSHEY_SIMPLEX, 0.85, 2)\n",
    "            tx = max(12, (fA.shape[1] - ts_sz[0]) // 2)\n",
    "            ty = max(28, fA.shape[0] - 12)\n",
    "            _safe_put_text(fA, ts_str, (tx, ty), (255, 255, 255), scale=0.85, thickness=2)\n",
    "\n",
    "            if fit_eyes_to_arena_height:\n",
    "                fR = _resize_to_height(fR, Ha)\n",
    "                fL = _resize_to_height(fL, Ha)\n",
    "                # arena stays native (Ha)\n",
    "            else:\n",
    "                # pad to common row height\n",
    "                def _pad(img: np.ndarray, H: int) -> np.ndarray:\n",
    "                    h, w = img.shape[:2]\n",
    "                    if h == H:\n",
    "                        return img\n",
    "                    return cv2.copyMakeBorder(img, 0, max(0, H - h), 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "\n",
    "                fR = _pad(fR, Hrow)\n",
    "                fA = _pad(fA, Hrow)\n",
    "                fL = _pad(fL, Hrow)\n",
    "\n",
    "            row_img = np.concatenate([fR, fA, fL], axis=1)\n",
    "\n",
    "            trace = _draw_trace_panel(\n",
    "                W=Wtotal,\n",
    "                t_ms=t_ms,\n",
    "                t_grid=t_grid,\n",
    "                Lsig=Lsig,\n",
    "                Rsig=Rsig,\n",
    "                t0=start_ms,\n",
    "                t1=end_ms,\n",
    "            )\n",
    "\n",
    "            frame = np.zeros((Htotal, Wtotal, 3), dtype=np.uint8)\n",
    "            frame[0:top_banner_h, :, :] = banner\n",
    "            frame[top_banner_h:top_banner_h + Hrow, :, :] = row_img\n",
    "            frame[top_banner_h + Hrow:top_banner_h + Hrow + trace_h, :, :] = trace\n",
    "\n",
    "            writer.write(frame)\n",
    "\n",
    "        return out_path\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            writer.release()\n",
    "        except Exception:\n",
    "            pass\n",
    "        for cap in (capR, capL, capA):\n",
    "            try:\n",
    "                cap.release()\n",
    "            except Exception:\n",
    "                pass\n"
   ],
   "id": "17c15c12d3036c33",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:17:34.125823Z",
     "start_time": "2025-12-18T13:03:17.385699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "export_block_synchronized_montage_video_v2(\n",
    "    block=block,\n",
    "    start_ms=240_000, end_ms=320_000,out_path = str(block.analysis_path / '240_320_montage_synced.mp4'),\n",
    "    fps= 60.0,\n",
    "    # Arena selection\n",
    "    arena_video = 'top',\n",
    "    arena_frame_shift=-3)"
   ],
   "id": "2ad2e30911fa5857",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[video] Using RIGHT DLC: wake3DLC_resnet_50_Eye_Tracking_piplineMar1shuffle1_950000_labeled.mp4\n",
      "[video] Using LEFT DLC:  wake3_LEDLC_resnet_50_Eye_Tracking_piplineMar1shuffle1_950000_labeled_LE.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting montage:   0%|          | 0/4801 [00:00<?, ?frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[export] frames=4801 | fps=60.0 | dt_ms=16.667\n",
      "[export] output=2720x1360 | rowH=1080 | fit_eyes_to_arena_height=False\n",
      "[arena] final_sync_df arena frame col='Arena_frame'\n",
      "[arena] arena_frame_shift=-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-33202e265489>:291: RuntimeWarning: invalid value encountered in cast\n",
      "  yL = (yy0 + (1.0 - np.clip(Ln, 0, 1)) * (Hax - 1)).astype(int)\n",
      "<ipython-input-20-33202e265489>:292: RuntimeWarning: invalid value encountered in cast\n",
      "  yR = (yy0 + (1.0 - np.clip(Rn, 0, 1)) * (Hax - 1)).astype(int)\n",
      "Exporting montage: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4801/4801 [14:05<00:00,  5.68frame/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('Z:/Nimrod/experiments/PV_126/2024_07_18/block_007/analysis/240_320_montage_synced.mp4')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T11:17:42.748170Z",
     "start_time": "2025-12-19T11:17:42.727709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Literal, Optional\n",
    "\n",
    "\n",
    "def compress_video_verbose(\n",
    "    in_path: str | Path,\n",
    "    out_path: Optional[str | Path] = None,\n",
    "    *,\n",
    "    preset: Literal[\n",
    "        \"lossless\",\n",
    "        \"visually_lossless\",\n",
    "        \"publication\",\n",
    "        \"web\",\n",
    "        \"aggressive\",\n",
    "    ] = \"publication\",\n",
    "    overwrite: bool = False,\n",
    "    keep_audio: bool = True,\n",
    "    threads: int = 0,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    ffmpeg video compression with:\n",
    "      - clear readouts (input/output + settings)\n",
    "      - ffmpeg built-in progress (frame/fps/time/speed)\n",
    "      - (optional) overwrite behavior\n",
    "\n",
    "    Requires: ffmpeg in PATH.\n",
    "    \"\"\"\n",
    "\n",
    "    in_path = Path(in_path)\n",
    "    if not in_path.exists():\n",
    "        raise FileNotFoundError(in_path)\n",
    "\n",
    "    if out_path is None:\n",
    "        out_path = in_path.with_name(in_path.stem + f\"__{preset}.mp4\")\n",
    "    else:\n",
    "        out_path = Path(out_path)\n",
    "\n",
    "    if out_path.exists() and not overwrite:\n",
    "        raise FileExistsError(out_path)\n",
    "\n",
    "    # -------- preset config --------\n",
    "    if preset == \"lossless\":\n",
    "        codec, crf, enc_preset = \"libx264\", \"0\", \"veryslow\"\n",
    "    elif preset == \"visually_lossless\":\n",
    "        codec, crf, enc_preset = \"libx264\", \"16\", \"slow\"\n",
    "    elif preset == \"publication\":\n",
    "        codec, crf, enc_preset = \"libx264\", \"18\", \"slow\"\n",
    "    elif preset == \"web\":\n",
    "        codec, crf, enc_preset = \"libx264\", \"23\", \"medium\"\n",
    "    elif preset == \"aggressive\":\n",
    "        codec, crf, enc_preset = \"libx265\", \"28\", \"slow\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown preset: {preset}\")\n",
    "\n",
    "    print(\"\\n=== Video compression ===\")\n",
    "    print(f\"Input : {in_path}\")\n",
    "    print(f\"Output: {out_path}\")\n",
    "    print(f\"Preset: {preset} | codec={codec} | crf={crf} | preset={enc_preset}\")\n",
    "    print(f\"Audio : {'copy' if keep_audio else 'disabled'}\")\n",
    "    print(f\"Overwrite: {overwrite}\")\n",
    "    if threads > 0:\n",
    "        print(f\"Threads: {threads}\")\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-hide_banner\",\n",
    "        \"-nostdin\",\n",
    "        \"-stats\",                 # prints frame/fps/size/time/bitrate/speed\n",
    "        \"-i\", str(in_path),\n",
    "        \"-map\", \"0:v:0\",\n",
    "        \"-c:v\", codec,\n",
    "        \"-crf\", crf,\n",
    "        \"-preset\", enc_preset,\n",
    "    ]\n",
    "\n",
    "    if keep_audio:\n",
    "        cmd += [\"-map\", \"0:a?\", \"-c:a\", \"copy\"]\n",
    "    else:\n",
    "        cmd += [\"-an\"]\n",
    "\n",
    "    if threads > 0:\n",
    "        cmd += [\"-threads\", str(threads)]\n",
    "\n",
    "    cmd += [\"-y\" if overwrite else \"-n\", str(out_path)]\n",
    "\n",
    "    print(\"Running ffmpeg command:\")\n",
    "    print(\"  \" + \" \".join(cmd))\n",
    "    print(\"\\nProgress (ffmpeg):\")\n",
    "\n",
    "    # ffmpeg prints progress primarily to stderr; stream it live\n",
    "    proc = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "        bufsize=1,\n",
    "        universal_newlines=True,\n",
    "    )\n",
    "\n",
    "    # Stream stderr lines and keep only the changing \"stats\" line readable\n",
    "    last_stats = \"\"\n",
    "    try:\n",
    "        assert proc.stderr is not None\n",
    "        for line in proc.stderr:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            # ffmpeg -stats produces lines starting with \"frame=\"\n",
    "            if line.strip().startswith(\"frame=\"):\n",
    "                last_stats = line.strip()\n",
    "                print(\"\\r\" + last_stats + \" \" * 10, end=\"\", flush=True)\n",
    "            else:\n",
    "                # print non-stats messages on their own lines\n",
    "                if line.strip():\n",
    "                    print(\"\\n\" + line)\n",
    "        proc.wait()\n",
    "    finally:\n",
    "        print()  # newline after carriage-return progress\n",
    "\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(f\"ffmpeg failed with return code {proc.returncode}\")\n",
    "\n",
    "    # Final readout\n",
    "    in_size = in_path.stat().st_size\n",
    "    out_size = out_path.stat().st_size if out_path.exists() else None\n",
    "    if out_size is not None:\n",
    "        ratio = out_size / in_size if in_size else float(\"nan\")\n",
    "        print(\"\\nDone.\")\n",
    "        print(f\"Output written: {out_path}\")\n",
    "        print(f\"Size: {in_size/1e6:.1f} MB -> {out_size/1e6:.1f} MB  (ratio {ratio:.3f})\")\n",
    "    else:\n",
    "        print(\"\\nDone (but output file not found?).\")\n",
    "\n",
    "    return out_path\n"
   ],
   "id": "7cbeae7928a0c320",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T23:59:28.745961Z",
     "start_time": "2025-12-22T23:57:29.164056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "compress_video_verbose(\n",
    "    str(block.analysis_path / '240_300_montage_raw_synced.mp4'),\n",
    "    preset=\"publication\",\n",
    "    overwrite=False\n",
    ")\n"
   ],
   "id": "16d657e9be709c99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Video compression ===\n",
      "Input : Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\\240_300_montage_raw_synced.mp4\n",
      "Output: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\\240_300_montage_raw_synced__publication.mp4\n",
      "Preset: publication | codec=libx264 | crf=18 | preset=slow\n",
      "Audio : copy\n",
      "Overwrite: False\n",
      "-------------------------\n",
      "Running ffmpeg command:\n",
      "  ffmpeg -hide_banner -nostdin -stats -i Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\\240_300_montage_raw_synced.mp4 -map 0:v:0 -c:v libx264 -crf 18 -preset slow -map 0:a? -c:a copy -n Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\\240_300_montage_raw_synced__publication.mp4\n",
      "\n",
      "Progress (ffmpeg):\n",
      "\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\\240_300_montage_raw_synced.mp4':\n",
      "\n",
      "  Metadata:\n",
      "\n",
      "    major_brand     : isom\n",
      "\n",
      "    minor_version   : 512\n",
      "\n",
      "    compatible_brands: isomiso2mp41\n",
      "\n",
      "    encoder         : Lavf58.29.100\n",
      "\n",
      "  Duration: 00:01:00.02, start: 0.000000, bitrate: 14092 kb/s\n",
      "\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 2720x1360 [SAR 1:1 DAR 2:1], 14090 kb/s, 60 fps, 60 tbr, 15360 tbn, 60 tbc (default)\n",
      "\n",
      "    Metadata:\n",
      "\n",
      "      handler_name    : VideoHandler\n",
      "\n",
      "      vendor_id       : [0][0][0][0]\n",
      "\n",
      "Stream mapping:\n",
      "\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "\n",
      "[libx264 @ 000001781fb3df80] using SAR=1/1\n",
      "\n",
      "[libx264 @ 000001781fb3df80] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\n",
      "[libx264 @ 000001781fb3df80] profile High, level 5.1, 4:2:0, 8-bit\n",
      "\n",
      "[libx264 @ 000001781fb3df80] 264 - core 161 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=5 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=8 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=2 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=3 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=50 rc=crf mbtree=1 crf=18.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "\n",
      "Output #0, mp4, to 'Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\\240_300_montage_raw_synced__publication.mp4':\n",
      "\n",
      "  Metadata:\n",
      "\n",
      "    major_brand     : isom\n",
      "\n",
      "    minor_version   : 512\n",
      "\n",
      "    compatible_brands: isomiso2mp41\n",
      "\n",
      "    encoder         : Lavf58.71.100\n",
      "\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 2720x1360 [SAR 1:1 DAR 2:1], q=2-31, 60 fps, 15360 tbn (default)\n",
      "\n",
      "    Metadata:\n",
      "\n",
      "      handler_name    : VideoHandler\n",
      "\n",
      "      vendor_id       : [0][0][0][0]\n",
      "\n",
      "      encoder         : Lavc58.129.100 libx264\n",
      "\n",
      "    Side data:\n",
      "\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame= 3601 fps= 30 q=-1.0 Lsize=   25552kB time=00:00:59.96 bitrate=3490.6kbits/s speed=0.504x           \n",
      "video:25509kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.169157%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] frame I:15    Avg QP:11.14  size:192224\n",
      "\n",
      "[libx264 @ 000001781fb3df80] frame P:949   Avg QP:17.76  size: 17095\n",
      "\n",
      "[libx264 @ 000001781fb3df80] frame B:2637  Avg QP:21.98  size:  2660\n",
      "\n",
      "[libx264 @ 000001781fb3df80] consecutive B-frames:  1.8%  1.2%  1.3% 95.6%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] mb I  I16..4: 43.7% 43.4% 12.9%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] mb P  I16..4:  0.6%  2.8%  0.1%  P16..4: 14.8%  4.2%  2.3%  0.0%  0.0%    skip:75.1%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] mb B  I16..4:  0.2%  0.7%  0.0%  B16..8: 11.6%  0.4%  0.0%  direct: 0.1%  skip:87.1%  L0:49.5% L1:49.3% BI: 1.1%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] 8x8 transform intra:72.0% inter:57.9%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] direct mvs  spatial:99.7% temporal:0.3%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] coded y,uvDC,uvAC intra: 37.1% 13.7% 2.7% inter: 1.7% 1.1% 0.0%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] i16 v,h,dc,p: 47% 35% 10%  7%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 24% 44%  2%  2%  2%  2%  2%  3%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 31% 14%  3%  5%  5%  6%  4%  7%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] i8c dc,h,v,p: 80% 12%  7%  1%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] ref P L0: 63.0%  6.2% 17.8%  5.6%  7.3%  0.2%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] ref B L0: 73.1% 20.5%  4.7%  1.8%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] ref B L1: 93.1%  6.9%\n",
      "\n",
      "[libx264 @ 000001781fb3df80] kb/s:3481.71\n",
      "\n",
      "\n",
      "Done.\n",
      "Output written: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\\240_300_montage_raw_synced__publication.mp4\n",
      "Size: 105.7 MB -> 26.2 MB  (ratio 0.247)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('Z:/Nimrod/experiments/PV_126/2024_07_18/block_007/analysis/240_300_montage_raw_synced__publication.mp4')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "878fa9d1aaec6def"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# BLOCK DEFINITION #\n",
    "# This was the previous run\n",
    "#animals = ['PV_62', 'PV_126', 'PV_57']\n",
    "#block_lists = [[24, 26, 38], [7, 8, 9, 10, 11, 12], [7, 8, 9, 12, 13]]\n",
    "#This with new animals:\n",
    "animals = ['PV_208']\n",
    "block_lists = [[21]]\n",
    "experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "bad_blocks = [0]  # Example of bad blocks\n",
    "\n",
    "block_collection, block_dict = create_block_collections(\n",
    "    animals=animals,\n",
    "    block_lists=block_lists,\n",
    "    experiment_path=experiment_path,\n",
    "    bad_blocks=bad_blocks\n",
    ")\n",
    "for block in block_collection:\n",
    "    block.parse_open_ephys_events()\n",
    "    block.get_eye_brightness_vectors()\n",
    "    block.synchronize_block()\n",
    "    block.create_eye_brightness_df(threshold_value=20)\n",
    "\n",
    "    # if the code fails here, go to manual synchronization\n",
    "    block.import_manual_sync_df()\n",
    "    block.read_dlc_data()\n",
    "    block.calibrate_pixel_size(10)\n",
    "    #load_eye_data_2d_w_rotation_matrix(block) #should be integrated again... later\n",
    "\n",
    "    for block in block_collection:\n",
    "        # block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_corr_angles.csv')\n",
    "        # block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_corr_angles.csv')\n",
    "        #block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_raw_xflipped.csv')\n",
    "        #block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_raw_xflipped.csv')\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_raw_verified.csv')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_raw_verified.csv')\n",
    "        # block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_3d_corr_verified.csv')\n",
    "        # block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_3d_corr_verified.csv')\n",
    "        #block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_rotated_verified.csv')\n",
    "        #block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_rotated_verified.csv')\n",
    "\n",
    "    # calibrate pupil diameter:\n",
    "    # if 'pupil_diameter' not in block.left_eye_data.columns:\n",
    "    #     block.left_eye_data['pupil_diameter_pixels'] = block.left_eye_data.major_ax * 2 * np.pi\n",
    "    #     block.right_eye_data['pupil_diameter_pixels'] = block.right_eye_data.major_ax * 2 * np.pi\n",
    "    #     block.left_eye_data['pupil_diameter'] = block.left_eye_data['pupil_diameter_pixels'] * block.L_pix_size\n",
    "    #     block.right_eye_data['pupil_diameter'] = block.right_eye_data['pupil_diameter_pixels'] * block.R_pix_size"
   ],
   "id": "503c3f386e05760d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
