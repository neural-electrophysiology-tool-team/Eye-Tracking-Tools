{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:17:13.246892Z",
     "start_time": "2025-12-31T08:17:12.109498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import cycle\n",
    "import pickle\n",
    "import pathlib\n",
    "import math\n",
    "import tqdm\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import re\n",
    "from lxml import etree as ET\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "from scipy.stats import kde\n",
    "from BlockSync_current import BlockSync\n",
    "import UtilityFunctions_newOE as uf\n",
    "from scipy import signal\n",
    "import bokeh\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "rcParams['pdf.fonttype'] = 42  # Ensure fonts are embedded and editable\n",
    "rcParams['ps.fonttype'] = 42  # Ensure compatibility with vector outputs\n",
    "\n",
    "\n",
    "def bokeh_plotter(data_list, x_axis_list=None, label_list=None,\n",
    "                  plot_name='default',\n",
    "                  x_axis_label='X', y_axis_label='Y',\n",
    "                  peaks=None, peaks_list=False, export_path=False):\n",
    "    \"\"\"Generates an interactive Bokeh plot for the given data vector.\n",
    "    Args:\n",
    "        data_list (list or array): The data to be plotted.\n",
    "        label_list (list of str): The labels of the data vectors\n",
    "        plot_name (str, optional): The title of the plot. Defaults to 'default'.\n",
    "        x_axis (str, optional): The label for the x-axis. Defaults to 'X'.\n",
    "        y_axis (str, optional): The label for the y-axis. Defaults to 'Y'.\n",
    "        peaks (list or array, optional): Indices of peaks to highlight on the plot. Defaults to None.\n",
    "        export_path (False or str): when set to str, will output the resulting html fig\n",
    "    \"\"\"\n",
    "    color_cycle = cycle(bokeh.palettes.Category10_10)\n",
    "    fig = bokeh.plotting.figure(title=f'bokeh explorer: {plot_name}',\n",
    "                                x_axis_label=x_axis_label,\n",
    "                                y_axis_label=y_axis_label,\n",
    "                                plot_width=1500,\n",
    "                                plot_height=700)\n",
    "\n",
    "    for i, data_vector in enumerate(data_list):\n",
    "\n",
    "        color = next(color_cycle)\n",
    "\n",
    "        if x_axis_list is None:\n",
    "            x_axis = range(len(data_vector))\n",
    "        elif len(x_axis_list) == len(data_list):\n",
    "            print('x_axis manually set')\n",
    "            x_axis = x_axis_list[i]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                'problem with x_axis_list input - should be either None, or a list with the same length as data_list')\n",
    "        if label_list is None:\n",
    "            fig.line(x_axis, data_vector, line_color=color, legend_label=f\"Line {i + 1}\")\n",
    "        elif len(label_list) == len(data_list):\n",
    "            fig.line(range(len(data_vector)), data_vector, line_color=color, legend_label=f\"{label_list[i]}\")\n",
    "        if peaks is not None and peaks_list is True:\n",
    "            fig.circle(peaks[i], data_vector[peaks[i]], size=10, color=color)\n",
    "\n",
    "    if peaks is not None and peaks_list is False:\n",
    "        fig.circle(peaks, data_vector[peaks], size=10, color='red')\n",
    "\n",
    "    if export_path is not False:\n",
    "        print(f'exporting to {export_path}')\n",
    "        bokeh.io.output.output_file(filename=str(export_path / f'{plot_name}.html'), title=f'{plot_name}')\n",
    "    bokeh.plotting.show(fig)\n",
    "\n",
    "\n",
    "def load_eye_data_2d_w_rotation_matrix(block):\n",
    "    \"\"\"\n",
    "    This function checks if the eye dataframes and rotation dict object exist, then imports them\n",
    "    :param block: The current blocksync class with verifiec re/le dfs\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data.csv', index_col=0, engine='python')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data.csv', index_col=0, engine='python')\n",
    "    except FileNotFoundError:\n",
    "        print('eye_data files not found, run the pipeline!')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(block.analysis_path / 'rotate_eye_data_params.pkl', 'rb') as file:\n",
    "            rotation_dict = pickle.load(file)\n",
    "            block.left_rotation_matrix = rotation_dict['left_rotation_matrix']\n",
    "            block.right_rotation_matrix = rotation_dict['right_rotation_matrix']\n",
    "            block.left_rotation_angle = rotation_dict['left_rotation_angle']\n",
    "            block.right_rotation_angle = rotation_dict['right_rotation_angle']\n",
    "    except FileNotFoundError:\n",
    "        print('No rotation matrix file, create it')\n",
    "\n",
    "\n",
    "def create_saccade_events_df(eye_data_df, speed_threshold, bokeh_verify_threshold=False, magnitude_calib=1,\n",
    "                             speed_profile=True):\n",
    "    \"\"\"\n",
    "    Detects saccade events in eye tracking data and computes relevant metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - eye_data_df (pd.DataFrame): Input DataFrame containing eye tracking data.\n",
    "    - speed_threshold (float): Threshold for saccade detection based on speed.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): Modified input DataFrame with added columns for speed and saccade detection.\n",
    "    - saccade_events_df (pd.DataFrame): DataFrame containing information about detected saccade events.\n",
    "\n",
    "    Steps:\n",
    "    1. Calculate speed components ('speed_x', 'speed_y') based on differences in 'center_x' and 'center_y'.\n",
    "    2. Compute the magnitude of the velocity vector ('speed_r').\n",
    "    3. Create a binary column ('is_saccade') indicating saccade events based on the speed threshold.\n",
    "    4. Determine saccade onset and offset indices and timestamps.\n",
    "    5. Create a DataFrame ('saccade_events_df') with columns:\n",
    "        - 'saccade_start_ind': Indices of saccade onset.\n",
    "        - 'saccade_start_timestamp': Timestamps corresponding to saccade onset.\n",
    "        - 'saccade_end_ind': Indices of saccade offset.\n",
    "        - 'saccade_end_timestamp': Timestamps corresponding to saccade offset.\n",
    "        - 'length': Duration of each saccade event.\n",
    "    6. Calculate distance traveled and angles for each saccade event.\n",
    "    7. Append additional columns to 'saccade_events_df':\n",
    "        - 'magnitude': Magnitude of the distance traveled during each saccade.\n",
    "        - 'angle': Angle of the saccade vector in degrees.\n",
    "        - 'initial_x', 'initial_y': Initial coordinates of the saccade.\n",
    "        - 'end_x', 'end_y': End coordinates of the saccade.\n",
    "\n",
    "    Note: The original 'eye_data_df' is not modified; modified data is returned as 'df'.\n",
    "    \"\"\"\n",
    "    df = eye_data_df\n",
    "    df['speed_x'] = df['center_x'].diff()  # Difference between consecutive 'center_x' values\n",
    "    df['speed_y'] = df['center_y'].diff()  # Difference between consecutive 'center_y' values\n",
    "\n",
    "    # Step 2: Calculate magnitude of the velocity vector (R vector speed)\n",
    "    df['speed_r'] = (df['speed_x'] ** 2 + df['speed_y'] ** 2) ** 0.5\n",
    "\n",
    "    # Create a column for saccade detection\n",
    "    df['is_saccade'] = df['speed_r'] > speed_threshold\n",
    "\n",
    "    # create a saccade_on_off indicator where 1 is rising edge and -1 is falling edge by subtracting a shifted binary mask\n",
    "    saccade_on_off = df.is_saccade.astype(int) - df.is_saccade.shift(periods=1, fill_value=False).astype(int)\n",
    "    saccade_on_inds = np.where(saccade_on_off == 1)[\n",
    "                          0] - 1  # notice the manual shift here, chosen to include the first (sometimes slower) eye frame, just before saccade threshold crossing\n",
    "    saccade_on_ms = df['ms_axis'].iloc[saccade_on_inds]\n",
    "    saccade_on_timestamps = df['OE_timestamp'].iloc[saccade_on_inds]\n",
    "    saccade_off_inds = np.where(saccade_on_off == -1)[0]\n",
    "    saccade_off_timestamps = df['OE_timestamp'].iloc[saccade_off_inds]\n",
    "    saccade_off_ms = df['ms_axis'].iloc[saccade_off_inds]\n",
    "\n",
    "    saccade_dict = {'saccade_start_ind': saccade_on_inds,\n",
    "                    'saccade_start_timestamp': saccade_on_timestamps.values,\n",
    "                    'saccade_end_ind': saccade_off_inds,\n",
    "                    'saccade_end_timestamp': saccade_off_timestamps.values,\n",
    "                    'saccade_on_ms': saccade_on_ms.values,\n",
    "                    'saccade_off_ms': saccade_off_ms.values}\n",
    "\n",
    "    saccade_events_df = pd.DataFrame.from_dict(saccade_dict)\n",
    "    saccade_events_df['length'] = saccade_events_df['saccade_end_ind'] - saccade_events_df['saccade_start_ind']\n",
    "    # Drop columns used for intermediate steps\n",
    "    df = df.drop(['is_saccade'], axis=1)\n",
    "\n",
    "    distances = []\n",
    "    angles = []\n",
    "    speed_list = []\n",
    "    diameter_list = []\n",
    "    for index, row in tqdm.tqdm(saccade_events_df.iterrows()):\n",
    "        saccade_samples = df.loc[(df['OE_timestamp'] >= row['saccade_start_timestamp']) &\n",
    "                                 (df['OE_timestamp'] <= row['saccade_end_timestamp'])]\n",
    "        distance_traveled = saccade_samples['speed_r'].sum()\n",
    "        if speed_profile:\n",
    "            saccade_speed_profile = saccade_samples['speed_r'].values\n",
    "            speed_list.append(saccade_speed_profile)\n",
    "        saccade_diameter_profile = saccade_samples['pupil_diameter'].values\n",
    "        diameter_list.append(saccade_diameter_profile)\n",
    "        # Calculate angle from initial position to endpoint\n",
    "        initial_position = saccade_samples.iloc[0][['center_x', 'center_y']]\n",
    "        endpoint = saccade_samples.iloc[-1][['center_x', 'center_y']]\n",
    "        overall_angle = np.arctan2(endpoint['center_y'] - initial_position['center_y'],\n",
    "                                   endpoint['center_x'] - initial_position['center_x'])\n",
    "\n",
    "        angles.append(overall_angle)\n",
    "        distances.append(distance_traveled)\n",
    "\n",
    "    saccade_events_df['magnitude_raw'] = np.array(distances)\n",
    "    saccade_events_df['magnitude'] = np.array(distances) * magnitude_calib\n",
    "    saccade_events_df['angle'] = np.where(np.isnan(angles), angles, np.rad2deg(\n",
    "        angles) % 360)  # Convert radians to degrees and ensure result is in [0, 360)\n",
    "    start_ts = saccade_events_df['saccade_start_timestamp'].values\n",
    "    end_ts = saccade_events_df['saccade_end_timestamp'].values\n",
    "    saccade_start_df = df[df['OE_timestamp'].isin(start_ts)]\n",
    "    saccade_end_df = df[df['OE_timestamp'].isin(end_ts)]\n",
    "    start_x_coord = saccade_start_df['center_x']\n",
    "    start_y_coord = saccade_start_df['center_y']\n",
    "    end_x_coord = saccade_end_df['center_x']\n",
    "    end_y_coord = saccade_end_df['center_y']\n",
    "    saccade_events_df['initial_x'] = start_x_coord.values\n",
    "    saccade_events_df['initial_y'] = start_y_coord.values\n",
    "    saccade_events_df['end_x'] = end_x_coord.values\n",
    "    saccade_events_df['end_y'] = end_y_coord.values\n",
    "    saccade_events_df['calib_dx'] = (saccade_events_df['end_x'].values - saccade_events_df[\n",
    "        'initial_x'].values) * magnitude_calib\n",
    "    saccade_events_df['calib_dy'] = (saccade_events_df['end_y'].values - saccade_events_df[\n",
    "        'initial_y'].values) * magnitude_calib\n",
    "    if speed_profile:\n",
    "        saccade_events_df['speed_profile'] = speed_list\n",
    "    saccade_events_df['diameter_profile'] = diameter_list\n",
    "    if bokeh_verify_threshold:\n",
    "        bokeh_plotter(data_list=[df.speed_r], label_list=['Pupil Velocity'], peaks=saccade_on_inds)\n",
    "\n",
    "    return df, saccade_events_df\n",
    "\n",
    "\n",
    "# create a multi-animal block_collection:\n",
    "\n",
    "def create_block_collections(animals, block_lists, experiment_path, bad_blocks=None):\n",
    "    \"\"\"\n",
    "    Create block collections and a block dictionary from multiple animals and their respective block lists.\n",
    "\n",
    "    Parameters:\n",
    "    - animals: list of str, names of the animals.\n",
    "    - block_lists: list of lists of int, block numbers corresponding to each animal.\n",
    "    - experiment_path: pathlib.Path, path to the experiment directory.\n",
    "    - bad_blocks: list of int, blocks to exclude. Default is an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - block_collection: list of BlockSync objects for all specified blocks.\n",
    "    - block_dict: dictionary where keys are block numbers as strings and values are BlockSync objects.\n",
    "    \"\"\"\n",
    "    import UtilityFunctions_newOE as uf\n",
    "\n",
    "    if bad_blocks is None:\n",
    "        bad_blocks = []\n",
    "\n",
    "    block_collection = []\n",
    "    block_dict = {}\n",
    "\n",
    "    for animal, blocks in zip(animals, block_lists):\n",
    "        # Generate blocks for the current animal\n",
    "        current_blocks = uf.block_generator(\n",
    "            block_numbers=blocks,\n",
    "            experiment_path=experiment_path,\n",
    "            animal=animal,\n",
    "            bad_blocks=bad_blocks\n",
    "        )\n",
    "        # Add to collection and dictionary\n",
    "        block_collection.extend(current_blocks)\n",
    "        for b in current_blocks:\n",
    "            block_dict[f\"{animal}_block_{b.block_num}\"] = b\n",
    "\n",
    "    return block_collection, block_dict\n"
   ],
   "id": "8a1b0a8321e053bf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:18:09.082250Z",
     "start_time": "2025-12-31T08:17:14.238447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "# This was the previous run\n",
    "#animals = ['PV_62', 'PV_126', 'PV_57']\n",
    "#block_lists = [[24, 26, 38], [7, 8, 9, 10, 11, 12], [7, 8, 9, 12, 13]]\n",
    "#This with new animals:\n",
    "animals = ['PV_106','PV_143','PV_62','PV_126', 'PV_57']\n",
    "block_lists = [[8,9,10,11,12],[1,2,3,4],[24, 26, 38],[7, 8, 9, 10, 11, 12], [7, 8, 9, 12, 13]]\n",
    "experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "bad_blocks = [0]  # Example of bad blocks\n",
    "\n",
    "block_collection, block_dict = create_block_collections(\n",
    "    animals=animals,\n",
    "    block_lists=block_lists,\n",
    "    experiment_path=experiment_path,\n",
    "    bad_blocks=bad_blocks\n",
    ")\n",
    "for block in block_collection:\n",
    "    print(f'working on {block}')\n",
    "    block.parse_open_ephys_events()\n",
    "    block.get_eye_brightness_vectors()\n",
    "    block.synchronize_block()\n",
    "    block.create_eye_brightness_df(threshold_value=20)\n",
    "\n",
    "    # if the code fails here, go to manual synchronization\n",
    "    #block.import_manual_sync_df()\n",
    "    block.read_dlc_data()\n",
    "    block.calibrate_pixel_size(10)\n",
    "    #load_eye_data_2d_w_rotation_matrix(block) #should be integrated again... later"
   ],
   "id": "152c65e2d90b0daf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_008, new OE version\n",
      "Found the sample rate for block 008 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 010 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_010, new OE version\n",
      "Found the sample rate for block 010 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 010\n",
      "got it!\n",
      "instantiated block number 011 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_011, new OE version\n",
      "Found the sample rate for block 011 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 011\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 001 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_001, new OE version\n",
      "Found the sample rate for block 001 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 001\n",
      "got it!\n",
      "instantiated block number 002 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_002, new OE version\n",
      "Found the sample rate for block 002 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 002\n",
      "got it!\n",
      "instantiated block number 003 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_003, new OE version\n",
      "Found the sample rate for block 003 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 003\n",
      "got it!\n",
      "instantiated block number 004 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_004, new OE version\n",
      "Found the sample rate for block 004 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 004\n",
      "got it!\n",
      "instantiated block number 024 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_024, new OE version\n",
      "Found the sample rate for block 024 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 024\n",
      "got it!\n",
      "instantiated block number 026 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_026, new OE version\n",
      "Found the sample rate for block 026 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 026\n",
      "got it!\n",
      "instantiated block number 038 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_05_01\\block_038, new OE version\n",
      "Found the sample rate for block 038 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 038\n",
      "got it!\n",
      "instantiated block number 007 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007, new OE version\n",
      "Found the sample rate for block 007 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 007\n",
      "got it!\n",
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_008, new OE version\n",
      "could not find the sample rate in the xml file due to error, will look in the cont file of the first recording...\n",
      "found the sample rate, it is 20000\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 010 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_010, new OE version\n",
      "Found the sample rate for block 010 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 010\n",
      "got it!\n",
      "instantiated block number 011 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_011, new OE version\n",
      "Found the sample rate for block 011 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 011\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 007 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_007, new OE version\n",
      "Found the sample rate for block 007 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 007\n",
      "got it!\n",
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_008, new OE version\n",
      "Found the sample rate for block 008 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 013 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013, new OE version\n",
      "Found the sample rate for block 013 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 013\n",
      "got it!\n",
      "working on PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19\n",
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43\n",
      "running parse_open_ephys_events...\n",
      "block 010 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 010...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30\n",
      "running parse_open_ephys_events...\n",
      "block 011 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 011...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08\n",
      "running parse_open_ephys_events...\n",
      "block 001 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 001...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11\n",
      "running parse_open_ephys_events...\n",
      "block 002 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 002...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35\n",
      "running parse_open_ephys_events...\n",
      "block 003 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 003...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28\n",
      "running parse_open_ephys_events...\n",
      "block 004 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 004...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_62, block 024, on 2023-04-27_11-22-56\n",
      "running parse_open_ephys_events...\n",
      "block 024 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 024...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_62, block 026, on 2023-04-27_12-21-41\n",
      "running parse_open_ephys_events...\n",
      "block 026 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 026...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_62, block 038, on 2023-05-01_13-57-45\n",
      "running parse_open_ephys_events...\n",
      "block 038 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 038...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12\n",
      "running parse_open_ephys_events...\n",
      "block 007 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 007...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41\n",
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57\n",
      "running parse_open_ephys_events...\n",
      "block 010 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 010...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 011, on PV126_Trial115_eyeTracking_w7\n",
      "running parse_open_ephys_events...\n",
      "block 011 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 011...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 012, on PV126_Trial116_eyeTracking_h8\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31\n",
      "running parse_open_ephys_events...\n",
      "block 007 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 007...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18\n",
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43\n",
      "running parse_open_ephys_events...\n",
      "block 013 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 013...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:18:25.579803Z",
     "start_time": "2025-12-31T08:18:09.114283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    for block in block_collection:\n",
    "        print('working on {}'.format(block))\n",
    "        # block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_corr_angles.csv')\n",
    "        # block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_corr_angles.csv')\n",
    "        #block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_raw_xflipped.csv')\n",
    "        #block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_raw_xflipped.csv')\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_raw_verified.csv')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_raw_verified.csv')\n",
    "        # block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_3d_corr_verified.csv')\n",
    "        # block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_3d_corr_verified.csv')\n",
    "        #block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_rotated_verified.csv')\n",
    "        #block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_rotated_verified.csv')\n",
    "\n",
    "    # calibrate pupil diameter:\n",
    "    # if 'pupil_diameter' not in block.left_eye_data.columns:\n",
    "    #     block.left_eye_data['pupil_diameter_pixels'] = block.left_eye_data.major_ax * 2 * np.pi\n",
    "    #     block.right_eye_data['pupil_diameter_pixels'] = block.right_eye_data.major_ax * 2 * np.pi\n",
    "    #     block.left_eye_data['pupil_diameter'] = block.left_eye_data['pupil_diameter_pixels'] * block.L_pix_size\n",
    "    #     block.right_eye_data['pupil_diameter'] = block.right_eye_data['pupil_diameter_pixels'] * block.R_pix_size"
   ],
   "id": "9b3a854885319344",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19\n",
      "working on PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43\n",
      "working on PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43\n",
      "working on PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30\n",
      "working on PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30\n",
      "working on PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08\n",
      "working on PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11\n",
      "working on PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35\n",
      "working on PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28\n",
      "working on PV_62, block 024, on 2023-04-27_11-22-56\n",
      "working on PV_62, block 026, on 2023-04-27_12-21-41\n",
      "working on PV_62, block 038, on 2023-05-01_13-57-45\n",
      "working on PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12\n",
      "working on PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41\n",
      "working on PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15\n",
      "working on PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57\n",
      "working on PV_126, block 011, on PV126_Trial115_eyeTracking_w7\n",
      "working on PV_126, block 012, on PV126_Trial116_eyeTracking_h8\n",
      "working on PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31\n",
      "working on PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18\n",
      "working on PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35\n",
      "working on PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39\n",
      "working on PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:18:25.610017Z",
     "start_time": "2025-12-31T08:18:25.597018Z"
    }
   },
   "cell_type": "code",
   "source": "block_collection",
   "id": "7ee46d0fb4633e25",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BlockSync object for animal PV_106 with \n",
       " block_num 008 at date PV106_ET_d3t12025-08-06_11-52-19,\n",
       " BlockSync object for animal PV_106 with \n",
       " block_num 009 at date PV106_ET_d3t2_2025-08-06_12-09-43,\n",
       " BlockSync object for animal PV_106 with \n",
       " block_num 010 at date PV106_ET_d3t3_2025-08-06_12-26-43,\n",
       " BlockSync object for animal PV_106 with \n",
       " block_num 011 at date PV106_ET_d3t4_2025-08-06_12-44-30,\n",
       " BlockSync object for animal PV_106 with \n",
       " block_num 012 at date PV106_ET_d3t5_2025-08-06_13-21-30,\n",
       " BlockSync object for animal PV_143 with \n",
       " block_num 001 at date PV143_ET_d1t1_2025-08-11_13-29-08,\n",
       " BlockSync object for animal PV_143 with \n",
       " block_num 002 at date PV143_ET_d1t2_2025-08-11_13-50-11,\n",
       " BlockSync object for animal PV_143 with \n",
       " block_num 003 at date PV143_ET_d1t3_2025-08-11_14-20-35,\n",
       " BlockSync object for animal PV_143 with \n",
       " block_num 004 at date PV143_ET_d1t4_2025-08-11_14-58-28,\n",
       " BlockSync object for animal PV_62 with \n",
       " block_num 024 at date 2023-04-27_11-22-56,\n",
       " BlockSync object for animal PV_62 with \n",
       " block_num 026 at date 2023-04-27_12-21-41,\n",
       " BlockSync object for animal PV_62 with \n",
       " block_num 038 at date 2023-05-01_13-57-45,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 007 at date PV126_Trial16_wake3_2024-07-18_12-49-12,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 008 at date PV126_Trial16_wake4_2024-07-18_13-24-41,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 009 at date PV126_Trial18_wake5_2024-07-18_14-39-15,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 010 at date PV126_Trial19_wake6_2024-07-18_15-24-57,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 011 at date PV126_Trial115_eyeTracking_w7,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 012 at date PV126_Trial116_eyeTracking_h8,\n",
       " BlockSync object for animal PV_57 with \n",
       " block_num 007 at date pv_57_day2_03_2024-11-25_15-28-31,\n",
       " BlockSync object for animal PV_57 with \n",
       " block_num 008 at date pv_57_day2_05_2024-11-25_16-07-18,\n",
       " BlockSync object for animal PV_57 with \n",
       " block_num 009 at date pv_57_day2_06_2024-11-25_16-25-35,\n",
       " BlockSync object for animal PV_57 with \n",
       " block_num 012 at date PV_57_hunter_2_2024-12-01_16-08-39,\n",
       " BlockSync object for animal PV_57 with \n",
       " block_num 013 at date PV_57_hunter_2_2024-12-01_16-34-43]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:18:25.943514Z",
     "start_time": "2025-12-31T08:18:25.885584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for block in block_collection:\n",
    "  if 'pupil_diameter' not in block.left_eye_data.columns:\n",
    "        print(f'calculating pupil diameter for {block} ')\n",
    "        block.left_eye_data['pupil_diameter_pixels'] = block.left_eye_data.major_ax\n",
    "        block.right_eye_data['pupil_diameter_pixels'] = block.right_eye_data.major_ax\n",
    "        block.left_eye_data['pupil_diameter'] = block.left_eye_data['pupil_diameter_pixels'] * block.L_pix_size\n",
    "        block.right_eye_data['pupil_diameter'] = block.right_eye_data['pupil_diameter_pixels'] * block.R_pix_size"
   ],
   "id": "a08be8283b7cb785",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating pupil diameter for PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19 \n",
      "calculating pupil diameter for PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43 \n",
      "calculating pupil diameter for PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43 \n",
      "calculating pupil diameter for PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30 \n",
      "calculating pupil diameter for PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30 \n",
      "calculating pupil diameter for PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08 \n",
      "calculating pupil diameter for PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11 \n",
      "calculating pupil diameter for PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35 \n",
      "calculating pupil diameter for PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28 \n",
      "calculating pupil diameter for PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12 \n",
      "calculating pupil diameter for PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41 \n",
      "calculating pupil diameter for PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15 \n",
      "calculating pupil diameter for PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57 \n",
      "calculating pupil diameter for PV_126, block 011, on PV126_Trial115_eyeTracking_w7 \n",
      "calculating pupil diameter for PV_126, block 012, on PV126_Trial116_eyeTracking_h8 \n",
      "calculating pupil diameter for PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31 \n",
      "calculating pupil diameter for PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18 \n",
      "calculating pupil diameter for PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35 \n",
      "calculating pupil diameter for PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39 \n",
      "calculating pupil diameter for PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43 \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:18:26.075114Z",
     "start_time": "2025-12-31T08:18:26.059338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # uncomment to switch corrected values to k_phi / theta columns\n",
    "# for block in block_collection:\n",
    "#     block.left_eye_data.drop(columns=['k_phi', 'k_theta'], inplace=True)\n",
    "#     block.right_eye_data.drop(columns=['k_phi', 'k_theta'], inplace=True)\n",
    "#     # then rename in-place\n",
    "#     block.left_eye_data = block.left_eye_data.rename(columns={'corr_phi': 'k_phi', 'corr_theta': 'k_theta'})\n",
    "#     block.right_eye_data = block.right_eye_data.rename(columns={'corr_phi': 'k_phi', 'corr_theta': 'k_theta'})"
   ],
   "id": "bc044b56f6179dcd",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:18:26.514968Z",
     "start_time": "2025-12-31T08:18:26.201866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If you want to recenter the data (for span-related plots) against the median position, uncomment and run this:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "def recenter_eye_angles_to_rest(\n",
    "    eye_df: pd.DataFrame,\n",
    "    phi_col: str = \"k_phi\",\n",
    "    theta_col: str = \"k_theta\",\n",
    "    inplace: bool = False,\n",
    "    dropna: bool = True,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Recenter the eye's angular coordinates so that the median (resting position)\n",
    "    of k_phi and k_theta becomes zero degrees.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eye_df : pd.DataFrame\n",
    "        Eye dataframe containing k_phi and k_theta columns (can be *_eye_data_clean).\n",
    "    phi_col, theta_col : str\n",
    "        Column names for the vertical (phi) and horizontal (theta) gaze angles.\n",
    "    inplace : bool\n",
    "        If True, modifies the input DataFrame in place; otherwise returns a copy.\n",
    "    dropna : bool\n",
    "        Whether to ignore NaN values when computing medians (recommended True).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_out : pd.DataFrame\n",
    "        DataFrame with corrected columns (values centered around 0).\n",
    "    offsets : dict\n",
    "        {'phi_offset': float, 'theta_offset': float}\n",
    "        The medians that were subtracted from the original data.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - New columns 'k_phi_recentered' and 'k_theta_recentered' are added\n",
    "      (or the originals replaced if inplace=True).\n",
    "    - This assumes your angular units are degrees.\n",
    "    - The offsets correspond to the eye's resting orientation in the camera frame.\n",
    "    \"\"\"\n",
    "    # --- validate ---\n",
    "    for c in (phi_col, theta_col):\n",
    "        if c not in eye_df.columns:\n",
    "            raise ValueError(f\"Column '{c}' not found in dataframe\")\n",
    "\n",
    "    # Select working DataFrame\n",
    "    df = eye_df if inplace else eye_df.copy()\n",
    "\n",
    "    # Convert to numeric, handle NaN\n",
    "    phi_vals = pd.to_numeric(df[phi_col], errors=\"coerce\")\n",
    "    theta_vals = pd.to_numeric(df[theta_col], errors=\"coerce\")\n",
    "\n",
    "    # Compute medians (resting position)\n",
    "    phi_med = float(np.nanmedian(phi_vals)) if dropna else float(np.median(phi_vals))\n",
    "    theta_med = float(np.nanmedian(theta_vals)) if dropna else float(np.median(theta_vals))\n",
    "\n",
    "    # Apply centering\n",
    "    df[phi_col] = phi_vals - phi_med\n",
    "    df[theta_col] = theta_vals - theta_med\n",
    "\n",
    "    # Optionally store explicitly labeled recentered columns\n",
    "    df[f\"{phi_col}_recentered\"] = df[phi_col]\n",
    "    df[f\"{theta_col}_recentered\"] = df[theta_col]\n",
    "\n",
    "    offsets = {\"phi_offset\": phi_med, \"theta_offset\": theta_med}\n",
    "    return df, offsets\n",
    "\n",
    "for block in block_collection:\n",
    "    # Apply to the cleaned left eye data\n",
    "    df_left_clean = block.left_eye_data\n",
    "    df_left_centered, left_offsets = recenter_eye_angles_to_rest(df_left_clean)\n",
    "\n",
    "    # Same for right\n",
    "    df_right_clean = block.right_eye_data\n",
    "    df_right_centered, right_offsets = recenter_eye_angles_to_rest(df_right_clean)\n",
    "\n",
    "    # Store back on the block if desired\n",
    "    block.left_eye_data_centered = df_left_centered\n",
    "    block.right_eye_data_centered = df_right_centered\n",
    "\n",
    "    print(\"Left eye offsets:\", left_offsets)\n",
    "    print(\"Right eye offsets:\", right_offsets)\n"
   ],
   "id": "9027e1e2a1d1758e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left eye offsets: {'phi_offset': -13.585779190063475, 'theta_offset': -43.059635162353516}\n",
      "Right eye offsets: {'phi_offset': 6.654082298278809, 'theta_offset': -42.897987365722656}\n",
      "Left eye offsets: {'phi_offset': -17.727107048034668, 'theta_offset': -42.58493423461914}\n",
      "Right eye offsets: {'phi_offset': 27.34492111206055, 'theta_offset': -35.46980285644531}\n",
      "Left eye offsets: {'phi_offset': -10.522362232208252, 'theta_offset': -43.67327690124512}\n",
      "Right eye offsets: {'phi_offset': 18.342082977294922, 'theta_offset': -41.04368591308594}\n",
      "Left eye offsets: {'phi_offset': -17.197317123413086, 'theta_offset': -39.99274444580078}\n",
      "Right eye offsets: {'phi_offset': 15.23730182647705, 'theta_offset': -35.542009353637695}\n",
      "Left eye offsets: {'phi_offset': -9.613146305084229, 'theta_offset': -42.25788688659668}\n",
      "Right eye offsets: {'phi_offset': 17.132087707519528, 'theta_offset': -31.953716278076172}\n",
      "Left eye offsets: {'phi_offset': -4.765095924234248, 'theta_offset': -22.920942243820747}\n",
      "Right eye offsets: {'phi_offset': -6.081558283765075, 'theta_offset': -32.332562548209125}\n",
      "Left eye offsets: {'phi_offset': 6.717270756725407, 'theta_offset': -22.73536582355421}\n",
      "Right eye offsets: {'phi_offset': -7.349963001021514, 'theta_offset': -34.69546594598704}\n",
      "Left eye offsets: {'phi_offset': -3.3411342023697257, 'theta_offset': -23.22943620090117}\n",
      "Right eye offsets: {'phi_offset': -12.211777088319216, 'theta_offset': -31.632003931435236}\n",
      "Left eye offsets: {'phi_offset': 8.836101872565491, 'theta_offset': -19.082913307908587}\n",
      "Right eye offsets: {'phi_offset': -2.4849219291784705, 'theta_offset': -35.78167377342014}\n",
      "Left eye offsets: {'phi_offset': -13.379541988845094, 'theta_offset': -42.00602076834302}\n",
      "Right eye offsets: {'phi_offset': -10.491102335225383, 'theta_offset': -53.88236113913939}\n",
      "Left eye offsets: {'phi_offset': -9.456716228533796, 'theta_offset': -42.13492879256957}\n",
      "Right eye offsets: {'phi_offset': -14.639129285831814, 'theta_offset': -50.91800902486017}\n",
      "Left eye offsets: {'phi_offset': 0.5398996706061734, 'theta_offset': -39.90960235889185}\n",
      "Right eye offsets: {'phi_offset': -13.404561765009717, 'theta_offset': -45.15803480205908}\n",
      "Left eye offsets: {'phi_offset': -11.231744237296748, 'theta_offset': -36.60157545235916}\n",
      "Right eye offsets: {'phi_offset': 3.2023219976210138, 'theta_offset': -31.66914973221911}\n",
      "Left eye offsets: {'phi_offset': 4.781990733213082, 'theta_offset': -36.52978406182781}\n",
      "Right eye offsets: {'phi_offset': 5.405744730557667, 'theta_offset': -31.195833234977087}\n",
      "Left eye offsets: {'phi_offset': -15.437753034276009, 'theta_offset': -13.622562083289564}\n",
      "Right eye offsets: {'phi_offset': 0.8519743382863465, 'theta_offset': -29.74502997156846}\n",
      "Left eye offsets: {'phi_offset': -10.131454448162224, 'theta_offset': -25.683902048937462}\n",
      "Right eye offsets: {'phi_offset': 11.007525482976991, 'theta_offset': -34.17505590650313}\n",
      "Left eye offsets: {'phi_offset': -12.671329878828999, 'theta_offset': -29.975441893099028}\n",
      "Right eye offsets: {'phi_offset': 3.2894816086795173, 'theta_offset': -34.775078856782976}\n",
      "Left eye offsets: {'phi_offset': -11.47263509547851, 'theta_offset': -36.3473780788894}\n",
      "Right eye offsets: {'phi_offset': 6.010292696904187, 'theta_offset': -33.50162210321432}\n",
      "Left eye offsets: {'phi_offset': -1.3277312417803782, 'theta_offset': -30.342993476915403}\n",
      "Right eye offsets: {'phi_offset': 8.075220827369355, 'theta_offset': -46.83401046510298}\n",
      "Left eye offsets: {'phi_offset': -0.5764805267470189, 'theta_offset': -33.53067136176525}\n",
      "Right eye offsets: {'phi_offset': 9.0801838794262, 'theta_offset': -46.73370424496796}\n",
      "Left eye offsets: {'phi_offset': 3.3749205037913623, 'theta_offset': -33.94651113113754}\n",
      "Right eye offsets: {'phi_offset': 10.04576797344359, 'theta_offset': -45.47657200870528}\n",
      "Left eye offsets: {'phi_offset': -0.023510983274669828, 'theta_offset': -32.14669928857302}\n",
      "Right eye offsets: {'phi_offset': 10.47040309890966, 'theta_offset': -45.50488359301998}\n",
      "Left eye offsets: {'phi_offset': -6.169015631368135, 'theta_offset': -30.765523499882732}\n",
      "Right eye offsets: {'phi_offset': 15.858912523931906, 'theta_offset': -45.98475896789136}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:18:26.574831Z",
     "start_time": "2025-12-31T08:18:26.545968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_saccade_events_with_direction_segmentation_robust(\n",
    "        eye_data_df,\n",
    "        speed_threshold,  # angular speed threshold in degrees/frame\n",
    "        directional_delta_threshold_deg=25,  # threshold for change in instantaneous angle (degrees)\n",
    "        magnitude_calib=1,\n",
    "        speed_profile=True,\n",
    "        min_subsaccade_samples=2,\n",
    "        min_net_disp=0.5  # minimal net angular displacement (in degrees) for a segment to be valid\n",
    "):\n",
    "    \"\"\"\n",
    "    Detects and segments saccade events in eye tracking data using angular speed and directional changes.\n",
    "    This robust version avoids producing segments with near-zero net displacement by:\n",
    "      1. Defining the saccade onset as the first frame where the angular speed exceeds the threshold.\n",
    "      2. Segmenting the event based on sustained directional changes.\n",
    "      3. Discarding segments whose overall net angular displacement (computed from k_phi and k_theta)\n",
    "         is below a user-specified minimal value.\n",
    "\n",
    "    Parameters:\n",
    "      - eye_data_df (pd.DataFrame): DataFrame with columns including:\n",
    "            'center_x', 'center_y', 'k_phi', 'k_theta', 'OE_timestamp', 'ms_axis', 'pupil_diameter'.\n",
    "      - speed_threshold (float): Angular speed threshold (degrees/frame) for detection.\n",
    "      - directional_delta_threshold_deg (float): Angular change threshold to determine segmentation boundaries.\n",
    "      - magnitude_calib (float): Calibration factor (not applied to angular measures).\n",
    "      - speed_profile (bool): Whether to record speed profiles.\n",
    "      - min_subsaccade_samples (int): Minimum number of samples required for a valid segment.\n",
    "      - min_net_disp (float): Minimal net angular displacement (in degrees) required for a segment to be kept.\n",
    "\n",
    "    Returns:\n",
    "      - df (pd.DataFrame): The input DataFrame with added computed columns.\n",
    "      - saccade_events_df (pd.DataFrame): DataFrame listing detected and segmented saccade events, with metrics.\n",
    "    \"\"\"\n",
    "    # Make a copy so as not to modify the original DataFrame.\n",
    "    df = eye_data_df.copy()\n",
    "\n",
    "    ### 1. Compute Frame-to-Frame Differences\n",
    "    df[\"speed_x\"] = df[\"center_x\"].diff()\n",
    "    df[\"speed_y\"] = df[\"center_y\"].diff()\n",
    "    df[\"speed_r\"] = np.sqrt(df[\"speed_x\"] ** 2 + df[\"speed_y\"] ** 2)\n",
    "\n",
    "    # Angular differences (k_phi and k_theta are in degrees)\n",
    "    df[\"angular_speed_phi\"] = df[\"k_phi\"].diff()\n",
    "    df[\"angular_speed_theta\"] = df[\"k_theta\"].diff()\n",
    "    df[\"angular_speed_r\"] = np.sqrt(df[\"angular_speed_phi\"] ** 2 + df[\"angular_speed_theta\"] ** 2)\n",
    "\n",
    "    ### 2. Saccade Detection Based on Angular Speed\n",
    "    # Mark frames where the instantaneous angular speed exceeds the threshold.\n",
    "    df[\"is_saccade_angle\"] = df[\"angular_speed_r\"] > speed_threshold\n",
    "\n",
    "    # Identify transitions to detect onsets and offsets.\n",
    "    saccade_on_off = df[\"is_saccade_angle\"].astype(int) - df[\"is_saccade_angle\"].shift(1, fill_value=0).astype(int)\n",
    "    # Use the first frame above threshold as onset\n",
    "    saccade_on_inds = np.where(saccade_on_off == 1)[0]\n",
    "    saccade_off_inds = np.where(saccade_on_off == -1)[0]\n",
    "\n",
    "    # Handle mismatches: if a saccade starts but does not end, drop the last onset.\n",
    "    if len(saccade_on_inds) > len(saccade_off_inds):\n",
    "        saccade_on_inds = saccade_on_inds[:-1]\n",
    "\n",
    "    saccade_events = []\n",
    "\n",
    "    ### 3. Process Each Detected Saccade for Segmentation\n",
    "    for start_ind, end_ind in zip(saccade_on_inds, saccade_off_inds):\n",
    "        saccade_df = df.iloc[start_ind:end_ind + 1].copy()\n",
    "        if saccade_df.empty or len(saccade_df) < min_subsaccade_samples:\n",
    "            continue\n",
    "\n",
    "        # Compute instantaneous angles (for both pixel- and angular-based estimates)\n",
    "        saccade_df[\"inst_angle_pixel\"] = np.degrees(np.arctan2(saccade_df[\"speed_y\"], saccade_df[\"speed_x\"]))\n",
    "        saccade_df[\"inst_angle_deg\"] = np.degrees(\n",
    "            np.arctan2(saccade_df[\"angular_speed_theta\"], saccade_df[\"angular_speed_phi\"]))\n",
    "\n",
    "        # Define helper function for minimal angular difference (handling circularity)\n",
    "        minimal_angle_diff_deg = lambda a, b: ((a - b + 180) % 360) - 180\n",
    "\n",
    "        angles = saccade_df[\"inst_angle_deg\"].values\n",
    "        # Compute consecutive differences\n",
    "        angle_diffs = np.array([minimal_angle_diff_deg(angles[i + 1], angles[i]) for i in range(len(angles) - 1)])\n",
    "\n",
    "        # Identify candidate segmentation boundaries when the absolute change exceeds threshold.\n",
    "        candidate_boundaries = np.where(np.abs(angle_diffs) > directional_delta_threshold_deg)[0].tolist()\n",
    "\n",
    "        # Always include the first and last frame of the saccade.\n",
    "        boundaries = [0] + candidate_boundaries + [len(saccade_df) - 1]\n",
    "\n",
    "        # Process each segment defined by these boundaries.\n",
    "        for i in range(len(boundaries) - 1):\n",
    "            seg_start = boundaries[i]\n",
    "            seg_end = boundaries[i + 1]\n",
    "            subsaccade = saccade_df.iloc[seg_start: seg_end + 1]\n",
    "            if len(subsaccade) < min_subsaccade_samples:\n",
    "                continue\n",
    "\n",
    "            # Compute net angular displacement using the angular positions (k_phi and k_theta)\n",
    "            initial_pos_angle = subsaccade.iloc[0][[\"k_phi\", \"k_theta\"]]\n",
    "            final_pos_angle = subsaccade.iloc[-1][[\"k_phi\", \"k_theta\"]]\n",
    "            net_disp = np.sqrt((final_pos_angle[\"k_phi\"] - initial_pos_angle[\"k_phi\"]) ** 2 +\n",
    "                               (final_pos_angle[\"k_theta\"] - initial_pos_angle[\"k_theta\"]) ** 2)\n",
    "\n",
    "            # Only record segments whose net displacement is above min_net_disp.\n",
    "            if net_disp < min_net_disp:\n",
    "                continue\n",
    "\n",
    "            # Timing and indices\n",
    "            sub_start_timestamp = subsaccade[\"OE_timestamp\"].iloc[0]\n",
    "            sub_end_timestamp = subsaccade[\"OE_timestamp\"].iloc[-1]\n",
    "            sub_start_ms = subsaccade[\"ms_axis\"].iloc[0]\n",
    "            sub_end_ms = subsaccade[\"ms_axis\"].iloc[-1]\n",
    "            sub_length = subsaccade.index[-1] - subsaccade.index[0]\n",
    "\n",
    "            # Pixel-based metrics\n",
    "            magnitude_raw_pixel = subsaccade[\"speed_r\"].sum()\n",
    "            magnitude_pixel = magnitude_raw_pixel * magnitude_calib\n",
    "\n",
    "            # Angular-based metric: sum of instantaneous angular speeds\n",
    "            magnitude_raw_angular = subsaccade[\"angular_speed_r\"].sum()\n",
    "\n",
    "            # Overall angular-based angle (from start to end)\n",
    "            overall_angle_deg = (np.degrees(np.arctan2(\n",
    "                final_pos_angle[\"k_theta\"] - initial_pos_angle[\"k_theta\"],\n",
    "                final_pos_angle[\"k_phi\"] - initial_pos_angle[\"k_phi\"]\n",
    "            )) % 360)\n",
    "\n",
    "            # (Optional) Capture speed profiles and other details\n",
    "            speed_profile_pixel = subsaccade[\"speed_r\"].values if speed_profile else None\n",
    "            speed_profile_pixel_calib = (speed_profile_pixel * magnitude_calib) if speed_profile else None\n",
    "            speed_profile_angular = subsaccade[\"angular_speed_r\"].values if speed_profile else None\n",
    "            diameter_profile = subsaccade[\"pupil_diameter\"].values\n",
    "\n",
    "            saccade_events.append({\n",
    "                \"saccade_start_ind\": subsaccade.index[0],\n",
    "                \"saccade_end_ind\": subsaccade.index[-1],\n",
    "                \"saccade_start_timestamp\": sub_start_timestamp,\n",
    "                \"saccade_end_timestamp\": sub_end_timestamp,\n",
    "                \"saccade_on_ms\": sub_start_ms,\n",
    "                \"saccade_off_ms\": sub_end_ms,\n",
    "                \"length\": sub_length,\n",
    "                \"magnitude_raw_pixel\": magnitude_raw_pixel,\n",
    "                \"magnitude_pixel\": magnitude_pixel,\n",
    "                \"magnitude_raw_angular\": magnitude_raw_angular,\n",
    "                \"overall_angle_deg\": overall_angle_deg,\n",
    "                \"net_angular_disp\": net_disp,\n",
    "                \"speed_profile_pixel\": speed_profile_pixel,\n",
    "                \"speed_profile_pixel_calib\": speed_profile_pixel_calib,\n",
    "                \"speed_profile_angular\": speed_profile_angular,\n",
    "                \"diameter_profile\": diameter_profile,\n",
    "                \"theta_init_pos\": initial_pos_angle[\"k_theta\"],\n",
    "                \"theta_end_pos\": final_pos_angle[\"k_theta\"],\n",
    "                \"phi_init_pos\": initial_pos_angle[\"k_phi\"],\n",
    "                \"phi_end_pos\": final_pos_angle[\"k_phi\"]\n",
    "            })\n",
    "\n",
    "    # Convert the list to a DataFrame.\n",
    "    saccade_events_df = pd.DataFrame(saccade_events)\n",
    "\n",
    "    # Optionally remove intermediate column\n",
    "    df.drop([\"is_saccade_angle\"], axis=1, inplace=True)\n",
    "\n",
    "    # Calculate delta columns for convenience.\n",
    "    if not saccade_events_df.empty:\n",
    "        saccade_events_df['delta_theta'] = saccade_events_df['theta_end_pos'] - saccade_events_df['theta_init_pos']\n",
    "        saccade_events_df['delta_phi'] = saccade_events_df['phi_end_pos'] - saccade_events_df['phi_init_pos']\n",
    "\n",
    "    return df, saccade_events_df"
   ],
   "id": "86b3e32dba52388b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:20:00.701205Z",
     "start_time": "2025-12-31T08:18:26.689122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for block in block_collection:\n",
    "    print(block)\n",
    "    block.left_eye_data, block.l_saccade_df = create_saccade_events_with_direction_segmentation_robust(\n",
    "        block.left_eye_data,\n",
    "        0.8,  # angular speed threshold in degrees/frame\n",
    "        directional_delta_threshold_deg=90,  # threshold for change in instantaneous angle (degrees)\n",
    "        magnitude_calib=1,\n",
    "        speed_profile=True,\n",
    "        min_subsaccade_samples=2)\n",
    "    block.right_eye_data, block.r_saccade_df = create_saccade_events_with_direction_segmentation_robust(\n",
    "        block.right_eye_data,\n",
    "        0.8,  # angular speed threshold in degrees/frame\n",
    "        directional_delta_threshold_deg=90,  # threshold for change in instantaneous angle (degrees)\n",
    "        magnitude_calib=1,\n",
    "        speed_profile=True,\n",
    "        min_subsaccade_samples=2)\n"
   ],
   "id": "8381368f8068821f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19\n",
      "PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43\n",
      "PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43\n",
      "PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30\n",
      "PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30\n",
      "PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08\n",
      "PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11\n",
      "PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35\n",
      "PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28\n",
      "PV_62, block 024, on 2023-04-27_11-22-56\n",
      "PV_62, block 026, on 2023-04-27_12-21-41\n",
      "PV_62, block 038, on 2023-05-01_13-57-45\n",
      "PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12\n",
      "PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41\n",
      "PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15\n",
      "PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57\n",
      "PV_126, block 011, on PV126_Trial115_eyeTracking_w7\n",
      "PV_126, block 012, on PV126_Trial116_eyeTracking_h8\n",
      "PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31\n",
      "PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18\n",
      "PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35\n",
      "PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39\n",
      "PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:20:02.981391Z",
     "start_time": "2025-12-31T08:20:00.922912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### over here, I get the lizard movements binary from mark's analysis\n",
    "import os\n",
    "def block_get_lizard_movement(block):\n",
    "    # collect accelerometer data\n",
    "    # path definition\n",
    "    p = block.oe_path / 'analysis'\n",
    "    analysis_list = os.listdir(p)\n",
    "    correct_analysis = [i for i in analysis_list if block.animal_call in i][0]\n",
    "    p = p / str(correct_analysis)\n",
    "    mat_path = p / 'lizMov.mat'\n",
    "    print(f'path to mat file is {mat_path}')\n",
    "    # read mat file\n",
    "    try:\n",
    "        mat_data = h5py.File(str(mat_path), 'r')\n",
    "        mat_dict = {'t_mov_ms': mat_data['t_mov_ms'][:],\n",
    "                    'movAll': mat_data['movAll'][:]}\n",
    "\n",
    "        acc_df = pd.DataFrame(data=np.array([mat_dict['t_mov_ms'][:, 0], mat_dict['movAll'][:, 0]]).T,\n",
    "                              columns=['t_mov_ms', 'movAll'])\n",
    "        mat_data.close()\n",
    "        block.liz_mov_df = acc_df\n",
    "        print(f'liz_mov_df created for {block}')\n",
    "    except FileNotFoundError:\n",
    "        print('mat file does not exist - run the matlab getLizMovement function')\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# this cell now labels the saccades as with/without head movements\n",
    "def get_head_mov_col(df, mov_times):\n",
    "    head_mov_bool = np.zeros(len(df), dtype=bool)  # Initialize array of False\n",
    "\n",
    "    for i, saccade in enumerate(df.itertuples()):\n",
    "        saccade_start = saccade.saccade_on_ms\n",
    "        saccade_end = saccade.saccade_off_ms\n",
    "\n",
    "        overlapping_mov_times = mov_times[np.logical_and(mov_times >= saccade_start, mov_times <= saccade_end)]\n",
    "\n",
    "        if overlapping_mov_times.size > 0:\n",
    "            head_mov_bool[i] = True\n",
    "\n",
    "    df['head_movement'] = head_mov_bool\n",
    "    return df\n",
    "\n",
    "def label_saccade_movements(block):\n",
    "    mov_times = block.liz_mov_df.t_mov_ms.values\n",
    "    block.l_saccade_df = get_head_mov_col(block.l_saccade_df,mov_times=mov_times)\n",
    "    block.r_saccade_df = get_head_mov_col(block.r_saccade_df,mov_times=mov_times)\n",
    "\n",
    "# Create a list to store blocks where movement data exists\n",
    "block_collection_w_mov = []\n",
    "\n",
    "for block in block_collection:\n",
    "    try:\n",
    "        block_get_lizard_movement(block)  # Try loading movement data\n",
    "        label_saccade_movements(block)    # Try labeling saccades\n",
    "\n",
    "        # If both steps succeed, add block to the valid collection\n",
    "        block_collection_w_mov.append(block)\n",
    "\n",
    "    except (FileNotFoundError, OSError) as e:\n",
    "        print(f\"Skipping block {block}: {str(e)}\")  # Notify which block failed\n"
   ],
   "id": "ba2e8fba1b530ba5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path to mat file is Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_008\\oe_files\\PV106_ET_d3t12025-08-06_11-52-19\\Record Node 102\\analysis\\recNames=Block008,Animal=PV_106\\lizMov.mat\n",
      "liz_mov_df created for PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_009\\oe_files\\PV106_ET_d3t2_2025-08-06_12-09-43\\Record Node 102\\analysis\\recNames=Block009,Animal=PV_106\\lizMov.mat\n",
      "liz_mov_df created for PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_010\\oe_files\\PV106_ET_d3t3_2025-08-06_12-26-43\\Record Node 102\\analysis\\recNames=Block010,Animal=PV_106\\lizMov.mat\n",
      "liz_mov_df created for PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_011\\oe_files\\PV106_ET_d3t4_2025-08-06_12-44-30\\Record Node 102\\analysis\\recNames=Block011,Animal=PV_106\\lizMov.mat\n",
      "liz_mov_df created for PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_012\\oe_files\\PV106_ET_d3t5_2025-08-06_13-21-30\\Record Node 102\\analysis\\recNames=Block012,Animal=PV_106\\lizMov.mat\n",
      "liz_mov_df created for PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_001\\oe_files\\PV143_ET_d1t1_2025-08-11_13-29-08\\Record Node 102\\analysis\\recNames=Block001,Animal=PV_143\\lizMov.mat\n",
      "liz_mov_df created for PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_002\\oe_files\\PV143_ET_d1t2_2025-08-11_13-50-11\\Record Node 102\\analysis\\recNames=Block002,Animal=PV_143\\lizMov.mat\n",
      "liz_mov_df created for PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_003\\oe_files\\PV143_ET_d1t3_2025-08-11_14-20-35\\Record Node 102\\analysis\\recNames=Block003,Animal=PV_143\\lizMov.mat\n",
      "liz_mov_df created for PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_004\\oe_files\\PV143_ET_d1t4_2025-08-11_14-58-28\\Record Node 103\\analysis\\recNames=Block004,Animal=PV_143\\lizMov.mat\n",
      "liz_mov_df created for PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_024\\oe_files\\2023-04-27_11-22-56\\Record Node 108\\analysis\\recNames=Block0024,Animal=PV_62\\lizMov.mat\n",
      "liz_mov_df created for PV_62, block 024, on 2023-04-27_11-22-56\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_026\\oe_files\\2023-04-27_12-21-41\\Record Node 108\\analysis\\recNames=Block0026,Animal=PV_62\\lizMov.mat\n",
      "liz_mov_df created for PV_62, block 026, on 2023-04-27_12-21-41\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_62\\2023_05_01\\block_038\\oe_files\\2023-05-01_13-57-45\\Record Node 108\\analysis\\recNames=Block0038,Animal=PV_62\\lizMov.mat\n",
      "liz_mov_df created for PV_62, block 038, on 2023-05-01_13-57-45\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\oe_files\\PV126_Trial16_wake3_2024-07-18_12-49-12\\Record Node 102\\analysis\\Animal=PV_126,recNames=block_007\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_008\\oe_files\\PV126_Trial16_wake4_2024-07-18_13-24-41\\Record Node 102\\analysis\\recNames=block_008,Animal=PV_126\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_009\\oe_files\\PV126_Trial18_wake5_2024-07-18_14-39-15\\Record Node 102\\analysis\\recNames=block_009,Animal=PV_126\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_010\\oe_files\\PV126_Trial19_wake6_2024-07-18_15-24-57\\Record Node 102\\analysis\\recNames=block_010,Animal=PV_126\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_011\\oe_files\\PV126_Trial115_eyeTracking_w7\\Record Node 102\\analysis\\recNames=block_011,Animal=PV_126\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 011, on PV126_Trial115_eyeTracking_w7\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_012\\oe_files\\PV126_Trial116_eyeTracking_h8\\Record Node 102\\analysis\\recNames=block_012,Animal=PV_126\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 012, on PV126_Trial116_eyeTracking_h8\n",
      "Skipping block PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31: [WinError 3] The system cannot find the path specified: 'Z:\\\\Nimrod\\\\experiments\\\\PV_57\\\\2024_11_25\\\\block_007\\\\oe_files\\\\pv_57_day2_03_2024-11-25_15-28-31\\\\Record Node 102\\\\analysis'\n",
      "Skipping block PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18: [WinError 3] The system cannot find the path specified: 'Z:\\\\Nimrod\\\\experiments\\\\PV_57\\\\2024_11_25\\\\block_008\\\\oe_files\\\\pv_57_day2_05_2024-11-25_16-07-18\\\\Record Node 102\\\\analysis'\n",
      "Skipping block PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35: [WinError 3] The system cannot find the path specified: 'Z:\\\\Nimrod\\\\experiments\\\\PV_57\\\\2024_11_25\\\\block_009\\\\oe_files\\\\pv_57_day2_06_2024-11-25_16-25-35\\\\Record Node 102\\\\analysis'\n",
      "Skipping block PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39: [WinError 3] The system cannot find the path specified: 'Z:\\\\Nimrod\\\\experiments\\\\PV_57\\\\2024_12_01\\\\block_012\\\\oe_files\\\\PV_57_hunter_2_2024-12-01_16-08-39\\\\Record Node 102\\\\analysis'\n",
      "Skipping block PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43: [WinError 3] The system cannot find the path specified: 'Z:\\\\Nimrod\\\\experiments\\\\PV_57\\\\2024_12_01\\\\block_013\\\\oe_files\\\\PV_57_hunter_2_2024-12-01_16-34-43\\\\Record Node 102\\\\analysis'\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:20:03.105949Z",
     "start_time": "2025-12-31T08:20:03.012801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add annotations for a joint dataframe:\n",
    "for block in block_collection:\n",
    "    block.r_saccade_df['eye'] = 'R'\n",
    "    block.r_saccade_df['block'] = block.block_num\n",
    "    block.r_saccade_df['animal'] = block.animal_call\n",
    "    block.l_saccade_df['eye'] = 'L'\n",
    "    block.l_saccade_df['block'] = block.block_num\n",
    "    block.l_saccade_df['animal'] = block.animal_call\n",
    "    block.all_saccade_df = pd.concat([block.l_saccade_df,block.r_saccade_df])"
   ],
   "id": "ba8d5a92f7c77023",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:20:03.184447Z",
     "start_time": "2025-12-31T08:20:03.140889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "saccade_df_list = []\n",
    "for block in block_collection:\n",
    "    saccade_df_list.append(block.all_saccade_df)\n",
    "saccade_collection = pd.concat(saccade_df_list)"
   ],
   "id": "8efd97fbe1f21463",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:20:07.894637Z",
     "start_time": "2025-12-31T08:20:03.264530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_closest_diff_ind(timestamp, timeseries):\n",
    "    \"\"\"\n",
    "    This function extracts a frame from a series so that it is as close as possible to a given timestamp\n",
    "    :param timestamp: The time to match a frame to\n",
    "    :param timeseries: The time frames series to look at for a match\n",
    "    :param report_acc: if set to 1, will report the accuracy of the match\n",
    "    :return: index_of_lowest_diff , accuracy of match (if requested)\n",
    "    \"\"\"\n",
    "    array = np.abs(timeseries - timestamp)\n",
    "    index_of_lowest_diff = np.argmin(array)\n",
    "    lowest_diff_val = timeseries[index_of_lowest_diff]\n",
    "    return index_of_lowest_diff, lowest_diff_val\n",
    "\n",
    "def find_synced_saccades(df, diff_threshold=680):\n",
    "    synced_saccades = []\n",
    "    non_synced_saccades = []\n",
    "    l_df = df.query('eye == \"L\"')\n",
    "    r_df = df.query('eye == \"R\"')\n",
    "    for i, row in tqdm.tqdm(l_df.iterrows()):\n",
    "        l_timestamp = row['saccade_start_timestamp']\n",
    "        ind_min_diff, r_timestamp = get_closest_diff_ind(l_timestamp, r_df['saccade_start_timestamp'].values)\n",
    "        #print(i,ind_lowest_diff)\n",
    "        time_diff = np.abs(l_timestamp - r_timestamp)\n",
    "        if time_diff < diff_threshold:\n",
    "            synced_saccades.append((row, r_df.iloc[ind_min_diff]))  # Collect synchronized rows\n",
    "        else:\n",
    "            non_synced_saccades.append(row)  # Collect non-synchronized rows\n",
    "    # Create DataFrame with multi-index\n",
    "    multi_index = pd.MultiIndex.from_tuples([(i, 'L') for i in range(len(synced_saccades))] + [(i, 'R') for i in range(len(synced_saccades))], names=['Main', 'Sub'])\n",
    "    synced_df = pd.DataFrame(index=multi_index, columns=df.columns)\n",
    "    # Populate DataFrame\n",
    "    for idx, (l_row, r_row) in enumerate(synced_saccades):\n",
    "        synced_df.loc[(idx, 'L')] = l_row\n",
    "        synced_df.loc[(idx, 'R')] = r_row\n",
    "    r_non_synced_leftovers = r_df[~r_df['saccade_start_timestamp'].isin(synced_df.query('eye == \"R\"')['saccade_start_timestamp'].values)]\n",
    "    print(len(r_non_synced_leftovers),len(r_df))\n",
    "    # Create DataFrame for non-synced saccades\n",
    "    non_synced_df = pd.DataFrame(non_synced_saccades, columns=df.columns)\n",
    "    non_synced_df = pd.concat([non_synced_df,r_non_synced_leftovers])\n",
    "\n",
    "    return synced_df, non_synced_df\n",
    "\n",
    "synced_df_list = []\n",
    "non_synced_df_list = []\n",
    "for saccade_df in saccade_df_list:\n",
    "    # Find synced saccades:\n",
    "    synced_df, non_synced_df = find_synced_saccades(saccade_df.dropna(), diff_threshold=680)\n",
    "    if len(non_synced_df.dropna()) + len(synced_df.dropna()) == len(saccade_df.dropna()):\n",
    "        print('got them all')\n",
    "\n",
    "    synced_df_list.append(synced_df)\n",
    "    non_synced_df_list.append(non_synced_df)\n"
   ],
   "id": "8a73da13a0d1842a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "924it [00:00, 8062.92it/s]\n",
      "395it [00:00, 7064.34it/s]\n",
      "472it [00:00, 9466.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 517\n",
      "102 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1273it [00:00, 7883.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "724it [00:00, 4969.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377 961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "519it [00:00, 6277.02it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333 650\n",
      "234 565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "322it [00:00, 6996.30it/s]\n",
      "387it [00:00, 7404.08it/s]\n",
      "265it [00:00, 8161.08it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 320\n",
      "256 495\n",
      "93 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "675it [00:00, 7241.97it/s]\n",
      "623it [00:00, 7834.44it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 638\n",
      "374 761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1090it [00:00, 7745.22it/s]\n",
      "648it [00:00, 6420.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071 1649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1409it [00:00, 6591.16it/s]\n",
      "429it [00:00, 8260.86it/s]\n",
      "529it [00:00, 6992.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435 1315\n",
      "289 541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "271it [00:00, 7551.98it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 539\n",
      "183 353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1056it [00:00, 6018.77it/s]\n",
      "112it [00:00, 9734.99it/s]\n",
      "934it [00:00, 6888.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539 1251\n",
      "53 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "949it [00:00, 6507.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635 2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "794it [00:00, 7678.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461 1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "786it [00:00, 5741.14it/s]\n",
      "635it [00:00, 6334.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487 888\n",
      "286 763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:00, 4866.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573 1245\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:20:08.028322Z",
     "start_time": "2025-12-31T08:20:07.965881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_synced_dataframes(dataframes):\n",
    "    combined_dfs = []\n",
    "    start_index = 0\n",
    "    for df in dataframes:\n",
    "        num_rows = len(df) // 2  # Assuming each dataframe contains pairs of rows\n",
    "        main_index = pd.MultiIndex.from_tuples([(i + start_index, 'L') for i in range(num_rows)] + [(i + start_index, 'R') for i in range(num_rows)], names=['Main', 'Sub'])\n",
    "        df.index = main_index\n",
    "        combined_dfs.append(df)\n",
    "        start_index += num_rows\n",
    "    combined_df = pd.concat(combined_dfs)\n",
    "    combined_df.reset_index(inplace=True)\n",
    "    return combined_df\n",
    "\n",
    "synced_saccade_collection = combine_synced_dataframes(synced_df_list)\n",
    "non_synced_saccade_collection = pd.concat(non_synced_df_list)\n",
    "\n"
   ],
   "id": "b468fce282724d27",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:23:34.941015Z",
     "start_time": "2025-12-31T08:23:34.907699Z"
    }
   },
   "cell_type": "code",
   "source": "all_saccade_collection = pd.concat([synced_saccade_collection,non_synced_saccade_collection])",
   "id": "6718f66c3ef63476",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:23:43.199584Z",
     "start_time": "2025-12-31T08:23:35.937155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#clean monocular saccade df from false detections (actually not monocular):\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helper: find left/right per-frame eye trace dfs in a block\n",
    "# ------------------------------------------------------------\n",
    "def _get_eye_df_from_block(block, candidates):\n",
    "    for attr in candidates:\n",
    "        if hasattr(block, attr):\n",
    "            df = getattr(block, attr)\n",
    "            if isinstance(df, pd.DataFrame) and len(df) > 0:\n",
    "                return df\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_eye_trace_lookup_from_block_collection(\n",
    "    block_collection,\n",
    "    animal_attr=\"animal_call\",\n",
    "    block_attr=\"block_num\",\n",
    "    left_df_attrs=None,\n",
    "    right_df_attrs=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      eye_trace_lookup[(animal, block, 'L'/'R')] = per-frame eye dataframe\n",
    "\n",
    "    Notes:\n",
    "    - You may need to adjust left_df_attrs/right_df_attrs to match your BlockSync object fields.\n",
    "    \"\"\"\n",
    "    if left_df_attrs is None:\n",
    "        left_df_attrs = [\"left_eye_data\",\"l_eye_df\", \"left_eye_df\", \"l_df\", \"left_df\", \"l_eye_data_df\", \"left_eye_data_df\"]\n",
    "    if right_df_attrs is None:\n",
    "        right_df_attrs = [\"right_eye_data\",\"r_eye_df\", \"right_eye_df\", \"r_df\", \"right_df\", \"r_eye_data_df\", \"right_eye_data_df\"]\n",
    "\n",
    "    lookup = {}\n",
    "    for blk in block_collection:\n",
    "        animal = getattr(blk, animal_attr, \"unknown\")\n",
    "        bnum = getattr(blk, block_attr, \"unknown\")\n",
    "\n",
    "        ldf = _get_eye_df_from_block(blk, left_df_attrs)\n",
    "        rdf = _get_eye_df_from_block(blk, right_df_attrs)\n",
    "\n",
    "        if ldf is not None:\n",
    "            lookup[(animal, bnum, \"L\")] = ldf\n",
    "        if rdf is not None:\n",
    "            lookup[(animal, bnum, \"R\")] = rdf\n",
    "\n",
    "    return lookup\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Core: verify monocular by checking other-eye speed near onset\n",
    "# ------------------------------------------------------------\n",
    "def annotate_monocular_by_other_eye_speed(\n",
    "    non_synced_df,\n",
    "    eye_trace_lookup,\n",
    "    t0_col=\"saccade_on_ms\",\n",
    "    eye_col=\"eye\",\n",
    "    animal_col=\"animal\",\n",
    "    block_col=\"block\",\n",
    "    ms_col=\"ms_axis\",\n",
    "    speed_col=\"angular_speed_r\",\n",
    "    window_ms=80,\n",
    "    speed_thresh=5.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds:\n",
    "      - other_eye_peak_speed\n",
    "      - verified_monocular (True/False/NaN)\n",
    "        True  = other-eye peak speed < speed_thresh in +/- window_ms\n",
    "        False = other-eye peak speed >= speed_thresh\n",
    "        NaN   = missing trace/cols/window\n",
    "\n",
    "    Returns: annotated dataframe\n",
    "    \"\"\"\n",
    "    d = non_synced_df.copy()\n",
    "\n",
    "    # Support alternative eye labeling if needed (e.g., 'Sub' == 'L'/'R')\n",
    "    if eye_col not in d.columns and \"Sub\" in d.columns:\n",
    "        d[eye_col] = d[\"Sub\"]\n",
    "\n",
    "    peaks = []\n",
    "    verified = []\n",
    "\n",
    "    for _, r in d.iterrows():\n",
    "        try:\n",
    "            animal = r[animal_col]\n",
    "            block = r[block_col]\n",
    "            eye = r[eye_col]\n",
    "            t0 = float(r[t0_col])\n",
    "        except Exception:\n",
    "            peaks.append(np.nan)\n",
    "            verified.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        if not np.isfinite(t0) or eye not in (\"L\", \"R\"):\n",
    "            peaks.append(np.nan)\n",
    "            verified.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        other_eye = \"R\" if eye == \"L\" else \"L\"\n",
    "        key = (animal, block, other_eye)\n",
    "\n",
    "        if key not in eye_trace_lookup:\n",
    "            peaks.append(np.nan)\n",
    "            verified.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        tr = eye_trace_lookup[key]\n",
    "        if (ms_col not in tr.columns) or (speed_col not in tr.columns):\n",
    "            peaks.append(np.nan)\n",
    "            verified.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        ms = tr[ms_col].astype(float).to_numpy()\n",
    "        sp = tr[speed_col].astype(float).to_numpy()\n",
    "\n",
    "        m = (ms >= (t0 - window_ms)) & (ms <= (t0 + window_ms)) & np.isfinite(sp)\n",
    "        if not np.any(m):\n",
    "            peaks.append(np.nan)\n",
    "            verified.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        peak = float(np.nanmax(sp[m]))\n",
    "        peaks.append(peak)\n",
    "        verified.append(bool(peak < float(speed_thresh)))\n",
    "\n",
    "    d[\"other_eye_peak_speed\"] = np.asarray(peaks, dtype=float)\n",
    "    d[\"verified_monocular\"] = verified\n",
    "    return d\n",
    "\n",
    "\n",
    "def create_verified_monocular_saccade_collection(\n",
    "    non_synced_saccade_collection,\n",
    "    block_collection,\n",
    "    t0_col=\"saccade_on_ms\",\n",
    "    ms_col=\"ms_axis\",\n",
    "    speed_col=\"angular_speed_r\",\n",
    "    window_ms=80,\n",
    "    speed_thresh=5.0,\n",
    "    keep_unverifiable=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Pipeline entry-point:\n",
    "      Input: non_synced_saccade_collection (your monocular candidates)\n",
    "      Output:\n",
    "        - verified_monocular_saccade_collection (subset)\n",
    "        - annotated_non_synced_df (with other_eye_peak_speed + verified_monocular column)\n",
    "        - diagnostics dict\n",
    "    \"\"\"\n",
    "    eye_trace_lookup = build_eye_trace_lookup_from_block_collection(block_collection)\n",
    "\n",
    "    annotated = annotate_monocular_by_other_eye_speed(\n",
    "        non_synced_df=non_synced_saccade_collection,\n",
    "        eye_trace_lookup=eye_trace_lookup,\n",
    "        t0_col=t0_col,\n",
    "        ms_col=ms_col,\n",
    "        speed_col=speed_col,\n",
    "        window_ms=window_ms,\n",
    "        speed_thresh=speed_thresh,\n",
    "    )\n",
    "\n",
    "    vc = annotated[\"verified_monocular\"].value_counts(dropna=False)\n",
    "    n_true = int(vc.get(True, 0))\n",
    "    n_false = int(vc.get(False, 0))\n",
    "    n_nan = int(vc.get(np.nan, 0))\n",
    "    n_total = len(annotated)\n",
    "\n",
    "    if keep_unverifiable:\n",
    "        # treat NaN as \"not verified but keep\"\n",
    "        verified_df = annotated.loc[(annotated[\"verified_monocular\"] == True) | (annotated[\"verified_monocular\"].isna())].copy()\n",
    "    else:\n",
    "        verified_df = annotated.loc[annotated[\"verified_monocular\"] == True].copy()\n",
    "\n",
    "    diagnostics = {\n",
    "        \"lookup_entries\": len(eye_trace_lookup),\n",
    "        \"n_total_non_synced\": n_total,\n",
    "        \"n_verified_true\": n_true,\n",
    "        \"n_verified_false\": n_false,\n",
    "        \"n_verified_nan\": n_nan,\n",
    "        \"verified_fraction_of_classifiable\": (n_true / float(n_true + n_false)) if (n_true + n_false) > 0 else np.nan,\n",
    "        \"nan_fraction\": (n_nan / float(n_total)) if n_total > 0 else np.nan,\n",
    "        \"speed_col\": speed_col,\n",
    "        \"speed_thresh\": speed_thresh,\n",
    "        \"window_ms\": window_ms,\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Lookup entries:\", diagnostics[\"lookup_entries\"])\n",
    "        print(\"verified_monocular counts:\", vc.to_dict())\n",
    "        print(\"Verified fraction (of classifiable True/False):\", diagnostics[\"verified_fraction_of_classifiable\"])\n",
    "\n",
    "    return verified_df, annotated, diagnostics\n",
    "\n",
    "verified_monocular_saccade_collection, non_synced_annotated, mono_diag = create_verified_monocular_saccade_collection(\n",
    "    non_synced_saccade_collection=non_synced_saccade_collection,\n",
    "    block_collection=block_collection,          # IMPORTANT: use the full/original one\n",
    "    speed_col=\"angular_speed_r\",                # or \"speed_r\" if that's what your eye dfs have\n",
    "    ms_col=\"ms_axis\",\n",
    "    t0_col=\"saccade_on_ms\",\n",
    "    window_ms=80,\n",
    "    speed_thresh=0.8,                   # use the threshold you just tuned\n",
    "    keep_unverifiable=False,                    # strict\n",
    "    verbose=True,\n",
    ")\n"
   ],
   "id": "c59c92af8d6e3b5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookup entries: 46\n",
      "verified_monocular counts: {False: 7292, True: 5321, nan: 1679}\n",
      "Verified fraction (of classifiable True/False): 0.42186632839134225\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:23:45.011094Z",
     "start_time": "2025-12-31T08:23:43.309877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def compute_event_stats_from_synced_tables(\n",
    "    synced_saccade_collection: pd.DataFrame,\n",
    "    non_synced_saccade_collection: pd.DataFrame,\n",
    "    head_col: str = \"head_movement\",\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Uses your existing verified annotation:\n",
    "      - synced_saccade_collection: paired L/R saccades, with columns ['Main','Sub', ...] after reset_index()\n",
    "      - non_synced_saccade_collection: unpaired single-eye saccades\n",
    "\n",
    "    Returns:\n",
    "      per_animal_df, overall_df\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------\n",
    "    # 1) Build event-level df\n",
    "    # -----------------------\n",
    "    events = []\n",
    "\n",
    "    # Binocular events: group by (animal, block, Main) in synced collection\n",
    "    if len(synced_saccade_collection) > 0:\n",
    "        required = set([\"animal\", \"block\", \"Main\", head_col])\n",
    "        missing = required - set(synced_saccade_collection.columns)\n",
    "        if missing:\n",
    "            raise ValueError(\"synced_saccade_collection missing columns: %s\" % sorted(list(missing)))\n",
    "\n",
    "        gcols = [\"animal\", \"block\", \"Main\"]\n",
    "        for (animal, block, main), g in synced_saccade_collection.groupby(gcols, dropna=False):\n",
    "            # event is binocular by definition\n",
    "            # head movement at event-level: OR across the two eyes (robust)\n",
    "            head_m = bool(np.any(g[head_col].astype(bool).to_numpy()))\n",
    "            events.append(dict(\n",
    "                animal=animal,\n",
    "                block=block,\n",
    "                event_type=\"binocular\",\n",
    "                head_movement=head_m,\n",
    "            ))\n",
    "\n",
    "    # Monocular events: each row is one event\n",
    "    if len(non_synced_saccade_collection) > 0:\n",
    "        required = set([\"animal\", \"block\", head_col])\n",
    "        missing = required - set(non_synced_saccade_collection.columns)\n",
    "        if missing:\n",
    "            raise ValueError(\"non_synced_saccade_collection missing columns: %s\" % sorted(list(missing)))\n",
    "\n",
    "        for _, r in non_synced_saccade_collection.iterrows():\n",
    "            events.append(dict(\n",
    "                animal=r[\"animal\"],\n",
    "                block=r[\"block\"],\n",
    "                event_type=\"monocular\",\n",
    "                head_movement=bool(r[head_col]),\n",
    "            ))\n",
    "\n",
    "    events = pd.DataFrame(events)\n",
    "    if events.empty:\n",
    "        raise RuntimeError(\"No events created. Check that synced/non-synced tables are non-empty.\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 2) Per-animal summary\n",
    "    # -----------------------\n",
    "    out = []\n",
    "    for animal, aev in events.groupby(\"animal\"):\n",
    "        total = len(aev)\n",
    "        still = aev.loc[~aev[\"head_movement\"].astype(bool)]\n",
    "        moving = aev.loc[aev[\"head_movement\"].astype(bool)]\n",
    "\n",
    "        def pct_monocular(df):\n",
    "            if len(df) == 0:\n",
    "                return np.nan\n",
    "            return 100.0 * np.mean(df[\"event_type\"].to_numpy() == \"monocular\")\n",
    "\n",
    "        out.append(dict(\n",
    "            animal=animal,\n",
    "            n_events=total,\n",
    "            pct_events_head_still=100.0 * len(still) / total if total else np.nan,\n",
    "            pct_events_head_moving=100.0 * len(moving) / total if total else np.nan,\n",
    "            pct_monocular_when_head_still=pct_monocular(still),\n",
    "            pct_monocular_when_head_moving=pct_monocular(moving),\n",
    "            n_head_still=len(still),\n",
    "            n_head_moving=len(moving),\n",
    "        ))\n",
    "\n",
    "    per_animal = pd.DataFrame(out).sort_values(\"animal\").reset_index(drop=True)\n",
    "\n",
    "    # -----------------------\n",
    "    # 3) Overall summary\n",
    "    # -----------------------\n",
    "    def mean_sem(x):\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        x = x[np.isfinite(x)]\n",
    "        if x.size == 0:\n",
    "            return np.nan, np.nan\n",
    "        mean = float(np.mean(x))\n",
    "        sem = float(np.std(x, ddof=1) / np.sqrt(x.size)) if x.size > 1 else np.nan\n",
    "        return mean, sem\n",
    "\n",
    "    pooled_pct_head_still = 100.0 * np.mean(~events[\"head_movement\"].astype(bool))\n",
    "    pooled_pct_mono_still = (\n",
    "        100.0 * np.mean(events.loc[~events[\"head_movement\"].astype(bool), \"event_type\"].to_numpy() == \"monocular\")\n",
    "        if np.any(~events[\"head_movement\"].astype(bool)) else np.nan\n",
    "    )\n",
    "    pooled_pct_mono_moving = (\n",
    "        100.0 * np.mean(events.loc[events[\"head_movement\"].astype(bool), \"event_type\"].to_numpy() == \"monocular\")\n",
    "        if np.any(events[\"head_movement\"].astype(bool)) else np.nan\n",
    "    )\n",
    "\n",
    "    m1, s1 = mean_sem(per_animal[\"pct_events_head_still\"])\n",
    "    m2, s2 = mean_sem(per_animal[\"pct_monocular_when_head_still\"])\n",
    "    m3, s3 = mean_sem(per_animal[\"pct_monocular_when_head_moving\"])\n",
    "\n",
    "    overall = pd.DataFrame([\n",
    "        dict(metric=\"pct_events_head_still\",\n",
    "             mean_across_animals=m1, sem_across_animals=s1,\n",
    "             pooled_value=pooled_pct_head_still, pooled_n_events=len(events)),\n",
    "        dict(metric=\"pct_monocular_when_head_still\",\n",
    "             mean_across_animals=m2, sem_across_animals=s2,\n",
    "             pooled_value=pooled_pct_mono_still, pooled_n_events=len(events)),\n",
    "        dict(metric=\"pct_monocular_when_head_moving\",\n",
    "             mean_across_animals=m3, sem_across_animals=s3,\n",
    "             pooled_value=pooled_pct_mono_moving, pooled_n_events=len(events)),\n",
    "    ])\n",
    "\n",
    "    return per_animal, overall\n",
    "compute_event_stats_from_synced_tables(synced_saccade_collection,verified_monocular_saccade_collection)"
   ],
   "id": "bdfad1c3e61d2540",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   animal  n_events  pct_events_head_still  pct_events_head_moving  \\\n",
       " 0  PV_106      3398              40.435550               59.564450   \n",
       " 1  PV_126      3456              39.409722               60.590278   \n",
       " 2  PV_143      1240              29.677419               70.322581   \n",
       " 3   PV_57      5254               0.000000              100.000000   \n",
       " 4   PV_62      2265              56.600442               43.399558   \n",
       " \n",
       "    pct_monocular_when_head_still  pct_monocular_when_head_moving  \\\n",
       " 0                      70.524017                       13.982213   \n",
       " 1                      27.973568                       15.759312   \n",
       " 2                      45.923913                       12.041284   \n",
       " 3                            NaN                       41.720594   \n",
       " 4                      51.170047                       24.008138   \n",
       " \n",
       "    n_head_still  n_head_moving  \n",
       " 0          1374           2024  \n",
       " 1          1362           2094  \n",
       " 2           368            872  \n",
       " 3             0           5254  \n",
       " 4          1282            983  ,\n",
       "                            metric  mean_across_animals  sem_across_animals  \\\n",
       " 0           pct_events_head_still            33.224627            9.362532   \n",
       " 1   pct_monocular_when_head_still            48.897886            8.753684   \n",
       " 2  pct_monocular_when_head_moving            21.502308            5.450243   \n",
       " \n",
       "    pooled_value  pooled_n_events  \n",
       " 0     28.091975            15613  \n",
       " 1     49.589603            15613  \n",
       " 2     28.021733            15613  )"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:23:58.381301Z",
     "start_time": "2025-12-31T08:23:45.110303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# verify the numerousity of monocular events here:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def relabel_pairs_by_window_overlap(\n",
    "    synced_saccade_collection: pd.DataFrame,\n",
    "    non_synced_saccade_collection: pd.DataFrame,\n",
    "    all_saccade_collection: pd.DataFrame,\n",
    "    on_col: str = \"saccade_on_ms\",\n",
    "    off_col: str = \"saccade_off_ms\",\n",
    "    eye_col: str = \"eye\",\n",
    "    animal_col: str = \"animal\",\n",
    "    block_col: str = \"block\",\n",
    "    max_onset_dt_ms: float = 40.0,\n",
    "    min_overlap_ms: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Re-check each 'non_synced' event: does the other eye have a saccade whose window overlaps?\n",
    "    If yes -> reclassify as binocular (was \"missed pair\").\n",
    "    Requires all_saccade_collection to include BOTH eyes' saccade windows (L+R) with on/off times.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start by treating current synced as binocular events; non_synced as monocular candidates\n",
    "    non = non_synced_saccade_collection.copy()\n",
    "\n",
    "    # Make sure we know which eye each non-synced event belongs to\n",
    "    if eye_col not in non.columns:\n",
    "        raise ValueError(\"non_synced_saccade_collection must include an 'eye' column (L/R).\")\n",
    "\n",
    "    # We'll look up candidate matches in the opposite eye within each animal+block\n",
    "    all_df = all_saccade_collection.copy()\n",
    "\n",
    "    # Basic guards\n",
    "    for c in [animal_col, block_col, eye_col, on_col, off_col]:\n",
    "        if c not in all_df.columns:\n",
    "            raise ValueError(f\"all_saccade_collection missing required column: {c}\")\n",
    "\n",
    "    # Index all events by animal+block for fast filtering\n",
    "    grouped = dict(tuple(all_df.groupby([animal_col, block_col], dropna=False)))\n",
    "\n",
    "    reclassified = np.zeros(len(non), dtype=bool)\n",
    "\n",
    "    for i, r in non.iterrows():\n",
    "        key = (r[animal_col], r[block_col])\n",
    "        if key not in grouped:\n",
    "            continue\n",
    "\n",
    "        eye = r[eye_col]\n",
    "        other_eye = \"R\" if eye == \"L\" else \"L\"\n",
    "        s0 = float(r[on_col])\n",
    "        s1 = float(r[off_col])\n",
    "        if not (np.isfinite(s0) and np.isfinite(s1)):\n",
    "            continue\n",
    "\n",
    "        cand = grouped[key]\n",
    "        cand = cand[cand[eye_col] == other_eye]\n",
    "\n",
    "        if cand.empty:\n",
    "            continue\n",
    "\n",
    "        # onset proximity constraint (optional but helps avoid nonsense matches)\n",
    "        cand_on = cand[on_col].astype(float).to_numpy()\n",
    "        onset_dt = np.abs(cand_on - s0)\n",
    "        cand = cand.loc[onset_dt <= max_onset_dt_ms]\n",
    "        if cand.empty:\n",
    "            continue\n",
    "\n",
    "        # overlap condition\n",
    "        c0 = cand[on_col].astype(float).to_numpy()\n",
    "        c1 = cand[off_col].astype(float).to_numpy()\n",
    "        overlap = np.minimum(s1, c1) - np.maximum(s0, c0)  # positive => overlap in ms\n",
    "\n",
    "        if np.any(overlap >= min_overlap_ms):\n",
    "            reclassified[i] = True\n",
    "\n",
    "    # Build adjusted event tables\n",
    "    non[\"reclassified_as_binocular\"] = reclassified\n",
    "    adj_non_synced = non.loc[~non[\"reclassified_as_binocular\"]].copy()\n",
    "\n",
    "    # Return updated non-synced + a count\n",
    "    return adj_non_synced, int(np.sum(reclassified))\n",
    "\n",
    "adj_non, n_repaired = relabel_pairs_by_window_overlap(\n",
    "    synced_saccade_collection,\n",
    "    non_synced_saccade_collection,\n",
    "    all_saccade_collection,\n",
    "    max_onset_dt_ms=40,     # start with 2060 ms\n",
    "    min_overlap_ms=0,       # or try 510 ms\n",
    ")\n",
    "print(\"Repaired (formerly 'monocular' but window-overlap matched):\", n_repaired)\n"
   ],
   "id": "daef0429b6d00bbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repaired (formerly 'monocular' but window-overlap matched): 795\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:24:17.418930Z",
     "start_time": "2025-12-31T08:24:04.437679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def confirm_monocular_by_other_eye_speed(\n",
    "    non_synced_df: pd.DataFrame,\n",
    "    eye_trace_lookup: dict,\n",
    "    # eye_trace_lookup[(animal, block, eye)] -> dataframe with ms_axis and speed column\n",
    "    t0_col=\"saccade_on_ms\",\n",
    "    eye_col=\"eye\",\n",
    "    animal_col=\"animal\",\n",
    "    block_col=\"block\",\n",
    "    ms_col=\"ms_axis\",\n",
    "    speed_col=\"angular_speed_r\",\n",
    "    window_ms=80,\n",
    "    speed_thresh=150,  # set based on your speed units/distribution\n",
    "):\n",
    "    \"\"\"\n",
    "    Labels each non-synced event as 'confirmed_monocular' if the other eye has NO speed peak\n",
    "    above speed_thresh in +/- window_ms around event onset.\n",
    "    \"\"\"\n",
    "    d = non_synced_df.copy()\n",
    "    confirmed = []\n",
    "\n",
    "    for _, r in d.iterrows():\n",
    "        animal, block, eye = r[animal_col], r[block_col], r[eye_col]\n",
    "        other_eye = \"R\" if eye == \"L\" else \"L\"\n",
    "        t0 = float(r[t0_col])\n",
    "\n",
    "        key = (animal, block, other_eye)\n",
    "        if key not in eye_trace_lookup:\n",
    "            confirmed.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        tr = eye_trace_lookup[key]\n",
    "        if ms_col not in tr.columns or speed_col not in tr.columns:\n",
    "            confirmed.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        ms = tr[ms_col].astype(float).to_numpy()\n",
    "        sp = tr[speed_col].astype(float).to_numpy()\n",
    "\n",
    "        m = (ms >= t0 - window_ms) & (ms <= t0 + window_ms) & np.isfinite(sp)\n",
    "        if not np.any(m):\n",
    "            confirmed.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        peak = np.nanmax(sp[m])\n",
    "        confirmed.append(bool(peak < speed_thresh))\n",
    "\n",
    "    d[\"confirmed_monocular_by_speed\"] = confirmed\n",
    "    return d\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- paste/keep your function definition somewhere above this cell ---\n",
    "# def confirm_monocular_by_other_eye_speed(...): ...\n",
    "\n",
    "\n",
    "def build_eye_trace_lookup_from_block_collection(\n",
    "    block_collection,\n",
    "    eye_df_attr_left=\"left_eye_data\",\n",
    "    eye_df_attr_right=\"right_eye_data\",\n",
    "    animal_attr=\"animal_call\",\n",
    "    block_attr=\"block_num\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      eye_trace_lookup[(animal, block, 'L'/'R')] = per-frame dataframe\n",
    "    \"\"\"\n",
    "    eye_trace_lookup = {}\n",
    "\n",
    "    for blk in block_collection:\n",
    "        animal = getattr(blk, animal_attr, \"unknown\")\n",
    "        bnum = getattr(blk, block_attr, \"unknown\")\n",
    "\n",
    "        ldf = getattr(blk, eye_df_attr_left, None)\n",
    "        rdf = getattr(blk, eye_df_attr_right, None)\n",
    "\n",
    "        if isinstance(ldf, pd.DataFrame) and len(ldf) > 0:\n",
    "            eye_trace_lookup[(animal, bnum, \"L\")] = ldf\n",
    "\n",
    "        if isinstance(rdf, pd.DataFrame) and len(rdf) > 0:\n",
    "            eye_trace_lookup[(animal, bnum, \"R\")] = rdf\n",
    "\n",
    "    return eye_trace_lookup\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 1) Build lookup table\n",
    "# ------------------------\n",
    "eye_trace_lookup = build_eye_trace_lookup_from_block_collection(block_collection)\n",
    "\n",
    "print(\"Lookup entries:\", len(eye_trace_lookup))\n",
    "# Example keys: next(iter(eye_trace_lookup.keys()))\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 2) Run confirmation test\n",
    "# ------------------------\n",
    "# IMPORTANT:\n",
    "# - t0_col should match what you want to anchor on (onset is usually best): 'saccade_on_ms'\n",
    "# - ms_col must exist in eye dfs: usually 'ms_axis'\n",
    "# - speed_col must exist: try 'angular_speed_r' first, else maybe 'speed_r'\n",
    "# - speed_thresh must be in the same units as speed_col\n",
    "\n",
    "non_confirmed = confirm_monocular_by_other_eye_speed(\n",
    "    non_synced_df=non_synced_saccade_collection,\n",
    "    eye_trace_lookup=eye_trace_lookup,\n",
    "    t0_col=\"saccade_on_ms\",\n",
    "    eye_col=\"eye\",\n",
    "    animal_col=\"animal\",\n",
    "    block_col=\"block\",\n",
    "    ms_col=\"ms_axis\",\n",
    "    speed_col=\"angular_speed_r\",\n",
    "    window_ms=80,          # start with 80 ms; also try 50/100\n",
    "    speed_thresh=0.8,\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# 3) Summarize results\n",
    "# ------------------------\n",
    "# confirmed_monocular_by_speed == True  -> other eye stayed below threshold (confirmed monocular)\n",
    "# confirmed_monocular_by_speed == False -> other eye had a speed peak (likely \"missed binocular\")\n",
    "# confirmed_monocular_by_speed == NaN   -> missing trace / columns / window\n",
    "\n",
    "print(non_confirmed[\"confirmed_monocular_by_speed\"].value_counts(dropna=False))\n",
    "\n",
    "# Optional: confirm rates by head condition (if head_movement exists in non_synced df)\n",
    "if \"head_movement\" in non_confirmed.columns:\n",
    "    tmp = non_confirmed.copy()\n",
    "    tmp[\"head_state\"] = np.where(tmp[\"head_movement\"].astype(bool), \"moving\", \"still\")\n",
    "    print(\n",
    "        tmp.groupby(\"head_state\")[\"confirmed_monocular_by_speed\"]\n",
    "           .value_counts(normalize=True, dropna=False)\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 4) (Recommended) Tune speed_thresh empirically\n",
    "# ------------------------\n",
    "# Look at the distribution of the OTHER-eye peak speeds around non-synced events\n",
    "# by temporarily modifying the function to store peak, or do a quick estimate here:\n",
    "\n",
    "def compute_other_eye_peak_speeds(\n",
    "    non_synced_df, eye_trace_lookup,\n",
    "    t0_col=\"saccade_on_ms\", eye_col=\"eye\", animal_col=\"animal\", block_col=\"block\",\n",
    "    ms_col=\"ms_axis\", speed_col=\"angular_speed_r\",\n",
    "    window_ms=80\n",
    "):\n",
    "    peaks = []\n",
    "    for _, r in non_synced_df.iterrows():\n",
    "        animal, block, eye = r[animal_col], r[block_col], r[eye_col]\n",
    "        other_eye = \"R\" if eye == \"L\" else \"L\"\n",
    "        t0 = float(r[t0_col])\n",
    "        key = (animal, block, other_eye)\n",
    "        if key not in eye_trace_lookup:\n",
    "            peaks.append(np.nan)\n",
    "            continue\n",
    "        tr = eye_trace_lookup[key]\n",
    "        if ms_col not in tr.columns or speed_col not in tr.columns:\n",
    "            peaks.append(np.nan)\n",
    "            continue\n",
    "        ms = tr[ms_col].astype(float).to_numpy()\n",
    "        sp = tr[speed_col].astype(float).to_numpy()\n",
    "        m = (ms >= t0 - window_ms) & (ms <= t0 + window_ms) & np.isfinite(sp)\n",
    "        if not np.any(m):\n",
    "            peaks.append(np.nan)\n",
    "        else:\n",
    "            peaks.append(float(np.nanmax(sp[m])))\n",
    "    return np.asarray(peaks, dtype=float)\n",
    "\n",
    "peaks = compute_other_eye_peak_speeds(\n",
    "    non_synced_saccade_collection, eye_trace_lookup,\n",
    "    speed_col=\"angular_speed_r\", window_ms=80\n",
    ")\n",
    "\n",
    "print(\"Other-eye peak speed percentiles (non-synced events):\",\n",
    "      np.nanpercentile(peaks, [50, 75, 90, 95, 99]))\n"
   ],
   "id": "d4b814043321e52c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookup entries: 46\n",
      "False    7292\n",
      "True     5321\n",
      "NaN      1679\n",
      "Name: confirmed_monocular_by_speed, dtype: int64\n",
      "head_state  confirmed_monocular_by_speed\n",
      "moving      False                           0.575376\n",
      "            True                            0.338280\n",
      "            NaN                             0.086344\n",
      "still       True                            0.435697\n",
      "            False                           0.388822\n",
      "            NaN                             0.175481\n",
      "Name: confirmed_monocular_by_speed, dtype: float64\n",
      "Other-eye peak speed percentiles (non-synced events): [ 1.06764261  2.8285699   5.01649533  6.59673655 11.82123613]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:24:17.574680Z",
     "start_time": "2025-12-31T08:24:17.560653Z"
    }
   },
   "cell_type": "code",
   "source": "print(synced_saccade_collection.groupby([\"animal\",\"block\",\"Main\"]).size().value_counts())\n",
   "id": "58f8ae367d6c6caf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    10292\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:22:54.215650Z",
     "start_time": "2025-12-31T08:22:54.187652Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e8a5774b055a1444",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:24:23.746951Z",
     "start_time": "2025-12-31T08:24:23.732433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional, Union, List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# =========================\n",
    "# Sterile annotation settings\n",
    "# =========================\n",
    "CURATION_DIRNAME = \"curation_monocular_video\"     # under each block.analysis_path\n",
    "CURATION_CSV_NAME = \"monocular_video_curation.csv\"\n",
    "\n",
    "# tri-state: {True, False, None}\n",
    "INCLUDE_COL = \"include_in_monocular_video\"\n",
    "TS_COL = \"annotation_timestamp\"\n",
    "\n",
    "\n",
    "def _first_existing(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def _require_col(df, candidates, what):\n",
    "    c = _first_existing(df, candidates)\n",
    "    if c is None:\n",
    "        raise KeyError(\n",
    "            \"Missing {}. Tried: {}. Existing columns (first 40): {}\".format(\n",
    "                what, candidates, list(df.columns)[:40]\n",
    "            )\n",
    "        )\n",
    "    return c\n",
    "\n",
    "\n",
    "def _coerce_tristate_bool(v):\n",
    "    if v is None:\n",
    "        return None\n",
    "    try:\n",
    "        # np.nan handling\n",
    "        if isinstance(v, float) and np.isnan(v):\n",
    "            return None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if isinstance(v, (bool, np.bool_)):\n",
    "        return bool(v)\n",
    "\n",
    "    s = str(v).strip().lower()\n",
    "    if s in (\"true\", \"t\", \"1\", \"yes\", \"y\"):\n",
    "        return True\n",
    "    if s in (\"false\", \"f\", \"0\", \"no\", \"n\"):\n",
    "        return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def _zfill_block(x):\n",
    "    s = str(x)\n",
    "    return s.zfill(3) if s.isdigit() else s\n"
   ],
   "id": "e3146f60abb141e0",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:36:51.450359Z",
     "start_time": "2025-12-31T08:36:45.989244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _pick_first_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _norm_block_key(x):\n",
    "    # try to make a \"best effort\" key that matches whatever is in eye_trace_lookup\n",
    "    # (many of your objects store block_num as int-like)\n",
    "    s = str(x)\n",
    "    try:\n",
    "        return str(int(float(s)))\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "def attach_other_eye_peak_speed(\n",
    "    non_synced_df,\n",
    "    eye_trace_lookup,\n",
    "    t0_col=\"saccade_on_ms\",\n",
    "    eye_col=\"eye\",\n",
    "    animal_col=\"animal\",\n",
    "    block_col=\"block\",\n",
    "    ms_col=\"ms_axis\",\n",
    "    speed_col_candidates=None,\n",
    "    window_ms=80,\n",
    "    out_col=\"other_eye_peak_speed\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds out_col to non_synced_df:\n",
    "      out_col = max(other_eye_speed) within [t0-window_ms, t0+window_ms]\n",
    "    \"\"\"\n",
    "    if speed_col_candidates is None:\n",
    "        # include the common ones Ive seen across your codebases\n",
    "        speed_col_candidates = [\n",
    "            \"angular_speed_r\", \"angular_speed\", \"speed_r\", \"speed\",\n",
    "            \"velocity\",  # BlockSync_current uses df['velocity'] for pupil speed:contentReference[oaicite:3]{index=3}\n",
    "        ]\n",
    "\n",
    "    d = non_synced_df.copy()\n",
    "    peaks = []\n",
    "\n",
    "    for _, r in d.iterrows():\n",
    "        try:\n",
    "            animal = r[animal_col]\n",
    "            block = r[block_col]\n",
    "            eye = str(r[eye_col]).upper()\n",
    "            t0 = float(r[t0_col])\n",
    "        except Exception:\n",
    "            peaks.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        other_eye = \"R\" if eye.startswith(\"L\") else \"L\"\n",
    "\n",
    "        # lookup key(s)\n",
    "        k1 = (animal, block, other_eye)\n",
    "        k2 = (str(animal), str(block), other_eye)\n",
    "        k3 = (str(animal), _norm_block_key(block), other_eye)\n",
    "\n",
    "        tr = None\n",
    "        for k in (k1, k2, k3):\n",
    "            if k in eye_trace_lookup:\n",
    "                tr = eye_trace_lookup[k]\n",
    "                break\n",
    "\n",
    "        if tr is None or (ms_col not in tr.columns):\n",
    "            peaks.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        sp_col = _pick_first_col(tr, speed_col_candidates)\n",
    "        if sp_col is None:\n",
    "            peaks.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        ms = pd.to_numeric(tr[ms_col], errors=\"coerce\").to_numpy(dtype=float)\n",
    "        sp = pd.to_numeric(tr[sp_col], errors=\"coerce\").to_numpy(dtype=float)\n",
    "\n",
    "        m = (ms >= t0 - float(window_ms)) & (ms <= t0 + float(window_ms)) & np.isfinite(sp)\n",
    "        if not np.any(m):\n",
    "            peaks.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        peaks.append(float(np.nanmax(sp[m])))\n",
    "\n",
    "    d[out_col] = peaks\n",
    "    return d\n",
    "\n",
    "\n",
    "def select_top_monocular_events(\n",
    "    non_synced_saccade_collection,\n",
    "    animal_call,\n",
    "    block,\n",
    "    eye_trace_lookup=None,          # <-- new\n",
    "    window_ms_for_other_eye=80,     # <-- new\n",
    "    n_examples=10,\n",
    "    max_other_eye_metric=None,\n",
    "    prefer_eye=None\n",
    "):\n",
    "    if isinstance(non_synced_saccade_collection, pd.DataFrame):\n",
    "        df = non_synced_saccade_collection.copy()\n",
    "    else:\n",
    "        df = pd.DataFrame(non_synced_saccade_collection).copy()\n",
    "\n",
    "    # required identifiers\n",
    "    animal_col = _pick_first_col(df, [\"animal_call\", \"animal\", \"_animal_std\"])\n",
    "    block_col  = _pick_first_col(df, [\"block\", \"block_num\", \"_block_std\"])\n",
    "    eye_col    = _pick_first_col(df, [\"eye\", \"_eye_std\"])\n",
    "    if animal_col is None or block_col is None or eye_col is None:\n",
    "        raise KeyError(\"Missing one of required cols: animal, block, eye\")\n",
    "\n",
    "    # your real timing cols\n",
    "    start_col = _pick_first_col(df, [\"saccade_on_ms\", \"start_ms\", \"_start_ms_std\", \"start_time_ms\"])\n",
    "    end_col   = _pick_first_col(df, [\"saccade_off_ms\", \"end_ms\", \"_end_ms_std\", \"end_time_ms\"])\n",
    "    if start_col is None or end_col is None:\n",
    "        raise KeyError(\"Missing event timing cols (need saccade_on_ms / saccade_off_ms or equivalents)\")\n",
    "\n",
    "    amp_col = _pick_first_col(df, [\"net_angular_disp\", \"net_disp_deg\", \"net_disp\", \"amplitude_deg\", \"amp_deg\", \"amp\"])\n",
    "    if amp_col is None:\n",
    "        raise KeyError(\"No amplitude column found (expected net_angular_disp / amplitude_deg / etc.).\")\n",
    "\n",
    "    # If other-eye metric is missing, compute it\n",
    "    other_col = _pick_first_col(df, [\n",
    "        \"other_eye_peak_speed\", \"other_eye_peak_vel\", \"other_eye_peak_velocity\",\n",
    "        \"other_eye_max_speed\", \"other_eye_max_vel\",\n",
    "        \"monocular_score\", \"other_eye_score\"\n",
    "    ])\n",
    "\n",
    "    if other_col is None:\n",
    "        if eye_trace_lookup is None:\n",
    "            raise KeyError(\n",
    "                \"No 'other-eye motion' metric column exists, and no eye_trace_lookup was provided to compute it.\\n\"\n",
    "                \"Build eye_trace_lookup from block_collection, then call select_top_monocular_events(..., eye_trace_lookup=...).\"\n",
    "            )\n",
    "        df = attach_other_eye_peak_speed(\n",
    "            non_synced_df=df,\n",
    "            eye_trace_lookup=eye_trace_lookup,\n",
    "            t0_col=start_col,\n",
    "            eye_col=eye_col,\n",
    "            animal_col=animal_col,\n",
    "            block_col=block_col,\n",
    "            window_ms=window_ms_for_other_eye,\n",
    "            out_col=\"other_eye_peak_speed\",\n",
    "        )\n",
    "        other_col = \"other_eye_peak_speed\"\n",
    "\n",
    "    # filter to single animal+block\n",
    "    b_str = str(block)\n",
    "    sub = df[(df[animal_col].astype(str) == str(animal_call)) &\n",
    "             (df[block_col].astype(str) == b_str)].copy()\n",
    "\n",
    "    # fallback: sometimes block stored as int-like in df\n",
    "    if sub.empty:\n",
    "        b2 = _norm_block_key(block)\n",
    "        sub = df[(df[animal_col].astype(str) == str(animal_call)) &\n",
    "                 (df[block_col].astype(str) == b2)].copy()\n",
    "\n",
    "    if sub.empty:\n",
    "        raise ValueError(\"No events found for animal={} block={}\".format(animal_call, block))\n",
    "\n",
    "    # eye filter\n",
    "    if prefer_eye is not None:\n",
    "        pe = str(prefer_eye).lower()\n",
    "        if pe in (\"l\", \"left\"):\n",
    "            sub = sub[sub[eye_col].astype(str).str.lower().str.startswith(\"l\")].copy()\n",
    "        elif pe in (\"r\", \"right\"):\n",
    "            sub = sub[sub[eye_col].astype(str).str.lower().str.startswith(\"r\")].copy()\n",
    "\n",
    "    # numeric\n",
    "    for c in (start_col, end_col, amp_col, other_col):\n",
    "        sub[c] = pd.to_numeric(sub[c], errors=\"coerce\")\n",
    "    sub = sub.dropna(subset=[start_col, end_col, amp_col, other_col]).copy()\n",
    "\n",
    "    if max_other_eye_metric is not None:\n",
    "        sub = sub[sub[other_col] <= float(max_other_eye_metric)].copy()\n",
    "\n",
    "    # rank: most monocular (low other-eye peak) + high amplitude\n",
    "    sub = sub.sort_values([other_col, amp_col], ascending=[True, False]).copy()\n",
    "    pool = sub.head(max(5 * int(n_examples), int(n_examples))).copy()\n",
    "    pool = pool.sort_values([amp_col, other_col], ascending=[False, True]).head(int(n_examples)).reset_index(drop=True)\n",
    "\n",
    "    # standardized cols for downstream UI\n",
    "    pool[\"_animal_std\"] = str(animal_call)\n",
    "    pool[\"_block_std\"] = str(block)\n",
    "    pool[\"_start_ms_std\"] = pool[start_col].astype(float)\n",
    "    pool[\"_end_ms_std\"] = pool[end_col].astype(float)\n",
    "    pool[\"_eye_std\"] = pool[eye_col].astype(str)\n",
    "\n",
    "    view = pool[[animal_col, block_col, eye_col, start_col, end_col, amp_col, other_col]].copy()\n",
    "    colmap = dict(animal_col=animal_col, block_col=block_col, eye_col=eye_col,\n",
    "                  start_col=start_col, end_col=end_col, amp_col=amp_col, other_col=other_col)\n",
    "    return pool, view, colmap\n",
    "\n",
    "\n",
    "eye_trace_lookup = build_eye_trace_lookup_from_block_collection(block_collection)\n",
    "\n",
    "ANIMAL = \"PV_106\"\n",
    "BLOCK  = \"011\"\n",
    "\n",
    "top_events_df, top_events_view, colmap = select_top_monocular_events(\n",
    "    non_synced_saccade_collection,\n",
    "    animal_call=ANIMAL,\n",
    "    block=BLOCK,\n",
    "    eye_trace_lookup=eye_trace_lookup,\n",
    "    window_ms_for_other_eye=80,\n",
    "    n_examples=10,\n",
    "    max_other_eye_metric=None,\n",
    "    prefer_eye=None\n",
    ")\n",
    "\n",
    "top_events_view\n"
   ],
   "id": "a193599fcf4150df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   animal block eye  saccade_on_ms  saccade_off_ms  net_angular_disp  \\\n",
       "0  PV_106   011   L     1738025.15      1738091.75          3.801888   \n",
       "1  PV_106   011   R     1421858.30      1421891.60          3.682619   \n",
       "2  PV_106   011   L     1114665.80      1114699.10          3.487577   \n",
       "3  PV_106   011   L     1956856.10      1956922.70          3.395845   \n",
       "4  PV_106   011   R     1770076.40      1770143.00          3.261572   \n",
       "5  PV_106   011   L     1114649.15      1114665.80          2.659038   \n",
       "6  PV_106   011   L      741272.90       741306.20          2.585493   \n",
       "7  PV_106   011   L      752245.25       752295.20          2.474284   \n",
       "8  PV_106   011   L     1571525.15      1571575.10          2.369715   \n",
       "9  PV_106   011   L      532981.40       533014.70          1.845653   \n",
       "\n",
       "   other_eye_peak_speed  \n",
       "0              0.068240  \n",
       "1              0.056523  \n",
       "2              0.041838  \n",
       "3              0.049623  \n",
       "4              0.078489  \n",
       "5              0.041838  \n",
       "6              0.073441  \n",
       "7              0.052817  \n",
       "8              0.075919  \n",
       "9              0.057224  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>block</th>\n",
       "      <th>eye</th>\n",
       "      <th>saccade_on_ms</th>\n",
       "      <th>saccade_off_ms</th>\n",
       "      <th>net_angular_disp</th>\n",
       "      <th>other_eye_peak_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1738025.15</td>\n",
       "      <td>1738091.75</td>\n",
       "      <td>3.801888</td>\n",
       "      <td>0.068240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1421858.30</td>\n",
       "      <td>1421891.60</td>\n",
       "      <td>3.682619</td>\n",
       "      <td>0.056523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1114665.80</td>\n",
       "      <td>1114699.10</td>\n",
       "      <td>3.487577</td>\n",
       "      <td>0.041838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1956856.10</td>\n",
       "      <td>1956922.70</td>\n",
       "      <td>3.395845</td>\n",
       "      <td>0.049623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1770076.40</td>\n",
       "      <td>1770143.00</td>\n",
       "      <td>3.261572</td>\n",
       "      <td>0.078489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1114649.15</td>\n",
       "      <td>1114665.80</td>\n",
       "      <td>2.659038</td>\n",
       "      <td>0.041838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>741272.90</td>\n",
       "      <td>741306.20</td>\n",
       "      <td>2.585493</td>\n",
       "      <td>0.073441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>752245.25</td>\n",
       "      <td>752295.20</td>\n",
       "      <td>2.474284</td>\n",
       "      <td>0.052817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1571525.15</td>\n",
       "      <td>1571575.10</td>\n",
       "      <td>2.369715</td>\n",
       "      <td>0.075919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>532981.40</td>\n",
       "      <td>533014.70</td>\n",
       "      <td>1.845653</td>\n",
       "      <td>0.057224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T08:47:05.778272Z",
     "start_time": "2025-12-31T08:47:05.748241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_monocular_candidate_lists(\n",
    "    non_synced_saccade_collection,\n",
    "    animal_call,\n",
    "    block,\n",
    "    eye_trace_lookup=None,\n",
    "    window_ms_for_other_eye=80,\n",
    "    n_each=10,\n",
    "    max_other_eye_metric=0.8,   # <-- IMPORTANT: set this to your monocular cutoff (units = your speed metric)\n",
    "    prefer_eye=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns two DataFrames:\n",
    "      (A) most_monocular_df: top n_each with smallest other-eye motion (then high amp)\n",
    "      (B) largest_amp_monocular_df: top n_each with largest amp among events that pass monocular criterion\n",
    "\n",
    "    Requires:\n",
    "      - timing cols: saccade_on_ms / saccade_off_ms\n",
    "      - amplitude col: net_angular_disp (or similar)\n",
    "      - other-eye metric: computed as other_eye_peak_speed if missing\n",
    "    \"\"\"\n",
    "\n",
    "    # --- local helpers (reuse your earlier ones if already in notebook) ---\n",
    "    def _pick_first_col(df, candidates):\n",
    "        for c in candidates:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    def _norm_block_key(x):\n",
    "        s = str(x)\n",
    "        try:\n",
    "            return str(int(float(s)))\n",
    "        except Exception:\n",
    "            return s\n",
    "\n",
    "    def attach_other_eye_peak_speed(\n",
    "        df_in,\n",
    "        eye_trace_lookup,\n",
    "        t0_col,\n",
    "        eye_col,\n",
    "        animal_col,\n",
    "        block_col,\n",
    "        ms_col=\"ms_axis\",\n",
    "        window_ms=80,\n",
    "        out_col=\"other_eye_peak_speed\",\n",
    "        speed_col_candidates=None,\n",
    "    ):\n",
    "        if speed_col_candidates is None:\n",
    "            speed_col_candidates = [\"angular_speed_r\",\"angular_speed\",\"speed_r\",\"speed\",\"velocity\"]\n",
    "\n",
    "        d = df_in.copy()\n",
    "        peaks = []\n",
    "\n",
    "        for _, r in d.iterrows():\n",
    "            try:\n",
    "                animal = r[animal_col]\n",
    "                blk = r[block_col]\n",
    "                eye = str(r[eye_col]).upper()\n",
    "                t0 = float(r[t0_col])\n",
    "            except Exception:\n",
    "                peaks.append(np.nan); continue\n",
    "\n",
    "            other_eye = \"R\" if eye.startswith(\"L\") else \"L\"\n",
    "\n",
    "            keys = [\n",
    "                (animal, blk, other_eye),\n",
    "                (str(animal), str(blk), other_eye),\n",
    "                (str(animal), _norm_block_key(blk), other_eye),\n",
    "            ]\n",
    "            tr = None\n",
    "            for k in keys:\n",
    "                if k in eye_trace_lookup:\n",
    "                    tr = eye_trace_lookup[k]; break\n",
    "            if tr is None or (ms_col not in tr.columns):\n",
    "                peaks.append(np.nan); continue\n",
    "\n",
    "            sp_col = _pick_first_col(tr, speed_col_candidates)\n",
    "            if sp_col is None:\n",
    "                peaks.append(np.nan); continue\n",
    "\n",
    "            ms = pd.to_numeric(tr[ms_col], errors=\"coerce\").to_numpy(dtype=float)\n",
    "            sp = pd.to_numeric(tr[sp_col], errors=\"coerce\").to_numpy(dtype=float)\n",
    "\n",
    "            m = (ms >= t0 - float(window_ms)) & (ms <= t0 + float(window_ms)) & np.isfinite(sp)\n",
    "            if not np.any(m):\n",
    "                peaks.append(np.nan); continue\n",
    "\n",
    "            peaks.append(float(np.nanmax(sp[m])))\n",
    "\n",
    "        d[out_col] = peaks\n",
    "        return d\n",
    "\n",
    "    # --- input to df ---\n",
    "    if isinstance(non_synced_saccade_collection, pd.DataFrame):\n",
    "        df = non_synced_saccade_collection.copy()\n",
    "    else:\n",
    "        df = pd.DataFrame(non_synced_saccade_collection).copy()\n",
    "\n",
    "    # --- columns ---\n",
    "    animal_col = _pick_first_col(df, [\"animal_call\", \"animal\", \"_animal_std\"])\n",
    "    block_col  = _pick_first_col(df, [\"block\", \"block_num\", \"_block_std\"])\n",
    "    eye_col    = _pick_first_col(df, [\"eye\", \"_eye_std\"])\n",
    "    if animal_col is None or block_col is None or eye_col is None:\n",
    "        raise KeyError(\"Missing required identifiers: animal/block/eye.\")\n",
    "\n",
    "    start_col = _pick_first_col(df, [\"saccade_on_ms\", \"start_ms\", \"_start_ms_std\"])\n",
    "    end_col   = _pick_first_col(df, [\"saccade_off_ms\", \"end_ms\", \"_end_ms_std\"])\n",
    "    if start_col is None or end_col is None:\n",
    "        raise KeyError(\"Missing timing cols (need saccade_on_ms and saccade_off_ms or equivalents).\")\n",
    "\n",
    "    amp_col = _pick_first_col(df, [\"net_angular_disp\",\"net_disp_deg\",\"net_disp\",\"amplitude_deg\",\"amp_deg\",\"amp\"])\n",
    "    if amp_col is None:\n",
    "        raise KeyError(\"Missing amplitude col (need net_angular_disp or similar).\")\n",
    "\n",
    "    other_col = _pick_first_col(df, [\n",
    "        \"other_eye_peak_speed\",\"other_eye_peak_vel\",\"other_eye_peak_velocity\",\n",
    "        \"other_eye_max_speed\",\"other_eye_max_vel\"\n",
    "    ])\n",
    "\n",
    "    # --- compute other-eye metric if absent ---\n",
    "    if other_col is None:\n",
    "        if eye_trace_lookup is None:\n",
    "            raise KeyError(\"No other-eye metric in df, and eye_trace_lookup=None so I can't compute it.\")\n",
    "        df = attach_other_eye_peak_speed(\n",
    "            df_in=df,\n",
    "            eye_trace_lookup=eye_trace_lookup,\n",
    "            t0_col=start_col,\n",
    "            eye_col=eye_col,\n",
    "            animal_col=animal_col,\n",
    "            block_col=block_col,\n",
    "            window_ms=window_ms_for_other_eye,\n",
    "            out_col=\"other_eye_peak_speed\"\n",
    "        )\n",
    "        other_col = \"other_eye_peak_speed\"\n",
    "\n",
    "    # --- filter to block+animal ---\n",
    "    b_str = str(block)\n",
    "    sub = df[(df[animal_col].astype(str) == str(animal_call)) &\n",
    "             (df[block_col].astype(str) == b_str)].copy()\n",
    "    if sub.empty:\n",
    "        b2 = _norm_block_key(block)\n",
    "        sub = df[(df[animal_col].astype(str) == str(animal_call)) &\n",
    "                 (df[block_col].astype(str) == b2)].copy()\n",
    "\n",
    "    if sub.empty:\n",
    "        raise ValueError(\"No events for animal={} block={}\".format(animal_call, block))\n",
    "\n",
    "    # --- optional eye filter ---\n",
    "    if prefer_eye is not None:\n",
    "        pe = str(prefer_eye).lower()\n",
    "        if pe in (\"l\", \"left\"):\n",
    "            sub = sub[sub[eye_col].astype(str).str.lower().str.startswith(\"l\")].copy()\n",
    "        elif pe in (\"r\", \"right\"):\n",
    "            sub = sub[sub[eye_col].astype(str).str.lower().str.startswith(\"r\")].copy()\n",
    "\n",
    "    # --- numeric ---\n",
    "    for c in (start_col, end_col, amp_col, other_col):\n",
    "        sub[c] = pd.to_numeric(sub[c], errors=\"coerce\")\n",
    "    sub = sub.dropna(subset=[start_col, end_col, amp_col, other_col]).copy()\n",
    "\n",
    "    # --- define \"monocular pass\" ---\n",
    "    if max_other_eye_metric is None:\n",
    "        # still allow ranking, but largest-amp list won't be strictly monocular\n",
    "        monocular_pass = sub.copy()\n",
    "    else:\n",
    "        monocular_pass = sub[sub[other_col] <= float(max_other_eye_metric)].copy()\n",
    "\n",
    "    # (A) most monocular: smallest other-eye metric, then large amp\n",
    "    most_monocular = sub.sort_values([other_col, amp_col], ascending=[True, False]).head(int(n_each)).copy()\n",
    "\n",
    "    # (B) largest amplitude monocular: among pass set, max amplitude, tie-break by other-eye metric\n",
    "    if monocular_pass.empty:\n",
    "        largest_amp_monocular = monocular_pass.copy()  # empty\n",
    "    else:\n",
    "        largest_amp_monocular = monocular_pass.sort_values([amp_col, other_col], ascending=[False, True]).head(int(n_each)).copy()\n",
    "\n",
    "    # --- standardize cols for downstream viewer ---\n",
    "    for out_df in (most_monocular, largest_amp_monocular):\n",
    "        out_df[\"_animal_std\"] = str(animal_call)\n",
    "        out_df[\"_block_std\"] = str(block)\n",
    "        out_df[\"_start_ms_std\"] = out_df[start_col].astype(float)\n",
    "        out_df[\"_end_ms_std\"] = out_df[end_col].astype(float)\n",
    "        out_df[\"_eye_std\"] = out_df[eye_col].astype(str)\n",
    "\n",
    "    # compact views\n",
    "    view_cols = [animal_col, block_col, eye_col, start_col, end_col, amp_col, other_col]\n",
    "    view_cols = [c for c in view_cols if c in sub.columns]\n",
    "\n",
    "    most_view = most_monocular[view_cols].reset_index(drop=True)\n",
    "    amp_view  = largest_amp_monocular[view_cols].reset_index(drop=True)\n",
    "\n",
    "    meta = dict(\n",
    "        animal_col=animal_col, block_col=block_col, eye_col=eye_col,\n",
    "        start_col=start_col, end_col=end_col, amp_col=amp_col, other_col=other_col,\n",
    "        max_other_eye_metric=max_other_eye_metric\n",
    "    )\n",
    "    return most_monocular, largest_amp_monocular, most_view, amp_view, meta\n"
   ],
   "id": "f555216b56fd31d0",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T14:52:07.487130Z",
     "start_time": "2025-12-31T14:51:58.032956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build trace lookup once (from your existing pipeline helper)\n",
    "# eye_trace_lookup = build_eye_trace_lookup_from_block_collection(block_collection)\n",
    "\n",
    "ANIMAL = \"PV_106\"\n",
    "BLOCK = \"011\"\n",
    "\n",
    "# Pick a real cutoff. If your \"speed\" metric is deg/frame, 0.8 deg/frame ~ 48 deg/s at 60 fps.\n",
    "MAX_OTHER_EYE = 0.8\n",
    "\n",
    "most_df, largest_amp_df, most_view, amp_view, meta = get_monocular_candidate_lists(\n",
    "    non_synced_saccade_collection,\n",
    "    animal_call=ANIMAL,\n",
    "    block=BLOCK,\n",
    "    eye_trace_lookup=eye_trace_lookup,\n",
    "    window_ms_for_other_eye=80,\n",
    "    n_each=50,\n",
    "    max_other_eye_metric=MAX_OTHER_EYE,\n",
    "    prefer_eye=None\n",
    ")\n",
    "\n",
    "print(\"=== Most monocular (top 10) ===\")\n",
    "display(most_view)\n",
    "\n",
    "print(\"=== Largest amplitude monocular (top 10) ===\")\n",
    "display(amp_view)\n"
   ],
   "id": "bf6ba1e2b4807c09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Most monocular (top 10) ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    animal block eye  saccade_on_ms  saccade_off_ms  net_angular_disp  \\\n",
       "0   PV_106   011   L     1562733.95      1562750.60          0.831717   \n",
       "1   PV_106   011   L      191140.25       191156.90          0.837499   \n",
       "2   PV_106   011   L      191156.90       191173.55          0.802887   \n",
       "3   PV_106   011   L     1081981.85      1081998.50          0.891567   \n",
       "4   PV_106   011   L     1114665.80      1114699.10          3.487577   \n",
       "5   PV_106   011   L     1114649.15      1114665.80          2.659038   \n",
       "6   PV_106   011   L     1132298.15      1132331.45          0.874732   \n",
       "7   PV_106   011   L     2018744.15      2018760.80          0.673400   \n",
       "8   PV_106   011   R     1421941.55      1421974.85          1.373206   \n",
       "9   PV_106   011   L     1956856.10      1956922.70          3.395845   \n",
       "10  PV_106   011   L     1341988.25      1342021.55          1.433352   \n",
       "11  PV_106   011   L      752245.25       752295.20          2.474284   \n",
       "12  PV_106   011   L      354626.60       354643.25          0.922093   \n",
       "13  PV_106   011   L      459205.25       459221.90          1.177136   \n",
       "14  PV_106   011   R     1421858.30      1421891.60          3.682619   \n",
       "15  PV_106   011   L      532981.40       533014.70          1.845653   \n",
       "16  PV_106   011   L       83065.10        83098.40          0.873829   \n",
       "17  PV_106   011   L     2070658.85      2070675.50          0.622060   \n",
       "18  PV_106   011   L      462751.70       462785.00          0.851112   \n",
       "19  PV_106   011   L     2070259.25      2070292.55          1.688770   \n",
       "20  PV_106   011   L     1079983.85      1080017.15          0.957636   \n",
       "21  PV_106   011   L     1079967.20      1079983.85          0.887206   \n",
       "22  PV_106   011   L      840373.70       840390.35          0.922142   \n",
       "23  PV_106   011   L     1114599.20      1114632.50          1.104215   \n",
       "24  PV_106   011   L     1664781.80      1664798.45          0.646758   \n",
       "25  PV_106   011   L      459554.90       459571.55          1.064216   \n",
       "26  PV_106   011   L     2148830.60      2148847.25          0.707631   \n",
       "27  PV_106   011   L     1882364.00      1882380.65          0.516866   \n",
       "28  PV_106   011   R     1787342.45      1787359.10          0.631151   \n",
       "29  PV_106   011   L     1738025.15      1738091.75          3.801888   \n",
       "30  PV_106   011   L     1737941.90      1737975.20          1.657156   \n",
       "31  PV_106   011   L     1866663.05      1866679.70          0.563966   \n",
       "32  PV_106   011   L     1132647.80      1132681.10          0.863774   \n",
       "33  PV_106   011   L      123574.55       123607.85          1.566288   \n",
       "34  PV_106   011   L     1956806.15      1956839.45          1.341244   \n",
       "35  PV_106   011   L      459305.15       459321.80          1.114426   \n",
       "36  PV_106   011   L      459288.50       459305.15          1.085170   \n",
       "37  PV_106   011   L      459271.85       459288.50          1.025670   \n",
       "38  PV_106   011   L     1750695.80      1750712.45          0.601086   \n",
       "39  PV_106   011   L      741272.90       741306.20          2.585493   \n",
       "40  PV_106   011   L     1790189.60      1790206.25          0.562242   \n",
       "41  PV_106   011   L     1341888.35      1341905.00          0.510807   \n",
       "42  PV_106   011   R     1044436.10      1044452.75          0.613814   \n",
       "43  PV_106   011   L     1750762.40      1750795.70          1.652281   \n",
       "44  PV_106   011   L      123691.10       123707.75          1.369438   \n",
       "45  PV_106   011   L     1571525.15      1571575.10          2.369715   \n",
       "46  PV_106   011   L     2098447.70      2098481.00          1.411826   \n",
       "47  PV_106   011   L      920443.55       920460.20          0.956651   \n",
       "48  PV_106   011   R      867513.20       867529.85          0.561597   \n",
       "49  PV_106   011   R     1770076.40      1770143.00          3.261572   \n",
       "\n",
       "    other_eye_peak_speed  \n",
       "0               0.038099  \n",
       "1               0.040174  \n",
       "2               0.040174  \n",
       "3               0.041162  \n",
       "4               0.041838  \n",
       "5               0.041838  \n",
       "6               0.046816  \n",
       "7               0.047572  \n",
       "8               0.048792  \n",
       "9               0.049623  \n",
       "10              0.051067  \n",
       "11              0.052817  \n",
       "12              0.055350  \n",
       "13              0.056382  \n",
       "14              0.056523  \n",
       "15              0.057224  \n",
       "16              0.058489  \n",
       "17              0.058528  \n",
       "18              0.059748  \n",
       "19              0.060424  \n",
       "20              0.060817  \n",
       "21              0.060817  \n",
       "22              0.060948  \n",
       "23              0.061259  \n",
       "24              0.061663  \n",
       "25              0.062482  \n",
       "26              0.063520  \n",
       "27              0.064970  \n",
       "28              0.065327  \n",
       "29              0.068240  \n",
       "30              0.068240  \n",
       "31              0.071205  \n",
       "32              0.071662  \n",
       "33              0.072060  \n",
       "34              0.072119  \n",
       "35              0.073152  \n",
       "36              0.073152  \n",
       "37              0.073152  \n",
       "38              0.073281  \n",
       "39              0.073441  \n",
       "40              0.073580  \n",
       "41              0.074021  \n",
       "42              0.074253  \n",
       "43              0.075242  \n",
       "44              0.075522  \n",
       "45              0.075919  \n",
       "46              0.075929  \n",
       "47              0.076488  \n",
       "48              0.078382  \n",
       "49              0.078489  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>block</th>\n",
       "      <th>eye</th>\n",
       "      <th>saccade_on_ms</th>\n",
       "      <th>saccade_off_ms</th>\n",
       "      <th>net_angular_disp</th>\n",
       "      <th>other_eye_peak_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1562733.95</td>\n",
       "      <td>1562750.60</td>\n",
       "      <td>0.831717</td>\n",
       "      <td>0.038099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>191140.25</td>\n",
       "      <td>191156.90</td>\n",
       "      <td>0.837499</td>\n",
       "      <td>0.040174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>191156.90</td>\n",
       "      <td>191173.55</td>\n",
       "      <td>0.802887</td>\n",
       "      <td>0.040174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1081981.85</td>\n",
       "      <td>1081998.50</td>\n",
       "      <td>0.891567</td>\n",
       "      <td>0.041162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1114665.80</td>\n",
       "      <td>1114699.10</td>\n",
       "      <td>3.487577</td>\n",
       "      <td>0.041838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1114649.15</td>\n",
       "      <td>1114665.80</td>\n",
       "      <td>2.659038</td>\n",
       "      <td>0.041838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1132298.15</td>\n",
       "      <td>1132331.45</td>\n",
       "      <td>0.874732</td>\n",
       "      <td>0.046816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>2018744.15</td>\n",
       "      <td>2018760.80</td>\n",
       "      <td>0.673400</td>\n",
       "      <td>0.047572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1421941.55</td>\n",
       "      <td>1421974.85</td>\n",
       "      <td>1.373206</td>\n",
       "      <td>0.048792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1956856.10</td>\n",
       "      <td>1956922.70</td>\n",
       "      <td>3.395845</td>\n",
       "      <td>0.049623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1341988.25</td>\n",
       "      <td>1342021.55</td>\n",
       "      <td>1.433352</td>\n",
       "      <td>0.051067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>752245.25</td>\n",
       "      <td>752295.20</td>\n",
       "      <td>2.474284</td>\n",
       "      <td>0.052817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>354626.60</td>\n",
       "      <td>354643.25</td>\n",
       "      <td>0.922093</td>\n",
       "      <td>0.055350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>459205.25</td>\n",
       "      <td>459221.90</td>\n",
       "      <td>1.177136</td>\n",
       "      <td>0.056382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1421858.30</td>\n",
       "      <td>1421891.60</td>\n",
       "      <td>3.682619</td>\n",
       "      <td>0.056523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>532981.40</td>\n",
       "      <td>533014.70</td>\n",
       "      <td>1.845653</td>\n",
       "      <td>0.057224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>83065.10</td>\n",
       "      <td>83098.40</td>\n",
       "      <td>0.873829</td>\n",
       "      <td>0.058489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>2070658.85</td>\n",
       "      <td>2070675.50</td>\n",
       "      <td>0.622060</td>\n",
       "      <td>0.058528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>462751.70</td>\n",
       "      <td>462785.00</td>\n",
       "      <td>0.851112</td>\n",
       "      <td>0.059748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>2070259.25</td>\n",
       "      <td>2070292.55</td>\n",
       "      <td>1.688770</td>\n",
       "      <td>0.060424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1079983.85</td>\n",
       "      <td>1080017.15</td>\n",
       "      <td>0.957636</td>\n",
       "      <td>0.060817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1079967.20</td>\n",
       "      <td>1079983.85</td>\n",
       "      <td>0.887206</td>\n",
       "      <td>0.060817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>840373.70</td>\n",
       "      <td>840390.35</td>\n",
       "      <td>0.922142</td>\n",
       "      <td>0.060948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1114599.20</td>\n",
       "      <td>1114632.50</td>\n",
       "      <td>1.104215</td>\n",
       "      <td>0.061259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1664781.80</td>\n",
       "      <td>1664798.45</td>\n",
       "      <td>0.646758</td>\n",
       "      <td>0.061663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>459554.90</td>\n",
       "      <td>459571.55</td>\n",
       "      <td>1.064216</td>\n",
       "      <td>0.062482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>2148830.60</td>\n",
       "      <td>2148847.25</td>\n",
       "      <td>0.707631</td>\n",
       "      <td>0.063520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1882364.00</td>\n",
       "      <td>1882380.65</td>\n",
       "      <td>0.516866</td>\n",
       "      <td>0.064970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1787342.45</td>\n",
       "      <td>1787359.10</td>\n",
       "      <td>0.631151</td>\n",
       "      <td>0.065327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1738025.15</td>\n",
       "      <td>1738091.75</td>\n",
       "      <td>3.801888</td>\n",
       "      <td>0.068240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1737941.90</td>\n",
       "      <td>1737975.20</td>\n",
       "      <td>1.657156</td>\n",
       "      <td>0.068240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1866663.05</td>\n",
       "      <td>1866679.70</td>\n",
       "      <td>0.563966</td>\n",
       "      <td>0.071205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1132647.80</td>\n",
       "      <td>1132681.10</td>\n",
       "      <td>0.863774</td>\n",
       "      <td>0.071662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>123574.55</td>\n",
       "      <td>123607.85</td>\n",
       "      <td>1.566288</td>\n",
       "      <td>0.072060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1956806.15</td>\n",
       "      <td>1956839.45</td>\n",
       "      <td>1.341244</td>\n",
       "      <td>0.072119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>459305.15</td>\n",
       "      <td>459321.80</td>\n",
       "      <td>1.114426</td>\n",
       "      <td>0.073152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>459288.50</td>\n",
       "      <td>459305.15</td>\n",
       "      <td>1.085170</td>\n",
       "      <td>0.073152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>459271.85</td>\n",
       "      <td>459288.50</td>\n",
       "      <td>1.025670</td>\n",
       "      <td>0.073152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1750695.80</td>\n",
       "      <td>1750712.45</td>\n",
       "      <td>0.601086</td>\n",
       "      <td>0.073281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>741272.90</td>\n",
       "      <td>741306.20</td>\n",
       "      <td>2.585493</td>\n",
       "      <td>0.073441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1790189.60</td>\n",
       "      <td>1790206.25</td>\n",
       "      <td>0.562242</td>\n",
       "      <td>0.073580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1341888.35</td>\n",
       "      <td>1341905.00</td>\n",
       "      <td>0.510807</td>\n",
       "      <td>0.074021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1044436.10</td>\n",
       "      <td>1044452.75</td>\n",
       "      <td>0.613814</td>\n",
       "      <td>0.074253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1750762.40</td>\n",
       "      <td>1750795.70</td>\n",
       "      <td>1.652281</td>\n",
       "      <td>0.075242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>123691.10</td>\n",
       "      <td>123707.75</td>\n",
       "      <td>1.369438</td>\n",
       "      <td>0.075522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1571525.15</td>\n",
       "      <td>1571575.10</td>\n",
       "      <td>2.369715</td>\n",
       "      <td>0.075919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>2098447.70</td>\n",
       "      <td>2098481.00</td>\n",
       "      <td>1.411826</td>\n",
       "      <td>0.075929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>920443.55</td>\n",
       "      <td>920460.20</td>\n",
       "      <td>0.956651</td>\n",
       "      <td>0.076488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>867513.20</td>\n",
       "      <td>867529.85</td>\n",
       "      <td>0.561597</td>\n",
       "      <td>0.078382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1770076.40</td>\n",
       "      <td>1770143.00</td>\n",
       "      <td>3.261572</td>\n",
       "      <td>0.078489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Largest amplitude monocular (top 10) ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    animal block eye  saccade_on_ms  saccade_off_ms  net_angular_disp  \\\n",
       "0   PV_106   011   L      649548.05       649697.90         34.823644   \n",
       "1   PV_106   011   L     1397432.75      1397582.60         21.972547   \n",
       "2   PV_106   011   L      664583.00       664649.60         18.735991   \n",
       "3   PV_106   011   L      745751.75       745918.25         17.760907   \n",
       "4   PV_106   011   R      293354.60       293454.50         16.237197   \n",
       "5   PV_106   011   R     1821008.75      1821125.30         14.218852   \n",
       "6   PV_106   011   L      394769.75       394836.35         14.215709   \n",
       "7   PV_106   011   L     1316097.50      1316164.10         14.002508   \n",
       "8   PV_106   011   L      528169.55       528252.80         13.935054   \n",
       "9   PV_106   011   L      552178.85       552228.80         13.903795   \n",
       "10  PV_106   011   R      546551.15       546684.35         13.836607   \n",
       "11  PV_106   011   R      734379.80       734479.70         13.695490   \n",
       "12  PV_106   011   L     1333629.95      1333763.15         13.278076   \n",
       "13  PV_106   011   L      298732.55       298799.15         10.927681   \n",
       "14  PV_106   011   R      288259.70       288359.60         10.918229   \n",
       "15  PV_106   011   L     1162517.90      1162667.75         10.788144   \n",
       "16  PV_106   011   L      552228.80       552312.05         10.777776   \n",
       "17  PV_106   011   L      951562.40       951695.60         10.303575   \n",
       "18  PV_106   011   L      848781.95       848881.85         10.185611   \n",
       "19  PV_106   011   L     1274122.85      1274289.35         10.135252   \n",
       "20  PV_106   011   L     2156872.55      2156922.50         10.008256   \n",
       "21  PV_106   011   R      359971.25       360037.85          9.917917   \n",
       "22  PV_106   011   L     1465664.45      1465714.40          9.689049   \n",
       "23  PV_106   011   L     2071175.00      2071274.90          9.617523   \n",
       "24  PV_106   011   L     1396267.25      1396283.90          9.603444   \n",
       "25  PV_106   011   L     1396283.90      1396383.80          9.488860   \n",
       "26  PV_106   011   R      635478.80       635528.75          9.359589   \n",
       "27  PV_106   011   L      394836.35       394886.30          8.640473   \n",
       "28  PV_106   011   L      546800.90       546917.45          8.520734   \n",
       "29  PV_106   011   L     1357506.05      1357622.60          8.399239   \n",
       "30  PV_106   011   L      528302.75       528386.00          8.193194   \n",
       "31  PV_106   011   R      322275.65       322358.90          8.150578   \n",
       "32  PV_106   011   R      635578.70       635628.65          7.791445   \n",
       "33  PV_106   011   L      630383.90       630500.45          7.748637   \n",
       "34  PV_106   011   L     1675987.25      1676053.85          7.678931   \n",
       "35  PV_106   011   L      413734.10       413850.65          7.650363   \n",
       "36  PV_106   011   R      359854.70       359921.30          7.563842   \n",
       "37  PV_106   011   L     1116680.45      1116797.00          7.411182   \n",
       "38  PV_106   011   R     1406623.55      1406723.45          7.327612   \n",
       "39  PV_106   011   R     1398331.85      1398431.75          7.186644   \n",
       "40  PV_106   011   R     1724755.10      1724855.00          7.127906   \n",
       "41  PV_106   011   L     1266763.55      1266863.45          6.997302   \n",
       "42  PV_106   011   L     1410303.20      1410403.10          6.726936   \n",
       "43  PV_106   011   L     1615031.60      1615114.85          6.368147   \n",
       "44  PV_106   011   L     1455058.40      1455141.65          6.292468   \n",
       "45  PV_106   011   L       82349.15        82432.40          6.251176   \n",
       "46  PV_106   011   R     1735494.35      1735560.95          6.198964   \n",
       "47  PV_106   011   L     2101311.50      2101378.10          6.187598   \n",
       "48  PV_106   011   L     1465714.40      1465764.35          5.909294   \n",
       "49  PV_106   011   R     1843686.05      1843785.95          5.845848   \n",
       "\n",
       "    other_eye_peak_speed  \n",
       "0               0.457379  \n",
       "1               0.178496  \n",
       "2               0.539145  \n",
       "3               0.467697  \n",
       "4               0.721173  \n",
       "5               0.156091  \n",
       "6               0.583258  \n",
       "7               0.526883  \n",
       "8               0.567019  \n",
       "9               0.296782  \n",
       "10              0.591110  \n",
       "11              0.387694  \n",
       "12              0.464727  \n",
       "13              0.780913  \n",
       "14              0.523635  \n",
       "15              0.135417  \n",
       "16              0.332805  \n",
       "17              0.451088  \n",
       "18              0.777620  \n",
       "19              0.167884  \n",
       "20              0.766361  \n",
       "21              0.452421  \n",
       "22              0.414769  \n",
       "23              0.607554  \n",
       "24              0.435074  \n",
       "25              0.368809  \n",
       "26              0.784593  \n",
       "27              0.583258  \n",
       "28              0.595647  \n",
       "29              0.236627  \n",
       "30              0.591066  \n",
       "31              0.630610  \n",
       "32              0.775079  \n",
       "33              0.792119  \n",
       "34              0.236518  \n",
       "35              0.609874  \n",
       "36              0.743443  \n",
       "37              0.094594  \n",
       "38              0.398486  \n",
       "39              0.293521  \n",
       "40              0.161694  \n",
       "41              0.411512  \n",
       "42              0.160770  \n",
       "43              0.248357  \n",
       "44              0.629599  \n",
       "45              0.205015  \n",
       "46              0.361218  \n",
       "47              0.401076  \n",
       "48              0.600422  \n",
       "49              0.147799  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>block</th>\n",
       "      <th>eye</th>\n",
       "      <th>saccade_on_ms</th>\n",
       "      <th>saccade_off_ms</th>\n",
       "      <th>net_angular_disp</th>\n",
       "      <th>other_eye_peak_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>649548.05</td>\n",
       "      <td>649697.90</td>\n",
       "      <td>34.823644</td>\n",
       "      <td>0.457379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1397432.75</td>\n",
       "      <td>1397582.60</td>\n",
       "      <td>21.972547</td>\n",
       "      <td>0.178496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>664583.00</td>\n",
       "      <td>664649.60</td>\n",
       "      <td>18.735991</td>\n",
       "      <td>0.539145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>745751.75</td>\n",
       "      <td>745918.25</td>\n",
       "      <td>17.760907</td>\n",
       "      <td>0.467697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>293354.60</td>\n",
       "      <td>293454.50</td>\n",
       "      <td>16.237197</td>\n",
       "      <td>0.721173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1821008.75</td>\n",
       "      <td>1821125.30</td>\n",
       "      <td>14.218852</td>\n",
       "      <td>0.156091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>394769.75</td>\n",
       "      <td>394836.35</td>\n",
       "      <td>14.215709</td>\n",
       "      <td>0.583258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1316097.50</td>\n",
       "      <td>1316164.10</td>\n",
       "      <td>14.002508</td>\n",
       "      <td>0.526883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>528169.55</td>\n",
       "      <td>528252.80</td>\n",
       "      <td>13.935054</td>\n",
       "      <td>0.567019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>552178.85</td>\n",
       "      <td>552228.80</td>\n",
       "      <td>13.903795</td>\n",
       "      <td>0.296782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>546551.15</td>\n",
       "      <td>546684.35</td>\n",
       "      <td>13.836607</td>\n",
       "      <td>0.591110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>734379.80</td>\n",
       "      <td>734479.70</td>\n",
       "      <td>13.695490</td>\n",
       "      <td>0.387694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1333629.95</td>\n",
       "      <td>1333763.15</td>\n",
       "      <td>13.278076</td>\n",
       "      <td>0.464727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>298732.55</td>\n",
       "      <td>298799.15</td>\n",
       "      <td>10.927681</td>\n",
       "      <td>0.780913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>288259.70</td>\n",
       "      <td>288359.60</td>\n",
       "      <td>10.918229</td>\n",
       "      <td>0.523635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1162517.90</td>\n",
       "      <td>1162667.75</td>\n",
       "      <td>10.788144</td>\n",
       "      <td>0.135417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>552228.80</td>\n",
       "      <td>552312.05</td>\n",
       "      <td>10.777776</td>\n",
       "      <td>0.332805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>951562.40</td>\n",
       "      <td>951695.60</td>\n",
       "      <td>10.303575</td>\n",
       "      <td>0.451088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>848781.95</td>\n",
       "      <td>848881.85</td>\n",
       "      <td>10.185611</td>\n",
       "      <td>0.777620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1274122.85</td>\n",
       "      <td>1274289.35</td>\n",
       "      <td>10.135252</td>\n",
       "      <td>0.167884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>2156872.55</td>\n",
       "      <td>2156922.50</td>\n",
       "      <td>10.008256</td>\n",
       "      <td>0.766361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>359971.25</td>\n",
       "      <td>360037.85</td>\n",
       "      <td>9.917917</td>\n",
       "      <td>0.452421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1465664.45</td>\n",
       "      <td>1465714.40</td>\n",
       "      <td>9.689049</td>\n",
       "      <td>0.414769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>2071175.00</td>\n",
       "      <td>2071274.90</td>\n",
       "      <td>9.617523</td>\n",
       "      <td>0.607554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1396267.25</td>\n",
       "      <td>1396283.90</td>\n",
       "      <td>9.603444</td>\n",
       "      <td>0.435074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1396283.90</td>\n",
       "      <td>1396383.80</td>\n",
       "      <td>9.488860</td>\n",
       "      <td>0.368809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>635478.80</td>\n",
       "      <td>635528.75</td>\n",
       "      <td>9.359589</td>\n",
       "      <td>0.784593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>394836.35</td>\n",
       "      <td>394886.30</td>\n",
       "      <td>8.640473</td>\n",
       "      <td>0.583258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>546800.90</td>\n",
       "      <td>546917.45</td>\n",
       "      <td>8.520734</td>\n",
       "      <td>0.595647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1357506.05</td>\n",
       "      <td>1357622.60</td>\n",
       "      <td>8.399239</td>\n",
       "      <td>0.236627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>528302.75</td>\n",
       "      <td>528386.00</td>\n",
       "      <td>8.193194</td>\n",
       "      <td>0.591066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>322275.65</td>\n",
       "      <td>322358.90</td>\n",
       "      <td>8.150578</td>\n",
       "      <td>0.630610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>635578.70</td>\n",
       "      <td>635628.65</td>\n",
       "      <td>7.791445</td>\n",
       "      <td>0.775079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>630383.90</td>\n",
       "      <td>630500.45</td>\n",
       "      <td>7.748637</td>\n",
       "      <td>0.792119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1675987.25</td>\n",
       "      <td>1676053.85</td>\n",
       "      <td>7.678931</td>\n",
       "      <td>0.236518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>413734.10</td>\n",
       "      <td>413850.65</td>\n",
       "      <td>7.650363</td>\n",
       "      <td>0.609874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>359854.70</td>\n",
       "      <td>359921.30</td>\n",
       "      <td>7.563842</td>\n",
       "      <td>0.743443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1116680.45</td>\n",
       "      <td>1116797.00</td>\n",
       "      <td>7.411182</td>\n",
       "      <td>0.094594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1406623.55</td>\n",
       "      <td>1406723.45</td>\n",
       "      <td>7.327612</td>\n",
       "      <td>0.398486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1398331.85</td>\n",
       "      <td>1398431.75</td>\n",
       "      <td>7.186644</td>\n",
       "      <td>0.293521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1724755.10</td>\n",
       "      <td>1724855.00</td>\n",
       "      <td>7.127906</td>\n",
       "      <td>0.161694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1266763.55</td>\n",
       "      <td>1266863.45</td>\n",
       "      <td>6.997302</td>\n",
       "      <td>0.411512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1410303.20</td>\n",
       "      <td>1410403.10</td>\n",
       "      <td>6.726936</td>\n",
       "      <td>0.160770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1615031.60</td>\n",
       "      <td>1615114.85</td>\n",
       "      <td>6.368147</td>\n",
       "      <td>0.248357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1455058.40</td>\n",
       "      <td>1455141.65</td>\n",
       "      <td>6.292468</td>\n",
       "      <td>0.629599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>82349.15</td>\n",
       "      <td>82432.40</td>\n",
       "      <td>6.251176</td>\n",
       "      <td>0.205015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1735494.35</td>\n",
       "      <td>1735560.95</td>\n",
       "      <td>6.198964</td>\n",
       "      <td>0.361218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>2101311.50</td>\n",
       "      <td>2101378.10</td>\n",
       "      <td>6.187598</td>\n",
       "      <td>0.401076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>L</td>\n",
       "      <td>1465714.40</td>\n",
       "      <td>1465764.35</td>\n",
       "      <td>5.909294</td>\n",
       "      <td>0.600422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>R</td>\n",
       "      <td>1843686.05</td>\n",
       "      <td>1843785.95</td>\n",
       "      <td>5.845848</td>\n",
       "      <td>0.147799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:27:52.454421Z",
     "start_time": "2025-12-31T15:22:17.547766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Monocular verification: OpenCV manual curation UI (sterile, stand-alone) ---\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def curate_events_for_monocular_video_opencv(\n",
    "    block_dict,\n",
    "    events_df,\n",
    "    animal_call=None,\n",
    "    block=None,\n",
    "    pre_ms=200.0,\n",
    "    post_ms=200.0,\n",
    "    flip_eyes=True,\n",
    "    show_arena=False,\n",
    "    text_cols=None,\n",
    "    # display scaling:\n",
    "    window_scale=0.60,\n",
    "    scale_step=0.10,\n",
    "    min_scale=0.20,\n",
    "    max_scale=2.00,\n",
    "    # playback:\n",
    "    wait_ms_default=15,          # ~6070 Hz redraw; independent of step_ms\n",
    "    wait_step=5,\n",
    "    min_wait_ms=1,\n",
    "    max_wait_ms=200,\n",
    "    # tagging (sterile)\n",
    "    tag_col=\"keep_for_video\",    # True=keep, False=reject, None/unset\n",
    "    ts_col=\"curation_ts\",\n",
    "    out_dir_name=\"monocular_video_curation\",\n",
    "    overwrite_existing=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Manual curation UI for monocular events.\n",
    "    - events_df: can be your 'top events view' or full df; must contain animal+block+eye+start/end info.\n",
    "    - Tags saved per block to: bs.analysis_path / out_dir_name / '{animal}_block_{block}_monocular_curation.csv'\n",
    "\n",
    "    UI (mouse buttons + keys):\n",
    "      Space: play/pause\n",
    "      [ / ]: prev / next event\n",
    "      , / .: step -1 / +1 frame (in time, using step_ms)\n",
    "      k: KEEP (tag_col=True)\n",
    "      r: REJECT (tag_col=False)\n",
    "      e: export per-block CSVs (sterile)\n",
    "      z / x: scale - / scale +\n",
    "      - / +: slower / faster (changes wait_ms)\n",
    "      q / Esc: quit\n",
    "\n",
    "    Returns: events dataframe with tag_col + ts_col.\n",
    "    \"\"\"\n",
    "\n",
    "    if text_cols is None:\n",
    "        text_cols = []  # optionally show columns from eye dfs on overlay\n",
    "\n",
    "    # ---------------- helpers ----------------\n",
    "    def _now_stamp():\n",
    "        return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    def _zfill_block(b):\n",
    "        s = str(b)\n",
    "        m = re.search(r\"(\\d+)\", s)\n",
    "        if m:\n",
    "            return m.group(1).zfill(3)\n",
    "        return s.zfill(3)\n",
    "\n",
    "    def _first_existing(df, candidates):\n",
    "        for c in candidates:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    def _require_col(df, candidates, label):\n",
    "        c = _first_existing(df, candidates)\n",
    "        if c is None:\n",
    "            raise KeyError(\"Could not find {}. Tried: {}\".format(label, candidates))\n",
    "        return c\n",
    "\n",
    "    def _coerce_tag(v):\n",
    "        # allow None/NaN -> None; else bool\n",
    "        if v is None:\n",
    "            return None\n",
    "        try:\n",
    "            if isinstance(v, float) and np.isnan(v):\n",
    "                return None\n",
    "        except Exception:\n",
    "            pass\n",
    "        return bool(v)\n",
    "\n",
    "    def _block_for_key(block_dict_local, animal, b):\n",
    "        \"\"\"\n",
    "        Supports:\n",
    "          - dict keys as (animal, block)\n",
    "          - dict keys as 'PV_106_block_011'\n",
    "          - fallback: search string keys containing animal and block token.\n",
    "        \"\"\"\n",
    "        b = _zfill_block(b)\n",
    "        animal = str(animal)\n",
    "\n",
    "        # tuple key\n",
    "        if (animal, b) in block_dict_local:\n",
    "            return block_dict_local[(animal, b)]\n",
    "\n",
    "        # string key (your common case)\n",
    "        k1 = \"{}_block_{}\".format(animal, b)\n",
    "        if k1 in block_dict_local:\n",
    "            return block_dict_local[k1]\n",
    "\n",
    "        # sometimes block like 'block_011' inside key\n",
    "        k2 = \"{}_{}\".format(animal, \"block_{}\".format(b))\n",
    "        if k2 in block_dict_local:\n",
    "            return block_dict_local[k2]\n",
    "\n",
    "        # brute search on string keys\n",
    "        for k in block_dict_local.keys():\n",
    "            if isinstance(k, str):\n",
    "                if (animal in k) and (\"block_{}\".format(b) in k or k.endswith(\"_{}\".format(b))):\n",
    "                    return block_dict_local[k]\n",
    "\n",
    "        raise KeyError(\"Could not find BlockSync for animal={} block={}\".format(animal, b))\n",
    "\n",
    "    def _get_eye_dfs(bs):\n",
    "        # be permissive to your attribute naming across versions\n",
    "        left_df = getattr(bs, \"left_eye_data\", None)\n",
    "        right_df = getattr(bs, \"right_eye_data\", None)\n",
    "        if left_df is None:\n",
    "            left_df = getattr(bs, \"le_df\", None)\n",
    "        if right_df is None:\n",
    "            right_df = getattr(bs, \"re_df\", None)\n",
    "        return left_df, right_df\n",
    "\n",
    "    def _get_video_paths(bs):\n",
    "        # common in your pipeline\n",
    "        lv = getattr(bs, \"le_videos\", None)\n",
    "        rv = getattr(bs, \"re_videos\", None)\n",
    "        av = getattr(bs, \"arena_videos\", None)\n",
    "\n",
    "        lpath = None\n",
    "        rpath = None\n",
    "        apaths = []\n",
    "\n",
    "        if isinstance(lv, (list, tuple)) and len(lv):\n",
    "            lpath = lv[0]\n",
    "        elif isinstance(lv, str):\n",
    "            lpath = lv\n",
    "\n",
    "        if isinstance(rv, (list, tuple)) and len(rv):\n",
    "            rpath = rv[0]\n",
    "        elif isinstance(rv, str):\n",
    "            rpath = rv\n",
    "\n",
    "        if isinstance(av, (list, tuple)):\n",
    "            apaths = list(av)\n",
    "        elif isinstance(av, str):\n",
    "            apaths = [av]\n",
    "\n",
    "        return lpath, rpath, apaths\n",
    "\n",
    "    def _frame_col(df_eye):\n",
    "        # try your common frame columns\n",
    "        for c in [\"eye_frame\", \"L_eye_frame\", \"R_eye_frame\", \"frame\", \"frame_idx\"]:\n",
    "            if c in df_eye.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    def _nearest_row(df_eye, t_ms):\n",
    "        if df_eye is None or df_eye.empty:\n",
    "            return None\n",
    "        if \"ms_axis\" not in df_eye.columns:\n",
    "            return None\n",
    "        ms = df_eye[\"ms_axis\"].values\n",
    "        if ms.size == 0:\n",
    "            return None\n",
    "        idx = int(np.searchsorted(ms, t_ms))\n",
    "        if idx <= 0:\n",
    "            return df_eye.iloc[0]\n",
    "        if idx >= ms.size:\n",
    "            return df_eye.iloc[-1]\n",
    "        # choose closer neighbor\n",
    "        if abs(ms[idx] - t_ms) < abs(ms[idx - 1] - t_ms):\n",
    "            return df_eye.iloc[idx]\n",
    "        return df_eye.iloc[idx - 1]\n",
    "\n",
    "    def _median_step_ms(df_eye):\n",
    "        if df_eye is None or df_eye.empty or \"ms_axis\" not in df_eye.columns:\n",
    "            return 1000.0 / 60.0\n",
    "        ms = df_eye[\"ms_axis\"].values\n",
    "        if ms.size < 2:\n",
    "            return 1000.0 / 60.0\n",
    "        d = np.diff(ms)\n",
    "        d = d[np.isfinite(d) & (d > 0)]\n",
    "        if d.size == 0:\n",
    "            return 1000.0 / 60.0\n",
    "        return float(np.median(d))\n",
    "\n",
    "    def _apply_flip(img):\n",
    "        if not flip_eyes:\n",
    "            return img\n",
    "        img = cv2.flip(img, 0)\n",
    "        img = cv2.flip(img, 1)\n",
    "        return img\n",
    "\n",
    "    def _overlay_text(img, lines, origin=(10, 24), vstep=22, color=(255, 255, 255), font_scale=0.6, thickness=1):\n",
    "        x, y = origin\n",
    "        for ln in lines:\n",
    "            cv2.putText(img, ln, (x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness, cv2.LINE_AA)\n",
    "            y += vstep\n",
    "\n",
    "    def _overlay_ellipse(img, df_eye, frame_idx, thickness=2):\n",
    "        # draws pupil ellipse if columns exist\n",
    "        if df_eye is None or frame_idx is None:\n",
    "            return\n",
    "        fc = _frame_col(df_eye)\n",
    "        if fc is None:\n",
    "            return\n",
    "        hit = df_eye[df_eye[fc] == frame_idx]\n",
    "        if hit.empty:\n",
    "            return\n",
    "        row = hit.iloc[0]\n",
    "        cx = row.get(\"center_x\", np.nan)\n",
    "        cy = row.get(\"center_y\", np.nan)\n",
    "        w  = row.get(\"width\", np.nan)\n",
    "        h  = row.get(\"height\", np.nan)\n",
    "        phi = row.get(\"phi\", np.nan)\n",
    "        if not (pd.isna(cx) or pd.isna(cy) or pd.isna(w) or pd.isna(h)):\n",
    "            cv2.ellipse(\n",
    "                img,\n",
    "                (int(round(cx)), int(round(cy))),\n",
    "                (max(1, int(round(w))), max(1, int(round(h)))),\n",
    "                float(0 if pd.isna(phi) else phi),\n",
    "                0, 360, (0, 255, 0),\n",
    "                thickness\n",
    "            )\n",
    "\n",
    "    def _ensure_std_columns(df_local, animal_col, block_col, eye_col, start_col, end_col):\n",
    "        df_local[\"_animal_std\"] = df_local[animal_col].astype(str)\n",
    "        df_local[\"_block_std\"]  = df_local[block_col].astype(str).apply(_zfill_block)\n",
    "        df_local[\"_eye_std\"]    = df_local[eye_col].astype(str)\n",
    "        df_local[\"_start_ms_std\"] = pd.to_numeric(df_local[start_col], errors=\"coerce\")\n",
    "        df_local[\"_end_ms_std\"]   = pd.to_numeric(df_local[end_col], errors=\"coerce\")\n",
    "\n",
    "        # extend window for video review\n",
    "        df_local[\"_win_start_ms\"] = df_local[\"_start_ms_std\"] - float(pre_ms)\n",
    "        df_local[\"_win_end_ms\"]   = df_local[\"_end_ms_std\"] + float(post_ms)\n",
    "\n",
    "        if tag_col not in df_local.columns:\n",
    "            df_local[tag_col] = None\n",
    "        if ts_col not in df_local.columns:\n",
    "            df_local[ts_col] = \"\"\n",
    "\n",
    "        return df_local\n",
    "\n",
    "    def _write_block_annotations(bs, sub_df):\n",
    "        out_dir = Path(bs.analysis_path) / out_dir_name\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        animal_s = str(sub_df[\"_animal_std\"].iloc[0])\n",
    "        block_s  = str(sub_df[\"_block_std\"].iloc[0])\n",
    "        out_path = out_dir / \"{}_block_{}_monocular_curation.csv\".format(animal_s, block_s)\n",
    "\n",
    "        out = pd.DataFrame({\n",
    "            \"animal_call\": sub_df[\"_animal_std\"].astype(str),\n",
    "            \"block\": sub_df[\"_block_std\"].astype(str),\n",
    "            \"eye\": sub_df[\"_eye_std\"].astype(str),\n",
    "            \"start_ms\": sub_df[\"_start_ms_std\"].astype(float),\n",
    "            \"end_ms\": sub_df[\"_end_ms_std\"].astype(float),\n",
    "            tag_col: sub_df[tag_col].map(_coerce_tag).astype(\"object\"),\n",
    "            ts_col: sub_df[ts_col].astype(str)\n",
    "        })\n",
    "\n",
    "        # merge with existing (unless overwrite)\n",
    "        if out_path.exists() and (not overwrite_existing):\n",
    "            try:\n",
    "                old = pd.read_csv(out_path)\n",
    "                # outer merge on identity columns\n",
    "                key = [\"animal_call\", \"block\", \"eye\", \"start_ms\", \"end_ms\"]\n",
    "                merged = old.merge(out, on=key, how=\"outer\", suffixes=(\"_old\", \"\"))\n",
    "                # prefer new tag/ts if present\n",
    "                if \"{}_old\".format(tag_col) in merged.columns:\n",
    "                    merged[tag_col] = merged[tag_col].where(merged[tag_col].notna(), merged[\"{}_old\".format(tag_col)])\n",
    "                    merged = merged.drop(columns=[\"{}_old\".format(tag_col)], errors=\"ignore\")\n",
    "                if \"{}_old\".format(ts_col) in merged.columns:\n",
    "                    merged[ts_col] = merged[ts_col].where(merged[ts_col].astype(str) != \"\", merged[\"{}_old\".format(ts_col)].astype(str))\n",
    "                    merged = merged.drop(columns=[\"{}_old\".format(ts_col)], errors=\"ignore\")\n",
    "                merged.to_csv(out_path, index=False)\n",
    "                return out_path\n",
    "            except Exception:\n",
    "                # if merge fails, fall back to writing new\n",
    "                out.to_csv(out_path, index=False)\n",
    "                return out_path\n",
    "\n",
    "        out.to_csv(out_path, index=False)\n",
    "        return out_path\n",
    "\n",
    "    # ---------------- normalize events df ----------------\n",
    "    if isinstance(events_df, pd.DataFrame):\n",
    "        df = events_df.copy()\n",
    "    else:\n",
    "        df = pd.DataFrame(events_df).copy()\n",
    "\n",
    "    # allow filtering by animal/block if requested\n",
    "    animal_col = _require_col(df, [\"animal_call\", \"animal\", \"_animal_std\"], \"animal column\")\n",
    "    block_col  = _require_col(df, [\"block\", \"block_num\", \"_block_std\"], \"block column\")\n",
    "    eye_col    = _require_col(df, [\"eye\", \"_eye_std\"], \"eye column\")\n",
    "\n",
    "    start_col = _require_col(df, [\"_start_ms_std\", \"start_ms\", \"start_time_ms\", \"saccade_on_ms\"], \"start_ms column\")\n",
    "    end_col   = _require_col(df, [\"_end_ms_std\", \"end_ms\", \"end_time_ms\", \"saccade_off_ms\"], \"end_ms column\")\n",
    "\n",
    "    df = _ensure_std_columns(df, animal_col, block_col, eye_col, start_col, end_col)\n",
    "    df = df.dropna(subset=[\"_start_ms_std\", \"_end_ms_std\"]).reset_index(drop=True)\n",
    "\n",
    "    if animal_call is not None:\n",
    "        df = df[df[\"_animal_std\"].astype(str) == str(animal_call)].copy()\n",
    "    if block is not None:\n",
    "        df = df[df[\"_block_std\"].astype(str) == _zfill_block(block)].copy()\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No events to curate after filtering (animal_call/block).\")\n",
    "\n",
    "    # ---------------- OpenCV UI ----------------\n",
    "    # windows (mirror your pattern: separate windows + Controls):contentReference[oaicite:5]{index=5}\n",
    "    cv2.namedWindow(\"Controls\", cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow(\"Left Eye\", cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow(\"Right Eye\", cv2.WINDOW_NORMAL)\n",
    "    if show_arena:\n",
    "        cv2.namedWindow(\"Arena\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Controls panel geometry + buttons (your style):contentReference[oaicite:6]{index=6}\n",
    "    ctrl_w, ctrl_h = 540, 520\n",
    "    buttons = {\n",
    "        \"Play\":      ((10, 10),   (260, 60)),\n",
    "        \"Pause\":     ((280, 10),  (530, 60)),\n",
    "        \"Prev\":      ((10, 80),   (260, 130)),\n",
    "        \"Next\":      ((280, 80),  (530, 130)),\n",
    "        \"Step -1\":   ((10, 150),  (260, 200)),\n",
    "        \"Step +1\":   ((280, 150), (530, 200)),\n",
    "        \"KEEP\":      ((10, 220),  (260, 270)),\n",
    "        \"REJECT\":    ((280, 220), (530, 270)),\n",
    "        \"Scale -\":   ((10, 290),  (260, 340)),\n",
    "        \"Scale +\":   ((280, 290), (530, 340)),\n",
    "        \"Slower\":    ((10, 360),  (260, 410)),\n",
    "        \"Faster\":    ((280, 360), (530, 410)),\n",
    "        \"Export\":    ((10, 430),  (530, 480)),\n",
    "    }\n",
    "\n",
    "    COLOR_BG = (60, 60, 60)\n",
    "    COLOR_BORDER = (180, 180, 180)\n",
    "    COLOR_TEXT = (220, 220, 220)\n",
    "    COLOR_KEEP = (0, 255, 0)\n",
    "    COLOR_REJ  = (0, 0, 255)\n",
    "    COLOR_INFO = (180, 255, 180)\n",
    "    COLOR_WARN = (0, 165, 255)\n",
    "\n",
    "    playing = False\n",
    "    quit_flag = False\n",
    "    cur_idx = 0\n",
    "    cur_ms = None\n",
    "    step_ms = 1000.0 / 60.0\n",
    "    wait_ms = int(wait_ms_default)\n",
    "    last_status = \"\"\n",
    "\n",
    "    # video handles (persist across events when same block)\n",
    "    capL = None\n",
    "    capR = None\n",
    "    capA = None\n",
    "    arena_idx = 0\n",
    "    current_key = (None, None)\n",
    "\n",
    "    # current eye dfs / frame cols / dims\n",
    "    left_df = None\n",
    "    right_df = None\n",
    "    left_fc = None\n",
    "    right_fc = None\n",
    "    arena_df = None\n",
    "    arena_fc = None\n",
    "\n",
    "    # display dims (computed on open)\n",
    "    Wl = Hl = Wr = Hr = Wa = Ha = 0\n",
    "    disp_Wl = disp_Hl = disp_Wr = disp_Hr = disp_Wa = disp_Ha = 0\n",
    "\n",
    "    def _hit_button(x, y):\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                return name\n",
    "        return None\n",
    "\n",
    "    def _draw_controls(idx):\n",
    "        img = np.zeros((ctrl_h, ctrl_w, 3), dtype=np.uint8)\n",
    "        # header\n",
    "        state = df[tag_col].iloc[idx]\n",
    "        state = _coerce_tag(state)\n",
    "        if state is None:\n",
    "            state_str = \"UNSET\"\n",
    "        elif bool(state):\n",
    "            state_str = \"KEEP\"\n",
    "        else:\n",
    "            state_str = \"REJECT\"\n",
    "\n",
    "        header = \"Event {}/{} | state={} | scale={:.2f} | wait={}ms\".format(\n",
    "            idx + 1, len(df), state_str, float(window_scale), int(wait_ms)\n",
    "        )\n",
    "        cv2.putText(img, header, (10, ctrl_h - 12), cv2.FONT_HERSHEY_SIMPLEX, 0.55, COLOR_TEXT, 1, cv2.LINE_AA)\n",
    "\n",
    "        # status line\n",
    "        if last_status:\n",
    "            cv2.putText(img, last_status, (10, 22), cv2.FONT_HERSHEY_SIMPLEX, 0.55, COLOR_INFO, 1, cv2.LINE_AA)\n",
    "\n",
    "        # buttons\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            # color by function/state\n",
    "            color = COLOR_BORDER\n",
    "            if name == \"KEEP\":\n",
    "                color = COLOR_KEEP\n",
    "            elif name == \"REJECT\":\n",
    "                color = COLOR_REJ\n",
    "            elif name == \"Export\":\n",
    "                color = COLOR_WARN\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(img, name, (x1 + 10, y2 - 18), cv2.FONT_HERSHEY_SIMPLEX, 0.7, COLOR_TEXT, 2, cv2.LINE_AA)\n",
    "        return img\n",
    "\n",
    "    def _seek(cap, idx):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, int(idx)))\n",
    "\n",
    "    def _read(cap):\n",
    "        ret, f = cap.read()\n",
    "        return f if ret else None\n",
    "\n",
    "    def _set_display_scale(force=False):\n",
    "        nonlocal disp_Wl, disp_Hl, disp_Wr, disp_Hr, disp_Wa, disp_Ha\n",
    "        nonlocal window_scale\n",
    "        # compute & resizeWindow (your pattern):contentReference[oaicite:7]{index=7}\n",
    "        if Wl > 0 and Hl > 0:\n",
    "            disp_Wl, disp_Hl = int(Wl * window_scale), int(Hl * window_scale)\n",
    "            cv2.resizeWindow(\"Left Eye\", disp_Wl, disp_Hl)\n",
    "        if Wr > 0 and Hr > 0:\n",
    "            disp_Wr, disp_Hr = int(Wr * window_scale), int(Hr * window_scale)\n",
    "            cv2.resizeWindow(\"Right Eye\", disp_Wr, disp_Hr)\n",
    "        if show_arena and Wa > 0 and Ha > 0:\n",
    "            disp_Wa, disp_Ha = int(Wa * window_scale), int(Ha * window_scale)\n",
    "            cv2.resizeWindow(\"Arena\", disp_Wa, disp_Ha)\n",
    "        cv2.resizeWindow(\"Controls\", ctrl_w, ctrl_h)\n",
    "\n",
    "    def _open_for(animal, b):\n",
    "        nonlocal capL, capR, capA, current_key, arena_idx\n",
    "        nonlocal left_df, right_df, left_fc, right_fc, Wl, Hl, Wr, Hr, Wa, Ha\n",
    "        nonlocal arena_df, arena_fc\n",
    "\n",
    "        key = (str(animal), _zfill_block(b))\n",
    "        if key == current_key and capL is not None and capR is not None:\n",
    "            return\n",
    "\n",
    "        # close previous\n",
    "        try:\n",
    "            if capL is not None: capL.release()\n",
    "            if capR is not None: capR.release()\n",
    "            if capA is not None: capA.release()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        bs = _block_for_key(block_dict, key[0], key[1])\n",
    "        left_df, right_df = _get_eye_dfs(bs)\n",
    "        left_fc = _frame_col(left_df) if left_df is not None else None\n",
    "        right_fc = _frame_col(right_df) if right_df is not None else None\n",
    "\n",
    "        lpath, rpath, apaths = _get_video_paths(bs)\n",
    "        if lpath is None or rpath is None:\n",
    "            raise RuntimeError(\"Could not resolve le/re video paths for {} block {}\".format(key[0], key[1]))\n",
    "\n",
    "        capL = cv2.VideoCapture(str(lpath))\n",
    "        capR = cv2.VideoCapture(str(rpath))\n",
    "        if not capL.isOpened() or not capR.isOpened():\n",
    "            raise RuntimeError(\"Could not open eye videos: L={} R={}\".format(lpath, rpath))\n",
    "\n",
    "        # dims\n",
    "        Wl = int(capL.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        Hl = int(capL.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        Wr = int(capR.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        Hr = int(capR.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # arena\n",
    "        arena_df = None\n",
    "        arena_fc = None\n",
    "        Wa = Ha = 0\n",
    "        capA = None\n",
    "        arena_idx = 0\n",
    "        if show_arena and apaths:\n",
    "            capA_try = cv2.VideoCapture(str(apaths[arena_idx]))\n",
    "            if capA_try.isOpened():\n",
    "                capA = capA_try\n",
    "                Wa = int(capA.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                Ha = int(capA.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                # if you have a precomputed arena sync df, plug here; otherwise leave None.\n",
    "                # For now: no arena_df => \"no synchronized frame\" message.\n",
    "                arena_df = None\n",
    "                arena_fc = None\n",
    "            else:\n",
    "                capA = None\n",
    "\n",
    "        current_key = key\n",
    "        _set_display_scale(force=True)\n",
    "\n",
    "    def _export_per_block():\n",
    "        nonlocal last_status\n",
    "        written = []\n",
    "        # group by standardized (animal, block)\n",
    "        for (animal, b), sub in df.groupby([\"_animal_std\", \"_block_std\"], dropna=False):\n",
    "            bs = _block_for_key(block_dict, animal, b)\n",
    "            p = _write_block_annotations(bs, sub.copy())\n",
    "            written.append(str(p))\n",
    "        last_status = \"Exported sterile curation to {} block file(s).\".format(len(written))\n",
    "\n",
    "    # initial paint\n",
    "    cv2.imshow(\"Controls\", _draw_controls(cur_idx))\n",
    "\n",
    "    def on_mouse_controls(event, x, y, flags, param):\n",
    "        nonlocal playing, quit_flag, cur_idx, cur_ms, last_status, window_scale, wait_ms\n",
    "        if event != cv2.EVENT_LBUTTONDOWN:\n",
    "            return\n",
    "        name = _hit_button(x, y)\n",
    "        if name is None:\n",
    "            return\n",
    "\n",
    "        last_status = \"\"\n",
    "\n",
    "        if name == \"Play\":\n",
    "            playing = True\n",
    "        elif name == \"Pause\":\n",
    "            playing = False\n",
    "        elif name == \"Prev\":\n",
    "            playing = False\n",
    "            cur_idx = (cur_idx - 1) % len(df)\n",
    "            cur_ms = None\n",
    "        elif name == \"Next\":\n",
    "            playing = False\n",
    "            cur_idx = (cur_idx + 1) % len(df)\n",
    "            cur_ms = None\n",
    "        elif name == \"Step -1\":\n",
    "            playing = False\n",
    "            if cur_ms is not None:\n",
    "                cur_ms -= step_ms\n",
    "        elif name == \"Step +1\":\n",
    "            playing = False\n",
    "            if cur_ms is not None:\n",
    "                cur_ms += step_ms\n",
    "        elif name == \"KEEP\":\n",
    "            df.at[cur_idx, tag_col] = True\n",
    "            df.at[cur_idx, ts_col] = _now_stamp()\n",
    "        elif name == \"REJECT\":\n",
    "            df.at[cur_idx, tag_col] = False\n",
    "            df.at[cur_idx, ts_col] = _now_stamp()\n",
    "        elif name == \"Scale -\":\n",
    "            window_scale = max(min_scale, float(window_scale) - float(scale_step))\n",
    "            _set_display_scale(force=True)\n",
    "        elif name == \"Scale +\":\n",
    "            window_scale = min(max_scale, float(window_scale) + float(scale_step))\n",
    "            _set_display_scale(force=True)\n",
    "        elif name == \"Slower\":\n",
    "            wait_ms = min(max_wait_ms, int(wait_ms) + int(wait_step))\n",
    "        elif name == \"Faster\":\n",
    "            wait_ms = max(min_wait_ms, int(wait_ms) - int(wait_step))\n",
    "        elif name == \"Export\":\n",
    "            _export_per_block()\n",
    "\n",
    "        cv2.imshow(\"Controls\", _draw_controls(cur_idx))\n",
    "\n",
    "    cv2.setMouseCallback(\"Controls\", on_mouse_controls)\n",
    "\n",
    "    # ---------------- main loop ----------------\n",
    "    while True:\n",
    "        k = cv2.waitKey(int(wait_ms)) & 0xFF\n",
    "\n",
    "        # keyboard shortcuts mirror your original structure:contentReference[oaicite:8]{index=8}\n",
    "        if k in (27, ord('q'), ord('Q')):\n",
    "            quit_flag = True\n",
    "        elif k == 32:  # space\n",
    "            playing = not playing\n",
    "        elif k == ord('['):\n",
    "            playing = False\n",
    "            cur_idx = (cur_idx - 1) % len(df)\n",
    "            cur_ms = None\n",
    "        elif k == ord(']'):\n",
    "            playing = False\n",
    "            cur_idx = (cur_idx + 1) % len(df)\n",
    "            cur_ms = None\n",
    "        elif k == ord(','):\n",
    "            playing = False\n",
    "            if cur_ms is not None:\n",
    "                cur_ms -= step_ms\n",
    "        elif k == ord('.'):\n",
    "            playing = False\n",
    "            if cur_ms is not None:\n",
    "                cur_ms += step_ms\n",
    "        elif k in (ord('k'), ord('K')):\n",
    "            df.at[cur_idx, tag_col] = True\n",
    "            df.at[cur_idx, ts_col] = _now_stamp()\n",
    "        elif k in (ord('r'), ord('R')):\n",
    "            df.at[cur_idx, tag_col] = False\n",
    "            df.at[cur_idx, ts_col] = _now_stamp()\n",
    "        elif k in (ord('e'), ord('E')):\n",
    "            _export_per_block()\n",
    "        elif k in (ord('z'), ord('Z')):\n",
    "            window_scale = max(min_scale, float(window_scale) - float(scale_step))\n",
    "            _set_display_scale(force=True)\n",
    "        elif k in (ord('x'), ord('X')):\n",
    "            window_scale = min(max_scale, float(window_scale) + float(scale_step))\n",
    "            _set_display_scale(force=True)\n",
    "        elif k == ord('-'):\n",
    "            wait_ms = min(max_wait_ms, int(wait_ms) + int(wait_step))\n",
    "        elif k in (ord('+'), ord('=')):  # '=' is '+' without shift on many keyboards\n",
    "            wait_ms = max(min_wait_ms, int(wait_ms) - int(wait_step))\n",
    "\n",
    "        if quit_flag:\n",
    "            break\n",
    "\n",
    "        row = df.iloc[cur_idx]\n",
    "        animal = str(row[\"_animal_std\"])\n",
    "        b = str(row[\"_block_std\"])\n",
    "\n",
    "        # open block\n",
    "        _open_for(animal, b)\n",
    "\n",
    "        # update step_ms from actual eye df timing\n",
    "        step_ms = float(np.mean([_median_step_ms(left_df), _median_step_ms(right_df)]))\n",
    "\n",
    "        start_ms = float(row[\"_win_start_ms\"])\n",
    "        end_ms   = float(row[\"_win_end_ms\"])\n",
    "\n",
    "        if cur_ms is None:\n",
    "            cur_ms = start_ms\n",
    "        cur_ms = min(max(cur_ms, start_ms), end_ms)\n",
    "\n",
    "        # map to nearest rows in eye dfs\n",
    "        rowL = _nearest_row(left_df, cur_ms)\n",
    "        rowR = _nearest_row(right_df, cur_ms)\n",
    "\n",
    "        # Left frame\n",
    "        L_img = np.zeros((max(1, Hl), max(1, Wl), 3), dtype=np.uint8)\n",
    "        if rowL is not None and left_fc is not None:\n",
    "            L_idx = rowL.get(left_fc, np.nan)\n",
    "            if pd.notna(L_idx):\n",
    "                L_idx = int(L_idx)\n",
    "                _seek(capL, L_idx)\n",
    "                fL = _read(capL)\n",
    "                if fL is not None:\n",
    "                    _overlay_ellipse(fL, left_df, L_idx)\n",
    "                    img = _apply_flip(fL.copy())\n",
    "                    lines = [\"Left | {} B{} | t={:.1f}ms | frame={}\".format(animal, b, cur_ms, L_idx)]\n",
    "                    for c in text_cols:\n",
    "                        if (left_df is not None) and (c in left_df.columns):\n",
    "                            v = rowL.get(c, np.nan)\n",
    "                            if pd.notna(v):\n",
    "                                try:\n",
    "                                    lines.append(\"{}={:.3f}\".format(c, float(v)))\n",
    "                                except Exception:\n",
    "                                    pass\n",
    "                    _overlay_text(img, lines, origin=(10, 24))\n",
    "                    L_img = img\n",
    "                else:\n",
    "                    _overlay_text(L_img, [\"Left | read error\"], origin=(10, 24))\n",
    "                    L_img = _apply_flip(L_img)\n",
    "            else:\n",
    "                _overlay_text(L_img, [\"Left | no synchronized frame\"], origin=(10, 24))\n",
    "                L_img = _apply_flip(L_img)\n",
    "\n",
    "        # Right frame\n",
    "        R_img = np.zeros((max(1, Hr), max(1, Wr), 3), dtype=np.uint8)\n",
    "        if rowR is not None and right_fc is not None:\n",
    "            R_idx = rowR.get(right_fc, np.nan)\n",
    "            if pd.notna(R_idx):\n",
    "                R_idx = int(R_idx)\n",
    "                _seek(capR, R_idx)\n",
    "                fR = _read(capR)\n",
    "                if fR is not None:\n",
    "                    _overlay_ellipse(fR, right_df, R_idx)\n",
    "                    img = _apply_flip(fR.copy())\n",
    "                    lines = [\"Right | {} B{} | t={:.1f}ms | frame={}\".format(animal, b, cur_ms, R_idx)]\n",
    "                    for c in text_cols:\n",
    "                        if (right_df is not None) and (c in right_df.columns):\n",
    "                            v = rowR.get(c, np.nan)\n",
    "                            if pd.notna(v):\n",
    "                                try:\n",
    "                                    lines.append(\"{}={:.3f}\".format(c, float(v)))\n",
    "                                except Exception:\n",
    "                                    pass\n",
    "                    _overlay_text(img, lines, origin=(10, 24))\n",
    "                    R_img = img\n",
    "                else:\n",
    "                    _overlay_text(R_img, [\"Right | read error\"], origin=(10, 24))\n",
    "                    R_img = _apply_flip(R_img)\n",
    "            else:\n",
    "                _overlay_text(R_img, [\"Right | no synchronized frame\"], origin=(10, 24))\n",
    "                R_img = _apply_flip(R_img)\n",
    "\n",
    "        # show\n",
    "        if disp_Wl > 0 and disp_Hl > 0:\n",
    "            cv2.imshow(\"Left Eye\", cv2.resize(L_img, (disp_Wl, disp_Hl)))\n",
    "        else:\n",
    "            cv2.imshow(\"Left Eye\", L_img)\n",
    "\n",
    "        if disp_Wr > 0 and disp_Hr > 0:\n",
    "            cv2.imshow(\"Right Eye\", cv2.resize(R_img, (disp_Wr, disp_Hr)))\n",
    "        else:\n",
    "            cv2.imshow(\"Right Eye\", R_img)\n",
    "\n",
    "        # controls repaint\n",
    "        cv2.imshow(\"Controls\", _draw_controls(cur_idx))\n",
    "\n",
    "        # playback advance (same logic as your outlier tool):contentReference[oaicite:9]{index=9}\n",
    "        if playing:\n",
    "            cur_ms += step_ms\n",
    "            if cur_ms > end_ms:\n",
    "                playing = False\n",
    "                cur_idx = (cur_idx + 1) % len(df)\n",
    "                cur_ms = None\n",
    "\n",
    "    # cleanup\n",
    "    try:\n",
    "        if capL is not None: capL.release()\n",
    "        if capR is not None: capR.release()\n",
    "        if capA is not None: capA.release()\n",
    "    except Exception:\n",
    "        pass\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = curate_events_for_monocular_video_opencv(\n",
    "    block_dict,\n",
    "    largest_amp_df,\n",
    "    animal_call=\"PV_106\",\n",
    "    block=\"011\",\n",
    "    pre_ms=250.0,\n",
    "    post_ms=250.0,\n",
    "    flip_eyes=True,\n",
    "    show_arena=True,\n",
    "    text_cols=None,\n",
    "    # display scaling:\n",
    "    window_scale=0.60,\n",
    "    scale_step=0.10,\n",
    "    min_scale=0.20,\n",
    "    max_scale=2.00,\n",
    "    # playback:\n",
    "    wait_ms_default=15,          # ~6070 Hz redraw; independent of step_ms\n",
    "    wait_step=5,\n",
    "    min_wait_ms=1,\n",
    "    max_wait_ms=200,\n",
    "    # tagging (sterile)\n",
    "    tag_col=\"keep_for_video\",    # True=keep, False=reject, None/unset\n",
    "    ts_col=\"curation_ts\",\n",
    "    out_dir_name=\"monocular_video_curation\",\n",
    "    overwrite_existing=False\n",
    ")"
   ],
   "id": "439bb7b30708ef73",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:27:55.607499Z",
     "start_time": "2025-12-31T15:27:55.564679Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "42d371b939e922de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    saccade_start_ind  saccade_end_ind  saccade_start_timestamp  \\\n",
       "0               37609            37618               12990961.0   \n",
       "1               82527            82536               27948655.0   \n",
       "2               38512            38516               13291660.0   \n",
       "3               43387            43397               14915035.0   \n",
       "4               16216            16222                5867092.0   \n",
       "5              107967           107974               36420175.0   \n",
       "6               22307            22311                7895395.0   \n",
       "7               77642            77646               26321950.0   \n",
       "8               30319            30324               10563391.0   \n",
       "9               31761            31764               11043577.0   \n",
       "10              31423            31431               10931023.0   \n",
       "11              42704            42710               14687596.0   \n",
       "12              78695            78703               26672599.0   \n",
       "13              16539            16543                5974651.0   \n",
       "14              15910            15916                5765194.0   \n",
       "15              68418            68427               23250358.0   \n",
       "16              31764            31769               11044576.0   \n",
       "17              55748            55756               19031248.0   \n",
       "18              49575            49581               16975639.0   \n",
       "19              75121            75131               25482457.0   \n",
       "20             128139           128142               43137451.0   \n",
       "21              20217            20221                7199425.0   \n",
       "22              86625            86628               29313289.0   \n",
       "23             122992           122998               41423500.0   \n",
       "24              82457            82458               27925345.0   \n",
       "25              82458            82464               27925678.0   \n",
       "26              36764            36767               12709576.0   \n",
       "27              22311            22314                7896727.0   \n",
       "28              31438            31445               10936018.0   \n",
       "29              80129            80136               27150121.0   \n",
       "30              30327            30332               10566055.0   \n",
       "31              17953            17958                6445513.0   \n",
       "32              36770            36773               12711574.0   \n",
       "33              36458            36465               12607678.0   \n",
       "34              99257            99261               33519745.0   \n",
       "35              23446            23453                8274682.0   \n",
       "36              20210            20214                7197094.0   \n",
       "37              65665            65672               22333609.0   \n",
       "38              83079            83085               28132471.0   \n",
       "39              82581            82587               27966637.0   \n",
       "40             102186           102192               34495102.0   \n",
       "41              74679            74685               25335271.0   \n",
       "42              83300            83306               28206064.0   \n",
       "43              95596            95601               32300632.0   \n",
       "44              85988            85993               29101168.0   \n",
       "45               3543             3548                1646983.0   \n",
       "46             102831           102835               34709887.0   \n",
       "47             124802           124806               42026230.0   \n",
       "48              86628            86631               29314288.0   \n",
       "49             109329           109335               36873721.0   \n",
       "\n",
       "    saccade_end_timestamp  saccade_on_ms  saccade_off_ms  length  \\\n",
       "0              12993958.0      649548.05       649697.90       9   \n",
       "1              27951652.0     1397432.75      1397582.60       9   \n",
       "2              13292992.0      664583.00       664649.60       4   \n",
       "3              14918365.0      745751.75       745918.25      10   \n",
       "4               5869090.0      293354.60       293454.50       6   \n",
       "5              36422506.0     1821008.75      1821125.30       7   \n",
       "6               7896727.0      394769.75       394836.35       4   \n",
       "7              26323282.0     1316097.50      1316164.10       4   \n",
       "8              10565056.0      528169.55       528252.80       5   \n",
       "9              11044576.0      552178.85       552228.80       3   \n",
       "10             10933687.0      546551.15       546684.35       8   \n",
       "11             14689594.0      734379.80       734479.70       6   \n",
       "12             26675263.0     1333629.95      1333763.15       8   \n",
       "13              5975983.0      298732.55       298799.15       4   \n",
       "14              5767192.0      288259.70       288359.60       6   \n",
       "15             23253355.0     1162517.90      1162667.75       9   \n",
       "16             11046241.0      552228.80       552312.05       5   \n",
       "17             19033912.0      951562.40       951695.60       8   \n",
       "18             16977637.0      848781.95       848881.85       6   \n",
       "19             25485787.0     1274122.85      1274289.35      10   \n",
       "20             43138450.0     2156872.55      2156922.50       3   \n",
       "21              7200757.0      359971.25       360037.85       4   \n",
       "22             29314288.0     1465664.45      1465714.40       3   \n",
       "23             41425498.0     2071175.00      2071274.90       6   \n",
       "24             27925678.0     1396267.25      1396283.90       1   \n",
       "25             27927676.0     1396283.90      1396383.80       6   \n",
       "26             12710575.0      635478.80       635528.75       3   \n",
       "27              7897726.0      394836.35       394886.30       3   \n",
       "28             10938349.0      546800.90       546917.45       7   \n",
       "29             27152452.0     1357506.05      1357622.60       7   \n",
       "30             10567720.0      528302.75       528386.00       5   \n",
       "31              6447178.0      322275.65       322358.90       5   \n",
       "32             12712573.0      635578.70       635628.65       3   \n",
       "33             12610009.0      630383.90       630500.45       7   \n",
       "34             33521077.0     1675987.25      1676053.85       4   \n",
       "35              8277013.0      413734.10       413850.65       7   \n",
       "36              7198426.0      359854.70       359921.30       4   \n",
       "37             22335940.0     1116680.45      1116797.00       7   \n",
       "38             28134469.0     1406623.55      1406723.45       6   \n",
       "39             27968635.0     1398331.85      1398431.75       6   \n",
       "40             34497100.0     1724755.10      1724855.00       6   \n",
       "41             25337269.0     1266763.55      1266863.45       6   \n",
       "42             28208062.0     1410303.20      1410403.10       6   \n",
       "43             32302297.0     1615031.60      1615114.85       5   \n",
       "44             29102833.0     1455058.40      1455141.65       5   \n",
       "45              1648648.0       82349.15        82432.40       5   \n",
       "46             34711219.0     1735494.35      1735560.95       4   \n",
       "47             42027562.0     2101311.50      2101378.10       4   \n",
       "48             29315287.0     1465714.40      1465764.35       3   \n",
       "49             36875719.0     1843686.05      1843785.95       6   \n",
       "\n",
       "    magnitude_raw_pixel  magnitude_pixel  magnitude_raw_angular  ...  \\\n",
       "0             74.325777        74.325777              41.100213  ...   \n",
       "1             57.118510        57.118510              29.949464  ...   \n",
       "2             22.086375        22.086375              23.127384  ...   \n",
       "3             32.182984        32.182984              19.086935  ...   \n",
       "4             38.189611        38.189611              18.225718  ...   \n",
       "5             38.978089        38.978089              16.010049  ...   \n",
       "6             29.517137        29.517137              15.847297  ...   \n",
       "7             31.443291        31.443291              18.284548  ...   \n",
       "8             33.783532        33.783532              18.780982  ...   \n",
       "9             28.881512        28.881512              20.099988  ...   \n",
       "10            38.866501        38.866501              15.685274  ...   \n",
       "11            36.084991        36.084991              15.392490  ...   \n",
       "12            27.404801        27.404801              16.166355  ...   \n",
       "13            24.431590        24.431590              14.224493  ...   \n",
       "14            24.402723        24.402723              12.088616  ...   \n",
       "15            23.155874        23.155874              12.243171  ...   \n",
       "16            30.362405        30.362405              19.825867  ...   \n",
       "17            18.646824        18.646824              11.798286  ...   \n",
       "18            19.253007        19.253007              12.052912  ...   \n",
       "19            16.683480        16.683480              11.302172  ...   \n",
       "20            24.111722        24.111722              13.018443  ...   \n",
       "21            34.411216        34.411216              14.378565  ...   \n",
       "22            22.854647        22.854647              13.443223  ...   \n",
       "23            14.339411        14.339411              10.702460  ...   \n",
       "24            25.469897        25.469897              14.725506  ...   \n",
       "25            33.176828        33.176828              19.671088  ...   \n",
       "26            39.150472        39.150472              15.295684  ...   \n",
       "27            21.225024        21.225024              11.520919  ...   \n",
       "28            16.682255        16.682255               9.692498  ...   \n",
       "29            17.562555        17.562555               9.447070  ...   \n",
       "30            16.028507        16.028507              10.524924  ...   \n",
       "31            17.871046        17.871046               9.257108  ...   \n",
       "32            31.237466        31.237466              12.343070  ...   \n",
       "33            16.209635        16.209635               8.886310  ...   \n",
       "34            16.664210        16.664210               9.939092  ...   \n",
       "35            17.111300        17.111300               8.928014  ...   \n",
       "36            26.793230        26.793230              11.877680  ...   \n",
       "37            15.021945        15.021945               9.327096  ...   \n",
       "38            22.632262        22.632262               8.521158  ...   \n",
       "39            22.168935        22.168935               8.338747  ...   \n",
       "40            18.549598        18.549598               8.344946  ...   \n",
       "41            15.430862        15.430862               8.217169  ...   \n",
       "42            15.412458        15.412458               8.224377  ...   \n",
       "43            12.098828        12.098828               8.254310  ...   \n",
       "44             8.815241         8.815241               7.360257  ...   \n",
       "45            11.405971        11.405971               7.449303  ...   \n",
       "46            18.808061        18.808061               7.956637  ...   \n",
       "47             8.671516         8.671516               7.364487  ...   \n",
       "48            14.392579        14.392579               9.087790  ...   \n",
       "49            16.571034        16.571034               7.204019  ...   \n",
       "\n",
       "    other_eye_peak_speed  _animal_std _block_std _start_ms_std _end_ms_std  \\\n",
       "0               0.457379       PV_106        011     649548.05   649697.90   \n",
       "1               0.178496       PV_106        011    1397432.75  1397582.60   \n",
       "2               0.539145       PV_106        011     664583.00   664649.60   \n",
       "3               0.467697       PV_106        011     745751.75   745918.25   \n",
       "4               0.721173       PV_106        011     293354.60   293454.50   \n",
       "5               0.156091       PV_106        011    1821008.75  1821125.30   \n",
       "6               0.583258       PV_106        011     394769.75   394836.35   \n",
       "7               0.526883       PV_106        011    1316097.50  1316164.10   \n",
       "8               0.567019       PV_106        011     528169.55   528252.80   \n",
       "9               0.296782       PV_106        011     552178.85   552228.80   \n",
       "10              0.591110       PV_106        011     546551.15   546684.35   \n",
       "11              0.387694       PV_106        011     734379.80   734479.70   \n",
       "12              0.464727       PV_106        011    1333629.95  1333763.15   \n",
       "13              0.780913       PV_106        011     298732.55   298799.15   \n",
       "14              0.523635       PV_106        011     288259.70   288359.60   \n",
       "15              0.135417       PV_106        011    1162517.90  1162667.75   \n",
       "16              0.332805       PV_106        011     552228.80   552312.05   \n",
       "17              0.451088       PV_106        011     951562.40   951695.60   \n",
       "18              0.777620       PV_106        011     848781.95   848881.85   \n",
       "19              0.167884       PV_106        011    1274122.85  1274289.35   \n",
       "20              0.766361       PV_106        011    2156872.55  2156922.50   \n",
       "21              0.452421       PV_106        011     359971.25   360037.85   \n",
       "22              0.414769       PV_106        011    1465664.45  1465714.40   \n",
       "23              0.607554       PV_106        011    2071175.00  2071274.90   \n",
       "24              0.435074       PV_106        011    1396267.25  1396283.90   \n",
       "25              0.368809       PV_106        011    1396283.90  1396383.80   \n",
       "26              0.784593       PV_106        011     635478.80   635528.75   \n",
       "27              0.583258       PV_106        011     394836.35   394886.30   \n",
       "28              0.595647       PV_106        011     546800.90   546917.45   \n",
       "29              0.236627       PV_106        011    1357506.05  1357622.60   \n",
       "30              0.591066       PV_106        011     528302.75   528386.00   \n",
       "31              0.630610       PV_106        011     322275.65   322358.90   \n",
       "32              0.775079       PV_106        011     635578.70   635628.65   \n",
       "33              0.792119       PV_106        011     630383.90   630500.45   \n",
       "34              0.236518       PV_106        011    1675987.25  1676053.85   \n",
       "35              0.609874       PV_106        011     413734.10   413850.65   \n",
       "36              0.743443       PV_106        011     359854.70   359921.30   \n",
       "37              0.094594       PV_106        011    1116680.45  1116797.00   \n",
       "38              0.398486       PV_106        011    1406623.55  1406723.45   \n",
       "39              0.293521       PV_106        011    1398331.85  1398431.75   \n",
       "40              0.161694       PV_106        011    1724755.10  1724855.00   \n",
       "41              0.411512       PV_106        011    1266763.55  1266863.45   \n",
       "42              0.160770       PV_106        011    1410303.20  1410403.10   \n",
       "43              0.248357       PV_106        011    1615031.60  1615114.85   \n",
       "44              0.629599       PV_106        011    1455058.40  1455141.65   \n",
       "45              0.205015       PV_106        011      82349.15    82432.40   \n",
       "46              0.361218       PV_106        011    1735494.35  1735560.95   \n",
       "47              0.401076       PV_106        011    2101311.50  2101378.10   \n",
       "48              0.600422       PV_106        011    1465714.40  1465764.35   \n",
       "49              0.147799       PV_106        011    1843686.05  1843785.95   \n",
       "\n",
       "   _eye_std  _win_start_ms  _win_end_ms  keep_for_video          curation_ts  \n",
       "0         L      649298.05    649947.90            True  2025-12-31_17-22-25  \n",
       "1         L     1397182.75   1397832.60           False  2025-12-31_17-22-29  \n",
       "2         L      664333.00    664899.60            True  2025-12-31_17-22-30  \n",
       "3         L      745501.75    746168.25            True  2025-12-31_17-22-38  \n",
       "4         R      293104.60    293704.50            True  2025-12-31_17-22-41  \n",
       "5         R     1820758.75   1821375.30            True  2025-12-31_17-22-46  \n",
       "6         L      394519.75    395086.35           False  2025-12-31_17-22-49  \n",
       "7         L     1315847.50   1316414.10           False  2025-12-31_17-22-51  \n",
       "8         L      527919.55    528502.80           False  2025-12-31_17-23-05  \n",
       "9         L      551928.85    552478.80            True  2025-12-31_17-23-18  \n",
       "10        R      546301.15    546934.35           False  2025-12-31_17-23-20  \n",
       "11        R      734129.80    734729.70            True  2025-12-31_17-23-24  \n",
       "12        L     1333379.95   1334013.15            True  2025-12-31_17-23-27  \n",
       "13        L      298482.55    299049.15           False  2025-12-31_17-23-31  \n",
       "14        R      288009.70    288609.60            True  2025-12-31_17-23-33  \n",
       "15        L     1162267.90   1162917.75           False  2025-12-31_17-23-35  \n",
       "16        L      551978.80    552562.05            True  2025-12-31_17-23-39  \n",
       "17        L      951312.40    951945.60           False  2025-12-31_17-23-42  \n",
       "18        L      848531.95    849131.85           False  2025-12-31_17-23-45  \n",
       "19        L     1273872.85   1274539.35           False  2025-12-31_17-23-49  \n",
       "20        L     2156622.55   2157172.50            True  2025-12-31_17-23-52  \n",
       "21        R      359721.25    360287.85           False  2025-12-31_17-23-56  \n",
       "22        L     1465414.45   1465964.40           False  2025-12-31_17-23-59  \n",
       "23        L     2070925.00   2071524.90            True  2025-12-31_17-25-25  \n",
       "24        L     1396017.25   1396533.90           False  2025-12-31_17-25-29  \n",
       "25        L     1396033.90   1396633.80           False  2025-12-31_17-25-35  \n",
       "26        R      635228.80    635778.75           False  2025-12-31_17-25-38  \n",
       "27        L      394586.35    395136.30           False  2025-12-31_17-25-42  \n",
       "28        L      546550.90    547167.45           False  2025-12-31_17-25-42  \n",
       "29        L     1357256.05   1357872.60           False  2025-12-31_17-25-45  \n",
       "30        L      528052.75    528636.00            True  2025-12-31_17-25-51  \n",
       "31        R      322025.65    322608.90            True  2025-12-31_17-25-55  \n",
       "32        R      635328.70    635878.65           False  2025-12-31_17-25-58  \n",
       "33        L      630133.90    630750.45           False  2025-12-31_17-26-02  \n",
       "34        L     1675737.25   1676303.85            True  2025-12-31_17-26-06  \n",
       "35        L      413484.10    414100.65            True  2025-12-31_17-26-11  \n",
       "36        R      359604.70    360171.30           False  2025-12-31_17-26-20  \n",
       "37        L     1116430.45   1117047.00           False  2025-12-31_17-26-35  \n",
       "38        R     1406373.55   1406973.45            True  2025-12-31_17-26-43  \n",
       "39        R     1398081.85   1398681.75           False  2025-12-31_17-26-45  \n",
       "40        R     1724505.10   1725105.00           False  2025-12-31_17-26-51  \n",
       "41        L     1266513.55   1267113.45           False  2025-12-31_17-26-51  \n",
       "42        L     1410053.20   1410653.10           False  2025-12-31_17-26-55  \n",
       "43        L     1614781.60   1615364.85            True  2025-12-31_17-27-01  \n",
       "44        L     1454808.40   1455391.65            True  2025-12-31_17-27-19  \n",
       "45        L       82099.15     82682.40           False  2025-12-31_17-27-24  \n",
       "46        R     1735244.35   1735810.95            True  2025-12-31_17-27-27  \n",
       "47        L     2101061.50   2101628.10           False  2025-12-31_17-27-31  \n",
       "48        L     1465464.40   1466014.35            True  2025-12-31_17-27-36  \n",
       "49        R     1843436.05   1844035.95           False  2025-12-31_17-27-48  \n",
       "\n",
       "[50 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>saccade_start_ind</th>\n",
       "      <th>saccade_end_ind</th>\n",
       "      <th>saccade_start_timestamp</th>\n",
       "      <th>saccade_end_timestamp</th>\n",
       "      <th>saccade_on_ms</th>\n",
       "      <th>saccade_off_ms</th>\n",
       "      <th>length</th>\n",
       "      <th>magnitude_raw_pixel</th>\n",
       "      <th>magnitude_pixel</th>\n",
       "      <th>magnitude_raw_angular</th>\n",
       "      <th>...</th>\n",
       "      <th>other_eye_peak_speed</th>\n",
       "      <th>_animal_std</th>\n",
       "      <th>_block_std</th>\n",
       "      <th>_start_ms_std</th>\n",
       "      <th>_end_ms_std</th>\n",
       "      <th>_eye_std</th>\n",
       "      <th>_win_start_ms</th>\n",
       "      <th>_win_end_ms</th>\n",
       "      <th>keep_for_video</th>\n",
       "      <th>curation_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37609</td>\n",
       "      <td>37618</td>\n",
       "      <td>12990961.0</td>\n",
       "      <td>12993958.0</td>\n",
       "      <td>649548.05</td>\n",
       "      <td>649697.90</td>\n",
       "      <td>9</td>\n",
       "      <td>74.325777</td>\n",
       "      <td>74.325777</td>\n",
       "      <td>41.100213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457379</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>649548.05</td>\n",
       "      <td>649697.90</td>\n",
       "      <td>L</td>\n",
       "      <td>649298.05</td>\n",
       "      <td>649947.90</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-22-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82527</td>\n",
       "      <td>82536</td>\n",
       "      <td>27948655.0</td>\n",
       "      <td>27951652.0</td>\n",
       "      <td>1397432.75</td>\n",
       "      <td>1397582.60</td>\n",
       "      <td>9</td>\n",
       "      <td>57.118510</td>\n",
       "      <td>57.118510</td>\n",
       "      <td>29.949464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178496</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1397432.75</td>\n",
       "      <td>1397582.60</td>\n",
       "      <td>L</td>\n",
       "      <td>1397182.75</td>\n",
       "      <td>1397832.60</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-22-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38512</td>\n",
       "      <td>38516</td>\n",
       "      <td>13291660.0</td>\n",
       "      <td>13292992.0</td>\n",
       "      <td>664583.00</td>\n",
       "      <td>664649.60</td>\n",
       "      <td>4</td>\n",
       "      <td>22.086375</td>\n",
       "      <td>22.086375</td>\n",
       "      <td>23.127384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539145</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>664583.00</td>\n",
       "      <td>664649.60</td>\n",
       "      <td>L</td>\n",
       "      <td>664333.00</td>\n",
       "      <td>664899.60</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-22-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43387</td>\n",
       "      <td>43397</td>\n",
       "      <td>14915035.0</td>\n",
       "      <td>14918365.0</td>\n",
       "      <td>745751.75</td>\n",
       "      <td>745918.25</td>\n",
       "      <td>10</td>\n",
       "      <td>32.182984</td>\n",
       "      <td>32.182984</td>\n",
       "      <td>19.086935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467697</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>745751.75</td>\n",
       "      <td>745918.25</td>\n",
       "      <td>L</td>\n",
       "      <td>745501.75</td>\n",
       "      <td>746168.25</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-22-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16216</td>\n",
       "      <td>16222</td>\n",
       "      <td>5867092.0</td>\n",
       "      <td>5869090.0</td>\n",
       "      <td>293354.60</td>\n",
       "      <td>293454.50</td>\n",
       "      <td>6</td>\n",
       "      <td>38.189611</td>\n",
       "      <td>38.189611</td>\n",
       "      <td>18.225718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721173</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>293354.60</td>\n",
       "      <td>293454.50</td>\n",
       "      <td>R</td>\n",
       "      <td>293104.60</td>\n",
       "      <td>293704.50</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-22-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107967</td>\n",
       "      <td>107974</td>\n",
       "      <td>36420175.0</td>\n",
       "      <td>36422506.0</td>\n",
       "      <td>1821008.75</td>\n",
       "      <td>1821125.30</td>\n",
       "      <td>7</td>\n",
       "      <td>38.978089</td>\n",
       "      <td>38.978089</td>\n",
       "      <td>16.010049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156091</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1821008.75</td>\n",
       "      <td>1821125.30</td>\n",
       "      <td>R</td>\n",
       "      <td>1820758.75</td>\n",
       "      <td>1821375.30</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-22-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22307</td>\n",
       "      <td>22311</td>\n",
       "      <td>7895395.0</td>\n",
       "      <td>7896727.0</td>\n",
       "      <td>394769.75</td>\n",
       "      <td>394836.35</td>\n",
       "      <td>4</td>\n",
       "      <td>29.517137</td>\n",
       "      <td>29.517137</td>\n",
       "      <td>15.847297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583258</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>394769.75</td>\n",
       "      <td>394836.35</td>\n",
       "      <td>L</td>\n",
       "      <td>394519.75</td>\n",
       "      <td>395086.35</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-22-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77642</td>\n",
       "      <td>77646</td>\n",
       "      <td>26321950.0</td>\n",
       "      <td>26323282.0</td>\n",
       "      <td>1316097.50</td>\n",
       "      <td>1316164.10</td>\n",
       "      <td>4</td>\n",
       "      <td>31.443291</td>\n",
       "      <td>31.443291</td>\n",
       "      <td>18.284548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526883</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1316097.50</td>\n",
       "      <td>1316164.10</td>\n",
       "      <td>L</td>\n",
       "      <td>1315847.50</td>\n",
       "      <td>1316414.10</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-22-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30319</td>\n",
       "      <td>30324</td>\n",
       "      <td>10563391.0</td>\n",
       "      <td>10565056.0</td>\n",
       "      <td>528169.55</td>\n",
       "      <td>528252.80</td>\n",
       "      <td>5</td>\n",
       "      <td>33.783532</td>\n",
       "      <td>33.783532</td>\n",
       "      <td>18.780982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567019</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>528169.55</td>\n",
       "      <td>528252.80</td>\n",
       "      <td>L</td>\n",
       "      <td>527919.55</td>\n",
       "      <td>528502.80</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-23-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31761</td>\n",
       "      <td>31764</td>\n",
       "      <td>11043577.0</td>\n",
       "      <td>11044576.0</td>\n",
       "      <td>552178.85</td>\n",
       "      <td>552228.80</td>\n",
       "      <td>3</td>\n",
       "      <td>28.881512</td>\n",
       "      <td>28.881512</td>\n",
       "      <td>20.099988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296782</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>552178.85</td>\n",
       "      <td>552228.80</td>\n",
       "      <td>L</td>\n",
       "      <td>551928.85</td>\n",
       "      <td>552478.80</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-23-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31423</td>\n",
       "      <td>31431</td>\n",
       "      <td>10931023.0</td>\n",
       "      <td>10933687.0</td>\n",
       "      <td>546551.15</td>\n",
       "      <td>546684.35</td>\n",
       "      <td>8</td>\n",
       "      <td>38.866501</td>\n",
       "      <td>38.866501</td>\n",
       "      <td>15.685274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591110</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>546551.15</td>\n",
       "      <td>546684.35</td>\n",
       "      <td>R</td>\n",
       "      <td>546301.15</td>\n",
       "      <td>546934.35</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-23-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42704</td>\n",
       "      <td>42710</td>\n",
       "      <td>14687596.0</td>\n",
       "      <td>14689594.0</td>\n",
       "      <td>734379.80</td>\n",
       "      <td>734479.70</td>\n",
       "      <td>6</td>\n",
       "      <td>36.084991</td>\n",
       "      <td>36.084991</td>\n",
       "      <td>15.392490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387694</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>734379.80</td>\n",
       "      <td>734479.70</td>\n",
       "      <td>R</td>\n",
       "      <td>734129.80</td>\n",
       "      <td>734729.70</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-23-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>78695</td>\n",
       "      <td>78703</td>\n",
       "      <td>26672599.0</td>\n",
       "      <td>26675263.0</td>\n",
       "      <td>1333629.95</td>\n",
       "      <td>1333763.15</td>\n",
       "      <td>8</td>\n",
       "      <td>27.404801</td>\n",
       "      <td>27.404801</td>\n",
       "      <td>16.166355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464727</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1333629.95</td>\n",
       "      <td>1333763.15</td>\n",
       "      <td>L</td>\n",
       "      <td>1333379.95</td>\n",
       "      <td>1334013.15</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-23-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16539</td>\n",
       "      <td>16543</td>\n",
       "      <td>5974651.0</td>\n",
       "      <td>5975983.0</td>\n",
       "      <td>298732.55</td>\n",
       "      <td>298799.15</td>\n",
       "      <td>4</td>\n",
       "      <td>24.431590</td>\n",
       "      <td>24.431590</td>\n",
       "      <td>14.224493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780913</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>298732.55</td>\n",
       "      <td>298799.15</td>\n",
       "      <td>L</td>\n",
       "      <td>298482.55</td>\n",
       "      <td>299049.15</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-23-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15910</td>\n",
       "      <td>15916</td>\n",
       "      <td>5765194.0</td>\n",
       "      <td>5767192.0</td>\n",
       "      <td>288259.70</td>\n",
       "      <td>288359.60</td>\n",
       "      <td>6</td>\n",
       "      <td>24.402723</td>\n",
       "      <td>24.402723</td>\n",
       "      <td>12.088616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523635</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>288259.70</td>\n",
       "      <td>288359.60</td>\n",
       "      <td>R</td>\n",
       "      <td>288009.70</td>\n",
       "      <td>288609.60</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-23-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>68418</td>\n",
       "      <td>68427</td>\n",
       "      <td>23250358.0</td>\n",
       "      <td>23253355.0</td>\n",
       "      <td>1162517.90</td>\n",
       "      <td>1162667.75</td>\n",
       "      <td>9</td>\n",
       "      <td>23.155874</td>\n",
       "      <td>23.155874</td>\n",
       "      <td>12.243171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135417</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1162517.90</td>\n",
       "      <td>1162667.75</td>\n",
       "      <td>L</td>\n",
       "      <td>1162267.90</td>\n",
       "      <td>1162917.75</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-23-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31764</td>\n",
       "      <td>31769</td>\n",
       "      <td>11044576.0</td>\n",
       "      <td>11046241.0</td>\n",
       "      <td>552228.80</td>\n",
       "      <td>552312.05</td>\n",
       "      <td>5</td>\n",
       "      <td>30.362405</td>\n",
       "      <td>30.362405</td>\n",
       "      <td>19.825867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332805</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>552228.80</td>\n",
       "      <td>552312.05</td>\n",
       "      <td>L</td>\n",
       "      <td>551978.80</td>\n",
       "      <td>552562.05</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-23-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>55748</td>\n",
       "      <td>55756</td>\n",
       "      <td>19031248.0</td>\n",
       "      <td>19033912.0</td>\n",
       "      <td>951562.40</td>\n",
       "      <td>951695.60</td>\n",
       "      <td>8</td>\n",
       "      <td>18.646824</td>\n",
       "      <td>18.646824</td>\n",
       "      <td>11.798286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451088</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>951562.40</td>\n",
       "      <td>951695.60</td>\n",
       "      <td>L</td>\n",
       "      <td>951312.40</td>\n",
       "      <td>951945.60</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-23-42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>49575</td>\n",
       "      <td>49581</td>\n",
       "      <td>16975639.0</td>\n",
       "      <td>16977637.0</td>\n",
       "      <td>848781.95</td>\n",
       "      <td>848881.85</td>\n",
       "      <td>6</td>\n",
       "      <td>19.253007</td>\n",
       "      <td>19.253007</td>\n",
       "      <td>12.052912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777620</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>848781.95</td>\n",
       "      <td>848881.85</td>\n",
       "      <td>L</td>\n",
       "      <td>848531.95</td>\n",
       "      <td>849131.85</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-23-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75121</td>\n",
       "      <td>75131</td>\n",
       "      <td>25482457.0</td>\n",
       "      <td>25485787.0</td>\n",
       "      <td>1274122.85</td>\n",
       "      <td>1274289.35</td>\n",
       "      <td>10</td>\n",
       "      <td>16.683480</td>\n",
       "      <td>16.683480</td>\n",
       "      <td>11.302172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167884</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1274122.85</td>\n",
       "      <td>1274289.35</td>\n",
       "      <td>L</td>\n",
       "      <td>1273872.85</td>\n",
       "      <td>1274539.35</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-23-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>128139</td>\n",
       "      <td>128142</td>\n",
       "      <td>43137451.0</td>\n",
       "      <td>43138450.0</td>\n",
       "      <td>2156872.55</td>\n",
       "      <td>2156922.50</td>\n",
       "      <td>3</td>\n",
       "      <td>24.111722</td>\n",
       "      <td>24.111722</td>\n",
       "      <td>13.018443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766361</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>2156872.55</td>\n",
       "      <td>2156922.50</td>\n",
       "      <td>L</td>\n",
       "      <td>2156622.55</td>\n",
       "      <td>2157172.50</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-23-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20217</td>\n",
       "      <td>20221</td>\n",
       "      <td>7199425.0</td>\n",
       "      <td>7200757.0</td>\n",
       "      <td>359971.25</td>\n",
       "      <td>360037.85</td>\n",
       "      <td>4</td>\n",
       "      <td>34.411216</td>\n",
       "      <td>34.411216</td>\n",
       "      <td>14.378565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452421</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>359971.25</td>\n",
       "      <td>360037.85</td>\n",
       "      <td>R</td>\n",
       "      <td>359721.25</td>\n",
       "      <td>360287.85</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-23-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>86625</td>\n",
       "      <td>86628</td>\n",
       "      <td>29313289.0</td>\n",
       "      <td>29314288.0</td>\n",
       "      <td>1465664.45</td>\n",
       "      <td>1465714.40</td>\n",
       "      <td>3</td>\n",
       "      <td>22.854647</td>\n",
       "      <td>22.854647</td>\n",
       "      <td>13.443223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414769</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1465664.45</td>\n",
       "      <td>1465714.40</td>\n",
       "      <td>L</td>\n",
       "      <td>1465414.45</td>\n",
       "      <td>1465964.40</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-23-59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>122992</td>\n",
       "      <td>122998</td>\n",
       "      <td>41423500.0</td>\n",
       "      <td>41425498.0</td>\n",
       "      <td>2071175.00</td>\n",
       "      <td>2071274.90</td>\n",
       "      <td>6</td>\n",
       "      <td>14.339411</td>\n",
       "      <td>14.339411</td>\n",
       "      <td>10.702460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607554</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>2071175.00</td>\n",
       "      <td>2071274.90</td>\n",
       "      <td>L</td>\n",
       "      <td>2070925.00</td>\n",
       "      <td>2071524.90</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-25-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>82457</td>\n",
       "      <td>82458</td>\n",
       "      <td>27925345.0</td>\n",
       "      <td>27925678.0</td>\n",
       "      <td>1396267.25</td>\n",
       "      <td>1396283.90</td>\n",
       "      <td>1</td>\n",
       "      <td>25.469897</td>\n",
       "      <td>25.469897</td>\n",
       "      <td>14.725506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435074</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1396267.25</td>\n",
       "      <td>1396283.90</td>\n",
       "      <td>L</td>\n",
       "      <td>1396017.25</td>\n",
       "      <td>1396533.90</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-25-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>82458</td>\n",
       "      <td>82464</td>\n",
       "      <td>27925678.0</td>\n",
       "      <td>27927676.0</td>\n",
       "      <td>1396283.90</td>\n",
       "      <td>1396383.80</td>\n",
       "      <td>6</td>\n",
       "      <td>33.176828</td>\n",
       "      <td>33.176828</td>\n",
       "      <td>19.671088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368809</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1396283.90</td>\n",
       "      <td>1396383.80</td>\n",
       "      <td>L</td>\n",
       "      <td>1396033.90</td>\n",
       "      <td>1396633.80</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-25-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36764</td>\n",
       "      <td>36767</td>\n",
       "      <td>12709576.0</td>\n",
       "      <td>12710575.0</td>\n",
       "      <td>635478.80</td>\n",
       "      <td>635528.75</td>\n",
       "      <td>3</td>\n",
       "      <td>39.150472</td>\n",
       "      <td>39.150472</td>\n",
       "      <td>15.295684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784593</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>635478.80</td>\n",
       "      <td>635528.75</td>\n",
       "      <td>R</td>\n",
       "      <td>635228.80</td>\n",
       "      <td>635778.75</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-25-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22311</td>\n",
       "      <td>22314</td>\n",
       "      <td>7896727.0</td>\n",
       "      <td>7897726.0</td>\n",
       "      <td>394836.35</td>\n",
       "      <td>394886.30</td>\n",
       "      <td>3</td>\n",
       "      <td>21.225024</td>\n",
       "      <td>21.225024</td>\n",
       "      <td>11.520919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583258</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>394836.35</td>\n",
       "      <td>394886.30</td>\n",
       "      <td>L</td>\n",
       "      <td>394586.35</td>\n",
       "      <td>395136.30</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-25-42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>31438</td>\n",
       "      <td>31445</td>\n",
       "      <td>10936018.0</td>\n",
       "      <td>10938349.0</td>\n",
       "      <td>546800.90</td>\n",
       "      <td>546917.45</td>\n",
       "      <td>7</td>\n",
       "      <td>16.682255</td>\n",
       "      <td>16.682255</td>\n",
       "      <td>9.692498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595647</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>546800.90</td>\n",
       "      <td>546917.45</td>\n",
       "      <td>L</td>\n",
       "      <td>546550.90</td>\n",
       "      <td>547167.45</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-25-42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>80129</td>\n",
       "      <td>80136</td>\n",
       "      <td>27150121.0</td>\n",
       "      <td>27152452.0</td>\n",
       "      <td>1357506.05</td>\n",
       "      <td>1357622.60</td>\n",
       "      <td>7</td>\n",
       "      <td>17.562555</td>\n",
       "      <td>17.562555</td>\n",
       "      <td>9.447070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236627</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1357506.05</td>\n",
       "      <td>1357622.60</td>\n",
       "      <td>L</td>\n",
       "      <td>1357256.05</td>\n",
       "      <td>1357872.60</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-25-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30327</td>\n",
       "      <td>30332</td>\n",
       "      <td>10566055.0</td>\n",
       "      <td>10567720.0</td>\n",
       "      <td>528302.75</td>\n",
       "      <td>528386.00</td>\n",
       "      <td>5</td>\n",
       "      <td>16.028507</td>\n",
       "      <td>16.028507</td>\n",
       "      <td>10.524924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591066</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>528302.75</td>\n",
       "      <td>528386.00</td>\n",
       "      <td>L</td>\n",
       "      <td>528052.75</td>\n",
       "      <td>528636.00</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-25-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>17953</td>\n",
       "      <td>17958</td>\n",
       "      <td>6445513.0</td>\n",
       "      <td>6447178.0</td>\n",
       "      <td>322275.65</td>\n",
       "      <td>322358.90</td>\n",
       "      <td>5</td>\n",
       "      <td>17.871046</td>\n",
       "      <td>17.871046</td>\n",
       "      <td>9.257108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630610</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>322275.65</td>\n",
       "      <td>322358.90</td>\n",
       "      <td>R</td>\n",
       "      <td>322025.65</td>\n",
       "      <td>322608.90</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-25-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>36770</td>\n",
       "      <td>36773</td>\n",
       "      <td>12711574.0</td>\n",
       "      <td>12712573.0</td>\n",
       "      <td>635578.70</td>\n",
       "      <td>635628.65</td>\n",
       "      <td>3</td>\n",
       "      <td>31.237466</td>\n",
       "      <td>31.237466</td>\n",
       "      <td>12.343070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775079</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>635578.70</td>\n",
       "      <td>635628.65</td>\n",
       "      <td>R</td>\n",
       "      <td>635328.70</td>\n",
       "      <td>635878.65</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-25-58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>36458</td>\n",
       "      <td>36465</td>\n",
       "      <td>12607678.0</td>\n",
       "      <td>12610009.0</td>\n",
       "      <td>630383.90</td>\n",
       "      <td>630500.45</td>\n",
       "      <td>7</td>\n",
       "      <td>16.209635</td>\n",
       "      <td>16.209635</td>\n",
       "      <td>8.886310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792119</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>630383.90</td>\n",
       "      <td>630500.45</td>\n",
       "      <td>L</td>\n",
       "      <td>630133.90</td>\n",
       "      <td>630750.45</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-26-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>99257</td>\n",
       "      <td>99261</td>\n",
       "      <td>33519745.0</td>\n",
       "      <td>33521077.0</td>\n",
       "      <td>1675987.25</td>\n",
       "      <td>1676053.85</td>\n",
       "      <td>4</td>\n",
       "      <td>16.664210</td>\n",
       "      <td>16.664210</td>\n",
       "      <td>9.939092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236518</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1675987.25</td>\n",
       "      <td>1676053.85</td>\n",
       "      <td>L</td>\n",
       "      <td>1675737.25</td>\n",
       "      <td>1676303.85</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-26-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>23446</td>\n",
       "      <td>23453</td>\n",
       "      <td>8274682.0</td>\n",
       "      <td>8277013.0</td>\n",
       "      <td>413734.10</td>\n",
       "      <td>413850.65</td>\n",
       "      <td>7</td>\n",
       "      <td>17.111300</td>\n",
       "      <td>17.111300</td>\n",
       "      <td>8.928014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609874</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>413734.10</td>\n",
       "      <td>413850.65</td>\n",
       "      <td>L</td>\n",
       "      <td>413484.10</td>\n",
       "      <td>414100.65</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-26-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20210</td>\n",
       "      <td>20214</td>\n",
       "      <td>7197094.0</td>\n",
       "      <td>7198426.0</td>\n",
       "      <td>359854.70</td>\n",
       "      <td>359921.30</td>\n",
       "      <td>4</td>\n",
       "      <td>26.793230</td>\n",
       "      <td>26.793230</td>\n",
       "      <td>11.877680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743443</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>359854.70</td>\n",
       "      <td>359921.30</td>\n",
       "      <td>R</td>\n",
       "      <td>359604.70</td>\n",
       "      <td>360171.30</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-26-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>65665</td>\n",
       "      <td>65672</td>\n",
       "      <td>22333609.0</td>\n",
       "      <td>22335940.0</td>\n",
       "      <td>1116680.45</td>\n",
       "      <td>1116797.00</td>\n",
       "      <td>7</td>\n",
       "      <td>15.021945</td>\n",
       "      <td>15.021945</td>\n",
       "      <td>9.327096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094594</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1116680.45</td>\n",
       "      <td>1116797.00</td>\n",
       "      <td>L</td>\n",
       "      <td>1116430.45</td>\n",
       "      <td>1117047.00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-26-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>83079</td>\n",
       "      <td>83085</td>\n",
       "      <td>28132471.0</td>\n",
       "      <td>28134469.0</td>\n",
       "      <td>1406623.55</td>\n",
       "      <td>1406723.45</td>\n",
       "      <td>6</td>\n",
       "      <td>22.632262</td>\n",
       "      <td>22.632262</td>\n",
       "      <td>8.521158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1406623.55</td>\n",
       "      <td>1406723.45</td>\n",
       "      <td>R</td>\n",
       "      <td>1406373.55</td>\n",
       "      <td>1406973.45</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-26-43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>82581</td>\n",
       "      <td>82587</td>\n",
       "      <td>27966637.0</td>\n",
       "      <td>27968635.0</td>\n",
       "      <td>1398331.85</td>\n",
       "      <td>1398431.75</td>\n",
       "      <td>6</td>\n",
       "      <td>22.168935</td>\n",
       "      <td>22.168935</td>\n",
       "      <td>8.338747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293521</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1398331.85</td>\n",
       "      <td>1398431.75</td>\n",
       "      <td>R</td>\n",
       "      <td>1398081.85</td>\n",
       "      <td>1398681.75</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-26-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>102186</td>\n",
       "      <td>102192</td>\n",
       "      <td>34495102.0</td>\n",
       "      <td>34497100.0</td>\n",
       "      <td>1724755.10</td>\n",
       "      <td>1724855.00</td>\n",
       "      <td>6</td>\n",
       "      <td>18.549598</td>\n",
       "      <td>18.549598</td>\n",
       "      <td>8.344946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161694</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1724755.10</td>\n",
       "      <td>1724855.00</td>\n",
       "      <td>R</td>\n",
       "      <td>1724505.10</td>\n",
       "      <td>1725105.00</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-26-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>74679</td>\n",
       "      <td>74685</td>\n",
       "      <td>25335271.0</td>\n",
       "      <td>25337269.0</td>\n",
       "      <td>1266763.55</td>\n",
       "      <td>1266863.45</td>\n",
       "      <td>6</td>\n",
       "      <td>15.430862</td>\n",
       "      <td>15.430862</td>\n",
       "      <td>8.217169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411512</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1266763.55</td>\n",
       "      <td>1266863.45</td>\n",
       "      <td>L</td>\n",
       "      <td>1266513.55</td>\n",
       "      <td>1267113.45</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-26-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>83300</td>\n",
       "      <td>83306</td>\n",
       "      <td>28206064.0</td>\n",
       "      <td>28208062.0</td>\n",
       "      <td>1410303.20</td>\n",
       "      <td>1410403.10</td>\n",
       "      <td>6</td>\n",
       "      <td>15.412458</td>\n",
       "      <td>15.412458</td>\n",
       "      <td>8.224377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160770</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1410303.20</td>\n",
       "      <td>1410403.10</td>\n",
       "      <td>L</td>\n",
       "      <td>1410053.20</td>\n",
       "      <td>1410653.10</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-26-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>95596</td>\n",
       "      <td>95601</td>\n",
       "      <td>32300632.0</td>\n",
       "      <td>32302297.0</td>\n",
       "      <td>1615031.60</td>\n",
       "      <td>1615114.85</td>\n",
       "      <td>5</td>\n",
       "      <td>12.098828</td>\n",
       "      <td>12.098828</td>\n",
       "      <td>8.254310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248357</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1615031.60</td>\n",
       "      <td>1615114.85</td>\n",
       "      <td>L</td>\n",
       "      <td>1614781.60</td>\n",
       "      <td>1615364.85</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-27-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>85988</td>\n",
       "      <td>85993</td>\n",
       "      <td>29101168.0</td>\n",
       "      <td>29102833.0</td>\n",
       "      <td>1455058.40</td>\n",
       "      <td>1455141.65</td>\n",
       "      <td>5</td>\n",
       "      <td>8.815241</td>\n",
       "      <td>8.815241</td>\n",
       "      <td>7.360257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629599</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1455058.40</td>\n",
       "      <td>1455141.65</td>\n",
       "      <td>L</td>\n",
       "      <td>1454808.40</td>\n",
       "      <td>1455391.65</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-27-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3543</td>\n",
       "      <td>3548</td>\n",
       "      <td>1646983.0</td>\n",
       "      <td>1648648.0</td>\n",
       "      <td>82349.15</td>\n",
       "      <td>82432.40</td>\n",
       "      <td>5</td>\n",
       "      <td>11.405971</td>\n",
       "      <td>11.405971</td>\n",
       "      <td>7.449303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205015</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>82349.15</td>\n",
       "      <td>82432.40</td>\n",
       "      <td>L</td>\n",
       "      <td>82099.15</td>\n",
       "      <td>82682.40</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-27-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>102831</td>\n",
       "      <td>102835</td>\n",
       "      <td>34709887.0</td>\n",
       "      <td>34711219.0</td>\n",
       "      <td>1735494.35</td>\n",
       "      <td>1735560.95</td>\n",
       "      <td>4</td>\n",
       "      <td>18.808061</td>\n",
       "      <td>18.808061</td>\n",
       "      <td>7.956637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361218</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1735494.35</td>\n",
       "      <td>1735560.95</td>\n",
       "      <td>R</td>\n",
       "      <td>1735244.35</td>\n",
       "      <td>1735810.95</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-27-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>124802</td>\n",
       "      <td>124806</td>\n",
       "      <td>42026230.0</td>\n",
       "      <td>42027562.0</td>\n",
       "      <td>2101311.50</td>\n",
       "      <td>2101378.10</td>\n",
       "      <td>4</td>\n",
       "      <td>8.671516</td>\n",
       "      <td>8.671516</td>\n",
       "      <td>7.364487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401076</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>2101311.50</td>\n",
       "      <td>2101378.10</td>\n",
       "      <td>L</td>\n",
       "      <td>2101061.50</td>\n",
       "      <td>2101628.10</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-27-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>86628</td>\n",
       "      <td>86631</td>\n",
       "      <td>29314288.0</td>\n",
       "      <td>29315287.0</td>\n",
       "      <td>1465714.40</td>\n",
       "      <td>1465764.35</td>\n",
       "      <td>3</td>\n",
       "      <td>14.392579</td>\n",
       "      <td>14.392579</td>\n",
       "      <td>9.087790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600422</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1465714.40</td>\n",
       "      <td>1465764.35</td>\n",
       "      <td>L</td>\n",
       "      <td>1465464.40</td>\n",
       "      <td>1466014.35</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-12-31_17-27-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>109329</td>\n",
       "      <td>109335</td>\n",
       "      <td>36873721.0</td>\n",
       "      <td>36875719.0</td>\n",
       "      <td>1843686.05</td>\n",
       "      <td>1843785.95</td>\n",
       "      <td>6</td>\n",
       "      <td>16.571034</td>\n",
       "      <td>16.571034</td>\n",
       "      <td>7.204019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147799</td>\n",
       "      <td>PV_106</td>\n",
       "      <td>011</td>\n",
       "      <td>1843686.05</td>\n",
       "      <td>1843785.95</td>\n",
       "      <td>R</td>\n",
       "      <td>1843436.05</td>\n",
       "      <td>1844035.95</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-31_17-27-48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows  36 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:29:41.840761Z",
     "start_time": "2025-12-31T15:29:27.885816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Export curated events to MP4 (stand-alone cell, py<3.9)\n",
    "# =========================\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def _zfill_block(block):\n",
    "    s = str(block)\n",
    "    digits = \"\".join([c for c in s if c.isdigit()])\n",
    "    if digits == \"\":\n",
    "        return s.zfill(3)\n",
    "    return digits.zfill(3)\n",
    "\n",
    "def _block_for_key(block_dict, animal, block):\n",
    "    \"\"\"\n",
    "    Supports your dict style keys: 'PV_106_block_011'\n",
    "    \"\"\"\n",
    "    b = _zfill_block(block)\n",
    "    k1 = \"{}_block_{}\".format(str(animal), b)\n",
    "    if k1 in block_dict:\n",
    "        return block_dict[k1]\n",
    "\n",
    "    # (fallbacks if you ever also use tuple keys)\n",
    "    if (str(animal), b) in block_dict:\n",
    "        return block_dict[(str(animal), b)]\n",
    "    if (str(animal), str(int(b))) in block_dict:\n",
    "        return block_dict[(str(animal), str(int(b)))]\n",
    "\n",
    "    raise KeyError(\"Could not find BlockSync for animal={} block={}\".format(animal, b))\n",
    "\n",
    "def _frame_col(df):\n",
    "    for c in (\"eye_frame\", \"frame\", \"frame_idx\", \"video_frame\"):\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _nearest_row(df, ms):\n",
    "    arr = df[\"ms_axis\"].values\n",
    "    if arr.size == 0:\n",
    "        return None\n",
    "    idx = int(np.argmin(np.abs(arr - float(ms))))\n",
    "    return df.iloc[idx]\n",
    "\n",
    "def _ensure_arena_ms_axis(bs):\n",
    "    \"\"\"\n",
    "    Uses bs.final_sync_df; if it lacks ms_axis, tries to merge from eye ms_axis via OE_timestamp.\n",
    "    Mirrors your reviewer logic.:contentReference[oaicite:2]{index=2}\n",
    "    \"\"\"\n",
    "    fs = bs.final_sync_df.copy()\n",
    "    # resolve arena frame col\n",
    "    fcol = None\n",
    "    for c in [\"Arena_frame\", \"arena_frame\", \"arena_frames\", \"arena_frame_idx\", \"frame\", \"frame_idx\", \"video_frame\", \"arena_idx\"]:\n",
    "        if c in fs.columns:\n",
    "            fcol = c\n",
    "            break\n",
    "    if fcol is None:\n",
    "        raise RuntimeError(\"final_sync_df has no recognizable arena frame column.\")\n",
    "\n",
    "    if \"ms_axis\" not in fs.columns:\n",
    "        joined = False\n",
    "        for eye_df in [getattr(bs, \"left_eye_data\", None), getattr(bs, \"right_eye_data\", None)]:\n",
    "            if eye_df is not None and \"OE_timestamp\" in fs.columns and \"OE_timestamp\" in eye_df.columns and \"ms_axis\" in eye_df.columns:\n",
    "                tmp = eye_df[[\"OE_timestamp\", \"ms_axis\"]].dropna().drop_duplicates(subset=[\"OE_timestamp\"])\n",
    "                fs = fs.merge(tmp, on=\"OE_timestamp\", how=\"left\")\n",
    "                joined = True\n",
    "                break\n",
    "        if not joined:\n",
    "            fs[\"ms_axis\"] = np.nan\n",
    "\n",
    "    out = fs[[c for c in [\"ms_axis\", fcol, \"OE_timestamp\"] if c in fs.columns]].copy()\n",
    "    out[fcol] = pd.to_numeric(out[fcol], errors=\"coerce\").astype(\"Int64\")\n",
    "    out = out.dropna(subset=[fcol])\n",
    "    return out, fcol\n",
    "\n",
    "def export_curated_monocular_mp4(\n",
    "    block_dict,\n",
    "    curated_df,\n",
    "    out_mp4_path,\n",
    "    animal_col=\"animal\",\n",
    "    block_col=\"block\",\n",
    "    eye_col=\"eye\",\n",
    "    start_ms_col=None,   # auto-detect from start_ms / saccade_on_ms\n",
    "    end_ms_col=None,     # auto-detect from end_ms / saccade_off_ms\n",
    "    keep_col=None,       # auto-detect (keep_for_video / manual_outlier_detected / etc.)\n",
    "    keep_value=True,     # include rows where keep_col == keep_value (after coercion)\n",
    "    pre_ms=150,\n",
    "    post_ms=150,\n",
    "    fps_out=60.0,\n",
    "    step_ms=None,        # default: 1000/fps_out\n",
    "    window_scale=0.60,   # montage output scaling (controls final MP4 resolution)\n",
    "    include_arena=False,\n",
    "    arena_index=0,\n",
    "    flip_mode=\"vertical\",  # matches your viewer: \"vertical\" => cv2.flip(img,0):contentReference[oaicite:3]{index=3}\n",
    "    font_scale=0.6,\n",
    "    thickness=2,\n",
    "    add_title_frames=True,\n",
    "    title_frames_sec=0.5\n",
    "):\n",
    "    df = curated_df.copy().reset_index(drop=True)\n",
    "\n",
    "    # --- resolve time columns (you noted you needed saccade_on/off in the search) ---\n",
    "    cand_start = [start_ms_col, \"start_ms\", \"saccade_on_ms\"]\n",
    "    cand_end   = [end_ms_col, \"end_ms\", \"saccade_off_ms\"]\n",
    "    s_col = next((c for c in cand_start if c and c in df.columns), None)\n",
    "    e_col = next((c for c in cand_end   if c and c in df.columns), None)\n",
    "    if s_col is None or e_col is None:\n",
    "        raise ValueError(\"Could not resolve start/end ms columns from {} / {}\".format(cand_start, cand_end))\n",
    "\n",
    "    # --- resolve keep column ---\n",
    "    if keep_col is None:\n",
    "        for c in (\"keep_for_video\", \"keep\", \"include\", \"manual_outlier_detected\", \"is_good\", \"good\", \"tag\"):\n",
    "            if c in df.columns:\n",
    "                keep_col = c\n",
    "                break\n",
    "    if keep_col is None:\n",
    "        raise ValueError(\"Could not auto-detect keep_col. Pass keep_col explicitly.\")\n",
    "\n",
    "    def _coerce_bool(x):\n",
    "        if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "            return None\n",
    "        if isinstance(x, bool):\n",
    "            return x\n",
    "        s = str(x).strip().lower()\n",
    "        if s in (\"true\", \"t\", \"1\", \"yes\", \"y\"):\n",
    "            return True\n",
    "        if s in (\"false\", \"f\", \"0\", \"no\", \"n\"):\n",
    "            return False\n",
    "        return None\n",
    "\n",
    "    df[\"_keep_bool\"] = df[keep_col].map(_coerce_bool)\n",
    "\n",
    "    # If keep_col is \"manual_outlier_detected\", typical meaning is BAD=True; invert by default if user wants \"good\"\n",
    "    if keep_col == \"manual_outlier_detected\" and keep_value is True:\n",
    "        # keep_value=True would keep \"bad\"  probably not what you want, so warn via behavior:\n",
    "        # (we won't print; just recommend passing keep_value=False in usage)\n",
    "        pass\n",
    "\n",
    "    kept = df[df[\"_keep_bool\"] == bool(keep_value)].copy()\n",
    "    if kept.empty:\n",
    "        raise ValueError(\"No rows matched keep_col={} == {} (after coercion).\".format(keep_col, keep_value))\n",
    "\n",
    "    # sort for reproducibility\n",
    "    kept[block_col] = kept[block_col].astype(str).apply(_zfill_block)\n",
    "    kept[s_col] = pd.to_numeric(kept[s_col], errors=\"coerce\")\n",
    "    kept[e_col] = pd.to_numeric(kept[e_col], errors=\"coerce\")\n",
    "    kept = kept.dropna(subset=[s_col, e_col])\n",
    "    kept = kept.sort_values([animal_col, block_col, s_col]).reset_index(drop=True)\n",
    "\n",
    "    if step_ms is None:\n",
    "        step_ms = 1000.0 / float(fps_out)\n",
    "\n",
    "    out_mp4_path = Path(out_mp4_path)\n",
    "    out_mp4_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- helpers ---\n",
    "    def _apply_flip(img):\n",
    "        if flip_mode == \"vertical\":\n",
    "            return cv2.flip(img, 0)\n",
    "        return img\n",
    "\n",
    "    def _overlay_text(img, lines, origin=(10, 24), vstep=22):\n",
    "        x, y = origin\n",
    "        for ln in lines:\n",
    "            cv2.putText(img, str(ln), (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        float(font_scale), (255, 255, 255), int(thickness), cv2.LINE_AA)\n",
    "            y += vstep\n",
    "\n",
    "    # --- open-on-demand per (animal, block) ---\n",
    "    capL = capR = capA = None\n",
    "    left_df = right_df = arena_df = None\n",
    "    left_frame_col = right_frame_col = arena_frame_col = None\n",
    "    cur_animal = None\n",
    "    cur_block = None\n",
    "\n",
    "    def _release():\n",
    "        nonlocal capL, capR, capA\n",
    "        for c in (capL, capR, capA):\n",
    "            try:\n",
    "                if c is not None:\n",
    "                    c.release()\n",
    "            except Exception:\n",
    "                pass\n",
    "        capL = capR = capA = None\n",
    "\n",
    "    def _open_for(animal, block_num):\n",
    "        nonlocal capL, capR, capA\n",
    "        nonlocal left_df, right_df, arena_df\n",
    "        nonlocal left_frame_col, right_frame_col, arena_frame_col\n",
    "        nonlocal cur_animal, cur_block\n",
    "\n",
    "        if animal == cur_animal and block_num == cur_block:\n",
    "            return\n",
    "\n",
    "        _release()\n",
    "        bs = _block_for_key(block_dict, animal, block_num)\n",
    "        cur_animal, cur_block = animal, block_num\n",
    "\n",
    "        left_df = getattr(bs, \"left_eye_data\", None)\n",
    "        right_df = getattr(bs, \"right_eye_data\", None)\n",
    "        if left_df is None or right_df is None:\n",
    "            raise RuntimeError(\"Missing eye data for {} B{}\".format(animal, block_num))\n",
    "        if \"ms_axis\" not in left_df.columns or \"ms_axis\" not in right_df.columns:\n",
    "            raise RuntimeError(\"'ms_axis' missing for {} B{}\".format(animal, block_num))\n",
    "\n",
    "        left_frame_col = _frame_col(left_df)\n",
    "        right_frame_col = _frame_col(right_df)\n",
    "        if left_frame_col is None or right_frame_col is None:\n",
    "            raise RuntimeError(\"Could not resolve eye frame column for {} B{}\".format(animal, block_num))\n",
    "\n",
    "        lv = Path(bs.le_videos[0])\n",
    "        rv = Path(bs.re_videos[0])\n",
    "        capL = cv2.VideoCapture(str(lv))\n",
    "        capR = cv2.VideoCapture(str(rv))\n",
    "        if not capL.isOpened():\n",
    "            raise RuntimeError(\"Cannot open {}\".format(lv))\n",
    "        if not capR.isOpened():\n",
    "            raise RuntimeError(\"Cannot open {}\".format(rv))\n",
    "\n",
    "        # arena optional\n",
    "        capA = None\n",
    "        arena_df = None\n",
    "        arena_frame_col = None\n",
    "        if include_arena and getattr(bs, \"arena_videos\", None):\n",
    "            arena_df, arena_frame_col = _ensure_arena_ms_axis(bs)\n",
    "            av = Path(bs.arena_videos[int(arena_index)])\n",
    "            capA = cv2.VideoCapture(str(av))\n",
    "            if not capA.isOpened():\n",
    "                capA = None\n",
    "\n",
    "    # --- determine output size using first event ---\n",
    "    first = kept.iloc[0]\n",
    "    a0 = str(first[animal_col])\n",
    "    b0 = _zfill_block(first[block_col])\n",
    "    _open_for(a0, b0)\n",
    "\n",
    "    # grab one representative frame from each stream at start time\n",
    "    ms0 = float(first[s_col])\n",
    "    rowL = _nearest_row(left_df, ms0)\n",
    "    rowR = _nearest_row(right_df, ms0)\n",
    "\n",
    "    def _read_frame(cap, frame_idx):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(max(0, frame_idx)))\n",
    "        ret, f = cap.read()\n",
    "        return f if ret else None\n",
    "\n",
    "    L_idx = int(rowL[left_frame_col]) if rowL is not None and pd.notna(rowL[left_frame_col]) else 0\n",
    "    R_idx = int(rowR[right_frame_col]) if rowR is not None and pd.notna(rowR[right_frame_col]) else 0\n",
    "    fL = _read_frame(capL, L_idx)\n",
    "    fR = _read_frame(capR, R_idx)\n",
    "    if fL is None or fR is None:\n",
    "        raise RuntimeError(\"Could not read initial frames for sizing.\")\n",
    "\n",
    "    fL = _apply_flip(fL)\n",
    "    fR = _apply_flip(fR)\n",
    "\n",
    "    # optional arena sizing\n",
    "    if include_arena and capA is not None and arena_df is not None:\n",
    "        arow = _nearest_row(arena_df, ms0)\n",
    "        A_idx = int(arow[arena_frame_col]) if arow is not None and pd.notna(arow[arena_frame_col]) else 0\n",
    "        fA = _read_frame(capA, A_idx)\n",
    "        if fA is None:\n",
    "            include_arena_eff = False\n",
    "            fA = None\n",
    "        else:\n",
    "            include_arena_eff = True\n",
    "            fA = _apply_flip(fA)\n",
    "    else:\n",
    "        include_arena_eff = False\n",
    "        fA = None\n",
    "\n",
    "    # build montage and scale\n",
    "    def _montage(L_img, R_img, A_img=None):\n",
    "        # make heights equal (use L height as reference)\n",
    "        h = L_img.shape[0]\n",
    "        if R_img.shape[0] != h:\n",
    "            R_img = cv2.resize(R_img, (int(R_img.shape[1] * (h / float(R_img.shape[0]))), h))\n",
    "        LR = cv2.hconcat([L_img, R_img])\n",
    "        if A_img is not None:\n",
    "            if A_img.shape[0] != h:\n",
    "                A_img = cv2.resize(A_img, (int(A_img.shape[1] * (h / float(A_img.shape[0]))), h))\n",
    "            LR = cv2.hconcat([LR, A_img])\n",
    "        out = LR\n",
    "        if window_scale is not None and float(window_scale) > 0 and float(window_scale) != 1.0:\n",
    "            out = cv2.resize(out, (int(out.shape[1] * float(window_scale)), int(out.shape[0] * float(window_scale))))\n",
    "        return out\n",
    "\n",
    "    sample_m = _montage(fL, fR, fA if include_arena_eff else None)\n",
    "    H_out, W_out = sample_m.shape[0], sample_m.shape[1]\n",
    "\n",
    "    # --- open writer ---\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(str(out_mp4_path), fourcc, float(fps_out), (int(W_out), int(H_out)))\n",
    "    if not writer.isOpened():\n",
    "        raise RuntimeError(\"Could not open VideoWriter for {}\".format(out_mp4_path))\n",
    "\n",
    "    title_n = int(max(0, round(float(title_frames_sec) * float(fps_out))))\n",
    "\n",
    "    # --- export loop ---\n",
    "    try:\n",
    "        for i in range(len(kept)):\n",
    "            r = kept.iloc[i]\n",
    "            animal = str(r[animal_col])\n",
    "            block_num = _zfill_block(r[block_col])\n",
    "            t0 = float(r[s_col]) - float(pre_ms)\n",
    "            t1 = float(r[e_col]) + float(post_ms)\n",
    "\n",
    "            _open_for(animal, block_num)\n",
    "\n",
    "            # title card between events\n",
    "            if add_title_frames and title_n > 0:\n",
    "                card = np.zeros((H_out, W_out, 3), dtype=np.uint8)\n",
    "                lines = [\n",
    "                    \"Monocular verification\",\n",
    "                    \"Event {}/{}\".format(i+1, len(kept)),\n",
    "                    \"{}  block {}\".format(animal, block_num),\n",
    "                    \"t=[{:.1f}, {:.1f}] ms\".format(float(r[s_col]), float(r[e_col])),\n",
    "                ]\n",
    "                _overlay_text(card, lines, origin=(20, 50), vstep=30)\n",
    "                for _ in range(title_n):\n",
    "                    writer.write(card)\n",
    "\n",
    "            cur = t0\n",
    "            while cur <= t1:\n",
    "                rowL = _nearest_row(left_df, cur)\n",
    "                rowR = _nearest_row(right_df, cur)\n",
    "\n",
    "                # Left\n",
    "                if rowL is not None and pd.notna(rowL[left_frame_col]):\n",
    "                    L_idx = int(rowL[left_frame_col])\n",
    "                    fL = _read_frame(capL, L_idx)\n",
    "                    if fL is None:\n",
    "                        fL = np.zeros((int(capL.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1,\n",
    "                                       int(capL.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1, 3), dtype=np.uint8)\n",
    "                else:\n",
    "                    fL = np.zeros((int(capL.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1,\n",
    "                                   int(capL.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1, 3), dtype=np.uint8)\n",
    "\n",
    "                # Right\n",
    "                if rowR is not None and pd.notna(rowR[right_frame_col]):\n",
    "                    R_idx = int(rowR[right_frame_col])\n",
    "                    fR = _read_frame(capR, R_idx)\n",
    "                    if fR is None:\n",
    "                        fR = np.zeros((int(capR.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1,\n",
    "                                       int(capR.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1, 3), dtype=np.uint8)\n",
    "                else:\n",
    "                    fR = np.zeros((int(capR.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1,\n",
    "                                   int(capR.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1, 3), dtype=np.uint8)\n",
    "\n",
    "                fL = _apply_flip(fL)\n",
    "                fR = _apply_flip(fR)\n",
    "\n",
    "                # Arena (optional)\n",
    "                fA = None\n",
    "                if include_arena_eff and capA is not None and arena_df is not None:\n",
    "                    arow = _nearest_row(arena_df, cur)\n",
    "                    if arow is not None and pd.notna(arow[arena_frame_col]):\n",
    "                        A_idx = int(arow[arena_frame_col])\n",
    "                        fA = _read_frame(capA, A_idx)\n",
    "                        if fA is not None:\n",
    "                            fA = _apply_flip(fA)\n",
    "\n",
    "                # overlays\n",
    "                _overlay_text(fL, [\"L  {} B{}  t={:.1f}ms\".format(animal, block_num, cur)], origin=(10, 24))\n",
    "                _overlay_text(fR, [\"R  {} B{}  t={:.1f}ms\".format(animal, block_num, cur)], origin=(10, 24))\n",
    "                if fA is not None:\n",
    "                    _overlay_text(fA, [\"Arena  {} B{}  t={:.1f}ms\".format(animal, block_num, cur)], origin=(10, 24))\n",
    "\n",
    "                m = _montage(fL, fR, fA)\n",
    "                # ensure exact size for writer\n",
    "                if (m.shape[1], m.shape[0]) != (W_out, H_out):\n",
    "                    m = cv2.resize(m, (W_out, H_out))\n",
    "                writer.write(m)\n",
    "\n",
    "                cur += float(step_ms)\n",
    "\n",
    "    finally:\n",
    "        writer.release()\n",
    "        _release()\n",
    "\n",
    "    print(\"Wrote:\", out_mp4_path)\n",
    "    return out_mp4_path\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# USAGE (after curation)\n",
    "# -------------------------\n",
    "# 1) If your curated df has 'keep_for_video' (True = include)\n",
    "out_path = export_curated_monocular_mp4(block_dict, df, block.analysis_path / \"monocular_verification.mp4\",\n",
    "                                        keep_col=\"keep_for_video\", keep_value=True, window_scale=0.60)\n",
    "\n",
    "# 2) If your curated df uses 'manual_outlier_detected' (True = reject/bad), include the GOOD ones:\n",
    "# out_path = export_curated_monocular_mp4(block_dict, curated_df, r\"Z:\\...\\monocular_verification.mp4\",\n",
    "#                                         keep_col=\"manual_outlier_detected\", keep_value=False, window_scale=0.60)\n"
   ],
   "id": "9df18397e5f65595",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013\\analysis\\monocular_verification.mp4\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T18:53:22.890732Z",
     "start_time": "2025-12-31T18:52:36.988436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Export curated events to MP4 (no title cards + eye indicators + duration text + speed scalar)\n",
    "# Python <3.9 compatible, stand-alone\n",
    "# ============================================================\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def export_curated_monocular_mp4_v2(\n",
    "    block_dict,\n",
    "    curated_df,\n",
    "    out_mp4_path,\n",
    "    # column names (auto-detected if None)\n",
    "    animal_col=\"animal\",\n",
    "    block_col=\"block\",\n",
    "    eye_col=\"eye\",\n",
    "    start_ms_col=None,          # tries: start_ms, saccade_on_ms\n",
    "    end_ms_col=None,            # tries: end_ms, saccade_off_ms\n",
    "    keep_col=None,              # tries: keep_for_video, keep, include, manual_outlier_detected, ...\n",
    "    keep_value=True,\n",
    "    concurrent_col=None,        # optional: if provided and True -> show both circles\n",
    "    # clip window around event\n",
    "    pre_ms=150,\n",
    "    post_ms=150,\n",
    "    # output video timing\n",
    "    fps_out=60.0,\n",
    "    speed_scalar=1.0,           # 1=real-time, 0.5=half speed, 2=double speed (changes time step per output frame)\n",
    "    # layout/appearance\n",
    "    window_scale=0.60,\n",
    "    include_arena=False,\n",
    "    arena_index=0,\n",
    "    flip_mode=\"vertical\",       # \"vertical\" matches your older viewer (cv2.flip(img,0))\n",
    "    circle_radius=10,\n",
    "    circle_thickness=-1,        # -1 = filled\n",
    "    circle_margin=18,           # px from top-left corner inside each eye panel\n",
    "    text_corner=\"tl\",           # \"tl\" or \"tr\"\n",
    "    font_scale=0.6,\n",
    "    thickness=2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Writes one concatenated MP4 for all curated events where keep_col == keep_value.\n",
    "    Changes from v1:\n",
    "      - NO black title frames between events\n",
    "      - green circle indicator for the saccading eye (both when concurrent)\n",
    "      - corner text includes saccade duration (ms)\n",
    "      - speed controlled by speed_scalar (time-step per output frame scaled by this value)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------- helpers ----------------\n",
    "    def _zfill_block(block):\n",
    "        s = str(block)\n",
    "        digits = \"\".join([c for c in s if c.isdigit()])\n",
    "        if digits == \"\":\n",
    "            return s.zfill(3)\n",
    "        return digits.zfill(3)\n",
    "\n",
    "    def _block_for_key(block_dict_local, animal, block):\n",
    "        b = _zfill_block(block)\n",
    "        k1 = \"{}_block_{}\".format(str(animal), b)\n",
    "        if k1 in block_dict_local:\n",
    "            return block_dict_local[k1]\n",
    "        if (str(animal), b) in block_dict_local:\n",
    "            return block_dict_local[(str(animal), b)]\n",
    "        raise KeyError(\"Could not find BlockSync for animal={} block={}\".format(animal, b))\n",
    "\n",
    "    def _frame_col(df_eye):\n",
    "        for c in (\"eye_frame\", \"frame\", \"frame_idx\", \"video_frame\"):\n",
    "            if c in df_eye.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    def _nearest_row(df_eye, ms):\n",
    "        arr = df_eye[\"ms_axis\"].values\n",
    "        if arr.size == 0:\n",
    "            return None\n",
    "        idx = int(np.argmin(np.abs(arr - float(ms))))\n",
    "        return df_eye.iloc[idx]\n",
    "\n",
    "    def _read_frame(cap, frame_idx):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(max(0, frame_idx)))\n",
    "        ret, f = cap.read()\n",
    "        return f if ret else None\n",
    "\n",
    "    def _apply_flip(img):\n",
    "        if flip_mode == \"vertical\":\n",
    "            return cv2.flip(img, 0)\n",
    "        return img\n",
    "\n",
    "    def _overlay_text(img, lines, origin=(10, 24), vstep=22):\n",
    "        x, y = origin\n",
    "        for ln in lines:\n",
    "            cv2.putText(img, str(ln), (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        float(font_scale), (255, 255, 255), int(thickness), cv2.LINE_AA)\n",
    "            y += vstep\n",
    "\n",
    "    def _coerce_bool(x):\n",
    "        if x is None:\n",
    "            return None\n",
    "        try:\n",
    "            if isinstance(x, float) and np.isnan(x):\n",
    "                return None\n",
    "        except Exception:\n",
    "            pass\n",
    "        if isinstance(x, bool):\n",
    "            return x\n",
    "        s = str(x).strip().lower()\n",
    "        if s in (\"true\", \"t\", \"1\", \"yes\", \"y\"):\n",
    "            return True\n",
    "        if s in (\"false\", \"f\", \"0\", \"no\", \"n\"):\n",
    "            return False\n",
    "        return None\n",
    "\n",
    "    def _detect_event_eyes(row):\n",
    "        \"\"\"\n",
    "        Returns (left_active, right_active) for this event.\n",
    "        - If concurrent_col is provided and True => both\n",
    "        - Else infer from eye_col values\n",
    "        \"\"\"\n",
    "        if concurrent_col is not None and concurrent_col in row.index:\n",
    "            v = _coerce_bool(row[concurrent_col])\n",
    "            if v is True:\n",
    "                return True, True\n",
    "\n",
    "        ev = str(row[eye_col]).strip().lower()\n",
    "        if ev.startswith(\"l\") or ev in (\"left\",):\n",
    "            return True, False\n",
    "        if ev.startswith(\"r\") or ev in (\"right\",):\n",
    "            return False, True\n",
    "        # catch-all \"both\"/\"sync\"/\"concurrent\" style encodings\n",
    "        if (\"both\" in ev) or (\"sync\" in ev) or (\"concurrent\" in ev) or ev in (\"lr\", \"rl\"):\n",
    "            return True, True\n",
    "        # default: unknown -> no circles\n",
    "        return False, False\n",
    "\n",
    "    def _put_circle(img, x, y):\n",
    "        cv2.circle(img, (int(x), int(y)), int(circle_radius), (0, 255, 0), int(circle_thickness), cv2.LINE_AA)\n",
    "\n",
    "    def _montage(L_img, R_img, A_img=None):\n",
    "        # Equalize heights to L height\n",
    "        h = L_img.shape[0]\n",
    "        if R_img.shape[0] != h:\n",
    "            R_img = cv2.resize(R_img, (int(R_img.shape[1] * (h / float(R_img.shape[0]))), h))\n",
    "        LR = cv2.hconcat([L_img, R_img])\n",
    "        if A_img is not None:\n",
    "            if A_img.shape[0] != h:\n",
    "                A_img = cv2.resize(A_img, (int(A_img.shape[1] * (h / float(A_img.shape[0]))), h))\n",
    "            LR = cv2.hconcat([LR, A_img])\n",
    "        out = LR\n",
    "        if window_scale is not None and float(window_scale) > 0 and float(window_scale) != 1.0:\n",
    "            out = cv2.resize(out, (int(out.shape[1] * float(window_scale)), int(out.shape[0] * float(window_scale))),\n",
    "                             interpolation=cv2.INTER_AREA)\n",
    "        return out\n",
    "\n",
    "    def _ensure_arena_ms_axis(bs):\n",
    "        \"\"\"\n",
    "        Uses bs.final_sync_df if it contains ms_axis, otherwise tries to merge ms_axis by OE_timestamp\n",
    "        (same idea you used previously).\n",
    "        \"\"\"\n",
    "        fs = bs.final_sync_df.copy()\n",
    "        fcol = None\n",
    "        for c in [\"Arena_frame\", \"arena_frame\", \"frame\", \"frame_idx\", \"video_frame\", \"arena_idx\"]:\n",
    "            if c in fs.columns:\n",
    "                fcol = c\n",
    "                break\n",
    "        if fcol is None:\n",
    "            raise RuntimeError(\"final_sync_df has no recognizable arena frame column.\")\n",
    "\n",
    "        if \"ms_axis\" not in fs.columns:\n",
    "            joined = False\n",
    "            for eye_df in [getattr(bs, \"left_eye_data\", None), getattr(bs, \"right_eye_data\", None)]:\n",
    "                if eye_df is not None and \"OE_timestamp\" in fs.columns and \"OE_timestamp\" in eye_df.columns and \"ms_axis\" in eye_df.columns:\n",
    "                    tmp = eye_df[[\"OE_timestamp\", \"ms_axis\"]].dropna().drop_duplicates(subset=[\"OE_timestamp\"])\n",
    "                    fs = fs.merge(tmp, on=\"OE_timestamp\", how=\"left\")\n",
    "                    joined = True\n",
    "                    break\n",
    "            if not joined:\n",
    "                fs[\"ms_axis\"] = np.nan\n",
    "\n",
    "        out = fs[[c for c in [\"ms_axis\", fcol, \"OE_timestamp\"] if c in fs.columns]].copy()\n",
    "        out[fcol] = pd.to_numeric(out[fcol], errors=\"coerce\").astype(\"Int64\")\n",
    "        out = out.dropna(subset=[fcol])\n",
    "        return out, fcol\n",
    "\n",
    "    # ---------------- input + resolve columns ----------------\n",
    "    df = curated_df.copy().reset_index(drop=True)\n",
    "\n",
    "    # start/end\n",
    "    cand_start = [start_ms_col, \"start_ms\", \"saccade_on_ms\"]\n",
    "    cand_end   = [end_ms_col, \"end_ms\", \"saccade_off_ms\"]\n",
    "    s_col = next((c for c in cand_start if c and c in df.columns), None)\n",
    "    e_col = next((c for c in cand_end   if c and c in df.columns), None)\n",
    "    if s_col is None or e_col is None:\n",
    "        raise ValueError(\"Could not resolve start/end columns from {} / {}\".format(cand_start, cand_end))\n",
    "\n",
    "    # keep col\n",
    "    if keep_col is None:\n",
    "        for c in (\"keep_for_video\", \"keep\", \"include\", \"manual_outlier_detected\", \"is_good\", \"good\", \"tag\"):\n",
    "            if c in df.columns:\n",
    "                keep_col = c\n",
    "                break\n",
    "    if keep_col is None:\n",
    "        raise ValueError(\"Could not auto-detect keep_col. Pass keep_col explicitly.\")\n",
    "\n",
    "    # sanity\n",
    "    for c in (animal_col, block_col, eye_col):\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(\"Missing required column '{}' in curated_df.\".format(c))\n",
    "\n",
    "    df[\"_keep_bool\"] = df[keep_col].map(_coerce_bool)\n",
    "\n",
    "    kept = df[df[\"_keep_bool\"] == bool(keep_value)].copy()\n",
    "    if kept.empty:\n",
    "        raise ValueError(\"No rows matched keep_col={} == {} (after coercion).\".format(keep_col, keep_value))\n",
    "\n",
    "    kept[block_col] = kept[block_col].astype(str).apply(_zfill_block)\n",
    "    kept[s_col] = pd.to_numeric(kept[s_col], errors=\"coerce\")\n",
    "    kept[e_col] = pd.to_numeric(kept[e_col], errors=\"coerce\")\n",
    "    kept = kept.dropna(subset=[s_col, e_col]).sort_values([animal_col, block_col, s_col]).reset_index(drop=True)\n",
    "\n",
    "    # speed scalar -> time step per output frame\n",
    "    if speed_scalar is None:\n",
    "        speed_scalar = 1.0\n",
    "    speed_scalar = float(speed_scalar)\n",
    "    if speed_scalar <= 0:\n",
    "        raise ValueError(\"speed_scalar must be > 0. Got {}\".format(speed_scalar))\n",
    "\n",
    "    base_step_ms = 1000.0 / float(fps_out)\n",
    "    step_ms = base_step_ms * speed_scalar  # <-- key behavior\n",
    "\n",
    "    # output path\n",
    "    out_mp4_path = Path(out_mp4_path)\n",
    "    out_mp4_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ---------------- open-on-demand per (animal, block) ----------------\n",
    "    capL = capR = capA = None\n",
    "    left_df = right_df = arena_df = None\n",
    "    left_fc = right_fc = arena_fc = None\n",
    "    cur_animal = None\n",
    "    cur_block = None\n",
    "\n",
    "    def _release():\n",
    "        nonlocal capL, capR, capA\n",
    "        for c in (capL, capR, capA):\n",
    "            try:\n",
    "                if c is not None:\n",
    "                    c.release()\n",
    "            except Exception:\n",
    "                pass\n",
    "        capL = capR = capA = None\n",
    "\n",
    "    def _open_for(animal, block_num):\n",
    "        nonlocal capL, capR, capA\n",
    "        nonlocal left_df, right_df, arena_df\n",
    "        nonlocal left_fc, right_fc, arena_fc\n",
    "        nonlocal cur_animal, cur_block\n",
    "\n",
    "        if (animal == cur_animal) and (block_num == cur_block):\n",
    "            return\n",
    "\n",
    "        _release()\n",
    "        bs = _block_for_key(block_dict, animal, block_num)\n",
    "        cur_animal, cur_block = animal, block_num\n",
    "\n",
    "        left_df = getattr(bs, \"left_eye_data\", None)\n",
    "        right_df = getattr(bs, \"right_eye_data\", None)\n",
    "        if left_df is None or right_df is None:\n",
    "            raise RuntimeError(\"Missing eye data for {} B{}\".format(animal, block_num))\n",
    "        if \"ms_axis\" not in left_df.columns or \"ms_axis\" not in right_df.columns:\n",
    "            raise RuntimeError(\"'ms_axis' missing for {} B{}\".format(animal, block_num))\n",
    "\n",
    "        left_fc = _frame_col(left_df)\n",
    "        right_fc = _frame_col(right_df)\n",
    "        if left_fc is None or right_fc is None:\n",
    "            raise RuntimeError(\"Could not resolve eye frame column for {} B{}\".format(animal, block_num))\n",
    "\n",
    "        lv = Path(bs.le_videos[0])\n",
    "        rv = Path(bs.re_videos[0])\n",
    "        capL = cv2.VideoCapture(str(lv))\n",
    "        capR = cv2.VideoCapture(str(rv))\n",
    "        if not capL.isOpened():\n",
    "            raise RuntimeError(\"Cannot open {}\".format(lv))\n",
    "        if not capR.isOpened():\n",
    "            raise RuntimeError(\"Cannot open {}\".format(rv))\n",
    "\n",
    "        # arena optional\n",
    "        capA = None\n",
    "        arena_df = None\n",
    "        arena_fc = None\n",
    "        if include_arena and getattr(bs, \"arena_videos\", None):\n",
    "            if getattr(bs, \"final_sync_df\", None) is not None:\n",
    "                arena_df, arena_fc = _ensure_arena_ms_axis(bs)\n",
    "            av = Path(bs.arena_videos[int(arena_index)])\n",
    "            capA = cv2.VideoCapture(str(av))\n",
    "            if not capA.isOpened():\n",
    "                capA = None\n",
    "\n",
    "    # ---------------- determine output size from first event ----------------\n",
    "    first = kept.iloc[0]\n",
    "    a0 = str(first[animal_col])\n",
    "    b0 = _zfill_block(first[block_col])\n",
    "    _open_for(a0, b0)\n",
    "\n",
    "    ms0 = float(first[s_col])\n",
    "    rowL0 = _nearest_row(left_df, ms0)\n",
    "    rowR0 = _nearest_row(right_df, ms0)\n",
    "    L_idx0 = int(rowL0[left_fc]) if rowL0 is not None and pd.notna(rowL0[left_fc]) else 0\n",
    "    R_idx0 = int(rowR0[right_fc]) if rowR0 is not None and pd.notna(rowR0[right_fc]) else 0\n",
    "    fL0 = _read_frame(capL, L_idx0)\n",
    "    fR0 = _read_frame(capR, R_idx0)\n",
    "    if fL0 is None or fR0 is None:\n",
    "        raise RuntimeError(\"Could not read initial frames for sizing.\")\n",
    "    fL0 = _apply_flip(fL0)\n",
    "    fR0 = _apply_flip(fR0)\n",
    "\n",
    "    fA0 = None\n",
    "    include_arena_eff = False\n",
    "    if include_arena and capA is not None and arena_df is not None and arena_fc is not None:\n",
    "        arow0 = _nearest_row(arena_df, ms0)\n",
    "        if arow0 is not None and pd.notna(arow0[arena_fc]):\n",
    "            A_idx0 = int(arow0[arena_fc])\n",
    "            fA0 = _read_frame(capA, A_idx0)\n",
    "            if fA0 is not None:\n",
    "                fA0 = _apply_flip(fA0)\n",
    "                include_arena_eff = True\n",
    "\n",
    "    sample = _montage(fL0, fR0, fA0 if include_arena_eff else None)\n",
    "    H_out, W_out = sample.shape[0], sample.shape[1]\n",
    "\n",
    "    # ---------------- open writer ----------------\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(str(out_mp4_path), fourcc, float(fps_out), (int(W_out), int(H_out)))\n",
    "    if not writer.isOpened():\n",
    "        raise RuntimeError(\"Could not open VideoWriter for {}\".format(out_mp4_path))\n",
    "\n",
    "    # corner text placement\n",
    "    def _corner_origin(img, lines_count):\n",
    "        h, w = img.shape[:2]\n",
    "        if text_corner.lower() == \"tr\":\n",
    "            # approximate width; keep margin\n",
    "            return (max(10, w - 420), 24)\n",
    "        return (10, 24)\n",
    "\n",
    "    # ---------------- export loop ----------------\n",
    "    try:\n",
    "        for i in range(len(kept)):\n",
    "            r = kept.iloc[i]\n",
    "            animal = str(r[animal_col])\n",
    "            block_num = _zfill_block(r[block_col])\n",
    "\n",
    "            on_ms = float(r[s_col])\n",
    "            off_ms = float(r[e_col])\n",
    "            dur_ms = max(0.0, off_ms - on_ms)\n",
    "\n",
    "            win_start = on_ms - float(pre_ms)\n",
    "            win_end   = off_ms + float(post_ms)\n",
    "\n",
    "            left_active, right_active = _detect_event_eyes(r)\n",
    "\n",
    "            _open_for(animal, block_num)\n",
    "\n",
    "            cur = win_start\n",
    "            while cur <= win_end:\n",
    "                # nearest frames by ms_axis\n",
    "                rowL = _nearest_row(left_df, cur)\n",
    "                rowR = _nearest_row(right_df, cur)\n",
    "\n",
    "                # left frame\n",
    "                if rowL is not None and pd.notna(rowL[left_fc]):\n",
    "                    L_idx = int(rowL[left_fc])\n",
    "                    fL = _read_frame(capL, L_idx)\n",
    "                    if fL is None:\n",
    "                        fL = np.zeros((int(capL.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1,\n",
    "                                       int(capL.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1, 3), dtype=np.uint8)\n",
    "                else:\n",
    "                    fL = np.zeros((int(capL.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1,\n",
    "                                   int(capL.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1, 3), dtype=np.uint8)\n",
    "\n",
    "                # right frame\n",
    "                if rowR is not None and pd.notna(rowR[right_fc]):\n",
    "                    R_idx = int(rowR[right_fc])\n",
    "                    fR = _read_frame(capR, R_idx)\n",
    "                    if fR is None:\n",
    "                        fR = np.zeros((int(capR.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1,\n",
    "                                       int(capR.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1, 3), dtype=np.uint8)\n",
    "                else:\n",
    "                    fR = np.zeros((int(capR.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1,\n",
    "                                   int(capR.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1, 3), dtype=np.uint8)\n",
    "\n",
    "                fL = _apply_flip(fL)\n",
    "                fR = _apply_flip(fR)\n",
    "\n",
    "                # arena optional\n",
    "                fA = None\n",
    "                if include_arena_eff and capA is not None and arena_df is not None and arena_fc is not None:\n",
    "                    arow = _nearest_row(arena_df, cur)\n",
    "                    if arow is not None and pd.notna(arow[arena_fc]):\n",
    "                        A_idx = int(arow[arena_fc])\n",
    "                        fA = _read_frame(capA, A_idx)\n",
    "                        if fA is not None:\n",
    "                            fA = _apply_flip(fA)\n",
    "\n",
    "                # circles (draw in each eye panel before montage)\n",
    "                if left_active:\n",
    "                    _put_circle(fL, circle_margin, circle_margin)\n",
    "                if right_active:\n",
    "                    _put_circle(fR, circle_margin, circle_margin)\n",
    "\n",
    "                # light per-panel labels (optional)\n",
    "                _overlay_text(fL, [\"L\"], origin=(10, fL.shape[0] - 10), vstep=18)\n",
    "                _overlay_text(fR, [\"R\"], origin=(10, fR.shape[0] - 10), vstep=18)\n",
    "                if fA is not None:\n",
    "                    _overlay_text(fA, [\"Arena\"], origin=(10, fA.shape[0] - 10), vstep=18)\n",
    "\n",
    "                m = _montage(fL, fR, fA)\n",
    "\n",
    "                # corner text on the final montage\n",
    "                lines = [\n",
    "                    \"Event {}/{}  {}  block {}\".format(i + 1, len(kept), animal, block_num),\n",
    "                    \"Saccade dur: {:.1f} ms\".format(dur_ms),\n",
    "                    \"t = {:.1f} ms   speed x{:.2f}\".format(cur, float(speed_scalar)),\n",
    "                ]\n",
    "                _overlay_text(m, lines, origin=_corner_origin(m, len(lines)), vstep=22)\n",
    "\n",
    "                # ensure fixed writer size\n",
    "                if (m.shape[1], m.shape[0]) != (W_out, H_out):\n",
    "                    m = cv2.resize(m, (W_out, H_out), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                writer.write(m)\n",
    "                cur += float(step_ms)\n",
    "\n",
    "    finally:\n",
    "        writer.release()\n",
    "        _release()\n",
    "\n",
    "    print(\"Wrote:\", out_mp4_path)\n",
    "    return out_mp4_path\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CALL\n",
    "# -------------------------\n",
    "out_path = r'Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013\\analysis\\monocular_verification_slo.mp4'\n",
    "out_path = export_curated_monocular_mp4_v2(\n",
    "    block_dict=block_dict,\n",
    "    curated_df=curated_df2,\n",
    "    out_mp4_path=out_path,\n",
    "    keep_col=\"keep_for_video\",     # or \"manual_outlier_detected\"\n",
    "    keep_value=True,               # if manual_outlier_detected marks BAD, use keep_value=False\n",
    "    start_ms_col=\"saccade_on_ms\",\n",
    "    end_ms_col=\"saccade_off_ms\",\n",
    "    eye_col=\"eye\",\n",
    "    pre_ms=200,\n",
    "    post_ms=200,\n",
    "    fps_out=60.0,\n",
    "    speed_scalar=0.2,              # 0.5 half speed, 2.0 double speed\n",
    "    window_scale=1,\n",
    "    include_arena=True,\n",
    "    concurrent_col=None            # set if you have a boolean \"is_concurrent\" column\n",
    ")\n"
   ],
   "id": "f69aecbce7d62b2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013\\analysis\\monocular_verification_slo.mp4\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T18:52:01.575410Z",
     "start_time": "2025-12-31T18:47:45.293845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Monocular verification: OpenCV manual curation UI (sterile) ---\n",
    "# PATCH: show green dot DURING saccade interval to indicate which eye is \"active\"\n",
    "\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def curate_events_for_monocular_video_opencv(\n",
    "    block_dict,\n",
    "    events_df,\n",
    "    animal_call=None,\n",
    "    block=None,\n",
    "    pre_ms=200.0,\n",
    "    post_ms=200.0,\n",
    "    flip_eyes=True,\n",
    "    show_arena=False,\n",
    "    text_cols=None,\n",
    "    # display scaling:\n",
    "    window_scale=0.60,\n",
    "    scale_step=0.10,\n",
    "    min_scale=0.20,\n",
    "    max_scale=2.00,\n",
    "    # playback:\n",
    "    wait_ms_default=15,\n",
    "    wait_step=5,\n",
    "    min_wait_ms=1,\n",
    "    max_wait_ms=200,\n",
    "    # tagging (sterile)\n",
    "    tag_col=\"keep_for_video\",        # True=keep, False=reject, None/unset\n",
    "    ts_col=\"curation_ts\",\n",
    "    out_dir_name=\"monocular_video_curation\",\n",
    "    overwrite_existing=False,\n",
    "    # pre-annotation from existing column(s)\n",
    "    autodetect_existing_tags=True,\n",
    "    existing_tag_cols=None,\n",
    "    invert_tag_cols=None,\n",
    "    # NEW: active-eye dot during saccade\n",
    "    show_active_dot=True,\n",
    "    active_dot_only_during_saccade=True,\n",
    "    active_dot_radius=10,\n",
    "    active_dot_margin=18,            # px from top-left corner\n",
    "    concurrent_col=None              # optional boolean column: True => show dot on both eyes\n",
    "):\n",
    "    \"\"\"\n",
    "    Manual curation UI for monocular events.\n",
    "\n",
    "    NEW: green dot appears during the saccade interval to denote the currently \"active\" eye.\n",
    "         This helps catch blink/mislabeled events (dot should coincide with actual saccade motion).\n",
    "\n",
    "    Keyboard:\n",
    "      Space: play/pause\n",
    "      [ / ]: prev / next event\n",
    "      , / .: step -1 / +1 frame\n",
    "      k: KEEP\n",
    "      r: REJECT\n",
    "      e: export sterile per-block CSV(s)\n",
    "      z / x: scale - / +\n",
    "      - / +: slower / faster\n",
    "      q / Esc: quit\n",
    "    \"\"\"\n",
    "\n",
    "    if text_cols is None:\n",
    "        text_cols = []\n",
    "\n",
    "    if existing_tag_cols is None:\n",
    "        existing_tag_cols = [\n",
    "            \"keep_for_video\", \"keep\", \"include\", \"include_in_monocular_video\", \"include_in_video\",\n",
    "            \"is_good\", \"good\", \"accepted\", \"approved\",\n",
    "            \"manual_outlier_detected\", \"outlier\", \"reject\", \"rejected\", \"is_bad\", \"bad\"\n",
    "        ]\n",
    "    if invert_tag_cols is None:\n",
    "        invert_tag_cols = set([\"manual_outlier_detected\", \"outlier\", \"is_bad\", \"bad\", \"reject\", \"rejected\"])\n",
    "    else:\n",
    "        invert_tag_cols = set(invert_tag_cols)\n",
    "\n",
    "    # ---------------- helpers ----------------\n",
    "    def _now_stamp():\n",
    "        return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    def _zfill_block(b):\n",
    "        s = str(b)\n",
    "        m = re.search(r\"(\\d+)\", s)\n",
    "        if m:\n",
    "            return m.group(1).zfill(3)\n",
    "        return s.zfill(3)\n",
    "\n",
    "    def _first_existing(df, candidates):\n",
    "        for c in candidates:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    def _require_col(df, candidates, label):\n",
    "        c = _first_existing(df, candidates)\n",
    "        if c is None:\n",
    "            raise KeyError(\"Could not find {}. Tried: {}\".format(label, candidates))\n",
    "        return c\n",
    "\n",
    "    def _coerce_tag(v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        try:\n",
    "            if isinstance(v, float) and np.isnan(v):\n",
    "                return None\n",
    "        except Exception:\n",
    "            pass\n",
    "        if isinstance(v, (bool, np.bool_)):\n",
    "            return bool(v)\n",
    "        s = str(v).strip().lower()\n",
    "        if s in (\"true\", \"t\", \"1\", \"yes\", \"y\", \"keep\", \"include\", \"good\", \"accept\"):\n",
    "            return True\n",
    "        if s in (\"false\", \"f\", \"0\", \"no\", \"n\", \"reject\", \"bad\", \"exclude\"):\n",
    "            return False\n",
    "        return None\n",
    "\n",
    "    def _block_for_key(block_dict_local, animal, b):\n",
    "        b = _zfill_block(b)\n",
    "        animal = str(animal)\n",
    "\n",
    "        if (animal, b) in block_dict_local:\n",
    "            return block_dict_local[(animal, b)]\n",
    "\n",
    "        k1 = \"{}_block_{}\".format(animal, b)\n",
    "        if k1 in block_dict_local:\n",
    "            return block_dict_local[k1]\n",
    "\n",
    "        for k in block_dict_local.keys():\n",
    "            if isinstance(k, str):\n",
    "                if (animal in k) and (\"block_{}\".format(b) in k or k.endswith(\"_{}\".format(b))):\n",
    "                    return block_dict_local[k]\n",
    "\n",
    "        raise KeyError(\"Could not find BlockSync for animal={} block={}\".format(animal, b))\n",
    "\n",
    "    def _get_eye_dfs(bs):\n",
    "        left_df = getattr(bs, \"left_eye_data\", None)\n",
    "        right_df = getattr(bs, \"right_eye_data\", None)\n",
    "        if left_df is None:\n",
    "            left_df = getattr(bs, \"le_df\", None)\n",
    "        if right_df is None:\n",
    "            right_df = getattr(bs, \"re_df\", None)\n",
    "        return left_df, right_df\n",
    "\n",
    "    def _get_video_paths(bs):\n",
    "        lv = getattr(bs, \"le_videos\", None)\n",
    "        rv = getattr(bs, \"re_videos\", None)\n",
    "        av = getattr(bs, \"arena_videos\", None)\n",
    "\n",
    "        lpath = None\n",
    "        rpath = None\n",
    "        apaths = []\n",
    "\n",
    "        if isinstance(lv, (list, tuple)) and len(lv):\n",
    "            lpath = lv[0]\n",
    "        elif isinstance(lv, str):\n",
    "            lpath = lv\n",
    "\n",
    "        if isinstance(rv, (list, tuple)) and len(rv):\n",
    "            rpath = rv[0]\n",
    "        elif isinstance(rv, str):\n",
    "            rpath = rv\n",
    "\n",
    "        if isinstance(av, (list, tuple)):\n",
    "            apaths = list(av)\n",
    "        elif isinstance(av, str):\n",
    "            apaths = [av]\n",
    "\n",
    "        return lpath, rpath, apaths\n",
    "\n",
    "    def _frame_col(df_eye):\n",
    "        for c in [\"eye_frame\", \"L_eye_frame\", \"R_eye_frame\", \"frame\", \"frame_idx\"]:\n",
    "            if c in df_eye.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    def _nearest_row(df_eye, t_ms):\n",
    "        if df_eye is None or df_eye.empty or \"ms_axis\" not in df_eye.columns:\n",
    "            return None\n",
    "        ms = df_eye[\"ms_axis\"].values\n",
    "        if ms.size == 0:\n",
    "            return None\n",
    "        idx = int(np.searchsorted(ms, t_ms))\n",
    "        if idx <= 0:\n",
    "            return df_eye.iloc[0]\n",
    "        if idx >= ms.size:\n",
    "            return df_eye.iloc[-1]\n",
    "        if abs(ms[idx] - t_ms) < abs(ms[idx - 1] - t_ms):\n",
    "            return df_eye.iloc[idx]\n",
    "        return df_eye.iloc[idx - 1]\n",
    "\n",
    "    def _median_step_ms(df_eye):\n",
    "        if df_eye is None or df_eye.empty or \"ms_axis\" not in df_eye.columns:\n",
    "            return 1000.0 / 60.0\n",
    "        ms = df_eye[\"ms_axis\"].values\n",
    "        if ms.size < 2:\n",
    "            return 1000.0 / 60.0\n",
    "        d = np.diff(ms)\n",
    "        d = d[np.isfinite(d) & (d > 0)]\n",
    "        if d.size == 0:\n",
    "            return 1000.0 / 60.0\n",
    "        return float(np.median(d))\n",
    "\n",
    "    def _apply_flip(img):\n",
    "        if not flip_eyes:\n",
    "            return img\n",
    "        img = cv2.flip(img, 0)\n",
    "        img = cv2.flip(img, 1)\n",
    "        return img\n",
    "\n",
    "    def _overlay_text(img, lines, origin=(10, 24), vstep=22, color=(255, 255, 255), font_scale=0.6, thickness=1):\n",
    "        x, y = origin\n",
    "        for ln in lines:\n",
    "            cv2.putText(img, ln, (x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness, cv2.LINE_AA)\n",
    "            y += vstep\n",
    "\n",
    "    def _overlay_ellipse(img, df_eye, frame_idx, thickness=2):\n",
    "        if df_eye is None or frame_idx is None:\n",
    "            return\n",
    "        fc = _frame_col(df_eye)\n",
    "        if fc is None:\n",
    "            return\n",
    "        hit = df_eye[df_eye[fc] == frame_idx]\n",
    "        if hit.empty:\n",
    "            return\n",
    "        row = hit.iloc[0]\n",
    "        cx = row.get(\"center_x\", np.nan)\n",
    "        cy = row.get(\"center_y\", np.nan)\n",
    "        w  = row.get(\"width\", np.nan)\n",
    "        h  = row.get(\"height\", np.nan)\n",
    "        phi = row.get(\"phi\", np.nan)\n",
    "        if not (pd.isna(cx) or pd.isna(cy) or pd.isna(w) or pd.isna(h)):\n",
    "            cv2.ellipse(\n",
    "                img,\n",
    "                (int(round(cx)), int(round(cy))),\n",
    "                (max(1, int(round(w))), max(1, int(round(h)))),\n",
    "                float(0 if pd.isna(phi) else phi),\n",
    "                0, 360, (0, 255, 0),\n",
    "                thickness\n",
    "            )\n",
    "\n",
    "    def _draw_active_dot(img):\n",
    "        # draw AFTER flipping, so dot stays in the same visual corner\n",
    "        cv2.circle(\n",
    "            img,\n",
    "            (int(active_dot_margin), int(active_dot_margin)),\n",
    "            int(active_dot_radius),\n",
    "            (0, 255, 0),\n",
    "            -1,\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "    def _event_eye_flags(event_eye_str, concurrent_flag):\n",
    "        \"\"\"\n",
    "        Returns (left_active, right_active) based on event labels.\n",
    "        \"\"\"\n",
    "        if concurrent_flag:\n",
    "            return True, True\n",
    "\n",
    "        s = str(event_eye_str).strip().lower()\n",
    "        if s.startswith(\"l\") or s == \"left\":\n",
    "            return True, False\n",
    "        if s.startswith(\"r\") or s == \"right\":\n",
    "            return False, True\n",
    "        if (\"both\" in s) or (\"sync\" in s) or (\"concurrent\" in s) or s in (\"lr\", \"rl\"):\n",
    "            return True, True\n",
    "        return False, False\n",
    "\n",
    "    def _ensure_std_columns(df_local, animal_col, block_col, eye_col, start_col, end_col):\n",
    "        df_local[\"_animal_std\"] = df_local[animal_col].astype(str)\n",
    "        df_local[\"_block_std\"]  = df_local[block_col].astype(str).apply(_zfill_block)\n",
    "        df_local[\"_eye_std\"]    = df_local[eye_col].astype(str)\n",
    "        df_local[\"_start_ms_std\"] = pd.to_numeric(df_local[start_col], errors=\"coerce\")\n",
    "        df_local[\"_end_ms_std\"]   = pd.to_numeric(df_local[end_col], errors=\"coerce\")\n",
    "        df_local[\"_win_start_ms\"] = df_local[\"_start_ms_std\"] - float(pre_ms)\n",
    "        df_local[\"_win_end_ms\"]   = df_local[\"_end_ms_std\"] + float(post_ms)\n",
    "        if ts_col not in df_local.columns:\n",
    "            df_local[ts_col] = \"\"\n",
    "        return df_local\n",
    "\n",
    "    def _write_block_annotations(bs, sub_df):\n",
    "        out_dir = Path(bs.analysis_path) / out_dir_name\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        animal_s = str(sub_df[\"_animal_std\"].iloc[0])\n",
    "        block_s  = str(sub_df[\"_block_std\"].iloc[0])\n",
    "        out_path = out_dir / \"{}_block_{}_monocular_curation.csv\".format(animal_s, block_s)\n",
    "\n",
    "        out = pd.DataFrame({\n",
    "            \"animal_call\": sub_df[\"_animal_std\"].astype(str),\n",
    "            \"block\": sub_df[\"_block_std\"].astype(str),\n",
    "            \"eye\": sub_df[\"_eye_std\"].astype(str),\n",
    "            \"start_ms\": sub_df[\"_start_ms_std\"].astype(float),\n",
    "            \"end_ms\": sub_df[\"_end_ms_std\"].astype(float),\n",
    "            tag_col: sub_df[tag_col].map(_coerce_tag).astype(\"object\"),\n",
    "            ts_col: sub_df[ts_col].astype(str)\n",
    "        })\n",
    "\n",
    "        if out_path.exists() and (not overwrite_existing):\n",
    "            try:\n",
    "                old = pd.read_csv(out_path)\n",
    "                key = [\"animal_call\", \"block\", \"eye\", \"start_ms\", \"end_ms\"]\n",
    "                merged = old.merge(out, on=key, how=\"outer\", suffixes=(\"_old\", \"\"))\n",
    "                if \"{}_old\".format(tag_col) in merged.columns:\n",
    "                    merged[tag_col] = merged[tag_col].where(merged[tag_col].notna(), merged[\"{}_old\".format(tag_col)])\n",
    "                    merged = merged.drop(columns=[\"{}_old\".format(tag_col)], errors=\"ignore\")\n",
    "                if \"{}_old\".format(ts_col) in merged.columns:\n",
    "                    merged[ts_col] = merged[ts_col].where(merged[ts_col].astype(str) != \"\", merged[\"{}_old\".format(ts_col)].astype(str))\n",
    "                    merged = merged.drop(columns=[\"{}_old\".format(ts_col)], errors=\"ignore\")\n",
    "                merged.to_csv(out_path, index=False)\n",
    "                return out_path\n",
    "            except Exception:\n",
    "                out.to_csv(out_path, index=False)\n",
    "                return out_path\n",
    "\n",
    "        out.to_csv(out_path, index=False)\n",
    "        return out_path\n",
    "\n",
    "    # ---------------- normalize events df ----------------\n",
    "    df = events_df.copy() if isinstance(events_df, pd.DataFrame) else pd.DataFrame(events_df).copy()\n",
    "\n",
    "    animal_col = _require_col(df, [\"animal_call\", \"animal\", \"_animal_std\"], \"animal column\")\n",
    "    block_col  = _require_col(df, [\"block\", \"block_num\", \"_block_std\"], \"block column\")\n",
    "    eye_col    = _require_col(df, [\"eye\", \"_eye_std\"], \"eye column\")\n",
    "\n",
    "    # prefer your names\n",
    "    start_col = _require_col(df, [\"_start_ms_std\", \"saccade_on_ms\", \"start_ms\", \"start_time_ms\"], \"start_ms column\")\n",
    "    end_col   = _require_col(df, [\"_end_ms_std\", \"saccade_off_ms\", \"end_ms\", \"end_time_ms\"], \"end_ms column\")\n",
    "\n",
    "    df = _ensure_std_columns(df, animal_col, block_col, eye_col, start_col, end_col)\n",
    "    df = df.dropna(subset=[\"_start_ms_std\", \"_end_ms_std\"]).reset_index(drop=True)\n",
    "\n",
    "    if animal_call is not None:\n",
    "        df = df[df[\"_animal_std\"].astype(str) == str(animal_call)].copy()\n",
    "    if block is not None:\n",
    "        df = df[df[\"_block_std\"].astype(str) == _zfill_block(block)].copy()\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No events to curate after filtering (animal_call/block).\")\n",
    "\n",
    "    # pre-annotate tags if requested\n",
    "    if tag_col not in df.columns:\n",
    "        df[tag_col] = None\n",
    "\n",
    "    if autodetect_existing_tags:\n",
    "        has_any = df[tag_col].map(_coerce_tag).notna().any()\n",
    "        src_col = None\n",
    "        if not has_any:\n",
    "            for c in existing_tag_cols:\n",
    "                if c == tag_col:\n",
    "                    continue\n",
    "                if c in df.columns and df[c].map(_coerce_tag).notna().any():\n",
    "                    src_col = c\n",
    "                    break\n",
    "        if src_col is not None:\n",
    "            src_is_inverted = (src_col in invert_tag_cols)\n",
    "            cur = df[tag_col].map(_coerce_tag)\n",
    "            src = df[src_col].map(_coerce_tag)\n",
    "            if src_is_inverted:\n",
    "                src = src.map(lambda v: (None if v is None else (not bool(v))))\n",
    "            fill_mask = cur.isna() & src.notna()\n",
    "            df.loc[fill_mask, tag_col] = src[fill_mask]\n",
    "            if ts_col in df.columns:\n",
    "                ts_empty = df[ts_col].astype(str).replace(\"nan\", \"\").str.strip() == \"\"\n",
    "                stamp_mask = fill_mask & ts_empty\n",
    "                df.loc[stamp_mask, ts_col] = \"preload_from:{}\" .format(src_col)\n",
    "\n",
    "    df[tag_col] = df[tag_col].map(_coerce_tag)\n",
    "\n",
    "    # ---------------- OpenCV UI ----------------\n",
    "    cv2.namedWindow(\"Controls\", cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow(\"Left Eye\", cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow(\"Right Eye\", cv2.WINDOW_NORMAL)\n",
    "    if show_arena:\n",
    "        cv2.namedWindow(\"Arena\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    ctrl_w, ctrl_h = 540, 520\n",
    "    buttons = {\n",
    "        \"Play\":      ((10, 10),   (260, 60)),\n",
    "        \"Pause\":     ((280, 10),  (530, 60)),\n",
    "        \"Prev\":      ((10, 80),   (260, 130)),\n",
    "        \"Next\":      ((280, 80),  (530, 130)),\n",
    "        \"Step -1\":   ((10, 150),  (260, 200)),\n",
    "        \"Step +1\":   ((280, 150), (530, 200)),\n",
    "        \"KEEP\":      ((10, 220),  (260, 270)),\n",
    "        \"REJECT\":    ((280, 220), (530, 270)),\n",
    "        \"Scale -\":   ((10, 290),  (260, 340)),\n",
    "        \"Scale +\":   ((280, 290), (530, 340)),\n",
    "        \"Slower\":    ((10, 360),  (260, 410)),\n",
    "        \"Faster\":    ((280, 360), (530, 410)),\n",
    "        \"Export\":    ((10, 430),  (530, 480)),\n",
    "    }\n",
    "\n",
    "    COLOR_BORDER = (180, 180, 180)\n",
    "    COLOR_TEXT = (220, 220, 220)\n",
    "    COLOR_KEEP = (0, 255, 0)\n",
    "    COLOR_REJ  = (0, 0, 255)\n",
    "    COLOR_INFO = (180, 255, 180)\n",
    "    COLOR_WARN = (0, 165, 255)\n",
    "\n",
    "    playing = False\n",
    "    quit_flag = False\n",
    "    cur_idx = 0\n",
    "    cur_ms = None\n",
    "    step_ms = 1000.0 / 60.0\n",
    "    wait_ms = int(wait_ms_default)\n",
    "    last_status = \"\"\n",
    "\n",
    "    capL = capR = capA = None\n",
    "    current_key = (None, None)\n",
    "\n",
    "    left_df = right_df = None\n",
    "    left_fc = right_fc = None\n",
    "    Wl = Hl = Wr = Hr = 0\n",
    "    disp_Wl = disp_Hl = disp_Wr = disp_Hr = 0\n",
    "\n",
    "    def _hit_button(x, y):\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                return name\n",
    "        return None\n",
    "\n",
    "    def _format_state(v):\n",
    "        v = _coerce_tag(v)\n",
    "        if v is None:\n",
    "            return \"UNSET\"\n",
    "        return \"KEEP\" if v else \"REJECT\"\n",
    "\n",
    "    def _draw_controls(idx):\n",
    "        img = np.zeros((ctrl_h, ctrl_w, 3), dtype=np.uint8)\n",
    "        state_str = _format_state(df[tag_col].iloc[idx])\n",
    "        header = \"Event {}/{} | state={} | scale={:.2f} | wait={}ms\".format(\n",
    "            idx + 1, len(df), state_str, float(window_scale), int(wait_ms)\n",
    "        )\n",
    "        cv2.putText(img, header, (10, ctrl_h - 12), cv2.FONT_HERSHEY_SIMPLEX, 0.55, COLOR_TEXT, 1, cv2.LINE_AA)\n",
    "        if last_status:\n",
    "            cv2.putText(img, last_status, (10, 22), cv2.FONT_HERSHEY_SIMPLEX, 0.55, COLOR_INFO, 1, cv2.LINE_AA)\n",
    "\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            color = COLOR_BORDER\n",
    "            if name == \"KEEP\":\n",
    "                color = COLOR_KEEP\n",
    "            elif name == \"REJECT\":\n",
    "                color = COLOR_REJ\n",
    "            elif name == \"Export\":\n",
    "                color = COLOR_WARN\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(img, name, (x1 + 10, y2 - 18), cv2.FONT_HERSHEY_SIMPLEX, 0.7, COLOR_TEXT, 2, cv2.LINE_AA)\n",
    "        return img\n",
    "\n",
    "    def _seek(cap, idx):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, int(idx)))\n",
    "\n",
    "    def _read(cap):\n",
    "        ret, f = cap.read()\n",
    "        return f if ret else None\n",
    "\n",
    "    def _set_display_scale():\n",
    "        nonlocal disp_Wl, disp_Hl, disp_Wr, disp_Hr\n",
    "        if Wl > 0 and Hl > 0:\n",
    "            disp_Wl, disp_Hl = int(Wl * window_scale), int(Hl * window_scale)\n",
    "            cv2.resizeWindow(\"Left Eye\", disp_Wl, disp_Hl)\n",
    "        if Wr > 0 and Hr > 0:\n",
    "            disp_Wr, disp_Hr = int(Wr * window_scale), int(Hr * window_scale)\n",
    "            cv2.resizeWindow(\"Right Eye\", disp_Wr, disp_Hr)\n",
    "        cv2.resizeWindow(\"Controls\", ctrl_w, ctrl_h)\n",
    "\n",
    "    def _open_for(animal, b):\n",
    "        nonlocal capL, capR, capA, current_key\n",
    "        nonlocal left_df, right_df, left_fc, right_fc, Wl, Hl, Wr, Hr\n",
    "\n",
    "        key = (str(animal), _zfill_block(b))\n",
    "        if key == current_key and capL is not None and capR is not None:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            if capL is not None: capL.release()\n",
    "            if capR is not None: capR.release()\n",
    "            if capA is not None: capA.release()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        bs = _block_for_key(block_dict, key[0], key[1])\n",
    "        left_df, right_df = _get_eye_dfs(bs)\n",
    "        left_fc = _frame_col(left_df) if left_df is not None else None\n",
    "        right_fc = _frame_col(right_df) if right_df is not None else None\n",
    "\n",
    "        lpath, rpath, _ = _get_video_paths(bs)\n",
    "        if lpath is None or rpath is None:\n",
    "            raise RuntimeError(\"Could not resolve le/re video paths for {} block {}\".format(key[0], key[1]))\n",
    "\n",
    "        capL = cv2.VideoCapture(str(lpath))\n",
    "        capR = cv2.VideoCapture(str(rpath))\n",
    "        if not capL.isOpened() or not capR.isOpened():\n",
    "            raise RuntimeError(\"Could not open eye videos: L={} R={}\".format(lpath, rpath))\n",
    "\n",
    "        Wl = int(capL.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        Hl = int(capL.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        Wr = int(capR.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        Hr = int(capR.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        current_key = key\n",
    "        _set_display_scale()\n",
    "\n",
    "    def _export_per_block():\n",
    "        nonlocal last_status\n",
    "        written = []\n",
    "        for (animal, b), sub in df.groupby([\"_animal_std\", \"_block_std\"], dropna=False):\n",
    "            bs = _block_for_key(block_dict, animal, b)\n",
    "            p = _write_block_annotations(bs, sub.copy())\n",
    "            written.append(str(p))\n",
    "        last_status = \"Exported sterile curation to {} block file(s).\".format(len(written))\n",
    "\n",
    "    cv2.imshow(\"Controls\", _draw_controls(cur_idx))\n",
    "\n",
    "    def on_mouse_controls(event, x, y, flags, param):\n",
    "        nonlocal playing, quit_flag, cur_idx, cur_ms, last_status, window_scale, wait_ms\n",
    "        if event != cv2.EVENT_LBUTTONDOWN:\n",
    "            return\n",
    "        name = _hit_button(x, y)\n",
    "        if name is None:\n",
    "            return\n",
    "\n",
    "        last_status = \"\"\n",
    "        if name == \"Play\":\n",
    "            playing = True\n",
    "        elif name == \"Pause\":\n",
    "            playing = False\n",
    "        elif name == \"Prev\":\n",
    "            playing = False\n",
    "            cur_idx = (cur_idx - 1) % len(df)\n",
    "            cur_ms = None\n",
    "        elif name == \"Next\":\n",
    "            playing = False\n",
    "            cur_idx = (cur_idx + 1) % len(df)\n",
    "            cur_ms = None\n",
    "        elif name == \"Step -1\":\n",
    "            playing = False\n",
    "            if cur_ms is not None:\n",
    "                cur_ms -= step_ms\n",
    "        elif name == \"Step +1\":\n",
    "            playing = False\n",
    "            if cur_ms is not None:\n",
    "                cur_ms += step_ms\n",
    "        elif name == \"KEEP\":\n",
    "            df.at[cur_idx, tag_col] = True\n",
    "            df.at[cur_idx, ts_col] = _now_stamp()\n",
    "        elif name == \"REJECT\":\n",
    "            df.at[cur_idx, tag_col] = False\n",
    "            df.at[cur_idx, ts_col] = _now_stamp()\n",
    "        elif name == \"Scale -\":\n",
    "            window_scale = max(min_scale, float(window_scale) - float(scale_step))\n",
    "            _set_display_scale()\n",
    "        elif name == \"Scale +\":\n",
    "            window_scale = min(max_scale, float(window_scale) + float(scale_step))\n",
    "            _set_display_scale()\n",
    "        elif name == \"Slower\":\n",
    "            wait_ms = min(max_wait_ms, int(wait_ms) + int(wait_step))\n",
    "        elif name == \"Faster\":\n",
    "            wait_ms = max(min_wait_ms, int(wait_ms) - int(wait_step))\n",
    "        elif name == \"Export\":\n",
    "            _export_per_block()\n",
    "\n",
    "        cv2.imshow(\"Controls\", _draw_controls(cur_idx))\n",
    "\n",
    "    cv2.setMouseCallback(\"Controls\", on_mouse_controls)\n",
    "\n",
    "    # ---------------- main loop ----------------\n",
    "    while True:\n",
    "        k = cv2.waitKey(int(wait_ms)) & 0xFF\n",
    "\n",
    "        if k in (27, ord('q'), ord('Q')):\n",
    "            quit_flag = True\n",
    "        elif k == 32:\n",
    "            playing = not playing\n",
    "        elif k == ord('['):\n",
    "            playing = False\n",
    "            cur_idx = (cur_idx - 1) % len(df)\n",
    "            cur_ms = None\n",
    "        elif k == ord(']'):\n",
    "            playing = False\n",
    "            cur_idx = (cur_idx + 1) % len(df)\n",
    "            cur_ms = None\n",
    "        elif k == ord(','):\n",
    "            playing = False\n",
    "            if cur_ms is not None:\n",
    "                cur_ms -= step_ms\n",
    "        elif k == ord('.'):\n",
    "            playing = False\n",
    "            if cur_ms is not None:\n",
    "                cur_ms += step_ms\n",
    "        elif k in (ord('k'), ord('K')):\n",
    "            df.at[cur_idx, tag_col] = True\n",
    "            df.at[cur_idx, ts_col] = _now_stamp()\n",
    "        elif k in (ord('r'), ord('R')):\n",
    "            df.at[cur_idx, tag_col] = False\n",
    "            df.at[cur_idx, ts_col] = _now_stamp()\n",
    "        elif k in (ord('e'), ord('E')):\n",
    "            _export_per_block()\n",
    "        elif k in (ord('z'), ord('Z')):\n",
    "            window_scale = max(min_scale, float(window_scale) - float(scale_step))\n",
    "            _set_display_scale()\n",
    "        elif k in (ord('x'), ord('X')):\n",
    "            window_scale = min(max_scale, float(window_scale) + float(scale_step))\n",
    "            _set_display_scale()\n",
    "        elif k == ord('-'):\n",
    "            wait_ms = min(max_wait_ms, int(wait_ms) + int(wait_step))\n",
    "        elif k in (ord('+'), ord('=')):\n",
    "            wait_ms = max(min_wait_ms, int(wait_ms) - int(wait_step))\n",
    "\n",
    "        if quit_flag:\n",
    "            break\n",
    "\n",
    "        row = df.iloc[cur_idx]\n",
    "        animal = str(row[\"_animal_std\"])\n",
    "        b = str(row[\"_block_std\"])\n",
    "\n",
    "        _open_for(animal, b)\n",
    "        step_ms = float(np.mean([_median_step_ms(left_df), _median_step_ms(right_df)]))\n",
    "\n",
    "        win_start = float(row[\"_win_start_ms\"])\n",
    "        win_end   = float(row[\"_win_end_ms\"])\n",
    "        sac_on    = float(row[\"_start_ms_std\"])\n",
    "        sac_off   = float(row[\"_end_ms_std\"])\n",
    "\n",
    "        if cur_ms is None:\n",
    "            cur_ms = win_start\n",
    "        cur_ms = min(max(cur_ms, win_start), win_end)\n",
    "\n",
    "        # determine which eyes should be active for THIS event\n",
    "        concurrent_flag = False\n",
    "        if concurrent_col is not None and concurrent_col in df.columns:\n",
    "            v = _coerce_tag(row.get(concurrent_col, None))\n",
    "            concurrent_flag = (v is True)\n",
    "\n",
    "        left_active_flag, right_active_flag = _event_eye_flags(row[\"_eye_std\"], concurrent_flag)\n",
    "\n",
    "        # should the dot show at this timepoint?\n",
    "        in_saccade = (sac_on <= cur_ms <= sac_off)\n",
    "        show_dot_now = bool(show_active_dot) and (in_saccade if active_dot_only_during_saccade else True)\n",
    "\n",
    "        rowL = _nearest_row(left_df, cur_ms)\n",
    "        rowR = _nearest_row(right_df, cur_ms)\n",
    "\n",
    "        # Left frame\n",
    "        L_img = np.zeros((max(1, Hl), max(1, Wl), 3), dtype=np.uint8)\n",
    "        if rowL is not None and left_fc is not None:\n",
    "            L_idx = rowL.get(left_fc, np.nan)\n",
    "            if pd.notna(L_idx):\n",
    "                L_idx = int(L_idx)\n",
    "                _seek(capL, L_idx)\n",
    "                fL = _read(capL)\n",
    "                if fL is not None:\n",
    "                    _overlay_ellipse(fL, left_df, L_idx)\n",
    "                    img = _apply_flip(fL.copy())\n",
    "\n",
    "                    if show_dot_now and left_active_flag:\n",
    "                        _draw_active_dot(img)\n",
    "\n",
    "                    lines = [\"Left | {} B{} | t={:.1f}ms | frame={}\".format(animal, b, cur_ms, L_idx)]\n",
    "                    if show_dot_now:\n",
    "                        lines.append(\"saccade ACTIVE\" if left_active_flag else \"saccade inactive\")\n",
    "                    _overlay_text(img, lines, origin=(10, 24))\n",
    "                    L_img = img\n",
    "                else:\n",
    "                    _overlay_text(L_img, [\"Left | read error\"], origin=(10, 24))\n",
    "                    L_img = _apply_flip(L_img)\n",
    "            else:\n",
    "                _overlay_text(L_img, [\"Left | no synchronized frame\"], origin=(10, 24))\n",
    "                L_img = _apply_flip(L_img)\n",
    "\n",
    "        # Right frame\n",
    "        R_img = np.zeros((max(1, Hr), max(1, Wr), 3), dtype=np.uint8)\n",
    "        if rowR is not None and right_fc is not None:\n",
    "            R_idx = rowR.get(right_fc, np.nan)\n",
    "            if pd.notna(R_idx):\n",
    "                R_idx = int(R_idx)\n",
    "                _seek(capR, R_idx)\n",
    "                fR = _read(capR)\n",
    "                if fR is not None:\n",
    "                    _overlay_ellipse(fR, right_df, R_idx)\n",
    "                    img = _apply_flip(fR.copy())\n",
    "\n",
    "                    if show_dot_now and right_active_flag:\n",
    "                        _draw_active_dot(img)\n",
    "\n",
    "                    lines = [\"Right | {} B{} | t={:.1f}ms | frame={}\".format(animal, b, cur_ms, R_idx)]\n",
    "                    if show_dot_now:\n",
    "                        lines.append(\"saccade ACTIVE\" if right_active_flag else \"saccade inactive\")\n",
    "                    _overlay_text(img, lines, origin=(10, 24))\n",
    "                    R_img = img\n",
    "                else:\n",
    "                    _overlay_text(R_img, [\"Right | read error\"], origin=(10, 24))\n",
    "                    R_img = _apply_flip(R_img)\n",
    "            else:\n",
    "                _overlay_text(R_img, [\"Right | no synchronized frame\"], origin=(10, 24))\n",
    "                R_img = _apply_flip(R_img)\n",
    "\n",
    "        # show\n",
    "        if disp_Wl > 0 and disp_Hl > 0:\n",
    "            cv2.imshow(\"Left Eye\", cv2.resize(L_img, (disp_Wl, disp_Hl)))\n",
    "        else:\n",
    "            cv2.imshow(\"Left Eye\", L_img)\n",
    "\n",
    "        if disp_Wr > 0 and disp_Hr > 0:\n",
    "            cv2.imshow(\"Right Eye\", cv2.resize(R_img, (disp_Wr, disp_Hr)))\n",
    "        else:\n",
    "            cv2.imshow(\"Right Eye\", R_img)\n",
    "\n",
    "        cv2.imshow(\"Controls\", _draw_controls(cur_idx))\n",
    "\n",
    "        if playing:\n",
    "            cur_ms += step_ms\n",
    "            if cur_ms > win_end:\n",
    "                playing = False\n",
    "                cur_idx = (cur_idx + 1) % len(df)\n",
    "                cur_ms = None\n",
    "\n",
    "    try:\n",
    "        if capL is not None: capL.release()\n",
    "        if capR is not None: capR.release()\n",
    "        if capA is not None: capA.release()\n",
    "    except Exception:\n",
    "        pass\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CALL EXAMPLE\n",
    "# -------------------------\n",
    "curated_df2 = curate_events_for_monocular_video_opencv(\n",
    "    block_dict=block_dict,\n",
    "    events_df=df,             # or an already curated df to edit\n",
    "    animal_call=\"PV_106\",\n",
    "    block=\"011\",\n",
    "    tag_col=\"keep_for_video\",\n",
    "    show_active_dot=True,\n",
    "    active_dot_only_during_saccade=True, # <-- key: dot appears only during on/off\n",
    "    concurrent_col=None                  # set if you have an is_concurrent column\n",
    ")\n"
   ],
   "id": "f0530bd772d318f",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "202bd2101394f3aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
