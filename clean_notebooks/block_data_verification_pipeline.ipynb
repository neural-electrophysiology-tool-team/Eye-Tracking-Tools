{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7ce3c7fff42b32e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This pipeline designed for verifying rotation and alignment in 2D eye data and rotation matrices acquired from tear ducts - use before going into kerr degree conversion",
   "id": "f3574e7730283ec6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T16:03:55.708161Z",
     "start_time": "2026-01-04T16:03:55.476233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from BlockSync_current import BlockSync\n"
   ],
   "id": "7fea00481f6b192b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-04T16:03:56.575086Z",
     "start_time": "2026-01-04T16:03:56.538813Z"
    }
   },
   "source": [
    "def load_eye_data_2d_w_rotation_matrix(block):\n",
    "    \"\"\"\n",
    "    This function checks if the eye dataframes and rotation dict object exist, then imports them\n",
    "    :param block: The current blocksync class with verifiec re/le dfs\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data.csv', index_col=0, engine='python')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data.csv', index_col=0, engine='python')\n",
    "    except FileNotFoundError:\n",
    "        print('eye_data files not found, run the pipeline!')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(block.analysis_path / 'rotate_eye_data_params.pkl', 'rb') as file:\n",
    "            rotation_dict = pickle.load(file)\n",
    "            block.left_rotation_matrix = rotation_dict['left_rotation_matrix']\n",
    "            block.right_rotation_matrix = rotation_dict['right_rotation_matrix']\n",
    "            block.left_rotation_angle = rotation_dict['left_rotation_angle']\n",
    "            block.right_rotation_angle = rotation_dict['right_rotation_angle']\n",
    "    except FileNotFoundError:\n",
    "        print('No rotation matrix file, create it')\n",
    "\n",
    "\n",
    "# Interactive verification/correction version over here:\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def horizontal_flip_eye_data(df: pd.DataFrame, frame_width: int) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    df2['center_x'] = frame_width - df2['center_x']\n",
    "    df2['phi'] = (180 - df2['phi']) % 360\n",
    "    return df2\n",
    "\n",
    "\n",
    "def apply_inverse_rotation(df: pd.DataFrame, rot_mat: np.ndarray, rot_angle: float) -> pd.DataFrame:\n",
    "    inv = cv2.invertAffineTransform(rot_mat.astype(np.float32))\n",
    "    df2 = df.copy()\n",
    "    pts = df2[['center_x', 'center_y']].values.reshape(-1, 1, 2).astype(np.float32)\n",
    "    pts2 = cv2.transform(pts, inv)\n",
    "    df2['center_x'] = pts2[:, 0, 0]\n",
    "    df2['center_y'] = pts2[:, 0, 1]\n",
    "    df2['phi'] = (df2['phi'] - rot_angle) % 360\n",
    "    return df2\n",
    "\n",
    "\n",
    "def apply_rotation(df: pd.DataFrame, rot_mat: np.ndarray, rot_angle: float) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    pts = df2[['center_x', 'center_y']].values.reshape(-1, 1, 2).astype(np.float32)\n",
    "    pts2 = cv2.transform(pts, rot_mat.astype(np.float32))\n",
    "    df2['center_x'] = pts2[:, 0, 0]\n",
    "    df2['center_y'] = pts2[:, 0, 1]\n",
    "    df2['phi'] = (df2['phi'] + rot_angle) % 360\n",
    "    return df2\n",
    "\n",
    "\n",
    "def rotate_phi_only(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    df2['phi'] = (df2['phi'] + 90) % 360\n",
    "    return df2\n",
    "\n",
    "\n",
    "def flip_x_only(df: pd.DataFrame, frame_width: int) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    df2['center_x'] = frame_width - df2['center_x']\n",
    "    return df2\n",
    "\n",
    "\n",
    "def interactive_eye_data_corrector_synced(block, eye, ref_point_xy=None):\n",
    "    \"\"\"\n",
    "    Interactive synchronized video + ellipse editor with Play/Pause, correction, Save,\n",
    "    Flip-Dot, and Skip-forward/backward (1 minute) buttons.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : BlockSync\n",
    "        Your BlockSync instance with loaded eye_data and rotation_matrix attributes.\n",
    "    eye : str\n",
    "        'left' or 'right'\n",
    "    ref_point_xy : tuple[int,int] or None\n",
    "        If provided, a (x,y) coordinate in raw frame space to draw as a blue dot on every frame.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # 1) select data & video\n",
    "    if eye.lower() == 'left':\n",
    "        df_orig = block.left_eye_data.copy()\n",
    "        rot_mat = np.array(block.left_rotation_matrix, dtype=np.float32)\n",
    "        rot_angle = float(block.left_rotation_angle)\n",
    "        video = block.le_videos[0]\n",
    "    else:\n",
    "        df_orig = block.right_eye_data.copy()\n",
    "        rot_mat = np.array(block.right_rotation_matrix, dtype=np.float32)\n",
    "        rot_angle = float(block.right_rotation_angle)\n",
    "        video = block.re_videos[0]\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open {eye} video: {video}\")\n",
    "\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    skip_frames = int(fps * 60)  # skip 1 minute\n",
    "\n",
    "    # 2) prepare DataFrame & frame index column\n",
    "    df_current = df_orig.copy()\n",
    "    frame_col = 'eye_frame' if 'eye_frame' in df_current.columns else 'frame'\n",
    "\n",
    "    # 3) define buttons & layout\n",
    "    buttons = {\n",
    "        'Play': ((10, 10), (180, 60)),\n",
    "        'Pause': ((10, 80), (180, 130)),\n",
    "        'Un-rotate': ((10, 150), (180, 200)),\n",
    "        'X-flip': ((10, 220), (180, 270)),\n",
    "        'Re-rotate': ((10, 290), (180, 340)),\n",
    "        'Phi+90': ((10, 360), (180, 410)),\n",
    "        'FlipX-only': ((10, 430), (180, 480)),\n",
    "        'Flip Dot': ((10, 500), (180, 550)),\n",
    "        'Bwd': ((10, 570), (180, 620)),\n",
    "        'Fwd': ((10, 640), (180, 690)),\n",
    "        'Save': ((10, 710), (180, 760)),\n",
    "        'Quit': ((10, 780), (180, 830)),\n",
    "    }\n",
    "    ctrl_h, ctrl_w = 860, 200\n",
    "\n",
    "    def draw_controls():\n",
    "        img = np.zeros((ctrl_h, ctrl_w, 3), dtype=np.uint8)\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (50, 50, 50), -1)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (200, 200, 200), 2)\n",
    "            cv2.putText(img, name, (x1 + 5, y1 + 35),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2, cv2.LINE_AA)\n",
    "        return img\n",
    "\n",
    "    controls_img = draw_controls()\n",
    "    cv2.namedWindow('Controls', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # 4) interaction state\n",
    "    running = True\n",
    "    playing = False\n",
    "    current_ref = ref_point_xy\n",
    "    last_frame = None\n",
    "\n",
    "    # 5) mouse callback\n",
    "    def on_mouse(event, x, y, flags, param):\n",
    "        nonlocal df_current, running, playing, current_ref, last_frame\n",
    "        if event != cv2.EVENT_LBUTTONDOWN:\n",
    "            return\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                if name == 'Play':\n",
    "                    playing = True\n",
    "                elif name == 'Pause':\n",
    "                    playing = False\n",
    "                elif name == 'Un-rotate':\n",
    "                    df_current = apply_inverse_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name == 'X-flip':\n",
    "                    df_current = horizontal_flip_eye_data(df_current, W)\n",
    "                elif name == 'Re-rotate':\n",
    "                    df_current = apply_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name == 'Phi+90':\n",
    "                    df_current = rotate_phi_only(df_current)\n",
    "                elif name == 'FlipX-only':\n",
    "                    df_current = flip_x_only(df_current, W)\n",
    "                elif name == 'Flip Dot' and current_ref is not None:\n",
    "                    x0, y0 = current_ref\n",
    "                    current_ref = (W - x0, y0)\n",
    "                elif name == 'Bwd':\n",
    "                    # skip backward 1 minute\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "                    new_idx = max(idx - skip_frames, 0)\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, new_idx)\n",
    "                    last_frame = None\n",
    "                elif name == 'Fwd':\n",
    "                    # skip forward 1 minute\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "                    new_idx = min(idx + skip_frames, total_frames - 1)\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, new_idx)\n",
    "                    last_frame = None\n",
    "                elif name == 'Save':\n",
    "                    if eye.lower() == 'left':\n",
    "                        block.left_eye_data = df_current.copy()\n",
    "                    else:\n",
    "                        block.right_eye_data = df_current.copy()\n",
    "                    print(f\"{eye.capitalize()} eye data saved.\")\n",
    "                elif name == 'Quit':\n",
    "                    running = False\n",
    "                break\n",
    "\n",
    "    cv2.setMouseCallback('Controls', on_mouse)\n",
    "\n",
    "    # 6) play/pause loop\n",
    "    while running:\n",
    "        if playing or last_frame is None:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            last_frame = frame.copy()\n",
    "        else:\n",
    "            frame = last_frame.copy()\n",
    "\n",
    "        # sync: get current frame index\n",
    "        current_idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "        current_idx = max(current_idx, 0)\n",
    "\n",
    "        # draw reference dot if provided\n",
    "        annotated = frame.copy()\n",
    "        if current_ref is not None:\n",
    "            cv2.circle(annotated, current_ref, 5, (255, 0, 0), -1)\n",
    "\n",
    "        # draw ellipse if valid data exists\n",
    "        mask = df_current[frame_col] == current_idx\n",
    "        if mask.any():\n",
    "            row = df_current[mask].iloc[0]\n",
    "            cx, cy = row['center_x'], row['center_y']\n",
    "            if not (pd.isna(cx) or pd.isna(cy)):\n",
    "                x = int(round(cx))\n",
    "                y = int(round(cy))\n",
    "                w = int(row['width'])\n",
    "                h = int(row['height'])\n",
    "                phi = float(row['phi'])\n",
    "                cv2.ellipse(annotated, (x, y), (w, h), phi, 0, 360, (0, 255, 0), 2)\n",
    "\n",
    "        # final vertical flip for display\n",
    "        disp = cv2.flip(annotated, 0)\n",
    "        cv2.imshow('Frame', disp)\n",
    "        cv2.imshow('Controls', controls_img)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == 27:  # ESC to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def interactive_eye_rotation_checker(block, eye):\n",
    "    \"\"\"\n",
    "    Interactive tool to visualize how a rotation matrix would affect your\n",
    "    un-rotated eye data and frame, by drawing the raw ellipse first and then\n",
    "    warping the entire annotated frame.\n",
    "\n",
    "    Buttons:\n",
    "      • Play              : start auto-play\n",
    "      • Pause             : stop auto-play\n",
    "      • Original rotation : warp with block.<eye>_rotation_matrix\n",
    "      • Reversed rotation : warp with inverse matrix\n",
    "      • Quit              : exit\n",
    "\n",
    "    Workflow per frame:\n",
    "      1. Read raw frame (no flips).\n",
    "      2. Draw ellipse at raw (center_x, center_y) with raw φ from DataFrame.\n",
    "      3. Warp the *entire* annotated frame by the selected 2×3 matrix.\n",
    "      4. Vertically flip for display.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # 1) Pick eye‐specific data & matrices\n",
    "    if eye.lower() == 'left':\n",
    "        df = block.left_eye_data.copy()\n",
    "        R_orig = np.array(block.left_rotation_matrix, dtype=np.float32)\n",
    "        video = block.le_videos[0]\n",
    "    else:\n",
    "        df = block.right_eye_data.copy()\n",
    "        R_orig = np.array(block.right_rotation_matrix, dtype=np.float32)\n",
    "        video = block.re_videos[0]\n",
    "\n",
    "    # Compute inverse rotation matrix\n",
    "    R_rev = cv2.invertAffineTransform(R_orig)\n",
    "\n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(str(video))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open {eye} video: {video}\")\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    N = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Determine which column holds frame indices\n",
    "    frame_col = 'eye_frame' if 'eye_frame' in df.columns else 'frame'\n",
    "\n",
    "    # 2) Define buttons and layout\n",
    "    buttons = {\n",
    "        'Play': ((10, 10), (180, 60)),\n",
    "        'Pause': ((10, 80), (180, 130)),\n",
    "        'Original rotation': ((10, 150), (180, 200)),\n",
    "        'Reversed rotation': ((10, 220), (180, 270)),\n",
    "        'Quit': ((10, 290), (180, 340)),\n",
    "    }\n",
    "    ctrl_h, ctrl_w = 360, 200\n",
    "\n",
    "    def draw_controls():\n",
    "        img = np.zeros((ctrl_h, ctrl_w, 3), dtype=np.uint8)\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (50, 50, 50), -1)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (200, 200, 200), 2)\n",
    "            cv2.putText(img, name, (x1 + 5, y1 + 35),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2, cv2.LINE_AA)\n",
    "        return img\n",
    "\n",
    "    controls_img = draw_controls()\n",
    "    cv2.namedWindow('Controls', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # 3) Interaction state\n",
    "    running = True\n",
    "    playing = False\n",
    "    use_matrix = R_orig  # start with original rotation\n",
    "\n",
    "    def on_mouse(event, x, y, flags, param):\n",
    "        nonlocal running, playing, use_matrix\n",
    "        if event != cv2.EVENT_LBUTTONDOWN:\n",
    "            return\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                if name == 'Play':\n",
    "                    playing = True\n",
    "                elif name == 'Pause':\n",
    "                    playing = False\n",
    "                elif name == 'Original rotation':\n",
    "                    use_matrix = R_orig\n",
    "                elif name == 'Reversed rotation':\n",
    "                    use_matrix = R_rev\n",
    "                elif name == 'Quit':\n",
    "                    running = False\n",
    "                break\n",
    "\n",
    "    cv2.setMouseCallback('Controls', on_mouse)\n",
    "\n",
    "    # 4) Playback loop\n",
    "    last_frame = None\n",
    "    while running:\n",
    "        # Advance if playing\n",
    "        if playing or last_frame is None:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            last_frame = frame.copy()\n",
    "        else:\n",
    "            frame = last_frame.copy()\n",
    "\n",
    "        # Sync: current frame index\n",
    "        idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "        if idx < 0: idx = 0\n",
    "\n",
    "        # 5) Draw raw ellipse on native frame\n",
    "        annotated = frame.copy()\n",
    "        mask = df[frame_col] == idx\n",
    "        if mask.any():\n",
    "            row = df[mask].iloc[0]\n",
    "            cx, cy = row['center_x'], row['center_y']\n",
    "            if not (pd.isna(cx) or pd.isna(cy)):\n",
    "                x = int(round(cx))\n",
    "                y = int(round(cy))\n",
    "                w = int(row['width'])\n",
    "                h = int(row['height'])\n",
    "                phi = float(row['phi'])\n",
    "                cv2.ellipse(annotated, (x, y), (w, h), phi, 0, 360, (0, 255, 0), 2)\n",
    "\n",
    "        # 6) Warp the entire annotated frame\n",
    "        warped = cv2.warpAffine(\n",
    "            annotated,\n",
    "            use_matrix,\n",
    "            (W, H),\n",
    "            flags=cv2.INTER_LINEAR,\n",
    "            borderMode=cv2.BORDER_CONSTANT,\n",
    "            borderValue=(0, 0, 0)\n",
    "        )\n",
    "\n",
    "        # 7) Final vertical flip for display\n",
    "        disp = cv2.flip(warped, 0)\n",
    "        cv2.imshow('Frame', disp)\n",
    "        cv2.imshow('Controls', controls_img)\n",
    "\n",
    "        # 8) Exit on ESC\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def negate_eye_rotation(block, eye):\n",
    "    \"\"\"\n",
    "    Replace block.<eye>_rotation_matrix with its inverse (negated rotation)\n",
    "    and update block.<eye>_rotation_angle to -angle (mod 360).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : your BlockSync instance\n",
    "    eye : str\n",
    "        'left' or 'right'\n",
    "    \"\"\"\n",
    "    if eye.lower() == 'left':\n",
    "        R_old = np.array(block.left_rotation_matrix, dtype=np.float32)\n",
    "        ang_old = float(block.left_rotation_angle)\n",
    "        invR = cv2.invertAffineTransform(R_old)\n",
    "        block.left_rotation_matrix = invR\n",
    "        block.left_rotation_angle = (-ang_old) % 360.0\n",
    "        print(f\"Left rotation matrix negated; angle set to {block.left_rotation_angle:.2f}°\")\n",
    "    elif eye.lower() == 'right':\n",
    "        R_old = np.array(block.right_rotation_matrix, dtype=np.float32)\n",
    "        ang_old = float(block.right_rotation_angle)\n",
    "        invR = cv2.invertAffineTransform(R_old)\n",
    "        block.right_rotation_matrix = invR\n",
    "        block.right_rotation_angle = (-ang_old) % 360.0\n",
    "        print(f\"Right rotation matrix negated; angle set to {block.right_rotation_angle:.2f}°\")\n",
    "    else:\n",
    "        raise ValueError(\"eye must be 'left' or 'right'\")\n",
    "\n",
    "\n",
    "def export_corrected_eye_data(block):\n",
    "    \"\"\"\n",
    "    Overwrite the eye‐data CSVs and rotation‐params pickle so that\n",
    "    load_eye_data_2d_w_rotation_matrix(block) will load the current,\n",
    "    corrected attributes from disk.\n",
    "\n",
    "    Writes:\n",
    "      • block.analysis_path/'left_eye_data.csv'\n",
    "      • block.analysis_path/'right_eye_data.csv'\n",
    "      • block.analysis_path/'rotate_eye_data_params.pkl'\n",
    "    \"\"\"\n",
    "    # Ensure the analysis_path exists\n",
    "    analysis_path = Path(block.analysis_path)\n",
    "    analysis_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Write the DataFrames\n",
    "    block.left_eye_data.to_csv(analysis_path / 'left_eye_data.csv', index=True)\n",
    "    block.right_eye_data.to_csv(analysis_path / 'right_eye_data.csv', index=True)\n",
    "\n",
    "    # 2) Build and write the rotation‐params pickle\n",
    "    rot_dict = {\n",
    "        'left_rotation_matrix': block.left_rotation_matrix,\n",
    "        'left_rotation_angle': block.left_rotation_angle,\n",
    "        'right_rotation_matrix': block.right_rotation_matrix,\n",
    "        'right_rotation_angle': block.right_rotation_angle\n",
    "    }\n",
    "    with open(analysis_path / 'rotate_eye_data_params.pkl', 'wb') as f:\n",
    "        pickle.dump(rot_dict, f)\n",
    "\n",
    "    print(f\"Exported corrected eye data and rotation params to {analysis_path}\")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:01:55.345256Z",
     "start_time": "2025-11-02T14:01:54.945497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_block_collections(animals, block_lists, experiment_path, bad_blocks=None):\n",
    "    \"\"\"\n",
    "    Create block collections and a block dictionary from multiple animals and their respective block lists.\n",
    "\n",
    "    Parameters:\n",
    "    - animals: list of str, names of the animals.\n",
    "    - block_lists: list of lists of int, block numbers corresponding to each animal.\n",
    "    - experiment_path: pathlib.Path, path to the experiment directory.\n",
    "    - bad_blocks: list of int, blocks to exclude. Default is an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - block_collection: list of BlockSync objects for all specified blocks.\n",
    "    - block_dict: dictionary where keys are block numbers as strings and values are BlockSync objects.\n",
    "    \"\"\"\n",
    "    import UtilityFunctions_newOE as uf\n",
    "\n",
    "    if bad_blocks is None:\n",
    "        bad_blocks = []\n",
    "\n",
    "    block_collection = []\n",
    "    block_dict = {}\n",
    "\n",
    "    for animal, blocks in zip(animals, block_lists):\n",
    "        # Generate blocks for the current animal\n",
    "        current_blocks = uf.block_generator(\n",
    "            block_numbers=blocks,\n",
    "            experiment_path=experiment_path,\n",
    "            animal=animal,\n",
    "            bad_blocks=bad_blocks\n",
    "        )\n",
    "        # Add to collection and dictionary\n",
    "        block_collection.extend(current_blocks)\n",
    "        for b in current_blocks:\n",
    "            block_dict[f\"{animal}_block_{b.block_num}\"] = b\n",
    "\n",
    "    return block_collection, block_dict\n",
    "\n",
    "animals = [\"PV_62\"]\n",
    "#animals = ['PV_62', 'PV_126', 'PV_57']\n",
    "#block_lists = [[23, 24, 26, 38], [7, 8, 9, 10, 11, 12], [7, 8, 9, 11, 12, 13]]\n",
    "#block_lists = [[],[13],[]]\n",
    "block_lists = [[23,25,27]]\n",
    "experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "bad_blocks = [0]  # Example of bad blocks\n",
    "\n",
    "block_collection, block_dict = create_block_collections(\n",
    "    animals=animals,\n",
    "    block_lists=block_lists,\n",
    "    experiment_path=experiment_path,\n",
    "    bad_blocks=bad_blocks\n",
    ")"
   ],
   "id": "defe7d88f8af90da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 023 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_023, new OE version\n",
      "Found the sample rate for block 023 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 023\n",
      "got it!\n",
      "instantiated block number 025 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_025, new OE version\n",
      "Found the sample rate for block 025 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 025\n",
      "got it!\n",
      "instantiated block number 027 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_027, new OE version\n",
      "Found the sample rate for block 027 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 027\n",
      "got it!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:02:08.381482Z",
     "start_time": "2025-11-02T14:02:00.690007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for block in block_collection:\n",
    "\n",
    "    block.parse_open_ephys_events()\n",
    "    block.get_eye_brightness_vectors()\n",
    "    #block.synchronize_block()\n",
    "    #block.create_eye_brightness_df(threshold_value=20)\n",
    "    block.handle_eye_videos()\n",
    "    # if the code fails here, go to manual synchronization\n",
    "    #block.import_manual_sync_df()\n",
    "    #block.read_dlc_data()\n",
    "    #block.calibrate_pixel_size(10)\n",
    "    load_eye_data_2d_w_rotation_matrix(block)\n",
    "\n",
    "    #block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_3d_corr_verified.csv')\n",
    "    #block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_3d_corr_verified.csv')"
   ],
   "id": "390ae501290f0229",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parse_open_ephys_events...\n",
      "block 023 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 023...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_023\\\\eye_videos\\\\LE\\\\230427_pv62_trial1_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial1.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_023\\\\eye_videos\\\\RE\\\\230427_pv62_trial1_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial1.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_023\\\\eye_videos\\\\LE\\\\230427_pv62_trial1_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial1_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_023\\\\eye_videos\\\\RE\\\\230427_pv62_trial1_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial1.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_023\\eye_videos\\RE\\230427_pv62_trial1_640x480_60hz_experiment_1_recording_0\\230427_pv62_trial1.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230427_pv62_trial1_LE.mp4 has reported 97331 frames and has 97331 frames, it has dropped 0 frames\n",
      "The video named 230427_pv62_trial1.mp4 has reported 97329 frames and has 97329 frames, it has dropped 0 frames\n",
      "running parse_open_ephys_events...\n",
      "block 025 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 025...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_025\\\\eye_videos\\\\LE\\\\230427_pv62_trial3_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial3.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_025\\\\eye_videos\\\\RE\\\\230427_pv62_trial3_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial3.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_025\\\\eye_videos\\\\LE\\\\230427_pv62_trial3_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial3_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_025\\\\eye_videos\\\\RE\\\\230427_pv62_trial3_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial3.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_025\\eye_videos\\RE\\230427_pv62_trial3_640x480_60hz_experiment_1_recording_0\\230427_pv62_trial3.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230427_pv62_trial3_LE.mp4 has reported 96578 frames and has 96578 frames, it has dropped 0 frames\n",
      "The video named 230427_pv62_trial3.mp4 has reported 96570 frames and has 96570 frames, it has dropped 0 frames\n",
      "running parse_open_ephys_events...\n",
      "block 027 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 027...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "handling eye video files\n",
      "converting videos...\n",
      "converting files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_027\\\\eye_videos\\\\LE\\\\230427_pv62_trial5_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial5.h264', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_027\\\\eye_videos\\\\RE\\\\230427_pv62_trial5_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial5.h264'] \n",
      " avoiding conversion on files: ['Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_027\\\\eye_videos\\\\LE\\\\230427_pv62_trial5_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial5_LE.mp4', 'Z:\\\\Nimrod\\\\experiments\\\\PV_62\\\\2023_04_27\\\\block_027\\\\eye_videos\\\\RE\\\\230427_pv62_trial5_640x480_60hz_experiment_1_recording_0\\\\230427_pv62_trial5.mp4']\n",
      "The file Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_027\\eye_videos\\RE\\230427_pv62_trial5_640x480_60hz_experiment_1_recording_0\\230427_pv62_trial5.mp4 already exists, no conversion necessary\n",
      "Validating videos...\n",
      "The video named 230427_pv62_trial5_LE.mp4 has reported 91390 frames and has 91390 frames, it has dropped 0 frames\n",
      "The video named 230427_pv62_trial5.mp4 has reported 91391 frames and has 91391 frames, it has dropped 0 frames\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:02:12.903772Z",
     "start_time": "2025-11-02T14:02:12.880774Z"
    }
   },
   "cell_type": "code",
   "source": "block_dict.keys()",
   "id": "9c94a8161f6298e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['PV_62_block_023', 'PV_62_block_025', 'PV_62_block_027'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:02:18.377383Z",
     "start_time": "2025-11-02T14:02:18.364384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set up a block\n",
    "block = block_dict['PV_62_block_023']\n",
    "#pick_reference_opencv(block,'left')\n",
    "#block.load_best_reference(r'Z:\\Nimrod\\experiments\\cross_animals_data\\kerr_reference_all_animals_current_25_05_12.csv')"
   ],
   "id": "c5924043e12653bb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:02:21.878207Z",
     "start_time": "2025-11-02T14:02:20.490180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "r_ref = tuple([int(block.kerr_ref_r_x), int(block.kerr_ref_r_y)])\n",
    "l_ref = tuple([int(block.kerr_ref_l_x), int(block.kerr_ref_l_y)])"
   ],
   "id": "e0991ec1ea1103a8",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BlockSync' object has no attribute 'kerr_ref_r_x'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-036752878cde>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mr_ref\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkerr_ref_r_x\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkerr_ref_r_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0ml_ref\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkerr_ref_l_x\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkerr_ref_l_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'BlockSync' object has no attribute 'kerr_ref_r_x'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:02:25.200682Z",
     "start_time": "2025-11-02T14:02:25.168683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# with kerr reference pick\n",
    "def interactive_eye_data_corrector_synced(block, eye, ref_point_xy=None):\n",
    "    \"\"\"\n",
    "    Interactive synchronized video + ellipse editor with Play/Pause, correction, Save,\n",
    "    Flip-Dot, and Skip-forward/backward (1 minute) buttons.\n",
    "\n",
    "    NEW FEATURE:\n",
    "    - Click anywhere on the 'Frame' window to set/update the reference point.\n",
    "    - Press 'Save' to also update block.kerr_ref_<l/r>_<x/y> with the picked reference.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : BlockSync\n",
    "        Your BlockSync instance with loaded eye_data and rotation_matrix attributes.\n",
    "    eye : str\n",
    "        'left' or 'right'\n",
    "    ref_point_xy : tuple[int,int] or None\n",
    "        If provided, a (x,y) coordinate in raw frame space to draw as a blue dot on every frame.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # 1) select data & video\n",
    "    eye_lc = eye.lower()\n",
    "    if eye_lc == 'left':\n",
    "        df_orig = block.left_eye_data.copy()\n",
    "        rot_mat = np.array(block.left_rotation_matrix, dtype=np.float32)\n",
    "        rot_angle = float(block.left_rotation_angle)\n",
    "        video = block.le_videos[0]\n",
    "    elif eye_lc == 'right':\n",
    "        df_orig = block.right_eye_data.copy()\n",
    "        rot_mat = np.array(block.right_rotation_matrix, dtype=np.float32)\n",
    "        rot_angle = float(block.right_rotation_angle)\n",
    "        video = block.re_videos[0]\n",
    "    else:\n",
    "        raise ValueError(\"eye must be 'left' or 'right'\")\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open {eye} video: {video}\")\n",
    "\n",
    "    W  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    N  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    skip_frames = int(fps * 60)  # skip 1 minute\n",
    "\n",
    "    # 2) prepare DataFrame & frame index column\n",
    "    df_current = df_orig.copy()\n",
    "    frame_col = 'eye_frame' if 'eye_frame' in df_current.columns else 'frame'\n",
    "\n",
    "    # 3) define buttons & layout\n",
    "    buttons = {\n",
    "        'Play': ((10, 10), (180, 60)),\n",
    "        'Pause': ((10, 80), (180, 130)),\n",
    "        'Un-rotate': ((10, 150), (180, 200)),\n",
    "        'X-flip': ((10, 220), (180, 270)),\n",
    "        'Re-rotate': ((10, 290), (180, 340)),\n",
    "        'Phi+90': ((10, 360), (180, 410)),\n",
    "        'FlipX-only': ((10, 430), (180, 480)),\n",
    "        'Flip Dot': ((10, 500), (180, 550)),\n",
    "        'Bwd': ((10, 570), (180, 620)),\n",
    "        'Fwd': ((10, 640), (180, 690)),\n",
    "        'Save': ((10, 710), (180, 760)),\n",
    "        'Quit': ((10, 780), (180, 830)),\n",
    "    }\n",
    "    ctrl_h, ctrl_w = 860, 200\n",
    "\n",
    "    def draw_controls():\n",
    "        img = np.zeros((ctrl_h, ctrl_w, 3), dtype=np.uint8)\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (50, 50, 50), -1)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (200, 200, 200), 2)\n",
    "            cv2.putText(img, name, (x1 + 5, y1 + 35),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2, cv2.LINE_AA)\n",
    "        return img\n",
    "\n",
    "    controls_img = draw_controls()\n",
    "    cv2.namedWindow('Controls', cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('Frame', cv2.WINDOW_NORMAL)  # ensure we can bind a callback\n",
    "\n",
    "    # 4) interaction state\n",
    "    running   = True\n",
    "    playing   = False\n",
    "    current_ref = ref_point_xy  # raw-frame coordinates (before final vertical flip)\n",
    "    last_frame = None\n",
    "\n",
    "    # --------- Mouse callbacks ----------\n",
    "    # Controls window: button clicks\n",
    "    def on_mouse_controls(event, x, y, flags, param):\n",
    "        nonlocal df_current, running, playing, current_ref, last_frame\n",
    "        if event != cv2.EVENT_LBUTTONDOWN:\n",
    "            return\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                if name == 'Play':\n",
    "                    playing = True\n",
    "                elif name == 'Pause':\n",
    "                    playing = False\n",
    "                elif name == 'Un-rotate':\n",
    "                    df_current = apply_inverse_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name == 'X-flip':\n",
    "                    df_current = horizontal_flip_eye_data(df_current, W)\n",
    "                elif name == 'Re-rotate':\n",
    "                    df_current = apply_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name == 'Phi+90':\n",
    "                    df_current = rotate_phi_only(df_current)\n",
    "                elif name == 'FlipX-only':\n",
    "                    df_current = flip_x_only(df_current, W)\n",
    "                elif name == 'Flip Dot' and current_ref is not None:\n",
    "                    x0, y0 = current_ref\n",
    "                    current_ref = (W - x0, y0)\n",
    "                elif name == 'Bwd':\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "                    new_idx = max(idx - skip_frames, 0)\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, new_idx)\n",
    "                    last_frame = None\n",
    "                elif name == 'Fwd':\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "                    new_idx = min(idx + skip_frames, N - 1)\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, new_idx)\n",
    "                    last_frame = None\n",
    "                elif name == 'Save':\n",
    "                    # Save DataFrame edits\n",
    "                    if eye_lc == 'left':\n",
    "                        block.left_eye_data = df_current.copy()\n",
    "                    else:\n",
    "                        block.right_eye_data = df_current.copy()\n",
    "                    # Save reference point to block attributes if available\n",
    "                    if current_ref is not None:\n",
    "                        rx = int(round(current_ref[0]))\n",
    "                        ry = int(round(current_ref[1]))\n",
    "                        if eye_lc == 'left':\n",
    "                            block.kerr_ref_l_x = rx\n",
    "                            block.kerr_ref_l_y = ry\n",
    "                            print(f\"Saved left-eye reference to block: ({rx}, {ry})\")\n",
    "                        else:\n",
    "                            block.kerr_ref_r_x = rx\n",
    "                            block.kerr_ref_r_y = ry\n",
    "                            print(f\"Saved right-eye reference to block: ({rx}, {ry})\")\n",
    "                    print(f\"{eye.capitalize()} eye data saved.\")\n",
    "                elif name == 'Quit':\n",
    "                    running = False\n",
    "                break\n",
    "\n",
    "    # Frame window: click to set reference\n",
    "    # NOTE: The displayed frame is vertically flipped for viewing. Map click -> raw frame coords.\n",
    "    def on_mouse_frame(event, x, y, flags, param):\n",
    "        nonlocal current_ref\n",
    "        if event != cv2.EVENT_LBUTTONDOWN:\n",
    "            return\n",
    "        # y in 'Frame' is after a vertical flip; convert back to raw-frame coordinates:\n",
    "        y_raw = H - 1 - y\n",
    "        x_raw = x\n",
    "        current_ref = (int(x_raw), int(y_raw))\n",
    "        # Provide visual/console feedback:\n",
    "        print(f\"Picked reference (raw coords): ({current_ref[0]}, {current_ref[1]})\")\n",
    "\n",
    "    cv2.setMouseCallback('Controls', on_mouse_controls)\n",
    "    cv2.setMouseCallback('Frame', on_mouse_frame)\n",
    "\n",
    "    # 6) play/pause loop\n",
    "    while running:\n",
    "        if playing or last_frame is None:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            last_frame = frame.copy()\n",
    "        else:\n",
    "            frame = last_frame.copy()\n",
    "\n",
    "        # sync: get current frame index\n",
    "        current_idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "        current_idx = max(current_idx, 0)\n",
    "\n",
    "        # draw reference dot if provided (raw-frame coords)\n",
    "        annotated = frame.copy()\n",
    "        if current_ref is not None:\n",
    "            cv2.circle(annotated, (int(current_ref[0]), int(current_ref[1])), 5, (255, 0, 0), -1)\n",
    "\n",
    "        # draw ellipse if valid data exists\n",
    "        mask = df_current[frame_col] == current_idx\n",
    "        if mask.any():\n",
    "            row = df_current[mask].iloc[0]\n",
    "            cx, cy = row['center_x'], row['center_y']\n",
    "            if not (pd.isna(cx) or pd.isna(cy)):\n",
    "                x = int(round(cx))\n",
    "                y = int(round(cy))\n",
    "                w = int(row.get('width', 0))\n",
    "                h = int(row.get('height', 0))\n",
    "                phi = float(row.get('phi', 0.0))\n",
    "                # Guard widths/heights\n",
    "                w = max(w, 1); h = max(h, 1)\n",
    "                cv2.ellipse(annotated, (x, y), (w, h), phi, 0, 360, (0, 255, 0), 2)\n",
    "\n",
    "        # final vertical flip for display (maintains your y-positive-up convention)\n",
    "        disp = cv2.flip(annotated, 0)\n",
    "        cv2.imshow('Frame', disp)\n",
    "        cv2.imshow('Controls', controls_img)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == 27:  # ESC to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def export_current_kerr_refs(block, filename: str = \"self_kerr_refs.csv\") -> Path:\n",
    "    \"\"\"\n",
    "    Save the current block's Kerr reference coordinates to a small CSV in the analysis folder.\n",
    "\n",
    "    Writes a single-row CSV with columns:\n",
    "        kerr_ref_r_x, kerr_ref_r_y, kerr_ref_l_x, kerr_ref_l_y\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path\n",
    "        The path to the written CSV.\n",
    "    \"\"\"\n",
    "    analysis_path = Path(block.analysis_path)\n",
    "    analysis_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Pull attributes if present; otherwise write NaN so the schema stays consistent\n",
    "    vals = {\n",
    "        \"kerr_ref_r_x\": getattr(block, \"kerr_ref_r_x\", np.nan),\n",
    "        \"kerr_ref_r_y\": getattr(block, \"kerr_ref_r_y\", np.nan),\n",
    "        \"kerr_ref_l_x\": getattr(block, \"kerr_ref_l_x\", np.nan),\n",
    "        \"kerr_ref_l_y\": getattr(block, \"kerr_ref_l_y\", np.nan),\n",
    "    }\n",
    "\n",
    "    out_path = analysis_path / filename\n",
    "    pd.DataFrame([vals]).to_csv(out_path, index=False)\n",
    "    print(f\"Kerr refs exported to: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def load_self_kerr_refs(block, filename: str = \"self_kerr_refs.csv\") -> bool:\n",
    "    \"\"\"\n",
    "    Load Kerr reference coordinates from the analysis folder CSV and set them on `block`.\n",
    "\n",
    "    Reads a single-row CSV with columns:\n",
    "        kerr_ref_r_x, kerr_ref_r_y, kerr_ref_l_x, kerr_ref_l_y\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if refs were loaded and applied, False if the file was missing or empty.\n",
    "    \"\"\"\n",
    "    path = Path(block.analysis_path) / filename\n",
    "    if not path.exists():\n",
    "        print(f\"No Kerr refs file found at: {path}\")\n",
    "        return False\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    if df.empty:\n",
    "        print(f\"Kerr refs file is empty: {path}\")\n",
    "        return False\n",
    "\n",
    "    row = df.iloc[0]\n",
    "\n",
    "    # Helper to safely set attribute if value is finite\n",
    "    def _set_attr(name):\n",
    "        if name in row and pd.notna(row[name]):\n",
    "            try:\n",
    "                setattr(block, name, int(round(float(row[name]))))\n",
    "            except (ValueError, TypeError):\n",
    "                # keep existing value if conversion fails\n",
    "                pass\n",
    "\n",
    "    for col in (\"kerr_ref_r_x\", \"kerr_ref_r_y\", \"kerr_ref_l_x\", \"kerr_ref_l_y\"):\n",
    "        _set_attr(col)\n",
    "\n",
    "    print(f\"Kerr refs loaded from: {path}\")\n",
    "    return True\n"
   ],
   "id": "c03f6f941cd925e9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:03:06.084469Z",
     "start_time": "2025-11-02T14:02:34.892896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use the interactive tool to get a properly aligned data on a native frame (this is y-flipped after plotting and maintains the y-positive = up convention\n",
    "# save before exiting the tool!!\n",
    "interactive_eye_data_corrector_synced(block, eye='left')"
   ],
   "id": "656d8bb30f3e31fe",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T13:42:29.481423Z",
     "start_time": "2025-10-24T13:42:11.582052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run for right eye\n",
    "interactive_eye_data_corrector_synced(block, eye='right', ref_point_xy=(300,400))"
   ],
   "id": "22511726afea297f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked reference (raw coords): (359, 318)\n",
      "Picked reference (raw coords): (346, 318)\n",
      "Saved right-eye reference to block: (346, 318)\n",
      "Right eye data saved.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T13:42:36.533336Z",
     "start_time": "2025-10-24T13:42:33.470291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use this tool to verify correct tearducts-based correction, does not automatically updates the rotation matrix\n",
    "interactive_eye_rotation_checker(block, eye='right')"
   ],
   "id": "d6e5aecee5110907",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T18:26:26.747303Z",
     "start_time": "2025-08-26T18:26:23.323062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# and the left eye\n",
    "interactive_eye_rotation_checker(block, eye='left')"
   ],
   "id": "8b948d32d71fdaca",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T18:30:28.854127Z",
     "start_time": "2025-08-26T18:30:28.838622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if required, uncomment to negate rotation matrices\n",
    "negate_eye_rotation(block, 'left')\n",
    "negate_eye_rotation(block, 'right')"
   ],
   "id": "dfe5e0a6b23a24d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left rotation matrix negated; angle set to 24.22°\n",
      "Right rotation matrix negated; angle set to 342.14°\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T13:42:56.310687Z",
     "start_time": "2025-10-24T13:42:43.355816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# finally, export data by overwriting:\n",
    "export_corrected_eye_data(block)"
   ],
   "id": "e2a0a247ab7f7585",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported corrected eye data and rotation params to Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T13:42:56.358674Z",
     "start_time": "2025-10-24T13:42:56.327579Z"
    }
   },
   "cell_type": "code",
   "source": "export_current_kerr_refs(block)",
   "id": "429b8f1b80abf0ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kerr refs exported to: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\analysis\\self_kerr_refs.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('Z:/Nimrod/experiments/PV_126/2024_07_18/block_007/analysis/self_kerr_refs.csv')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T18:34:09.432766Z",
     "start_time": "2025-08-26T18:34:09.417086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(block.kerr_ref_r_x, block.kerr_ref_r_y)\n",
    "print(block.kerr_ref_l_x, block.kerr_ref_l_y)\n",
    "load_self_kerr_refs(block)\n",
    "print(block.kerr_ref_r_x, block.kerr_ref_r_y)\n",
    "print(block.kerr_ref_l_x, block.kerr_ref_l_y)"
   ],
   "id": "addd3eeb73915f80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 256\n",
      "328 245\n",
      "Kerr refs loaded from: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_004\\analysis\\self_kerr_refs.csv\n",
      "371 256\n",
      "328 245\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def interactive_eye_data_corrector_synced_with_matrix(block, eye, ref_point_xy=None):\n",
    "    \"\"\"\n",
    "    Interactive synchronized video + ellipse editor with Play/Pause, correction,\n",
    "    Save, Flip-Dot, Skip, AND:\n",
    "      • Matrix Rotate Frame: toggle warping the frame by the saved rotation matrix\n",
    "      • Matrix Rotate Data:  apply the saved rotation matrix to the overlay data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : BlockSync\n",
    "        Must have left_/right_eye_data, left_/right_rotation_matrix, etc.\n",
    "    eye : 'left' or 'right'\n",
    "    ref_point_xy : (x,y) or None\n",
    "        Optional blue dot coordinate to draw on every frame.\n",
    "    \"\"\"\n",
    "    import cv2, numpy as np, pandas as pd\n",
    "\n",
    "    # Select eye‐specific attributes\n",
    "    if eye.lower()=='left':\n",
    "        df_orig   = block.left_eye_data.copy()\n",
    "        rot_mat   = np.array(block.left_rotation_matrix, dtype=np.float32)\n",
    "        rot_angle = float(block.left_rotation_angle)\n",
    "        video     = block.le_videos[0]\n",
    "    else:\n",
    "        df_orig   = block.right_eye_data.copy()\n",
    "        rot_mat   = np.array(block.right_rotation_matrix, dtype=np.float32)\n",
    "        rot_angle = float(block.right_rotation_angle)\n",
    "        video     = block.re_videos[0]\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open {eye} video: {video}\")\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    skip = int(fps*60)\n",
    "\n",
    "    # DataFrame and frame index column\n",
    "    df_current = df_orig.copy()\n",
    "    frame_col  = 'eye_frame' if 'eye_frame' in df_current.columns else 'frame'\n",
    "\n",
    "    # Buttons\n",
    "    buttons = {\n",
    "        'Play':               ((10,   10), (190,  60)),\n",
    "        'Pause':              ((10,   70), (190, 120)),\n",
    "        'Un-rotate':          ((10,  130), (190, 180)),\n",
    "        'X-flip':             ((10,  190), (190, 240)),\n",
    "        'Re-rotate':          ((10,  250), (190, 300)),\n",
    "        'Phi+90':             ((10,  310), (190, 360)),\n",
    "        'FlipX-only':         ((10,  370), (190, 420)),\n",
    "        'Flip Dot':           ((10,  430), (190, 480)),\n",
    "        'Bwd':                ((10,  490), (190, 540)),\n",
    "        'Fwd':                ((10,  550), (190, 600)),\n",
    "        'Matrix Rotate Frame':((10,  610), (190, 660)),\n",
    "        'Matrix Rotate Data': ((10,  670), (190, 720)),\n",
    "        'Save':               ((10,  730), (190, 780)),\n",
    "        'Quit':               ((10,  790), (190, 840)),\n",
    "    }\n",
    "    ctrl_h = 850; ctrl_w = 200\n",
    "\n",
    "    def draw_controls():\n",
    "        img = np.zeros((ctrl_h, ctrl_w, 3), dtype=np.uint8)\n",
    "        for name, ((x1,y1),(x2,y2)) in buttons.items():\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), (50,50,50), -1)\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), (200,200,200), 2)\n",
    "            cv2.putText(img, name, (x1+5, y1+35),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200,200,200), 2, cv2.LINE_AA)\n",
    "        return img\n",
    "\n",
    "    controls_img = draw_controls()\n",
    "    cv2.namedWindow('Controls', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # State flags\n",
    "    running        = True\n",
    "    playing        = False\n",
    "    current_ref    = ref_point_xy\n",
    "    last_frame     = None\n",
    "    warp_frame     = False\n",
    "\n",
    "    # Mouse callback\n",
    "    def on_mouse(event, x, y, flags, param):\n",
    "        nonlocal df_current, running, playing, current_ref, last_frame, warp_frame\n",
    "        if event!=cv2.EVENT_LBUTTONDOWN:\n",
    "            return\n",
    "        for name, ((x1,y1),(x2,y2)) in buttons.items():\n",
    "            if x1<=x<=x2 and y1<=y<=y2:\n",
    "                if   name=='Play':               playing = True\n",
    "                elif name=='Pause':              playing = False\n",
    "                elif name=='Un-rotate':          df_current = apply_inverse_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name=='X-flip':             df_current = horizontal_flip_eye_data( df_current, W)\n",
    "                elif name=='Re-rotate':          df_current = apply_rotation( df_current, rot_mat, rot_angle)\n",
    "                elif name=='Phi+90':             df_current = rotate_phi_only(df_current)\n",
    "                elif name=='FlipX-only':         df_current = flip_x_only(df_current, W)\n",
    "                elif name=='Flip Dot' and current_ref is not None:\n",
    "                    x0,y0 = current_ref\n",
    "                    current_ref = (W-x0, y0)\n",
    "                elif name=='Bwd':\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES))-1\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, max(idx-skip,0))\n",
    "                    last_frame=None\n",
    "                elif name=='Fwd':\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES))-1\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, min(idx+skip, total_frames-1))\n",
    "                    last_frame=None\n",
    "                elif name=='Matrix Rotate Frame':\n",
    "                    warp_frame = not warp_frame\n",
    "                elif name=='Matrix Rotate Data':\n",
    "                    df_current = apply_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name=='Save':\n",
    "                    if eye.lower()=='left':\n",
    "                        block.left_eye_data = df_current.copy()\n",
    "                    else:\n",
    "                        block.right_eye_data = df_current.copy()\n",
    "                    print(f\"{eye} eye data saved.\")\n",
    "                elif name=='Quit':\n",
    "                    running = False\n",
    "                break\n",
    "\n",
    "    cv2.setMouseCallback('Controls', on_mouse)\n",
    "\n",
    "    # Main loop\n",
    "    while running:\n",
    "        if playing or last_frame is None:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            last_frame = frame.copy()\n",
    "        else:\n",
    "            frame = last_frame.copy()\n",
    "\n",
    "        # Optionally warp the frame\n",
    "        display_frame = frame\n",
    "        if warp_frame:\n",
    "            display_frame = cv2.warpAffine(display_frame, rot_mat,\n",
    "                                           (W, display_frame.shape[0]),\n",
    "                                           flags=cv2.INTER_LINEAR,\n",
    "                                           borderMode=cv2.BORDER_CONSTANT,\n",
    "                                           borderValue=(0,0,0))\n",
    "\n",
    "        # Sync current frame index\n",
    "        idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES))-1\n",
    "        idx = max(idx,0)\n",
    "\n",
    "        # Annotate\n",
    "        annotated = display_frame.copy()\n",
    "        # reference dot\n",
    "        if current_ref is not None:\n",
    "            cv2.circle(annotated, current_ref, 5, (255,0,0), -1)\n",
    "        # ellipse\n",
    "        mask = df_current[frame_col]==idx\n",
    "        if mask.any():\n",
    "            row = df_current[mask].iloc[0]\n",
    "            cx,cy = row['center_x'], row['center_y']\n",
    "            if not (pd.isna(cx) or pd.isna(cy)):\n",
    "                x,y = int(round(cx)), int(round(cy))\n",
    "                w,h = int(row['width']), int(row['height'])\n",
    "                phi = float(row['phi'])\n",
    "                cv2.ellipse(annotated, (x,y), (w,h), phi, 0,360, (0,255,0),2)\n",
    "\n",
    "        # final vertical flip for display\n",
    "        disp = cv2.flip(annotated, 0)\n",
    "        cv2.imshow('Frame', disp)\n",
    "        cv2.imshow('Controls', controls_img)\n",
    "\n",
    "        if cv2.waitKey(30)&0xFF==27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "3c7e094cb28d69b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "interactive_eye_data_corrector_synced_with_matrix(block,'right')",
   "id": "df901898c3ab6c64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# These could be useful someday - here for reference:",
   "id": "2051966aaaf01768"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# notice this function is here if reference errors need to be corrects:\n",
    "def pick_reference_opencv(self, eye):\n",
    "    \"\"\"\n",
    "    Display an image with candidate points overlaid as a continuous gradient\n",
    "    (using COLORMAP_TURBO) according to their ellipse ratio (major_ax/minor_ax)\n",
    "    from the rotated eye data. A background frame is shown (using a slider to\n",
    "    change the frame), candidate points are overlaid, and an extrapolated\n",
    "    reference is drawn. The user may click on the main image (excluding the\n",
    "    colorbar) to select a final reference point.\n",
    "\n",
    "    :param eye: 'left' or 'right'\n",
    "    :return: Tuple (ref_x, ref_y) representing the selected reference coordinates,\n",
    "             or None if canceled.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scipy.optimize import minimize\n",
    "    from scipy.interpolate import Rbf\n",
    "\n",
    "    # --- 1. Select and clean the data ---\n",
    "    if eye == 'left':\n",
    "        df = self.left_eye_data.copy()\n",
    "    elif eye == 'right':\n",
    "        df = self.right_eye_data.copy()\n",
    "    else:\n",
    "        print(\"Eye not recognized. Choose 'left' or 'right'.\")\n",
    "        return None\n",
    "\n",
    "    # Drop rows with missing center coordinates.\n",
    "    df = df.dropna(subset=['center_x', 'center_y'])\n",
    "\n",
    "    # Ensure the 'ratio' column exists (ratio = major_ax / minor_ax).\n",
    "    if 'ratio' not in df.columns:\n",
    "        df['ratio'] = df['major_ax'] / df['minor_ax']\n",
    "\n",
    "    # Determine ratio range.\n",
    "    min_ratio = df['ratio'].min()\n",
    "    max_ratio = df['ratio'].max()\n",
    "\n",
    "    # --- 2. Extrapolate the ideal reference point via RBF regression on a stratified subset ---\n",
    "    x_data = df['center_x'].values\n",
    "    y_data = df['center_y'].values\n",
    "    ratio_data = df['ratio'].values\n",
    "\n",
    "    # Stratified sampling: split the ratio range into bins and sample up to n_per_bin points.\n",
    "    n_bins = 10\n",
    "    n_per_bin = 50\n",
    "    subset_indices = []\n",
    "    bin_edges = np.linspace(min_ratio, max_ratio, n_bins + 1)\n",
    "    for i in range(n_bins):\n",
    "        indices = np.where((ratio_data >= bin_edges[i]) & (ratio_data < bin_edges[i + 1]))[0]\n",
    "        if len(indices) > 0:\n",
    "            n_select = min(n_per_bin, len(indices))\n",
    "            selected = np.random.choice(indices, n_select, replace=False)\n",
    "            subset_indices.extend(selected)\n",
    "    subset_indices = np.array(subset_indices)\n",
    "\n",
    "    if len(subset_indices) == 0:\n",
    "        print(\"No data available for regression.\")\n",
    "        return None\n",
    "\n",
    "    # Build the subset.\n",
    "    x_subset = x_data[subset_indices]\n",
    "    y_subset = y_data[subset_indices]\n",
    "    ratio_subset = ratio_data[subset_indices]\n",
    "\n",
    "    # Create the RBF interpolator.\n",
    "    rbf = Rbf(x_subset, y_subset, ratio_subset, function='multiquadric', smooth=1)\n",
    "\n",
    "    # Define an objective function: squared difference from 1.\n",
    "    def objective(p):\n",
    "        return (rbf(p[0], p[1]) - 1) ** 2\n",
    "\n",
    "    # Use the candidate with ratio closest to 1 as an initial guess.\n",
    "    idx_closest = np.argmin(np.abs(ratio_data - 1))\n",
    "    init_guess = np.array([x_data[idx_closest], y_data[idx_closest]])\n",
    "\n",
    "    res = minimize(objective, init_guess, method='Nelder-Mead')\n",
    "    extrapolated_ref = (int(round(res.x[0])), int(round(res.x[1])))\n",
    "\n",
    "    # --- 3. Determine frame range and initial frame ---\n",
    "    # We derive the frame range from the 'eye_frame' column.\n",
    "    min_frame = int(df['eye_frame'].min())\n",
    "    max_frame = int(df['eye_frame'].max())\n",
    "    best_frame_num = int(df.iloc[idx_closest]['eye_frame'])\n",
    "    current_frame_num = best_frame_num\n",
    "\n",
    "    # Create window and prepare a container for display images.\n",
    "    window_name = \"Select Reference\"\n",
    "    cv2.namedWindow(window_name)\n",
    "    display_images = {\"combined\": None, \"blended\": None}\n",
    "\n",
    "    # --- 4. Function to update the display given a frame number ---\n",
    "    def update_display(frame_num):\n",
    "        # Retrieve and process the new frame.\n",
    "        frame = self.get_rotated_frame(frame_num, eye)\n",
    "        print('hi')\n",
    "        if frame is None:\n",
    "            print(\"Error retrieving frame number {}\".format(frame_num))\n",
    "            return\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        background = cv2.cvtColor(frame_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Overlay candidate points.\n",
    "        overlay = background.copy()\n",
    "        for _, row in df.iterrows():\n",
    "            x = int(round(row['center_x']))\n",
    "            y = int(round(row['center_y']))\n",
    "            ratio = row['ratio']\n",
    "            norm = (ratio - min_ratio) / (max_ratio - min_ratio) if max_ratio > min_ratio else 0.5\n",
    "            value = int(norm * 255)\n",
    "            dummy = np.uint8([[value]])\n",
    "            color = cv2.applyColorMap(dummy, cv2.COLORMAP_TURBO)[0, 0].tolist()\n",
    "            cv2.circle(overlay, (x, y), radius=4, color=color, thickness=-1)\n",
    "\n",
    "        alpha = 0.5  # transparency for candidate points\n",
    "        blended = cv2.addWeighted(overlay, alpha, background, 1 - alpha, 0)\n",
    "\n",
    "        # Mark the extrapolated best reference point.\n",
    "        cv2.drawMarker(blended, extrapolated_ref, color=(0, 0, 255),\n",
    "                       markerType=cv2.MARKER_TILTED_CROSS, markerSize=30, thickness=3)\n",
    "        cv2.putText(blended, \"Extrapolated Best Ref\", (extrapolated_ref[0] + 10, extrapolated_ref[1] + 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        # Create a vertical colorbar.\n",
    "        bar_width = 50\n",
    "        bar_height = blended.shape[0]\n",
    "        gradient = np.linspace(0, 255, bar_height, dtype=np.uint8).reshape(bar_height, 1)\n",
    "        gradient = np.repeat(gradient, bar_width, axis=1)\n",
    "        colorbar = cv2.applyColorMap(gradient, cv2.COLORMAP_TURBO)\n",
    "        cv2.putText(colorbar, f\"{min_ratio:.2f}\", (5, 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(colorbar, f\"{max_ratio:.2f}\", (5, bar_height - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Combine the blended image and the colorbar.\n",
    "        combined = np.hstack([blended, colorbar])\n",
    "        cv2.putText(combined, \"Click on main image to select ref (ESC to cancel)\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        # Save the updated images in our container.\n",
    "        display_images[\"combined\"] = combined\n",
    "        display_images[\"blended\"] = blended\n",
    "        cv2.imshow(window_name, combined)\n",
    "\n",
    "    # Initial display update.\n",
    "    update_display(current_frame_num)\n",
    "\n",
    "    # --- 5. Create the slider (trackbar) ---\n",
    "    def on_trackbar(val):\n",
    "        # Convert trackbar value back to the actual frame number.\n",
    "        new_frame_num = val + min_frame\n",
    "        update_display(new_frame_num)\n",
    "\n",
    "    # The trackbar range is set from 0 to (max_frame - min_frame)\n",
    "    cv2.createTrackbar(\"Frame\", window_name, best_frame_num - min_frame, max_frame - min_frame, on_trackbar)\n",
    "\n",
    "    # --- 6. Interactive selection via mouse callback ---\n",
    "    ref_point = []\n",
    "\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        nonlocal ref_point\n",
    "        # Only register clicks in the main image area (exclude the colorbar).\n",
    "        if event == cv2.EVENT_LBUTTONDOWN and display_images[\"blended\"] is not None and x < \\\n",
    "                display_images[\"blended\"].shape[1]:\n",
    "            ref_point = [x, y]\n",
    "            cv2.drawMarker(display_images[\"combined\"], (x, y), color=(0, 255, 255),\n",
    "                           markerType=cv2.MARKER_STAR, markerSize=30, thickness=3)\n",
    "            cv2.imshow(window_name, display_images[\"combined\"])\n",
    "\n",
    "    cv2.setMouseCallback(window_name, mouse_callback)\n",
    "\n",
    "    # --- 7. Wait for selection or cancel ---\n",
    "    while True:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if ref_point:\n",
    "            break\n",
    "        if key == 27:  # ESC key to cancel.\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if ref_point:\n",
    "        print(block, eye)\n",
    "        print(\"Selected reference point: X = {}, Y = {}\".format(ref_point[0], ref_point[1]))\n",
    "        return ref_point[0], ref_point[1]\n",
    "    else:\n",
    "        print(\"No reference point selected.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "6f2c09db637874c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "e0788f26cbb5925f",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pick_reference_opencv(block,'right')",
   "id": "3b0b57ffeab709b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pick_reference_opencv(block,'left')",
   "id": "3fcbc4cbf082d614"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def plot_extreme_frames(video_path, eye_data, figsize=(10,8), cmap_frame=None):\n",
    "    \"\"\"\n",
    "    Plot the 4 most extreme pupil detections on a 2×2 grid:\n",
    "      - min center_x (leftmost)\n",
    "      - max center_x (rightmost)\n",
    "      - min center_y (topmost)\n",
    "      - max center_y (bottommost)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video_path : str\n",
    "        Path to your video file.\n",
    "    eye_data : pandas.DataFrame\n",
    "        Must have columns ['eye_frame', 'center_x', 'center_y',\n",
    "        'phi', 'major_ax', 'minor_ax'].\n",
    "    figsize : tuple\n",
    "        Matplotlib figure size.\n",
    "    cmap_frame : str or None\n",
    "        Matplotlib cmap for the frames (e.g. 'gray') or None for RGB.\n",
    "    \"\"\"\n",
    "    # 1. Clean out any rows with NaNs in the required columns\n",
    "    req = ['eye_frame','center_x','center_y','phi','major_ax','minor_ax']\n",
    "    df = eye_data.dropna(subset=req)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No valid rows after dropping NaNs.\")\n",
    "\n",
    "    # 2. Pick the four extremes\n",
    "    picks = {\n",
    "        'leftmost':  df.loc[df['center_x'].idxmin()],\n",
    "        'rightmost': df.loc[df['center_x'].idxmax()],\n",
    "        'topmost':   df.loc[df['center_y'].idxmin()],\n",
    "        'bottommost':df.loc[df['center_y'].idxmax()],\n",
    "    }\n",
    "\n",
    "    # 3. Grab frames\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video {video_path!r}\")\n",
    "\n",
    "    # store (image, row) for each\n",
    "    samples = {}\n",
    "    for name, row in picks.items():\n",
    "        frm = int(row.eye_frame)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frm)\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            raise IOError(f\"Failed to read frame {frm} from {video_path!r}\")\n",
    "        # convert BGR→RGB for plotting\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        samples[name] = (img, row)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # 4. Plot them\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, (name, (img, row)) in zip(axes, samples.items()):\n",
    "        # show frame\n",
    "        if cmap_frame:\n",
    "            ax.imshow(img[...,0], cmap=cmap_frame)  # single‐channel\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "\n",
    "        # overlay ellipse\n",
    "        # matplotlib Ellipse wants width/height = full diameters.\n",
    "        w, h = 2*row.major_ax, 2*row.minor_ax\n",
    "        e = Ellipse(\n",
    "            (row.center_x, row.center_y),\n",
    "            width=w, height=h,\n",
    "            angle=row.phi,\n",
    "            edgecolor='lime', facecolor='none', lw=2\n",
    "        )\n",
    "        ax.add_patch(e)\n",
    "\n",
    "        # annotate text\n",
    "        txt = (\n",
    "            f\"{name}\\n\"\n",
    "            f\"frame={int(row.eye_frame)}\\n\"\n",
    "            f\"x={row.center_x:.1f}, y={row.center_y:.1f}\\n\"\n",
    "            f\"φ={row.phi:.1f}°\"\n",
    "        )\n",
    "        ax.text(\n",
    "            0.02, 0.95, txt,\n",
    "            transform=ax.transAxes,\n",
    "            va='top', ha='left',\n",
    "            color='white', fontsize=9,\n",
    "            bbox=dict(facecolor='black', alpha=0.5, pad=3)\n",
    "        )\n",
    "\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_title(name, fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "block = block_dict['PV_126_block_011']\n",
    "plot_extreme_frames(block.le_videos[0],block.left_eye_data)"
   ],
   "id": "d7e1f062a55f686b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def interactive_eye_data_corrector_synced_with_vector(block, eye, ref_point_xy=None):\n",
    "    \"\"\"\n",
    "    Interactive synchronized video + ellipse editor displaying an OpenCV window\n",
    "    for the frame+data and a second OpenCV window showing the 3D vector (k_phi, k_theta).\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    # 1) select eye‐specific data\n",
    "    if eye.lower() == 'left':\n",
    "        df_orig = block.left_eye_data.copy()\n",
    "        video   = block.le_videos[0]\n",
    "    else:\n",
    "        df_orig = block.right_eye_data.copy()\n",
    "        video   = block.re_videos[0]\n",
    "\n",
    "    # open video\n",
    "    cap = cv2.VideoCapture(str(video))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open {eye} video: {video}\")\n",
    "\n",
    "    W   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    skip = int(fps * 60)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # DataFrame & frame index column\n",
    "    df_current = df_orig.copy()\n",
    "    frame_col  = 'eye_frame' if 'eye_frame' in df_current.columns else 'frame'\n",
    "\n",
    "    # --- Matplotlib figure setup (offscreen) ---\n",
    "    plt.ioff()\n",
    "    fig = plt.figure(figsize=(3, 3), dpi=100)\n",
    "    ax3 = fig.add_subplot(111, projection='3d')\n",
    "    ax3.set_xlim(-1, 1); ax3.set_ylim(-1, 1); ax3.set_zlim(-1, 1)\n",
    "    ax3.set_xlabel('X'); ax3.set_ylabel('Y'); ax3.set_zlabel('Z')\n",
    "\n",
    "    # --- OpenCV controls setup ---\n",
    "    buttons = {\n",
    "        'Play':        ((10,  10),(180,  60)),\n",
    "        'Pause':       ((10,  70),(180, 120)),\n",
    "        'Un-rotate':   ((10, 130),(180, 180)),\n",
    "        'X-flip':      ((10, 190),(180, 240)),\n",
    "        'Re-rotate':   ((10, 250),(180, 300)),\n",
    "        'Phi+90':      ((10, 310),(180, 360)),\n",
    "        'FlipX-only':  ((10, 370),(180, 420)),\n",
    "        'Flip Dot':    ((10, 430),(180, 480)),\n",
    "        'Bwd':         ((10, 490),(180, 540)),\n",
    "        'Fwd':         ((10, 550),(180, 600)),\n",
    "        'Save':        ((10, 610),(180, 660)),\n",
    "        'Quit':        ((10, 670),(180, 720)),\n",
    "    }\n",
    "    ctrl_h, ctrl_w = 760, 200\n",
    "\n",
    "    def draw_controls():\n",
    "        img = np.zeros((ctrl_h, ctrl_w, 3), dtype=np.uint8)\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (50, 50, 50), -1)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (200, 200, 200), 2)\n",
    "            cv2.putText(img, name, (x1 + 5, y1 + 35),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2, cv2.LINE_AA)\n",
    "        return img\n",
    "\n",
    "    controls_img = draw_controls()\n",
    "    cv2.namedWindow('Controls', cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('Frame',    cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('Vector',   cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # State\n",
    "    running     = True\n",
    "    playing     = False\n",
    "    current_ref = ref_point_xy\n",
    "    last_frame  = None\n",
    "\n",
    "    def on_mouse(event, x, y, flags, param):\n",
    "        nonlocal df_current, running, playing, current_ref, last_frame\n",
    "        if event != cv2.EVENT_LBUTTONDOWN:\n",
    "            return\n",
    "        for name, ((x1, y1), (x2, y2)) in buttons.items():\n",
    "            if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                if   name == 'Play':       playing = True\n",
    "                elif name == 'Pause':      playing = False\n",
    "                elif name == 'Un-rotate':  df_current = apply_inverse_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name == 'X-flip':     df_current = horizontal_flip_eye_data(df_current, W)\n",
    "                elif name == 'Re-rotate':  df_current = apply_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name == 'Phi+90':     df_current = rotate_phi_only(df_current)\n",
    "                elif name == 'FlipX-only': df_current = flip_x_only(df_current, W)\n",
    "                elif name == 'Flip Dot' and current_ref is not None:\n",
    "                    x0, y0 = current_ref\n",
    "                    current_ref = (W - x0, y0)\n",
    "                elif name == 'Bwd':\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, max(idx - skip, 0)); last_frame = None\n",
    "                elif name == 'Fwd':\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, min(idx + skip, total_frames - 1)); last_frame = None\n",
    "                elif name == 'Save':\n",
    "                    if eye.lower() == 'left':\n",
    "                        block.left_eye_data  = df_current.copy()\n",
    "                    else:\n",
    "                        block.right_eye_data = df_current.copy()\n",
    "                elif name == 'Quit':\n",
    "                    running = False\n",
    "                break\n",
    "\n",
    "    cv2.setMouseCallback('Controls', on_mouse)\n",
    "\n",
    "    # Main loop\n",
    "    while running:\n",
    "        # get frame\n",
    "        if playing or last_frame is None:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            last_frame = frame.copy()\n",
    "        else:\n",
    "            frame = last_frame.copy()\n",
    "\n",
    "        # current frame index\n",
    "        idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "        idx = max(idx, 0)\n",
    "\n",
    "        # 1) Annotate frame + data\n",
    "        annotated = frame.copy()\n",
    "        if current_ref is not None:\n",
    "            cv2.circle(annotated, current_ref, 5, (255, 0, 0), -1)\n",
    "        mask = df_current[frame_col] == idx\n",
    "        if mask.any():\n",
    "            row = df_current[mask].iloc[0]\n",
    "            cx, cy = row['center_x'], row['center_y']\n",
    "            if not (pd.isna(cx) or pd.isna(cy)):\n",
    "                cv2.ellipse(annotated,\n",
    "                            (int(round(cx)), int(round(cy))),\n",
    "                            (int(row['width']), int(row['height'])),\n",
    "                            float(row['phi']), 0, 360, (0, 255, 0), 2)\n",
    "        disp = cv2.flip(annotated, 0)\n",
    "        cv2.imshow('Frame', disp)\n",
    "        cv2.imshow('Controls', controls_img)\n",
    "\n",
    "        # 2) Build vector window image via Matplotlib canvas\n",
    "        if mask.any() and 'k_phi' in df_current.columns and 'k_theta' in df_current.columns:\n",
    "            row = df_current[mask].iloc[0]\n",
    "            kp = np.deg2rad(row['k_phi'])\n",
    "            kt = np.deg2rad(row['k_theta'])\n",
    "            x = np.cos(kt) * np.cos(kp)\n",
    "            y = np.cos(kt) * np.sin(kp)\n",
    "            z = np.sin(kt)\n",
    "\n",
    "            # redraw 3D arrow\n",
    "            ax3.cla()\n",
    "            ax3.set_xlim(-1,1); ax3.set_ylim(-1,1); ax3.set_zlim(-1,1)\n",
    "            ax3.set_xlabel('X'); ax3.set_ylabel('Y'); ax3.set_zlabel('Z')\n",
    "            ax3.quiver(0,0,0, x,y,z, length=1, normalize=True, color='blue')\n",
    "\n",
    "            fig.canvas.draw()\n",
    "            # grab canvas as RGB array\n",
    "            w, h = fig.canvas.get_width_height()\n",
    "            buf = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            buf = buf.reshape((h, w, 3))\n",
    "            vec_img = cv2.cvtColor(buf, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imshow('Vector', vec_img)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.close(fig)\n",
    "\n"
   ],
   "id": "180962a35599a2ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# with corrected column\n",
    "def interactive_eye_data_corrector_synced_with_vector(block, eye, ref_point_xy=None):\n",
    "    \"\"\"\n",
    "    Interactive synchronized video + ellipse editor with two OpenCV windows:\n",
    "      • 'Frame'    : video with ellipse/data overlay\n",
    "      • 'Controls' : play/pause, corrections, save, etc.\n",
    "      • 'Vector'   : 3D vector of (k_phi, k_theta) plus a red reference at (0,0)\n",
    "      • 'VectorCorr': 3D vector of (k_phi_corr, k_theta_corr) plus red reference\n",
    "\n",
    "    Requires in scope:\n",
    "      apply_inverse_rotation, horizontal_flip_eye_data,\n",
    "      apply_rotation, rotate_phi_only, flip_x_only\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    # --- 1) Select data & video path ---\n",
    "    if eye.lower() == 'left':\n",
    "        df_orig = block.left_eye_data.copy()\n",
    "        video   = block.le_videos[0]\n",
    "    else:\n",
    "        df_orig = block.right_eye_data.copy()\n",
    "        video   = block.re_videos[0]\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open {eye} video: {video}\")\n",
    "\n",
    "    W   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    skip = int(fps * 60)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    df_current = df_orig.copy()\n",
    "    frame_col  = 'eye_frame' if 'eye_frame' in df_current.columns else 'frame'\n",
    "\n",
    "    # --- 2) Off‐screen Matplotlib setup for two 3D plots ---\n",
    "    plt.ioff()\n",
    "    # Original angles\n",
    "    fig1 = plt.figure(figsize=(3, 3), dpi=100)\n",
    "    ax1  = fig1.add_subplot(111, projection='3d')\n",
    "    ax1.set_xlim(-1,1); ax1.set_ylim(-1,1); ax1.set_zlim(-1,1)\n",
    "    ax1.set_title('k\\_phi / k\\_theta')\n",
    "    # Corrected angles\n",
    "    fig2 = plt.figure(figsize=(3, 3), dpi=100)\n",
    "    ax2  = fig2.add_subplot(111, projection='3d')\n",
    "    ax2.set_xlim(-1,1); ax2.set_ylim(-1,1); ax2.set_zlim(-1,1)\n",
    "    ax2.set_title('k\\_phi\\_corr / k\\_theta\\_corr')\n",
    "\n",
    "    # --- 3) OpenCV UI windows ---\n",
    "    cv2.namedWindow('Frame',    cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('Controls', cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('Vector',   cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('VectorCorr', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Build controls layout (buttons as before)...\n",
    "    # [ same buttons dict and draw_controls() as previous version ]\n",
    "    buttons = {\n",
    "        'Play':        ((10, 10),(180, 60)),\n",
    "        'Pause':       ((10, 70),(180,120)),\n",
    "        'Un-rotate':   ((10,130),(180,180)),\n",
    "        'X-flip':      ((10,190),(180,240)),\n",
    "        'Re-rotate':   ((10,250),(180,300)),\n",
    "        'Phi+90':      ((10,310),(180,360)),\n",
    "        'FlipX-only':  ((10,370),(180,420)),\n",
    "        'Flip Dot':    ((10,430),(180,480)),\n",
    "        'Bwd':         ((10,490),(180,540)),\n",
    "        'Fwd':         ((10,550),(180,600)),\n",
    "        'Save':        ((10,610),(180,660)),\n",
    "        'Quit':        ((10,670),(180,720)),\n",
    "    }\n",
    "    ctrl_h, ctrl_w = 740, 200\n",
    "    def draw_controls():\n",
    "        img = np.zeros((ctrl_h, ctrl_w, 3), dtype=np.uint8)\n",
    "        for name, ((x1,y1),(x2,y2)) in buttons.items():\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), (50,50,50), -1)\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), (200,200,200), 2)\n",
    "            cv2.putText(img, name, (x1+5, y1+35),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200,200,200), 2, cv2.LINE_AA)\n",
    "        return img\n",
    "    controls_img = draw_controls()\n",
    "\n",
    "    # --- 4) Interaction state & callbacks ---\n",
    "    running     = True\n",
    "    playing     = False\n",
    "    current_ref = ref_point_xy\n",
    "    last_frame  = None\n",
    "\n",
    "    def on_mouse(event, x, y, flags, param):\n",
    "        nonlocal df_current, running, playing, current_ref, last_frame\n",
    "        if event != cv2.EVENT_LBUTTONDOWN: return\n",
    "        for name, ((x1,y1),(x2,y2)) in buttons.items():\n",
    "            if x1<=x<=x2 and y1<=y<=y2:\n",
    "                if   name=='Play':        playing = True\n",
    "                elif name=='Pause':       playing = False\n",
    "                elif name=='Un-rotate':   df_current = apply_inverse_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name=='X-flip':      df_current = horizontal_flip_eye_data(df_current, W)\n",
    "                elif name=='Re-rotate':   df_current = apply_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name=='Phi+90':      df_current = rotate_phi_only(df_current)\n",
    "                elif name=='FlipX-only':  df_current = flip_x_only(df_current, W)\n",
    "                elif name=='Flip Dot' and current_ref is not None:\n",
    "                    x0,y0 = current_ref\n",
    "                    current_ref = (W - x0, y0)\n",
    "                elif name=='Bwd':\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, max(idx-skip,0)); last_frame=None\n",
    "                elif name=='Fwd':\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, min(idx+skip,total_frames-1)); last_frame=None\n",
    "                elif name=='Save':\n",
    "                    if eye.lower()=='left':\n",
    "                        block.left_eye_data = df_current.copy()\n",
    "                    else:\n",
    "                        block.right_eye_data = df_current.copy()\n",
    "                elif name=='Quit':\n",
    "                    running = False\n",
    "                break\n",
    "\n",
    "    cv2.setMouseCallback('Controls', on_mouse)\n",
    "\n",
    "    # --- 5) Main loop ---\n",
    "    while running:\n",
    "        # frame fetch\n",
    "        if playing or last_frame is None:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            last_frame = frame.copy()\n",
    "        else:\n",
    "            frame = last_frame.copy()\n",
    "\n",
    "        idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "        idx = max(idx, 0)\n",
    "\n",
    "        # annotate frame + ellipse\n",
    "        annotated = frame.copy()\n",
    "        if current_ref is not None:\n",
    "            cv2.circle(annotated, current_ref, 5, (255,0,0), -1)\n",
    "        mask = df_current[frame_col] == idx\n",
    "        if mask.any():\n",
    "            row = df_current[mask].iloc[0]\n",
    "            cx, cy = row['center_x'], row['center_y']\n",
    "            if not (pd.isna(cx) or pd.isna(cy)):\n",
    "                cv2.ellipse(\n",
    "                    annotated,\n",
    "                    (int(round(cx)), int(round(cy))),\n",
    "                    (int(row['width']), int(row['height'])),\n",
    "                    float(row['phi']), 0,360, (0,255,0), 2\n",
    "                )\n",
    "\n",
    "        disp = cv2.flip(annotated, 0)\n",
    "        cv2.imshow('Frame', disp)\n",
    "        cv2.imshow('Controls', controls_img)\n",
    "\n",
    "        # --- original k_phi / k_theta vector ---\n",
    "        if mask.any() and 'k_phi' in df_current.columns and 'k_theta' in df_current.columns:\n",
    "            row = df_current[mask].iloc[0]\n",
    "            kp = np.deg2rad(row['k_phi'])\n",
    "            kt = np.deg2rad(row['k_theta'])\n",
    "            x = np.cos(kt)*np.cos(kp)\n",
    "            y = np.cos(kt)*np.sin(kp)\n",
    "            z = np.sin(kt)\n",
    "\n",
    "            ax1.cla()\n",
    "            ax1.set_xlim(-1,1); ax1.set_ylim(-1,1); ax1.set_zlim(-1,1)\n",
    "            # red reference vector at (0,0)\n",
    "            ax1.quiver(0,0,0, 1,0,0, length=0.5, normalize=True, color='red')\n",
    "            # dynamic vector\n",
    "            ax1.quiver(0,0,0, x,y,z, length=1, normalize=True, color='blue')\n",
    "            fig1.canvas.draw()\n",
    "            buf = np.frombuffer(fig1.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            h, w = fig1.canvas.get_width_height()\n",
    "            buf = buf.reshape((h, w, 3))\n",
    "            cv2.imshow('Vector', cv2.cvtColor(buf, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # --- corrected k_phi_corr / k_theta_corr vector ---\n",
    "        if mask.any() and 'corr_phi' in df_current.columns and 'corr_theta' in df_current.columns:\n",
    "            row = df_current[mask].iloc[0]\n",
    "            kp2 = np.deg2rad(row['corr_phi'])\n",
    "            kt2 = np.deg2rad(row['corr_theta'])\n",
    "            x2 = np.cos(kt2)*np.cos(kp2)\n",
    "            y2 = np.cos(kt2)*np.sin(kp2)\n",
    "            z2 = np.sin(kt2)\n",
    "\n",
    "            ax2.cla()\n",
    "            ax2.set_xlim(-1,1); ax2.set_ylim(-1,1); ax2.set_zlim(-1,1)\n",
    "            ax2.quiver(0,0,0, 1,0,0, length=0.5, normalize=True, color='red')\n",
    "            ax2.quiver(0,0,0, x2,y2,z2, length=1, normalize=True, color='green')\n",
    "            fig2.canvas.draw()\n",
    "            buf2 = np.frombuffer(fig2.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            h2, w2 = fig2.canvas.get_width_height()\n",
    "            buf2 = buf2.reshape((h2, w2, 3))\n",
    "            cv2.imshow('VectorCorr', cv2.cvtColor(buf2, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.close(fig1)\n",
    "    plt.close(fig2)\n"
   ],
   "id": "5e1547201f898cda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "interactive_eye_data_corrector_synced_with_vector(block, eye='right', ref_point_xy=r_ref)",
   "id": "2e5e780e841807e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "interactive_eye_data_corrector_synced_with_vector(block, eye='left', ref_point_xy=l_ref)",
   "id": "e53b5e00f82c5a4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def interactive_eye_data_corrector_synced_with_vector(block, eye, ref_point_xy=None):\n",
    "    \"\"\"\n",
    "    Interactive synchronized video + ellipse editor with:\n",
    "      • 'Frame'    : video + ellipse + ref dot + phi/theta text overlay\n",
    "      • 'Controls' : playback & transform buttons\n",
    "      • 'Vector'   : 3D vector of (k_phi, k_theta) with red 0° ref\n",
    "      • 'VectorCorr': 3D vector of (corr_phi, corr_theta) with red 0° ref\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : BlockSync\n",
    "        Must have left_/right_eye_data including columns\n",
    "        ['center_x','center_y','width','height','phi','k_phi','k_theta',\n",
    "         'corr_phi','corr_theta'], and rotation attributes.\n",
    "    eye : 'left' or 'right'\n",
    "    ref_point_xy : tuple[int,int] or None\n",
    "        Optional reference point to draw as blue dot.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    # Pick data & video\n",
    "    if eye.lower() == 'left':\n",
    "        df_current = block.left_eye_data.copy()\n",
    "        rot_mat = np.array(block.left_rotation_matrix, dtype=np.float32)\n",
    "        rot_angle = float(block.left_rotation_angle)\n",
    "        video = block.le_videos[0]\n",
    "    else:\n",
    "        df_current = block.right_eye_data.copy()\n",
    "        rot_mat = np.array(block.right_rotation_matrix, dtype=np.float32)\n",
    "        rot_angle = float(block.right_rotation_angle)\n",
    "        video = block.re_videos[0]\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open {eye} video: {video}\")\n",
    "\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    skip = int(fps * 60)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    frame_col = 'eye_frame' if 'eye_frame' in df_current.columns else 'frame'\n",
    "\n",
    "    # Offscreen Matplotlib figures\n",
    "    plt.ioff()\n",
    "    fig1 = plt.figure(figsize=(3,3), dpi=100)\n",
    "    ax1 = fig1.add_subplot(111, projection='3d')\n",
    "    fig2 = plt.figure(figsize=(3,3), dpi=100)\n",
    "    ax2 = fig2.add_subplot(111, projection='3d')\n",
    "\n",
    "    # OpenCV windows\n",
    "    cv2.namedWindow('Frame', cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('Controls', cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('Vector', cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('VectorCorr', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Buttons\n",
    "    buttons = {\n",
    "        'Play':((10,10),(180,60)), 'Pause':((10,70),(180,120)),\n",
    "        'Un-rotate':((10,130),(180,180)), 'X-flip':((10,190),(180,240)),\n",
    "        'Re-rotate':((10,250),(180,300)), 'Phi+90':((10,310),(180,360)),\n",
    "        'FlipX-only':((10,370),(180,420)), 'Flip Dot':((10,430),(180,480)),\n",
    "        'Bwd':((10,490),(180,540)), 'Fwd':((10,550),(180,600)),\n",
    "        'Save':((10,610),(180,660)), 'Quit':((10,670),(180,720)),\n",
    "    }\n",
    "    ctrl_h, ctrl_w = 740, 200\n",
    "    def draw_controls():\n",
    "        img = np.zeros((ctrl_h,ctrl_w,3), np.uint8)\n",
    "        for name, ((x1,y1),(x2,y2)) in buttons.items():\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(50,50,50),-1)\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(200,200,200),2)\n",
    "            cv2.putText(img,name,(x1+5,y1+35),cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.6,(200,200,200),2,cv2.LINE_AA)\n",
    "        return img\n",
    "    controls_img = draw_controls()\n",
    "\n",
    "    running = True\n",
    "    playing = False\n",
    "    current_ref = ref_point_xy\n",
    "    last_frame = None\n",
    "\n",
    "    def on_mouse(evt,x,y,flags,param):\n",
    "        nonlocal df_current, running, playing, current_ref, last_frame\n",
    "        if evt!=cv2.EVENT_LBUTTONDOWN: return\n",
    "        for name, ((x1,y1),(x2,y2)) in buttons.items():\n",
    "            if x1<=x<=x2 and y1<=y<=y2:\n",
    "                if name=='Play': playing=True\n",
    "                elif name=='Pause': playing=False\n",
    "                elif name=='Un-rotate':\n",
    "                    df_current = apply_inverse_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name=='X-flip':\n",
    "                    df_current = horizontal_flip_eye_data(df_current, W)\n",
    "                elif name=='Re-rotate':\n",
    "                    df_current = apply_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name=='Phi+90':\n",
    "                    df_current = rotate_phi_only(df_current)\n",
    "                elif name=='FlipX-only':\n",
    "                    df_current = flip_x_only(df_current, W)\n",
    "                elif name=='Flip Dot' and current_ref is not None:\n",
    "                    x0,y0=current_ref; current_ref=(W-x0,y0)\n",
    "                elif name=='Bwd':\n",
    "                    idx=int(cap.get(cv2.CAP_PROP_POS_FRAMES))-1\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES,max(idx-skip,0)); last_frame=None\n",
    "                elif name=='Fwd':\n",
    "                    idx=int(cap.get(cv2.CAP_PROP_POS_FRAMES))-1\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES,min(idx+skip,total_frames-1)); last_frame=None\n",
    "                elif name=='Save':\n",
    "                    if eye.lower()=='left': block.left_eye_data=df_current.copy()\n",
    "                    else: block.right_eye_data=df_current.copy()\n",
    "                elif name=='Quit': running=False\n",
    "                break\n",
    "\n",
    "    cv2.setMouseCallback('Controls', on_mouse)\n",
    "\n",
    "    while running:\n",
    "        if playing or last_frame is None:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            last_frame = frame.copy()\n",
    "        else:\n",
    "            frame = last_frame.copy()\n",
    "\n",
    "        idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES))-1\n",
    "        idx = max(idx,0)\n",
    "\n",
    "        # Frame annotation\n",
    "        ann = frame.copy()\n",
    "        if current_ref is not None:\n",
    "            cv2.circle(ann, current_ref, 5, (255,0,0), -1)\n",
    "        mask = df_current[frame_col]==idx\n",
    "        if mask.any():\n",
    "            row = df_current[mask].iloc[0]\n",
    "            cx,cy = row['center_x'], row['center_y']\n",
    "            if not (pd.isna(cx) or pd.isna(cy)):\n",
    "                cv2.ellipse(ann,(int(round(cx)),int(round(cy))),\n",
    "                            (int(row['width']),int(row['height'])),\n",
    "                            float(row['phi']),0,360,(0,255,0),2)\n",
    "        disp = cv2.flip(ann,0)\n",
    "\n",
    "        # Overlay plain text\n",
    "        if mask.any() and 'k_phi' in df_current.columns and 'k_theta' in df_current.columns:\n",
    "            row = df_current[mask].iloc[0]\n",
    "            kp = row['k_phi']; kt = row['k_theta']\n",
    "            txt = f\"phi={kp:.1f}, theta={kt:.1f}\"\n",
    "            cv2.putText(disp, txt, (10, disp.shape[0]-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Frame', disp)\n",
    "        cv2.imshow('Controls', controls_img)\n",
    "\n",
    "        # Vector plot for (k_phi, k_theta)\n",
    "        if mask.any() and 'k_phi' in df_current.columns and 'k_theta' in df_current.columns:\n",
    "            row = df_current[mask].iloc[0]\n",
    "            kp = np.deg2rad(row['k_phi']); kt = np.deg2rad(row['k_theta'])\n",
    "            x,y,z = np.cos(kt)*np.cos(kp), np.cos(kt)*np.sin(kp), np.sin(kt)\n",
    "            ax1.cla()\n",
    "            ax1.set_xlim(-1,1); ax1.set_ylim(-1,1); ax1.set_zlim(-1,1)\n",
    "            ax1.quiver(0,0,0,1,0,0,length=0.5,normalize=True,color='red')\n",
    "            ax1.quiver(0,0,0,x,y,z,length=1,normalize=True,color='blue')\n",
    "            fig1.canvas.draw()\n",
    "            buf = np.frombuffer(fig1.canvas.tostring_rgb(),np.uint8)\n",
    "            h,w = fig1.canvas.get_width_height()\n",
    "            vec = buf.reshape((h,w,3))\n",
    "            cv2.imshow('Vector', cv2.cvtColor(vec, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # VectorCorr for (corr_phi, corr_theta)\n",
    "        if mask.any() and 'corr_phi' in df_current.columns and 'corr_theta' in df_current.columns:\n",
    "            row = df_current[mask].iloc[0]\n",
    "            kp2 = np.deg2rad(row['corr_phi']); kt2 = np.deg2rad(row['corr_theta'])\n",
    "            x2,y2,z2 = np.cos(kt2)*np.cos(kp2), np.cos(kt2)*np.sin(kp2), np.sin(kt2)\n",
    "            ax2.cla()\n",
    "            ax2.set_xlim(-1,1); ax2.set_ylim(-1,1); ax2.set_zlim(-1,1)\n",
    "            ax2.quiver(0,0,0,1,0,0,length=0.5,normalize=True,color='red')\n",
    "            ax2.quiver(0,0,0,x2,y2,z2,length=1,normalize=True,color='green')\n",
    "            fig2.canvas.draw()\n",
    "            buf2 = np.frombuffer(fig2.canvas.tostring_rgb(),np.uint8)\n",
    "            h2,w2 = fig2.canvas.get_width_height()\n",
    "            vec2 = buf2.reshape((h2,w2,3))\n",
    "            cv2.imshow('VectorCorr', cv2.cvtColor(vec2, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.close(fig1); plt.close(fig2)\n",
    "\n"
   ],
   "id": "a752215c6448ea22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def interactive_eye_data_corrector_synced_with_vector(block, eye, ref_point_xy=None):\n",
    "    \"\"\"\n",
    "    Interactive synchronized video + ellipse editor with:\n",
    "      • Frame window: raw video + ellipse + ref dot + k_phi/k_theta text overlay\n",
    "      • Controls window: buttons for playback & transforms\n",
    "      • Vector window: 3D vector of (k_phi, k_theta) with red 0° reference\n",
    "      • VectorCorr window: 3D vector of (k_phi_corr, k_theta_corr) with red 0° reference\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : BlockSync\n",
    "        Must have left_/right_eye_data with columns ['center_x','center_y','width','height','phi',\n",
    "        'k_phi','k_theta','k_phi_corr','k_theta_corr'], plus rotation attributes.\n",
    "    eye : 'left' or 'right'\n",
    "    ref_point_xy : tuple[int,int] or None\n",
    "        Optional reference point to draw as a blue dot.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    # 1) Select data & video\n",
    "    if eye.lower() == 'left':\n",
    "        df_orig   = block.left_eye_data.copy()\n",
    "        rot_mat   = np.array(block.left_rotation_matrix, dtype=np.float32)\n",
    "        rot_angle = float(block.left_rotation_angle)\n",
    "        video     = block.le_videos[0]\n",
    "    else:\n",
    "        df_orig   = block.right_eye_data.copy()\n",
    "        rot_mat   = np.array(block.right_rotation_matrix, dtype=np.float32)\n",
    "        rot_angle = float(block.right_rotation_angle)\n",
    "        video     = block.re_videos[0]\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open {eye} video: {video}\")\n",
    "\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    skip = int(fps * 60)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    df_current = df_orig.copy()\n",
    "    frame_col  = 'eye_frame' if 'eye_frame' in df_current.columns else 'frame'\n",
    "\n",
    "    # 2) Offscreen Matplotlib for two 3D plots\n",
    "    plt.ioff()\n",
    "    fig1 = plt.figure(figsize=(3, 3), dpi=100)\n",
    "    ax1  = fig1.add_subplot(111, projection='3d')\n",
    "    fig2 = plt.figure(figsize=(3, 3), dpi=100)\n",
    "    ax2  = fig2.add_subplot(111, projection='3d')\n",
    "\n",
    "    # 3) OpenCV windows\n",
    "    cv2.namedWindow('Frame',    cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('Controls', cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('Vector',   cv2.WINDOW_NORMAL)\n",
    "    cv2.namedWindow('VectorCorr', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Buttons layout\n",
    "    buttons = {\n",
    "        'Play':        ((10,  10), (180,  60)),\n",
    "        'Pause':       ((10,  70), (180, 120)),\n",
    "        'Un-rotate':   ((10, 130), (180, 180)),\n",
    "        'X-flip':      ((10, 190), (180, 240)),\n",
    "        'Re-rotate':   ((10, 250), (180, 300)),\n",
    "        'Phi+90':      ((10, 310), (180, 360)),\n",
    "        'FlipX-only':  ((10, 370), (180, 420)),\n",
    "        'Flip Dot':    ((10, 430), (180, 480)),\n",
    "        'Bwd':         ((10, 490), (180, 540)),\n",
    "        'Fwd':         ((10, 550), (180, 600)),\n",
    "        'Save':        ((10, 610), (180, 660)),\n",
    "        'Quit':        ((10, 670), (180, 720)),\n",
    "    }\n",
    "    ctrl_h, ctrl_w = 740, 200\n",
    "\n",
    "    def draw_controls():\n",
    "        img = np.zeros((ctrl_h, ctrl_w, 3), dtype=np.uint8)\n",
    "        for name, ((x1,y1),(x2,y2)) in buttons.items():\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), (50,50,50), -1)\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), (200,200,200), 2)\n",
    "            cv2.putText(img, name, (x1+5, y1+35),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200,200,200), 2, cv2.LINE_AA)\n",
    "        return img\n",
    "\n",
    "    controls_img = draw_controls()\n",
    "\n",
    "    # 4) Interaction state\n",
    "    running     = True\n",
    "    playing     = False\n",
    "    current_ref = ref_point_xy\n",
    "    last_frame  = None\n",
    "\n",
    "    # 5) Mouse callback\n",
    "    def on_mouse(event, x, y, flags, param):\n",
    "        nonlocal df_current, running, playing, current_ref, last_frame\n",
    "        if event != cv2.EVENT_LBUTTONDOWN:\n",
    "            return\n",
    "        for name, ((x1,y1),(x2,y2)) in buttons.items():\n",
    "            if x1<=x<=x2 and y1<=y<=y2:\n",
    "                if   name == 'Play':\n",
    "                    playing = True\n",
    "                elif name == 'Pause':\n",
    "                    playing = False\n",
    "                elif name == 'Un-rotate':\n",
    "                    df_current = apply_inverse_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name == 'X-flip':\n",
    "                    df_current = horizontal_flip_eye_data(df_current, W)\n",
    "                elif name == 'Re-rotate':\n",
    "                    df_current = apply_rotation(df_current, rot_mat, rot_angle)\n",
    "                elif name == 'Phi+90':\n",
    "                    df_current = rotate_phi_only(df_current)\n",
    "                elif name == 'FlipX-only':\n",
    "                    df_current = flip_x_only(df_current, W)\n",
    "                elif name == 'Flip Dot' and current_ref is not None:\n",
    "                    x0, y0 = current_ref\n",
    "                    current_ref = (W - x0, y0)\n",
    "                elif name == 'Bwd':\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, max(idx - skip, 0))\n",
    "                    last_frame = None\n",
    "                elif name == 'Fwd':\n",
    "                    idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, min(idx + skip, total_frames - 1))\n",
    "                    last_frame = None\n",
    "                elif name == 'Save':\n",
    "                    if eye.lower() == 'left':\n",
    "                        block.left_eye_data  = df_current.copy()\n",
    "                    else:\n",
    "                        block.right_eye_data = df_current.copy()\n",
    "                elif name == 'Quit':\n",
    "                    running = False\n",
    "                break\n",
    "\n",
    "    cv2.setMouseCallback('Controls', on_mouse)\n",
    "\n",
    "    # 6) Main loop\n",
    "    while running:\n",
    "        # Read or reuse frame\n",
    "        if playing or last_frame is None:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            last_frame = frame.copy()\n",
    "        else:\n",
    "            frame = last_frame.copy()\n",
    "\n",
    "        # Sync index\n",
    "        idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "        idx = max(idx, 0)\n",
    "\n",
    "        # Annotate frame\n",
    "        annotated = frame.copy()\n",
    "        if current_ref is not None:\n",
    "            cv2.circle(annotated, current_ref, 5, (255,0,0), -1)\n",
    "        mask = df_current[frame_col] == idx\n",
    "        if mask.any():\n",
    "            row = df_current[mask].iloc[0]\n",
    "            cx, cy = row['center_x'], row['center_y']\n",
    "            if not (pd.isna(cx) or pd.isna(cy)):\n",
    "                cv2.ellipse(\n",
    "                    annotated,\n",
    "                    (int(round(cx)), int(round(cy))),\n",
    "                    (int(row['width']), int(row['height'])),\n",
    "                    float(row['phi']), 0, 360,\n",
    "                    (0,255,0), 2\n",
    "                )\n",
    "\n",
    "        # Flip for display\n",
    "        disp = cv2.flip(annotated, 0)\n",
    "\n",
    "        # Overlay k_phi / k_theta text\n",
    "        if mask.any() and 'k_phi' in df_current.columns and 'k_theta' in df_current.columns:\n",
    "            row = df_current[mask].iloc[0]\n",
    "            kp = row['k_phi']\n",
    "            kt = row['k_theta']\n",
    "            txt = f\"k_phi: {kp:.1f}°, k_theta: {kt:.1f}°\"\n",
    "            cv2.putText(\n",
    "                disp, txt,\n",
    "                (10, disp.shape[0] - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6, (255,255,255), 2, cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "        cv2.imshow('Frame', disp)\n",
    "        cv2.imshow('Controls', controls_img)\n",
    "\n",
    "        # Draw 3D vector for (k_phi, k_theta)\n",
    "        if mask.any() and 'k_phi' in df_current.columns and 'k_theta' in df_current.columns:\n",
    "            row = df_current[mask].iloc[0]\n",
    "            kp = np.deg2rad(row['k_phi'])\n",
    "            kt = np.deg2rad(row['k_theta'])\n",
    "            x = np.cos(kt) * np.cos(kp)\n",
    "            y = np.cos(kt) * np.sin(kp)\n",
    "            z = np.sin(kt)\n",
    "\n",
    "            ax1.cla()\n",
    "            ax1.view_init(elev=0, azim=0)\n",
    "            ax1.set_xlim(-1,1); ax1.set_ylim(-1,1); ax1.set_zlim(-1,1)\n",
    "            # red 0° ref\n",
    "            ax1.quiver(0,0,0, 1,0,0, length=0.5, normalize=True, color='red')\n",
    "            ax1.quiver(0,0,0, x,y,z, length=1, normalize=True, color='blue')\n",
    "            fig1.canvas.draw()\n",
    "            buf = np.frombuffer(fig1.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            h, w = fig1.canvas.get_width_height()\n",
    "            buf = buf.reshape((h, w, 3))\n",
    "            cv2.imshow('Vector', cv2.cvtColor(buf, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Draw 3D vector for (k_phi_corr, k_theta_corr)\n",
    "        if mask.any() and 'k_phi_corr' in df_current.columns and 'k_theta_corr' in df_current.columns:\n",
    "            row = df_current[mask].iloc[0]\n",
    "            kp2 = np.deg2rad(row['k_phi_corr'])\n",
    "            kt2 = np.deg2rad(row['k_theta_corr'])\n",
    "            x2 = np.cos(kt2) * np.cos(kp2)\n",
    "            y2 = np.cos(kt2) * np.sin(kp2)\n",
    "            z2 = np.sin(kt2)\n",
    "\n",
    "            ax2.cla()\n",
    "            ax2.view_init(elev=0, azim=0)\n",
    "            ax2.set_xlim(-1,1); ax2.set_ylim(-1,1); ax2.set_zlim(-1,1)\n",
    "            ax2.quiver(0,0,0, 1,0,0, length=0.5, normalize=True, color='red')\n",
    "            ax2.quiver(0,0,0, x2,y2,z2, length=1, normalize=True, color='green')\n",
    "            fig2.canvas.draw()\n",
    "            buf2 = np.frombuffer(fig2.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            h2, w2 = fig2.canvas.get_width_height()\n",
    "            buf2 = buf2.reshape((h2, w2, 3))\n",
    "            cv2.imshow('VectorCorr', cv2.cvtColor(buf2, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.close(fig1)\n",
    "    plt.close(fig2)\n"
   ],
   "id": "1b8ba931d6802ac9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "efc3d4b938384a41",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
