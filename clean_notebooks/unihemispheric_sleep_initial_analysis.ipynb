{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:21:25.300109Z",
     "start_time": "2025-11-06T10:21:24.215591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import cycle\n",
    "import pickle\n",
    "import pathlib\n",
    "import math\n",
    "import tqdm\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import re\n",
    "from lxml import etree as ET\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "from scipy.stats import kde\n",
    "from BlockSync_current import BlockSync\n",
    "import UtilityFunctions_newOE as uf\n",
    "from scipy import signal\n",
    "import bokeh\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "rcParams['pdf.fonttype'] = 42  # Ensure fonts are embedded and editable\n",
    "rcParams['ps.fonttype'] = 42  # Ensure compatibility with vector outputs\n",
    "\n",
    "\n",
    "def bokeh_plotter(data_list, x_axis_list=None, label_list=None,\n",
    "                  plot_name='default',\n",
    "                  x_axis_label='X', y_axis_label='Y',\n",
    "                  peaks=None, peaks_list=False, export_path=False):\n",
    "    \"\"\"Generates an interactive Bokeh plot for the given data vector.\n",
    "    Args:\n",
    "        data_list (list or array): The data to be plotted.\n",
    "        label_list (list of str): The labels of the data vectors\n",
    "        plot_name (str, optional): The title of the plot. Defaults to 'default'.\n",
    "        x_axis (str, optional): The label for the x-axis. Defaults to 'X'.\n",
    "        y_axis (str, optional): The label for the y-axis. Defaults to 'Y'.\n",
    "        peaks (list or array, optional): Indices of peaks to highlight on the plot. Defaults to None.\n",
    "        export_path (False or str): when set to str, will output the resulting html fig\n",
    "    \"\"\"\n",
    "    color_cycle = cycle(bokeh.palettes.Category10_10)\n",
    "    fig = bokeh.plotting.figure(title=f'bokeh explorer: {plot_name}',\n",
    "                                x_axis_label=x_axis_label,\n",
    "                                y_axis_label=y_axis_label,\n",
    "                                plot_width=1500,\n",
    "                                plot_height=700)\n",
    "\n",
    "    for i, data_vector in enumerate(data_list):\n",
    "\n",
    "        color = next(color_cycle)\n",
    "\n",
    "        if x_axis_list is None:\n",
    "            x_axis = range(len(data_vector))\n",
    "        elif len(x_axis_list) == len(data_list):\n",
    "            print('x_axis manually set')\n",
    "            x_axis = x_axis_list[i]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                'problem with x_axis_list input - should be either None, or a list with the same length as data_list')\n",
    "        if label_list is None:\n",
    "            fig.line(x_axis, data_vector, line_color=color, legend_label=f\"Line {i + 1}\")\n",
    "        elif len(label_list) == len(data_list):\n",
    "            fig.line(range(len(data_vector)), data_vector, line_color=color, legend_label=f\"{label_list[i]}\")\n",
    "        if peaks is not None and peaks_list is True:\n",
    "            fig.circle(peaks[i], data_vector[peaks[i]], size=10, color=color)\n",
    "\n",
    "    if peaks is not None and peaks_list is False:\n",
    "        fig.circle(peaks, data_vector[peaks], size=10, color='red')\n",
    "\n",
    "    if export_path is not False:\n",
    "        print(f'exporting to {export_path}')\n",
    "        bokeh.io.output.output_file(filename=str(export_path / f'{plot_name}.html'), title=f'{plot_name}')\n",
    "    bokeh.plotting.show(fig)\n",
    "\n",
    "\n",
    "def load_eye_data_2d_w_rotation_matrix(block):\n",
    "    \"\"\"\n",
    "    This function checks if the eye dataframes and rotation dict object exist, then imports them\n",
    "    :param block: The current blocksync class with verifiec re/le dfs\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / 'left_eye_data.csv', index_col=0, engine='python')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data.csv', index_col=0, engine='python')\n",
    "    except FileNotFoundError:\n",
    "        print('eye_data files not found, run the pipeline!')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(block.analysis_path / 'rotate_eye_data_params.pkl', 'rb') as file:\n",
    "            rotation_dict = pickle.load(file)\n",
    "            block.left_rotation_matrix = rotation_dict['left_rotation_matrix']\n",
    "            block.right_rotation_matrix = rotation_dict['right_rotation_matrix']\n",
    "            block.left_rotation_angle = rotation_dict['left_rotation_angle']\n",
    "            block.right_rotation_angle = rotation_dict['right_rotation_angle']\n",
    "    except FileNotFoundError:\n",
    "        print('No rotation matrix file, create it')\n",
    "\n",
    "\n",
    "def create_saccade_events_df(eye_data_df, speed_threshold, bokeh_verify_threshold=False, magnitude_calib=1,\n",
    "                             speed_profile=True):\n",
    "    \"\"\"\n",
    "    Detects saccade events in eye tracking data and computes relevant metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - eye_data_df (pd.DataFrame): Input DataFrame containing eye tracking data.\n",
    "    - speed_threshold (float): Threshold for saccade detection based on speed.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): Modified input DataFrame with added columns for speed and saccade detection.\n",
    "    - saccade_events_df (pd.DataFrame): DataFrame containing information about detected saccade events.\n",
    "\n",
    "    Steps:\n",
    "    1. Calculate speed components ('speed_x', 'speed_y') based on differences in 'center_x' and 'center_y'.\n",
    "    2. Compute the magnitude of the velocity vector ('speed_r').\n",
    "    3. Create a binary column ('is_saccade') indicating saccade events based on the speed threshold.\n",
    "    4. Determine saccade onset and offset indices and timestamps.\n",
    "    5. Create a DataFrame ('saccade_events_df') with columns:\n",
    "        - 'saccade_start_ind': Indices of saccade onset.\n",
    "        - 'saccade_start_timestamp': Timestamps corresponding to saccade onset.\n",
    "        - 'saccade_end_ind': Indices of saccade offset.\n",
    "        - 'saccade_end_timestamp': Timestamps corresponding to saccade offset.\n",
    "        - 'length': Duration of each saccade event.\n",
    "    6. Calculate distance traveled and angles for each saccade event.\n",
    "    7. Append additional columns to 'saccade_events_df':\n",
    "        - 'magnitude': Magnitude of the distance traveled during each saccade.\n",
    "        - 'angle': Angle of the saccade vector in degrees.\n",
    "        - 'initial_x', 'initial_y': Initial coordinates of the saccade.\n",
    "        - 'end_x', 'end_y': End coordinates of the saccade.\n",
    "\n",
    "    Note: The original 'eye_data_df' is not modified; modified data is returned as 'df'.\n",
    "    \"\"\"\n",
    "    df = eye_data_df\n",
    "    df['speed_x'] = df['center_x'].diff()  # Difference between consecutive 'center_x' values\n",
    "    df['speed_y'] = df['center_y'].diff()  # Difference between consecutive 'center_y' values\n",
    "\n",
    "    # Step 2: Calculate magnitude of the velocity vector (R vector speed)\n",
    "    df['speed_r'] = (df['speed_x'] ** 2 + df['speed_y'] ** 2) ** 0.5\n",
    "\n",
    "    # Create a column for saccade detection\n",
    "    df['is_saccade'] = df['speed_r'] > speed_threshold\n",
    "\n",
    "    # create a saccade_on_off indicator where 1 is rising edge and -1 is falling edge by subtracting a shifted binary mask\n",
    "    saccade_on_off = df.is_saccade.astype(int) - df.is_saccade.shift(periods=1, fill_value=False).astype(int)\n",
    "    saccade_on_inds = np.where(saccade_on_off == 1)[\n",
    "                          0] - 1  # notice the manual shift here, chosen to include the first (sometimes slower) eye frame, just before saccade threshold crossing\n",
    "    saccade_on_ms = df['ms_axis'].iloc[saccade_on_inds]\n",
    "    saccade_on_timestamps = df['OE_timestamp'].iloc[saccade_on_inds]\n",
    "    saccade_off_inds = np.where(saccade_on_off == -1)[0]\n",
    "    saccade_off_timestamps = df['OE_timestamp'].iloc[saccade_off_inds]\n",
    "    saccade_off_ms = df['ms_axis'].iloc[saccade_off_inds]\n",
    "\n",
    "    saccade_dict = {'saccade_start_ind': saccade_on_inds,\n",
    "                    'saccade_start_timestamp': saccade_on_timestamps.values,\n",
    "                    'saccade_end_ind': saccade_off_inds,\n",
    "                    'saccade_end_timestamp': saccade_off_timestamps.values,\n",
    "                    'saccade_on_ms': saccade_on_ms.values,\n",
    "                    'saccade_off_ms': saccade_off_ms.values}\n",
    "\n",
    "    saccade_events_df = pd.DataFrame.from_dict(saccade_dict)\n",
    "    saccade_events_df['length'] = saccade_events_df['saccade_end_ind'] - saccade_events_df['saccade_start_ind']\n",
    "    # Drop columns used for intermediate steps\n",
    "    df = df.drop(['is_saccade'], axis=1)\n",
    "\n",
    "    distances = []\n",
    "    angles = []\n",
    "    speed_list = []\n",
    "    diameter_list = []\n",
    "    for index, row in tqdm.tqdm(saccade_events_df.iterrows()):\n",
    "        saccade_samples = df.loc[(df['OE_timestamp'] >= row['saccade_start_timestamp']) &\n",
    "                                 (df['OE_timestamp'] <= row['saccade_end_timestamp'])]\n",
    "        distance_traveled = saccade_samples['speed_r'].sum()\n",
    "        if speed_profile:\n",
    "            saccade_speed_profile = saccade_samples['speed_r'].values\n",
    "            speed_list.append(saccade_speed_profile)\n",
    "        saccade_diameter_profile = saccade_samples['pupil_diameter'].values\n",
    "        diameter_list.append(saccade_diameter_profile)\n",
    "        # Calculate angle from initial position to endpoint\n",
    "        initial_position = saccade_samples.iloc[0][['center_x', 'center_y']]\n",
    "        endpoint = saccade_samples.iloc[-1][['center_x', 'center_y']]\n",
    "        overall_angle = np.arctan2(endpoint['center_y'] - initial_position['center_y'],\n",
    "                                   endpoint['center_x'] - initial_position['center_x'])\n",
    "\n",
    "        angles.append(overall_angle)\n",
    "        distances.append(distance_traveled)\n",
    "\n",
    "    saccade_events_df['magnitude_raw'] = np.array(distances)\n",
    "    saccade_events_df['magnitude'] = np.array(distances) * magnitude_calib\n",
    "    saccade_events_df['angle'] = np.where(np.isnan(angles), angles, np.rad2deg(\n",
    "        angles) % 360)  # Convert radians to degrees and ensure result is in [0, 360)\n",
    "    start_ts = saccade_events_df['saccade_start_timestamp'].values\n",
    "    end_ts = saccade_events_df['saccade_end_timestamp'].values\n",
    "    saccade_start_df = df[df['OE_timestamp'].isin(start_ts)]\n",
    "    saccade_end_df = df[df['OE_timestamp'].isin(end_ts)]\n",
    "    start_x_coord = saccade_start_df['center_x']\n",
    "    start_y_coord = saccade_start_df['center_y']\n",
    "    end_x_coord = saccade_end_df['center_x']\n",
    "    end_y_coord = saccade_end_df['center_y']\n",
    "    saccade_events_df['initial_x'] = start_x_coord.values\n",
    "    saccade_events_df['initial_y'] = start_y_coord.values\n",
    "    saccade_events_df['end_x'] = end_x_coord.values\n",
    "    saccade_events_df['end_y'] = end_y_coord.values\n",
    "    saccade_events_df['calib_dx'] = (saccade_events_df['end_x'].values - saccade_events_df[\n",
    "        'initial_x'].values) * magnitude_calib\n",
    "    saccade_events_df['calib_dy'] = (saccade_events_df['end_y'].values - saccade_events_df[\n",
    "        'initial_y'].values) * magnitude_calib\n",
    "    if speed_profile:\n",
    "        saccade_events_df['speed_profile'] = speed_list\n",
    "    saccade_events_df['diameter_profile'] = diameter_list\n",
    "    if bokeh_verify_threshold:\n",
    "        bokeh_plotter(data_list=[df.speed_r], label_list=['Pupil Velocity'], peaks=saccade_on_inds)\n",
    "\n",
    "    return df, saccade_events_df\n",
    "\n",
    "\n",
    "# create a multi-animal block_collection:\n",
    "\n",
    "def create_block_collections(animals, block_lists, experiment_path, bad_blocks=None):\n",
    "    \"\"\"\n",
    "    Create block collections and a block dictionary from multiple animals and their respective block lists.\n",
    "\n",
    "    Parameters:\n",
    "    - animals: list of str, names of the animals.\n",
    "    - block_lists: list of lists of int, block numbers corresponding to each animal.\n",
    "    - experiment_path: pathlib.Path, path to the experiment directory.\n",
    "    - bad_blocks: list of int, blocks to exclude. Default is an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - block_collection: list of BlockSync objects for all specified blocks.\n",
    "    - block_dict: dictionary where keys are block numbers as strings and values are BlockSync objects.\n",
    "    \"\"\"\n",
    "    import UtilityFunctions_newOE as uf\n",
    "\n",
    "    if bad_blocks is None:\n",
    "        bad_blocks = []\n",
    "\n",
    "    block_collection = []\n",
    "    block_dict = {}\n",
    "\n",
    "    for animal, blocks in zip(animals, block_lists):\n",
    "        # Generate blocks for the current animal\n",
    "        current_blocks = uf.block_generator(\n",
    "            block_numbers=blocks,\n",
    "            experiment_path=experiment_path,\n",
    "            animal=animal,\n",
    "            bad_blocks=bad_blocks\n",
    "        )\n",
    "        # Add to collection and dictionary\n",
    "        block_collection.extend(current_blocks)\n",
    "        for b in current_blocks:\n",
    "            block_dict[f\"{animal}_block_{b.block_num}\"] = b\n",
    "\n",
    "    return block_collection, block_dict\n"
   ],
   "id": "d806be61e3f6c87c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:22:11.765262Z",
     "start_time": "2025-11-06T10:21:26.406362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "# This was the previous run\n",
    "#animals = ['PV_62', 'PV_126', 'PV_57']\n",
    "#block_lists = [[24, 26, 38], [7, 8, 9, 10, 11, 12], [7, 8, 9, 12, 13]]\n",
    "#This with new animals:\n",
    "animals = ['PV_106','PV_143','PV_62','PV_126', 'PV_57']\n",
    "block_lists = [[8,9,10,11,12],[1,2,3,4],[24, 26, 38],[7, 8, 9, 10, 11, 12], [7, 8, 9, 12, 13]]\n",
    "experiment_path = pathlib.Path(r\"Z:\\Nimrod\\experiments\")\n",
    "bad_blocks = [0]  # Example of bad blocks\n",
    "\n",
    "block_collection, block_dict = create_block_collections(\n",
    "    animals=animals,\n",
    "    block_lists=block_lists,\n",
    "    experiment_path=experiment_path,\n",
    "    bad_blocks=bad_blocks\n",
    ")\n",
    "for block in block_collection:\n",
    "    print(f'working on {block}')\n",
    "    block.parse_open_ephys_events()\n",
    "    block.get_eye_brightness_vectors()\n",
    "    block.synchronize_block()\n",
    "    block.create_eye_brightness_df(threshold_value=20)\n",
    "\n",
    "    # if the code fails here, go to manual synchronization\n",
    "    #block.import_manual_sync_df()\n",
    "    block.read_dlc_data()\n",
    "    block.calibrate_pixel_size(10)\n",
    "    #load_eye_data_2d_w_rotation_matrix(block) #should be integrated again... later"
   ],
   "id": "a3cb55680a4268cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_008, new OE version\n",
      "Found the sample rate for block 008 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 010 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_010, new OE version\n",
      "Found the sample rate for block 010 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 010\n",
      "got it!\n",
      "instantiated block number 011 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_011, new OE version\n",
      "Found the sample rate for block 011 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 011\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 001 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_001, new OE version\n",
      "Found the sample rate for block 001 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 001\n",
      "got it!\n",
      "instantiated block number 002 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_002, new OE version\n",
      "Found the sample rate for block 002 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 002\n",
      "got it!\n",
      "instantiated block number 003 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_003, new OE version\n",
      "Found the sample rate for block 003 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 003\n",
      "got it!\n",
      "instantiated block number 004 at Path: Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_004, new OE version\n",
      "Found the sample rate for block 004 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 004\n",
      "got it!\n",
      "instantiated block number 024 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_024, new OE version\n",
      "Found the sample rate for block 024 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 024\n",
      "got it!\n",
      "instantiated block number 026 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_026, new OE version\n",
      "Found the sample rate for block 026 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 026\n",
      "got it!\n",
      "instantiated block number 038 at Path: Z:\\Nimrod\\experiments\\PV_62\\2023_05_01\\block_038, new OE version\n",
      "Found the sample rate for block 038 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 038\n",
      "got it!\n",
      "instantiated block number 007 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007, new OE version\n",
      "Found the sample rate for block 007 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 007\n",
      "got it!\n",
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_008, new OE version\n",
      "could not find the sample rate in the xml file due to error, will look in the cont file of the first recording...\n",
      "found the sample rate, it is 20000\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 010 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_010, new OE version\n",
      "Found the sample rate for block 010 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 010\n",
      "got it!\n",
      "instantiated block number 011 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_011, new OE version\n",
      "Found the sample rate for block 011 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 011\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 007 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_007, new OE version\n",
      "Found the sample rate for block 007 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 007\n",
      "got it!\n",
      "instantiated block number 008 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_008, new OE version\n",
      "Found the sample rate for block 008 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 008\n",
      "got it!\n",
      "instantiated block number 009 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_11_25\\block_009, new OE version\n",
      "Found the sample rate for block 009 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 009\n",
      "got it!\n",
      "instantiated block number 012 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_012, new OE version\n",
      "Found the sample rate for block 012 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 012\n",
      "got it!\n",
      "instantiated block number 013 at Path: Z:\\Nimrod\\experiments\\PV_57\\2024_12_01\\block_013, new OE version\n",
      "Found the sample rate for block 013 in the xml file, it is 20000 Hz\n",
      "created the .oe_rec attribute as an open ephys recording obj with get_data functionality\n",
      "retrieving zertoh sample number for block 013\n",
      "got it!\n",
      "working on PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19\n",
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43\n",
      "running parse_open_ephys_events...\n",
      "block 010 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 010...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30\n",
      "running parse_open_ephys_events...\n",
      "block 011 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 011...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08\n",
      "running parse_open_ephys_events...\n",
      "block 001 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 001...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11\n",
      "running parse_open_ephys_events...\n",
      "block 002 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 002...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35\n",
      "running parse_open_ephys_events...\n",
      "block 003 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 003...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28\n",
      "running parse_open_ephys_events...\n",
      "block 004 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 004...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_62, block 024, on 2023-04-27_11-22-56\n",
      "running parse_open_ephys_events...\n",
      "block 024 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 024...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_62, block 026, on 2023-04-27_12-21-41\n",
      "running parse_open_ephys_events...\n",
      "block 026 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 026...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_62, block 038, on 2023-05-01_13-57-45\n",
      "running parse_open_ephys_events...\n",
      "block 038 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 038...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12\n",
      "running parse_open_ephys_events...\n",
      "block 007 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 007...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41\n",
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57\n",
      "running parse_open_ephys_events...\n",
      "block 010 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 010...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 011, on PV126_Trial115_eyeTracking_w7\n",
      "running parse_open_ephys_events...\n",
      "block 011 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 011...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_126, block 012, on PV126_Trial116_eyeTracking_h8\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31\n",
      "running parse_open_ephys_events...\n",
      "block 007 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 007...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18\n",
      "running parse_open_ephys_events...\n",
      "block 008 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 008...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35\n",
      "running parse_open_ephys_events...\n",
      "block 009 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 009...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39\n",
      "running parse_open_ephys_events...\n",
      "block 012 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 012...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n",
      "working on PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43\n",
      "running parse_open_ephys_events...\n",
      "block 013 has a parsed events file, reading...\n",
      "Getting eye brightness values for block 013...\n",
      "Found an existing file!\n",
      "Eye brightness vectors generation complete.\n",
      "blocksync_df loaded from analysis folder\n",
      "eye_brightness_df loaded from analysis folder\n",
      "eye dataframes loaded from analysis folder\n",
      "got the calibration values from the analysis folder\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:22:27.326889Z",
     "start_time": "2025-11-06T10:22:11.782265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    for block in block_collection:\n",
    "        print('working on {}'.format(block))\n",
    "        # block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_corr_angles.csv')\n",
    "        # block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_corr_angles.csv')\n",
    "        #block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_raw_xflipped.csv')\n",
    "        #block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_raw_xflipped.csv')\n",
    "        block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_raw_verified.csv')\n",
    "        block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_raw_verified.csv')\n",
    "        # block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_3d_corr_verified.csv')\n",
    "        # block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_3d_corr_verified.csv')\n",
    "        #block.left_eye_data = pd.read_csv(block.analysis_path / f'left_eye_data_degrees_rotated_verified.csv')\n",
    "        #block.right_eye_data = pd.read_csv(block.analysis_path / 'right_eye_data_degrees_rotated_verified.csv')\n",
    "\n",
    "    # calibrate pupil diameter:\n",
    "    # if 'pupil_diameter' not in block.left_eye_data.columns:\n",
    "    #     block.left_eye_data['pupil_diameter_pixels'] = block.left_eye_data.major_ax * 2 * np.pi\n",
    "    #     block.right_eye_data['pupil_diameter_pixels'] = block.right_eye_data.major_ax * 2 * np.pi\n",
    "    #     block.left_eye_data['pupil_diameter'] = block.left_eye_data['pupil_diameter_pixels'] * block.L_pix_size\n",
    "    #     block.right_eye_data['pupil_diameter'] = block.right_eye_data['pupil_diameter_pixels'] * block.R_pix_size"
   ],
   "id": "b7b7fb6d75277833",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19\n",
      "working on PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43\n",
      "working on PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43\n",
      "working on PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30\n",
      "working on PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30\n",
      "working on PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08\n",
      "working on PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11\n",
      "working on PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35\n",
      "working on PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28\n",
      "working on PV_62, block 024, on 2023-04-27_11-22-56\n",
      "working on PV_62, block 026, on 2023-04-27_12-21-41\n",
      "working on PV_62, block 038, on 2023-05-01_13-57-45\n",
      "working on PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12\n",
      "working on PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41\n",
      "working on PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15\n",
      "working on PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57\n",
      "working on PV_126, block 011, on PV126_Trial115_eyeTracking_w7\n",
      "working on PV_126, block 012, on PV126_Trial116_eyeTracking_h8\n",
      "working on PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31\n",
      "working on PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18\n",
      "working on PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35\n",
      "working on PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39\n",
      "working on PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:22:27.357859Z",
     "start_time": "2025-11-06T10:22:27.342858Z"
    }
   },
   "cell_type": "code",
   "source": "block_collection",
   "id": "7b2e6126fe5eab01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BlockSync object for animal PV_106 with \n",
       " block_num 008 at date PV106_ET_d3t12025-08-06_11-52-19,\n",
       " BlockSync object for animal PV_106 with \n",
       " block_num 009 at date PV106_ET_d3t2_2025-08-06_12-09-43,\n",
       " BlockSync object for animal PV_106 with \n",
       " block_num 010 at date PV106_ET_d3t3_2025-08-06_12-26-43,\n",
       " BlockSync object for animal PV_106 with \n",
       " block_num 011 at date PV106_ET_d3t4_2025-08-06_12-44-30,\n",
       " BlockSync object for animal PV_106 with \n",
       " block_num 012 at date PV106_ET_d3t5_2025-08-06_13-21-30,\n",
       " BlockSync object for animal PV_143 with \n",
       " block_num 001 at date PV143_ET_d1t1_2025-08-11_13-29-08,\n",
       " BlockSync object for animal PV_143 with \n",
       " block_num 002 at date PV143_ET_d1t2_2025-08-11_13-50-11,\n",
       " BlockSync object for animal PV_143 with \n",
       " block_num 003 at date PV143_ET_d1t3_2025-08-11_14-20-35,\n",
       " BlockSync object for animal PV_143 with \n",
       " block_num 004 at date PV143_ET_d1t4_2025-08-11_14-58-28,\n",
       " BlockSync object for animal PV_62 with \n",
       " block_num 024 at date 2023-04-27_11-22-56,\n",
       " BlockSync object for animal PV_62 with \n",
       " block_num 026 at date 2023-04-27_12-21-41,\n",
       " BlockSync object for animal PV_62 with \n",
       " block_num 038 at date 2023-05-01_13-57-45,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 007 at date PV126_Trial16_wake3_2024-07-18_12-49-12,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 008 at date PV126_Trial16_wake4_2024-07-18_13-24-41,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 009 at date PV126_Trial18_wake5_2024-07-18_14-39-15,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 010 at date PV126_Trial19_wake6_2024-07-18_15-24-57,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 011 at date PV126_Trial115_eyeTracking_w7,\n",
       " BlockSync object for animal PV_126 with \n",
       " block_num 012 at date PV126_Trial116_eyeTracking_h8,\n",
       " BlockSync object for animal PV_57 with \n",
       " block_num 007 at date pv_57_day2_03_2024-11-25_15-28-31,\n",
       " BlockSync object for animal PV_57 with \n",
       " block_num 008 at date pv_57_day2_05_2024-11-25_16-07-18,\n",
       " BlockSync object for animal PV_57 with \n",
       " block_num 009 at date pv_57_day2_06_2024-11-25_16-25-35,\n",
       " BlockSync object for animal PV_57 with \n",
       " block_num 012 at date PV_57_hunter_2_2024-12-01_16-08-39,\n",
       " BlockSync object for animal PV_57 with \n",
       " block_num 013 at date PV_57_hunter_2_2024-12-01_16-34-43]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:22:27.656292Z",
     "start_time": "2025-11-06T10:22:27.596293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for block in block_collection:\n",
    "  if 'pupil_diameter' not in block.left_eye_data.columns:\n",
    "        print(f'calculating pupil diameter for {block} ')\n",
    "        block.left_eye_data['pupil_diameter_pixels'] = block.left_eye_data.major_ax\n",
    "        block.right_eye_data['pupil_diameter_pixels'] = block.right_eye_data.major_ax\n",
    "        block.left_eye_data['pupil_diameter'] = block.left_eye_data['pupil_diameter_pixels'] * block.L_pix_size\n",
    "        block.right_eye_data['pupil_diameter'] = block.right_eye_data['pupil_diameter_pixels'] * block.R_pix_size"
   ],
   "id": "1b76e6a6457c6a9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating pupil diameter for PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19 \n",
      "calculating pupil diameter for PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43 \n",
      "calculating pupil diameter for PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43 \n",
      "calculating pupil diameter for PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30 \n",
      "calculating pupil diameter for PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30 \n",
      "calculating pupil diameter for PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08 \n",
      "calculating pupil diameter for PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11 \n",
      "calculating pupil diameter for PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35 \n",
      "calculating pupil diameter for PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28 \n",
      "calculating pupil diameter for PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12 \n",
      "calculating pupil diameter for PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41 \n",
      "calculating pupil diameter for PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15 \n",
      "calculating pupil diameter for PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57 \n",
      "calculating pupil diameter for PV_126, block 011, on PV126_Trial115_eyeTracking_w7 \n",
      "calculating pupil diameter for PV_126, block 012, on PV126_Trial116_eyeTracking_h8 \n",
      "calculating pupil diameter for PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31 \n",
      "calculating pupil diameter for PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18 \n",
      "calculating pupil diameter for PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35 \n",
      "calculating pupil diameter for PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39 \n",
      "calculating pupil diameter for PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43 \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:22:27.767292Z",
     "start_time": "2025-11-06T10:22:27.753294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # uncomment to switch corrected values to k_phi / theta columns\n",
    "# for block in block_collection:\n",
    "#     block.left_eye_data.drop(columns=['k_phi', 'k_theta'], inplace=True)\n",
    "#     block.right_eye_data.drop(columns=['k_phi', 'k_theta'], inplace=True)\n",
    "#     # then rename in-place\n",
    "#     block.left_eye_data = block.left_eye_data.rename(columns={'corr_phi': 'k_phi', 'corr_theta': 'k_theta'})\n",
    "#     block.right_eye_data = block.right_eye_data.rename(columns={'corr_phi': 'k_phi', 'corr_theta': 'k_theta'})"
   ],
   "id": "90d799b4c4148c4e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:22:27.890292Z",
     "start_time": "2025-11-06T10:22:27.871294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_saccade_events_with_direction_segmentation_robust(\n",
    "        eye_data_df,\n",
    "        speed_threshold,  # angular speed threshold in degrees/frame\n",
    "        directional_delta_threshold_deg=25,  # threshold for change in instantaneous angle (degrees)\n",
    "        magnitude_calib=1,\n",
    "        speed_profile=True,\n",
    "        min_subsaccade_samples=2,\n",
    "        min_net_disp=0.5  # minimal net angular displacement (in degrees) for a segment to be valid\n",
    "):\n",
    "    \"\"\"\n",
    "    Detects and segments saccade events in eye tracking data using angular speed and directional changes.\n",
    "    This robust version avoids producing segments with near-zero net displacement by:\n",
    "      1. Defining the saccade onset as the first frame where the angular speed exceeds the threshold.\n",
    "      2. Segmenting the event based on sustained directional changes.\n",
    "      3. Discarding segments whose overall net angular displacement (computed from k_phi and k_theta)\n",
    "         is below a user-specified minimal value.\n",
    "\n",
    "    Parameters:\n",
    "      - eye_data_df (pd.DataFrame): DataFrame with columns including:\n",
    "            'center_x', 'center_y', 'k_phi', 'k_theta', 'OE_timestamp', 'ms_axis', 'pupil_diameter'.\n",
    "      - speed_threshold (float): Angular speed threshold (degrees/frame) for detection.\n",
    "      - directional_delta_threshold_deg (float): Angular change threshold to determine segmentation boundaries.\n",
    "      - magnitude_calib (float): Calibration factor (not applied to angular measures).\n",
    "      - speed_profile (bool): Whether to record speed profiles.\n",
    "      - min_subsaccade_samples (int): Minimum number of samples required for a valid segment.\n",
    "      - min_net_disp (float): Minimal net angular displacement (in degrees) required for a segment to be kept.\n",
    "\n",
    "    Returns:\n",
    "      - df (pd.DataFrame): The input DataFrame with added computed columns.\n",
    "      - saccade_events_df (pd.DataFrame): DataFrame listing detected and segmented saccade events, with metrics.\n",
    "    \"\"\"\n",
    "    # Make a copy so as not to modify the original DataFrame.\n",
    "    df = eye_data_df.copy()\n",
    "\n",
    "    ### 1. Compute Frame-to-Frame Differences\n",
    "    df[\"speed_x\"] = df[\"center_x\"].diff()\n",
    "    df[\"speed_y\"] = df[\"center_y\"].diff()\n",
    "    df[\"speed_r\"] = np.sqrt(df[\"speed_x\"] ** 2 + df[\"speed_y\"] ** 2)\n",
    "\n",
    "    # Angular differences (k_phi and k_theta are in degrees)\n",
    "    df[\"angular_speed_phi\"] = df[\"k_phi\"].diff()\n",
    "    df[\"angular_speed_theta\"] = df[\"k_theta\"].diff()\n",
    "    df[\"angular_speed_r\"] = np.sqrt(df[\"angular_speed_phi\"] ** 2 + df[\"angular_speed_theta\"] ** 2)\n",
    "\n",
    "    ### 2. Saccade Detection Based on Angular Speed\n",
    "    # Mark frames where the instantaneous angular speed exceeds the threshold.\n",
    "    df[\"is_saccade_angle\"] = df[\"angular_speed_r\"] > speed_threshold\n",
    "\n",
    "    # Identify transitions to detect onsets and offsets.\n",
    "    saccade_on_off = df[\"is_saccade_angle\"].astype(int) - df[\"is_saccade_angle\"].shift(1, fill_value=0).astype(int)\n",
    "    # Use the first frame above threshold as onset\n",
    "    saccade_on_inds = np.where(saccade_on_off == 1)[0]\n",
    "    saccade_off_inds = np.where(saccade_on_off == -1)[0]\n",
    "\n",
    "    # Handle mismatches: if a saccade starts but does not end, drop the last onset.\n",
    "    if len(saccade_on_inds) > len(saccade_off_inds):\n",
    "        saccade_on_inds = saccade_on_inds[:-1]\n",
    "\n",
    "    saccade_events = []\n",
    "\n",
    "    ### 3. Process Each Detected Saccade for Segmentation\n",
    "    for start_ind, end_ind in zip(saccade_on_inds, saccade_off_inds):\n",
    "        saccade_df = df.iloc[start_ind:end_ind + 1].copy()\n",
    "        if saccade_df.empty or len(saccade_df) < min_subsaccade_samples:\n",
    "            continue\n",
    "\n",
    "        # Compute instantaneous angles (for both pixel- and angular-based estimates)\n",
    "        saccade_df[\"inst_angle_pixel\"] = np.degrees(np.arctan2(saccade_df[\"speed_y\"], saccade_df[\"speed_x\"]))\n",
    "        saccade_df[\"inst_angle_deg\"] = np.degrees(\n",
    "            np.arctan2(saccade_df[\"angular_speed_theta\"], saccade_df[\"angular_speed_phi\"]))\n",
    "\n",
    "        # Define helper function for minimal angular difference (handling circularity)\n",
    "        minimal_angle_diff_deg = lambda a, b: ((a - b + 180) % 360) - 180\n",
    "\n",
    "        angles = saccade_df[\"inst_angle_deg\"].values\n",
    "        # Compute consecutive differences\n",
    "        angle_diffs = np.array([minimal_angle_diff_deg(angles[i + 1], angles[i]) for i in range(len(angles) - 1)])\n",
    "\n",
    "        # Identify candidate segmentation boundaries when the absolute change exceeds threshold.\n",
    "        candidate_boundaries = np.where(np.abs(angle_diffs) > directional_delta_threshold_deg)[0].tolist()\n",
    "\n",
    "        # Always include the first and last frame of the saccade.\n",
    "        boundaries = [0] + candidate_boundaries + [len(saccade_df) - 1]\n",
    "\n",
    "        # Process each segment defined by these boundaries.\n",
    "        for i in range(len(boundaries) - 1):\n",
    "            seg_start = boundaries[i]\n",
    "            seg_end = boundaries[i + 1]\n",
    "            subsaccade = saccade_df.iloc[seg_start: seg_end + 1]\n",
    "            if len(subsaccade) < min_subsaccade_samples:\n",
    "                continue\n",
    "\n",
    "            # Compute net angular displacement using the angular positions (k_phi and k_theta)\n",
    "            initial_pos_angle = subsaccade.iloc[0][[\"k_phi\", \"k_theta\"]]\n",
    "            final_pos_angle = subsaccade.iloc[-1][[\"k_phi\", \"k_theta\"]]\n",
    "            net_disp = np.sqrt((final_pos_angle[\"k_phi\"] - initial_pos_angle[\"k_phi\"]) ** 2 +\n",
    "                               (final_pos_angle[\"k_theta\"] - initial_pos_angle[\"k_theta\"]) ** 2)\n",
    "\n",
    "            # Only record segments whose net displacement is above min_net_disp.\n",
    "            if net_disp < min_net_disp:\n",
    "                continue\n",
    "\n",
    "            # Timing and indices\n",
    "            sub_start_timestamp = subsaccade[\"OE_timestamp\"].iloc[0]\n",
    "            sub_end_timestamp = subsaccade[\"OE_timestamp\"].iloc[-1]\n",
    "            sub_start_ms = subsaccade[\"ms_axis\"].iloc[0]\n",
    "            sub_end_ms = subsaccade[\"ms_axis\"].iloc[-1]\n",
    "            sub_length = subsaccade.index[-1] - subsaccade.index[0]\n",
    "\n",
    "            # Pixel-based metrics\n",
    "            magnitude_raw_pixel = subsaccade[\"speed_r\"].sum()\n",
    "            magnitude_pixel = magnitude_raw_pixel * magnitude_calib\n",
    "\n",
    "            # Angular-based metric: sum of instantaneous angular speeds\n",
    "            magnitude_raw_angular = subsaccade[\"angular_speed_r\"].sum()\n",
    "\n",
    "            # Overall angular-based angle (from start to end)\n",
    "            overall_angle_deg = (np.degrees(np.arctan2(\n",
    "                final_pos_angle[\"k_theta\"] - initial_pos_angle[\"k_theta\"],\n",
    "                final_pos_angle[\"k_phi\"] - initial_pos_angle[\"k_phi\"]\n",
    "            )) % 360)\n",
    "\n",
    "            # (Optional) Capture speed profiles and other details\n",
    "            speed_profile_pixel = subsaccade[\"speed_r\"].values if speed_profile else None\n",
    "            speed_profile_pixel_calib = (speed_profile_pixel * magnitude_calib) if speed_profile else None\n",
    "            speed_profile_angular = subsaccade[\"angular_speed_r\"].values if speed_profile else None\n",
    "            diameter_profile = subsaccade[\"pupil_diameter\"].values\n",
    "\n",
    "            saccade_events.append({\n",
    "                \"saccade_start_ind\": subsaccade.index[0],\n",
    "                \"saccade_end_ind\": subsaccade.index[-1],\n",
    "                \"saccade_start_timestamp\": sub_start_timestamp,\n",
    "                \"saccade_end_timestamp\": sub_end_timestamp,\n",
    "                \"saccade_on_ms\": sub_start_ms,\n",
    "                \"saccade_off_ms\": sub_end_ms,\n",
    "                \"length\": sub_length,\n",
    "                \"magnitude_raw_pixel\": magnitude_raw_pixel,\n",
    "                \"magnitude_pixel\": magnitude_pixel,\n",
    "                \"magnitude_raw_angular\": magnitude_raw_angular,\n",
    "                \"overall_angle_deg\": overall_angle_deg,\n",
    "                \"net_angular_disp\": net_disp,\n",
    "                \"speed_profile_pixel\": speed_profile_pixel,\n",
    "                \"speed_profile_pixel_calib\": speed_profile_pixel_calib,\n",
    "                \"speed_profile_angular\": speed_profile_angular,\n",
    "                \"diameter_profile\": diameter_profile,\n",
    "                \"theta_init_pos\": initial_pos_angle[\"k_theta\"],\n",
    "                \"theta_end_pos\": final_pos_angle[\"k_theta\"],\n",
    "                \"phi_init_pos\": initial_pos_angle[\"k_phi\"],\n",
    "                \"phi_end_pos\": final_pos_angle[\"k_phi\"]\n",
    "            })\n",
    "\n",
    "    # Convert the list to a DataFrame.\n",
    "    saccade_events_df = pd.DataFrame(saccade_events)\n",
    "\n",
    "    # Optionally remove intermediate column\n",
    "    df.drop([\"is_saccade_angle\"], axis=1, inplace=True)\n",
    "\n",
    "    # Calculate delta columns for convenience.\n",
    "    if not saccade_events_df.empty:\n",
    "        saccade_events_df['delta_theta'] = saccade_events_df['theta_end_pos'] - saccade_events_df['theta_init_pos']\n",
    "        saccade_events_df['delta_phi'] = saccade_events_df['phi_end_pos'] - saccade_events_df['phi_init_pos']\n",
    "\n",
    "    return df, saccade_events_df\n"
   ],
   "id": "db58155a96b7f94e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:05.755576Z",
     "start_time": "2025-11-06T10:22:28.001293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for block in block_collection:\n",
    "    print(block)\n",
    "    block.left_eye_data, block.l_saccade_df = create_saccade_events_with_direction_segmentation_robust(\n",
    "        block.left_eye_data,\n",
    "        0.8,  # angular speed threshold in degrees/frame\n",
    "        directional_delta_threshold_deg=90,  # threshold for change in instantaneous angle (degrees)\n",
    "        magnitude_calib=1,\n",
    "        speed_profile=True,\n",
    "        min_subsaccade_samples=2)\n",
    "    block.right_eye_data, block.r_saccade_df = create_saccade_events_with_direction_segmentation_robust(\n",
    "        block.right_eye_data,\n",
    "        0.8,  # angular speed threshold in degrees/frame\n",
    "        directional_delta_threshold_deg=90,  # threshold for change in instantaneous angle (degrees)\n",
    "        magnitude_calib=1,\n",
    "        speed_profile=True,\n",
    "        min_subsaccade_samples=2)\n"
   ],
   "id": "f03f8372309652ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19\n",
      "PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43\n",
      "PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43\n",
      "PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30\n",
      "PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30\n",
      "PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08\n",
      "PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11\n",
      "PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35\n",
      "PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28\n",
      "PV_62, block 024, on 2023-04-27_11-22-56\n",
      "PV_62, block 026, on 2023-04-27_12-21-41\n",
      "PV_62, block 038, on 2023-05-01_13-57-45\n",
      "PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12\n",
      "PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41\n",
      "PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15\n",
      "PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57\n",
      "PV_126, block 011, on PV126_Trial115_eyeTracking_w7\n",
      "PV_126, block 012, on PV126_Trial116_eyeTracking_h8\n",
      "PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31\n",
      "PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18\n",
      "PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35\n",
      "PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39\n",
      "PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:07.809184Z",
     "start_time": "2025-11-06T10:24:05.809589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### over here, I get the lizard movements binary from mark's analysis\n",
    "import os\n",
    "def block_get_lizard_movement(block):\n",
    "    # collect accelerometer data\n",
    "    # path definition\n",
    "    p = block.oe_path / 'analysis'\n",
    "    analysis_list = os.listdir(p)\n",
    "    correct_analysis = [i for i in analysis_list if block.animal_call in i][0]\n",
    "    p = p / str(correct_analysis)\n",
    "    mat_path = p / 'lizMov.mat'\n",
    "    print(f'path to mat file is {mat_path}')\n",
    "    # read mat file\n",
    "    try:\n",
    "        mat_data = h5py.File(str(mat_path), 'r')\n",
    "        mat_dict = {'t_mov_ms': mat_data['t_mov_ms'][:],\n",
    "                    'movAll': mat_data['movAll'][:]}\n",
    "\n",
    "        acc_df = pd.DataFrame(data=np.array([mat_dict['t_mov_ms'][:, 0], mat_dict['movAll'][:, 0]]).T,\n",
    "                              columns=['t_mov_ms', 'movAll'])\n",
    "        mat_data.close()\n",
    "        block.liz_mov_df = acc_df\n",
    "        print(f'liz_mov_df created for {block}')\n",
    "    except FileNotFoundError:\n",
    "        print('mat file does not exist - run the matlab getLizMovement function')\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# this cell now labels the saccades as with/without head movements\n",
    "def get_head_mov_col(df, mov_times):\n",
    "    head_mov_bool = np.zeros(len(df), dtype=bool)  # Initialize array of False\n",
    "\n",
    "    for i, saccade in enumerate(df.itertuples()):\n",
    "        saccade_start = saccade.saccade_on_ms\n",
    "        saccade_end = saccade.saccade_off_ms\n",
    "\n",
    "        overlapping_mov_times = mov_times[np.logical_and(mov_times >= saccade_start, mov_times <= saccade_end)]\n",
    "\n",
    "        if overlapping_mov_times.size > 0:\n",
    "            head_mov_bool[i] = True\n",
    "\n",
    "    df['head_movement'] = head_mov_bool\n",
    "    return df\n",
    "\n",
    "def label_saccade_movements(block):\n",
    "    mov_times = block.liz_mov_df.t_mov_ms.values\n",
    "    block.l_saccade_df = get_head_mov_col(block.l_saccade_df,mov_times=mov_times)\n",
    "    block.r_saccade_df = get_head_mov_col(block.r_saccade_df,mov_times=mov_times)\n",
    "\n",
    "# Create a list to store blocks where movement data exists\n",
    "block_collection_w_mov = []\n",
    "\n",
    "for block in block_collection:\n",
    "    try:\n",
    "        block_get_lizard_movement(block)  # Try loading movement data\n",
    "        label_saccade_movements(block)    # Try labeling saccades\n",
    "\n",
    "        # If both steps succeed, add block to the valid collection\n",
    "        block_collection_w_mov.append(block)\n",
    "\n",
    "    except (FileNotFoundError, OSError) as e:\n",
    "        print(f\"Skipping block {block}: {str(e)}\")  # Notify which block failed\n"
   ],
   "id": "5c967c6c82fcd567",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path to mat file is Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_008\\oe_files\\PV106_ET_d3t12025-08-06_11-52-19\\Record Node 102\\analysis\\recNames=Block008,Animal=PV_106\\lizMov.mat\n",
      "liz_mov_df created for PV_106, block 008, on PV106_ET_d3t12025-08-06_11-52-19\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_009\\oe_files\\PV106_ET_d3t2_2025-08-06_12-09-43\\Record Node 102\\analysis\\recNames=Block009,Animal=PV_106\\lizMov.mat\n",
      "liz_mov_df created for PV_106, block 009, on PV106_ET_d3t2_2025-08-06_12-09-43\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_010\\oe_files\\PV106_ET_d3t3_2025-08-06_12-26-43\\Record Node 102\\analysis\\recNames=Block010,Animal=PV_106\\lizMov.mat\n",
      "liz_mov_df created for PV_106, block 010, on PV106_ET_d3t3_2025-08-06_12-26-43\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_011\\oe_files\\PV106_ET_d3t4_2025-08-06_12-44-30\\Record Node 102\\analysis\\recNames=Block011,Animal=PV_106\\lizMov.mat\n",
      "liz_mov_df created for PV_106, block 011, on PV106_ET_d3t4_2025-08-06_12-44-30\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_106\\2025_08_06\\block_012\\oe_files\\PV106_ET_d3t5_2025-08-06_13-21-30\\Record Node 102\\analysis\\recNames=Block012,Animal=PV_106\\lizMov.mat\n",
      "liz_mov_df created for PV_106, block 012, on PV106_ET_d3t5_2025-08-06_13-21-30\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_001\\oe_files\\PV143_ET_d1t1_2025-08-11_13-29-08\\Record Node 102\\analysis\\recNames=Block001,Animal=PV_143\\lizMov.mat\n",
      "liz_mov_df created for PV_143, block 001, on PV143_ET_d1t1_2025-08-11_13-29-08\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_002\\oe_files\\PV143_ET_d1t2_2025-08-11_13-50-11\\Record Node 102\\analysis\\recNames=Block002,Animal=PV_143\\lizMov.mat\n",
      "liz_mov_df created for PV_143, block 002, on PV143_ET_d1t2_2025-08-11_13-50-11\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_003\\oe_files\\PV143_ET_d1t3_2025-08-11_14-20-35\\Record Node 102\\analysis\\recNames=Block003,Animal=PV_143\\lizMov.mat\n",
      "liz_mov_df created for PV_143, block 003, on PV143_ET_d1t3_2025-08-11_14-20-35\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_143\\2025_08_25\\block_004\\oe_files\\PV143_ET_d1t4_2025-08-11_14-58-28\\Record Node 103\\analysis\\recNames=Block004,Animal=PV_143\\lizMov.mat\n",
      "liz_mov_df created for PV_143, block 004, on PV143_ET_d1t4_2025-08-11_14-58-28\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_024\\oe_files\\2023-04-27_11-22-56\\Record Node 108\\analysis\\recNames=Block0024,Animal=PV_62\\lizMov.mat\n",
      "liz_mov_df created for PV_62, block 024, on 2023-04-27_11-22-56\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_62\\2023_04_27\\block_026\\oe_files\\2023-04-27_12-21-41\\Record Node 108\\analysis\\recNames=Block0026,Animal=PV_62\\lizMov.mat\n",
      "liz_mov_df created for PV_62, block 026, on 2023-04-27_12-21-41\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_62\\2023_05_01\\block_038\\oe_files\\2023-05-01_13-57-45\\Record Node 108\\analysis\\recNames=Block0038,Animal=PV_62\\lizMov.mat\n",
      "liz_mov_df created for PV_62, block 038, on 2023-05-01_13-57-45\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_007\\oe_files\\PV126_Trial16_wake3_2024-07-18_12-49-12\\Record Node 102\\analysis\\Animal=PV_126,recNames=block_007\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 007, on PV126_Trial16_wake3_2024-07-18_12-49-12\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_008\\oe_files\\PV126_Trial16_wake4_2024-07-18_13-24-41\\Record Node 102\\analysis\\recNames=block_008,Animal=PV_126\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 008, on PV126_Trial16_wake4_2024-07-18_13-24-41\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_009\\oe_files\\PV126_Trial18_wake5_2024-07-18_14-39-15\\Record Node 102\\analysis\\recNames=block_009,Animal=PV_126\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 009, on PV126_Trial18_wake5_2024-07-18_14-39-15\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_07_18\\block_010\\oe_files\\PV126_Trial19_wake6_2024-07-18_15-24-57\\Record Node 102\\analysis\\recNames=block_010,Animal=PV_126\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 010, on PV126_Trial19_wake6_2024-07-18_15-24-57\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_011\\oe_files\\PV126_Trial115_eyeTracking_w7\\Record Node 102\\analysis\\recNames=block_011,Animal=PV_126\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 011, on PV126_Trial115_eyeTracking_w7\n",
      "path to mat file is Z:\\Nimrod\\experiments\\PV_126\\2024_08_13\\block_012\\oe_files\\PV126_Trial116_eyeTracking_h8\\Record Node 102\\analysis\\recNames=block_012,Animal=PV_126\\lizMov.mat\n",
      "liz_mov_df created for PV_126, block 012, on PV126_Trial116_eyeTracking_h8\n",
      "Skipping block PV_57, block 007, on pv_57_day2_03_2024-11-25_15-28-31: [WinError 3] The system cannot find the path specified: 'Z:\\\\Nimrod\\\\experiments\\\\PV_57\\\\2024_11_25\\\\block_007\\\\oe_files\\\\pv_57_day2_03_2024-11-25_15-28-31\\\\Record Node 102\\\\analysis'\n",
      "Skipping block PV_57, block 008, on pv_57_day2_05_2024-11-25_16-07-18: [WinError 3] The system cannot find the path specified: 'Z:\\\\Nimrod\\\\experiments\\\\PV_57\\\\2024_11_25\\\\block_008\\\\oe_files\\\\pv_57_day2_05_2024-11-25_16-07-18\\\\Record Node 102\\\\analysis'\n",
      "Skipping block PV_57, block 009, on pv_57_day2_06_2024-11-25_16-25-35: [WinError 3] The system cannot find the path specified: 'Z:\\\\Nimrod\\\\experiments\\\\PV_57\\\\2024_11_25\\\\block_009\\\\oe_files\\\\pv_57_day2_06_2024-11-25_16-25-35\\\\Record Node 102\\\\analysis'\n",
      "Skipping block PV_57, block 012, on PV_57_hunter_2_2024-12-01_16-08-39: [WinError 3] The system cannot find the path specified: 'Z:\\\\Nimrod\\\\experiments\\\\PV_57\\\\2024_12_01\\\\block_012\\\\oe_files\\\\PV_57_hunter_2_2024-12-01_16-08-39\\\\Record Node 102\\\\analysis'\n",
      "Skipping block PV_57, block 013, on PV_57_hunter_2_2024-12-01_16-34-43: [WinError 3] The system cannot find the path specified: 'Z:\\\\Nimrod\\\\experiments\\\\PV_57\\\\2024_12_01\\\\block_013\\\\oe_files\\\\PV_57_hunter_2_2024-12-01_16-34-43\\\\Record Node 102\\\\analysis'\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:07.932178Z",
     "start_time": "2025-11-06T10:24:07.840154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add annotations for a joint dataframe:\n",
    "for block in block_collection:\n",
    "    block.r_saccade_df['eye'] = 'R'\n",
    "    block.r_saccade_df['block'] = block.block_num\n",
    "    block.r_saccade_df['animal'] = block.animal_call\n",
    "    block.l_saccade_df['eye'] = 'L'\n",
    "    block.l_saccade_df['block'] = block.block_num\n",
    "    block.l_saccade_df['animal'] = block.animal_call\n",
    "    block.all_saccade_df = pd.concat([block.l_saccade_df,block.r_saccade_df])"
   ],
   "id": "b057bb3dc8d645bb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:08.012178Z",
     "start_time": "2025-11-06T10:24:07.965155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "saccade_df_list = []\n",
    "for block in block_collection:\n",
    "    saccade_df_list.append(block.all_saccade_df)\n",
    "saccade_collection = pd.concat(saccade_df_list)"
   ],
   "id": "cc568dc789a062ae",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:12.513304Z",
     "start_time": "2025-11-06T10:24:08.045154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_closest_diff_ind(timestamp, timeseries):\n",
    "    \"\"\"\n",
    "    This function extracts a frame from a series so that it is as close as possible to a given timestamp\n",
    "    :param timestamp: The time to match a frame to\n",
    "    :param timeseries: The time frames series to look at for a match\n",
    "    :param report_acc: if set to 1, will report the accuracy of the match\n",
    "    :return: index_of_lowest_diff , accuracy of match (if requested)\n",
    "    \"\"\"\n",
    "    array = np.abs(timeseries - timestamp)\n",
    "    index_of_lowest_diff = np.argmin(array)\n",
    "    lowest_diff_val = timeseries[index_of_lowest_diff]\n",
    "    return index_of_lowest_diff, lowest_diff_val\n",
    "\n",
    "def find_synced_saccades(df, diff_threshold=680):\n",
    "    synced_saccades = []\n",
    "    non_synced_saccades = []\n",
    "    l_df = df.query('eye == \"L\"')\n",
    "    r_df = df.query('eye == \"R\"')\n",
    "    for i, row in tqdm.tqdm(l_df.iterrows()):\n",
    "        l_timestamp = row['saccade_start_timestamp']\n",
    "        ind_min_diff, r_timestamp = get_closest_diff_ind(l_timestamp, r_df['saccade_start_timestamp'].values)\n",
    "        #print(i,ind_lowest_diff)\n",
    "        time_diff = np.abs(l_timestamp - r_timestamp)\n",
    "        if time_diff < diff_threshold:\n",
    "            synced_saccades.append((row, r_df.iloc[ind_min_diff]))  # Collect synchronized rows\n",
    "        else:\n",
    "            non_synced_saccades.append(row)  # Collect non-synchronized rows\n",
    "    # Create DataFrame with multi-index\n",
    "    multi_index = pd.MultiIndex.from_tuples([(i, 'L') for i in range(len(synced_saccades))] + [(i, 'R') for i in range(len(synced_saccades))], names=['Main', 'Sub'])\n",
    "    synced_df = pd.DataFrame(index=multi_index, columns=df.columns)\n",
    "    # Populate DataFrame\n",
    "    for idx, (l_row, r_row) in enumerate(synced_saccades):\n",
    "        synced_df.loc[(idx, 'L')] = l_row\n",
    "        synced_df.loc[(idx, 'R')] = r_row\n",
    "    r_non_synced_leftovers = r_df[~r_df['saccade_start_timestamp'].isin(synced_df.query('eye == \"R\"')['saccade_start_timestamp'].values)]\n",
    "    print(len(r_non_synced_leftovers),len(r_df))\n",
    "    # Create DataFrame for non-synced saccades\n",
    "    non_synced_df = pd.DataFrame(non_synced_saccades, columns=df.columns)\n",
    "    non_synced_df = pd.concat([non_synced_df,r_non_synced_leftovers])\n",
    "\n",
    "    return synced_df, non_synced_df\n",
    "\n",
    "synced_df_list = []\n",
    "non_synced_df_list = []\n",
    "for saccade_df in saccade_df_list:\n",
    "    # Find synced saccades:\n",
    "    synced_df, non_synced_df = find_synced_saccades(saccade_df.dropna(), diff_threshold=680)\n",
    "    if len(non_synced_df.dropna()) + len(synced_df.dropna()) == len(saccade_df.dropna()):\n",
    "        print('got them all')\n",
    "\n",
    "    synced_df_list.append(synced_df)\n",
    "    non_synced_df_list.append(non_synced_df)\n"
   ],
   "id": "800e87430df36e3b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "924it [00:00, 5702.89it/s]\n",
      "395it [00:00, 7178.54it/s]\n",
      "472it [00:00, 8003.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 517\n",
      "102 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1273it [00:00, 8005.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "724it [00:00, 8514.99it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377 961\n",
      "333 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "519it [00:00, 7015.94it/s]\n",
      "322it [00:00, 8050.30it/s]\n",
      "387it [00:00, 7438.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 565\n",
      "145 320\n",
      "256 495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "265it [00:00, 7788.57it/s]\n",
      "675it [00:00, 7938.21it/s]\n",
      "406it [00:00, 4058.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 207\n",
      "262 638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "623it [00:00, 4789.91it/s]\n",
      "1090it [00:00, 8132.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "722it [00:00, 7218.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071 1649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1409it [00:00, 7116.21it/s]\n",
      "429it [00:00, 7530.01it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435 1315\n",
      "289 541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "529it [00:00, 7782.21it/s]\n",
      "271it [00:00, 7528.02it/s]\n",
      "691it [00:00, 6841.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 539\n",
      "183 353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1056it [00:00, 6600.07it/s]\n",
      "112it [00:00, 1726.09it/s]\n",
      "693it [00:00, 6863.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539 1251\n",
      "53 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "934it [00:00, 6819.04it/s]\n",
      "949it [00:00, 6499.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635 2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "794it [00:00, 7351.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461 1087\n",
      "487 888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "786it [00:00, 6718.07it/s]\n",
      "999it [00:00, 6241.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286 763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573 1245\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:12.638246Z",
     "start_time": "2025-11-06T10:24:12.577219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_synced_dataframes(dataframes):\n",
    "    combined_dfs = []\n",
    "    start_index = 0\n",
    "    for df in dataframes:\n",
    "        num_rows = len(df) // 2  # Assuming each dataframe contains pairs of rows\n",
    "        main_index = pd.MultiIndex.from_tuples([(i + start_index, 'L') for i in range(num_rows)] + [(i + start_index, 'R') for i in range(num_rows)], names=['Main', 'Sub'])\n",
    "        df.index = main_index\n",
    "        combined_dfs.append(df)\n",
    "        start_index += num_rows\n",
    "    combined_df = pd.concat(combined_dfs)\n",
    "    combined_df.reset_index(inplace=True)\n",
    "    return combined_df\n",
    "\n",
    "synced_saccade_collection = combine_synced_dataframes(synced_df_list)\n",
    "non_synced_saccade_collection = pd.concat(non_synced_df_list)\n"
   ],
   "id": "c7b16a6bc85a8d5a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:12.761218Z",
     "start_time": "2025-11-06T10:24:12.716219Z"
    }
   },
   "cell_type": "code",
   "source": "all_saccade_collection = pd.concat([synced_saccade_collection,non_synced_saccade_collection])\n",
   "id": "bc94e2ffad89189",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:24:00.450411Z",
     "start_time": "2025-11-09T10:23:58.673839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %% [single cell] Eye-closure bouts  5 s across multiple blocks (per eye)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import datetime as _dt\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional, Iterable\n",
    "\n",
    "# ----------------------------\n",
    "# Config (feel free to tweak)\n",
    "# ----------------------------\n",
    "MIN_CLOSURE_S = 5.0          # minimum bout duration in seconds\n",
    "BRIDGE_GAP_MS = 200.0        # bridge short gaps between closures (fill<=this)\n",
    "LOW_QUANTILE = 0.002         # additional rule: sustained tiny pupil threshold (0.2% quantile)\n",
    "USE_TINY_PUPIL_RULE = True   # apply low-quantile rule in addition to NaN rule\n",
    "EXPORT_DIR = None            # e.g., r\"Z:\\Nimrod\\exports\" or None for no export\n",
    "FONT_FAMILY = 'Arial'\n",
    "\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = [FONT_FAMILY]\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype']  = 42\n",
    "\n",
    "# ----------------------------\n",
    "# Helper dataclasses\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class EyeSignals:\n",
    "    ms: np.ndarray\n",
    "    pupil: np.ndarray  # float array (may include NaN), chosen from available columns\n",
    "    source: str        # which column we used\n",
    "\n",
    "@dataclass\n",
    "class ClosureBout:\n",
    "    block_key: str\n",
    "    eye: str\n",
    "    start_ms: float\n",
    "    end_ms: float\n",
    "    duration_s: float\n",
    "    rule: str  # 'nan_only' or 'nan_or_tiny'\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def _infer_fs(ms: np.ndarray, fallback=60.0) -> float:\n",
    "    \"\"\"Infer sampling frequency from ms_axis (robust to outliers).\"\"\"\n",
    "    if ms.size < 2:\n",
    "        return fallback\n",
    "    diffs = np.diff(ms.astype(np.float64))\n",
    "    diffs = diffs[np.isfinite(diffs) & (diffs > 0)]\n",
    "    if diffs.size == 0:\n",
    "        return fallback\n",
    "    med_dt = np.median(diffs)  # in ms\n",
    "    fs = 1000.0 / med_dt\n",
    "    return float(fs) if np.isfinite(fs) and fs > 0 else fallback\n",
    "\n",
    "def _select_pupil_column(df: pd.DataFrame) -> Tuple[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Choose best available pupil metric in priority order.\n",
    "    Returns (source_name, values as float array).\n",
    "    \"\"\"\n",
    "    candidates = ['pupil_diameter', 'pupil_diameter_pixels', 'minor_ax', 'height']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            vals = pd.to_numeric(df[c], errors='coerce').astype(float).values\n",
    "            return c, vals\n",
    "    # Fallback: no usable column  all NaN vector\n",
    "    return 'none', np.full(len(df), np.nan, dtype=float)\n",
    "\n",
    "def _build_closed_mask(ms: np.ndarray, pupil: np.ndarray,\n",
    "                       use_tiny_rule: bool,\n",
    "                       low_quantile: float) -> Tuple[np.ndarray, str, Optional[float]]:\n",
    "    \"\"\"\n",
    "    Closed if:\n",
    "      (A) pupil is NaN (proxy for tracking loss, typical during eyelid occlusion),\n",
    "    OR (B) pupil < adaptive threshold (LOW_QUANTILE) if use_tiny_rule=True and enough finite data.\n",
    "    Returns: (bool mask same length as ms, rule_str, threshold_or_None)\n",
    "    \"\"\"\n",
    "    is_nan = ~np.isfinite(pupil)\n",
    "    rule = 'nan_only'\n",
    "    thr_val = None\n",
    "\n",
    "    mask = is_nan.copy()\n",
    "    if use_tiny_rule:\n",
    "        finite = pupil[np.isfinite(pupil)]\n",
    "        if finite.size > 200:  # require enough samples to define a robust tiny threshold\n",
    "            thr_val = np.quantile(finite, low_quantile)\n",
    "            tiny = np.isfinite(pupil) & (pupil <= thr_val)\n",
    "            mask = mask | tiny\n",
    "            rule = 'nan_or_tiny'\n",
    "    return mask, rule, thr_val\n",
    "\n",
    "def _bridge_small_gaps(mask: np.ndarray, ms: np.ndarray, max_gap_ms: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Bridge short false negatives between closed samples: if open gaps shorter than max_gap_ms,\n",
    "    fill them closed. Works on 1D boolean arrays.\n",
    "    \"\"\"\n",
    "    if mask.size == 0:\n",
    "        return mask\n",
    "    out = mask.copy()\n",
    "    n = out.size\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if not out[i]:\n",
    "            i += 1\n",
    "            continue\n",
    "        # we're at a closed run; find its end\n",
    "        j = i\n",
    "        while j < n and out[j]:\n",
    "            j += 1\n",
    "        # now j is first False or n\n",
    "        k = j\n",
    "        while k < n and not out[k]:\n",
    "            k += 1\n",
    "        # now k is first True after the open gap, or n\n",
    "        if j < n and k < n:\n",
    "            # open gap from j..k-1\n",
    "            gap_ms = ms[k-1] - ms[j] if k-1 >= j else 0.0\n",
    "            if gap_ms <= max_gap_ms:\n",
    "                out[j:k] = True\n",
    "        i = k\n",
    "    return out\n",
    "\n",
    "def _bouts_from_mask(mask: np.ndarray, ms: np.ndarray, min_duration_s: float) -> List[Tuple[float,float]]:\n",
    "    \"\"\"Return list of (start_ms, end_ms) for contiguous True runs with duration >= min_duration_s.\"\"\"\n",
    "    bouts: List[Tuple[float,float]] = []\n",
    "    n = mask.size\n",
    "    if n == 0:\n",
    "        return bouts\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if not mask[i]:\n",
    "            i += 1\n",
    "            continue\n",
    "        j = i\n",
    "        while j < n and mask[j]:\n",
    "            j += 1\n",
    "        start_ms = ms[i]\n",
    "        end_ms   = ms[j-1]\n",
    "        dur_s = (end_ms - start_ms) / 1000.0\n",
    "        if dur_s >= min_duration_s:\n",
    "            bouts.append((float(start_ms), float(end_ms)))\n",
    "        i = j\n",
    "    return bouts\n",
    "\n",
    "def _extract_eye_signals(df: pd.DataFrame) -> EyeSignals:\n",
    "    ms = pd.to_numeric(df['ms_axis'], errors='coerce').astype(float).values\n",
    "    src, pupil = _select_pupil_column(df)\n",
    "    return EyeSignals(ms=ms, pupil=pupil, source=src)\n",
    "\n",
    "# ----------------------------\n",
    "# Main analysis\n",
    "# ----------------------------\n",
    "def find_eye_closure_bouts(\n",
    "    blocks: Iterable,\n",
    "    *,\n",
    "    min_closure_s: float = MIN_CLOSURE_S,\n",
    "    bridge_gap_ms: float = BRIDGE_GAP_MS,\n",
    "    use_tiny_rule: bool = USE_TINY_PUPIL_RULE,\n",
    "    low_quantile: float = LOW_QUANTILE,\n",
    "    export_dir: Optional[str] = EXPORT_DIR,\n",
    "    block_name_getter=None,          # optional function(block)->str\n",
    "    plot_examples: int = 3,          # number of example plots to draw\n",
    "    suppress_qc: bool = False,       # if True, close figures instead of showing\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Dict[str, dict]]]:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    blocks : iterable of Block-like objects or dict of key->Block\n",
    "        Block must expose .left_eye_data and .right_eye_data DataFrames with 'ms_axis' and a pupil metric.\n",
    "    min_closure_s : float\n",
    "        Minimum bout duration to report (seconds).\n",
    "    bridge_gap_ms : float\n",
    "        Bridge short open gaps between closed segments (ms).\n",
    "    use_tiny_rule : bool\n",
    "        If True, also treat extremely small sustained pupil values as closed (adaptive LOW_QUANTILE).\n",
    "    low_quantile : float\n",
    "        Quantile for the tiny-pupil threshold (0..1).\n",
    "    export_dir : str or None\n",
    "        If provided, saves CSV + plots.\n",
    "    block_name_getter : callable or None\n",
    "        If provided, called as name = block_name_getter(block). Otherwise attempt heuristics.\n",
    "    plot_examples : int\n",
    "        Produce up to this many quick QC plots (per eye).\n",
    "    suppress_qc : bool\n",
    "        If True, figures are created and saved (if export_dir) but not shown.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bouts_df : DataFrame with columns\n",
    "        ['block','eye','start_ms','end_ms','duration_s','rule']\n",
    "    diagnostics : nested dict\n",
    "        diagnostics[block][eye] = {\n",
    "            'fs': float, 'bridge_gap_ms': float, 'low_quantile': float, 'tiny_threshold': float or None,\n",
    "            'source_signal': str, 'n_samples': int, 'n_nan': int\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Normalize blocks to iterable of (key, block)\n",
    "    if isinstance(blocks, dict):\n",
    "        items = list(blocks.items())\n",
    "    else:\n",
    "        items = []\n",
    "        for idx, b in enumerate(blocks):\n",
    "            if block_name_getter is not None:\n",
    "                key = block_name_getter(b)\n",
    "            else:\n",
    "                key = getattr(b, 'name', None)\n",
    "                if key is None:\n",
    "                    animal = getattr(b, 'animal_call', 'UNK')\n",
    "                    num    = getattr(b, 'block_num', idx)\n",
    "                    key = f\"{animal}_block_{int(num):03d}\" if isinstance(num, (int, np.integer)) else f\"{animal}_block_{num}\"\n",
    "            items.append((key, b))\n",
    "\n",
    "    rows = []\n",
    "    diagnostics: Dict[str, Dict[str, dict]] = {}\n",
    "\n",
    "    for key, block in items:\n",
    "        # --- safely get DataFrames (avoid \"or\" with DataFrames) ---\n",
    "        L = getattr(block, 'left_eye_data', None)\n",
    "        if L is None:\n",
    "            L = getattr(block, 'left_eye_data_clean', None)\n",
    "\n",
    "        R = getattr(block, 'right_eye_data', None)\n",
    "        if R is None:\n",
    "            R = getattr(block, 'right_eye_data_clean', None)\n",
    "\n",
    "        block_diag = {}\n",
    "        for eye_label, df in (('L', L), ('R', R)):\n",
    "            if df is None or 'ms_axis' not in df.columns:\n",
    "                continue\n",
    "\n",
    "            sig = _extract_eye_signals(df)\n",
    "            if sig.ms.size == 0:\n",
    "                continue\n",
    "\n",
    "            fs = _infer_fs(sig.ms)\n",
    "\n",
    "            # closed mask\n",
    "            closed_mask, rule, thr_val = _build_closed_mask(\n",
    "                sig.ms, sig.pupil, use_tiny_rule=use_tiny_rule, low_quantile=low_quantile\n",
    "            )\n",
    "            # bridge small open gaps between closures\n",
    "            bridged = _bridge_small_gaps(closed_mask, sig.ms, max_gap_ms=bridge_gap_ms)\n",
    "\n",
    "            # bouts\n",
    "            bouts = _bouts_from_mask(bridged, sig.ms, min_duration_s=min_closure_s)\n",
    "            rows.extend([\n",
    "                {\n",
    "                    'block': key,\n",
    "                    'eye': eye_label,\n",
    "                    'start_ms': t0,\n",
    "                    'end_ms': t1,\n",
    "                    'duration_s': (t1 - t0)/1000.0,\n",
    "                    'rule': rule\n",
    "                }\n",
    "                for (t0, t1) in bouts\n",
    "            ])\n",
    "\n",
    "            block_diag[eye_label] = {\n",
    "                'fs': float(fs),\n",
    "                'bridge_gap_ms': float(bridge_gap_ms),\n",
    "                'low_quantile': float(low_quantile),\n",
    "                'tiny_threshold': None if thr_val is None or not np.isfinite(thr_val) else float(thr_val),\n",
    "                'source_signal': sig.source,\n",
    "                'n_samples': int(sig.ms.size),\n",
    "                'n_nan': int(np.count_nonzero(~np.isfinite(sig.pupil))),\n",
    "            }\n",
    "        diagnostics[key] = block_diag\n",
    "\n",
    "    bouts_df = pd.DataFrame(\n",
    "        rows, columns=['block','eye','start_ms','end_ms','duration_s','rule']\n",
    "    ).sort_values(['block','eye','start_ms']).reset_index(drop=True)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Exports\n",
    "    # ----------------------------\n",
    "    outdir = None\n",
    "    if export_dir is not None:\n",
    "        ts = _dt.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        outdir = Path(export_dir) / f\"eye_closure_bouts_{ts}\"\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "        bouts_df.to_csv(outdir / \"closure_bouts_over_5s.csv\", index=False)\n",
    "        import json\n",
    "        with open(outdir / \"diagnostics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(diagnostics, f, indent=2)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Quick QC plots (up to N examples per eye)\n",
    "    # ----------------------------\n",
    "    def _plot_example(block_key: str, eye: str, df: pd.DataFrame):\n",
    "        # plot pupil signal with marked closures\n",
    "        if outdir is not None:\n",
    "            save_path = outdir / f\"qc_{block_key}_{eye}.pdf\"\n",
    "        else:\n",
    "            save_path = None\n",
    "\n",
    "        sig = _extract_eye_signals(df)\n",
    "        ms = sig.ms\n",
    "        y  = sig.pupil\n",
    "        closed_mask, rule, thr_val = _build_closed_mask(ms, y, use_tiny_rule=USE_TINY_PUPIL_RULE, low_quantile=LOW_QUANTILE)\n",
    "        bridged = _bridge_small_gaps(closed_mask, ms, BRIDGE_GAP_MS)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7.0, 2.0), dpi=300)\n",
    "        ax.plot(ms/1000.0, y, lw=0.6)\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel(sig.source if sig.source != 'none' else 'pupil (none)')\n",
    "        ax.set_title(f\"{block_key} {eye}  rule={rule} thr={None if thr_val is None else np.round(thr_val,4)}\")\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ax.fill_between(ms/1000.0, ymin, ymax, where=bridged, alpha=0.18, step='pre')\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.grid(False)\n",
    "        plt.tight_layout()\n",
    "        if save_path is not None:\n",
    "            fig.savefig(save_path, bbox_inches='tight')\n",
    "        if suppress_qc:\n",
    "            plt.close(fig)\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    # Choose a few examples to visualize\n",
    "    if not bouts_df.empty and plot_examples > 0:\n",
    "        shown = 0\n",
    "        seen = set()\n",
    "        for _, row in bouts_df.iterrows():\n",
    "            k = (row['block'], row['eye'])\n",
    "            if k in seen:\n",
    "                continue\n",
    "            seen.add(k)\n",
    "            # recover the original block object by key\n",
    "            block = dict(items).get(row['block']) if isinstance(blocks, dict) else None\n",
    "            if block is None and not isinstance(blocks, dict):\n",
    "                for kk, b in items:\n",
    "                    if kk == row['block']:\n",
    "                        block = b\n",
    "                        break\n",
    "            if block is None:\n",
    "                continue\n",
    "\n",
    "            # safely fetch DF for plotting\n",
    "            if row['eye'] == 'L':\n",
    "                df = getattr(block, 'left_eye_data', None)\n",
    "                if df is None:\n",
    "                    df = getattr(block, 'left_eye_data_clean', None)\n",
    "            else:\n",
    "                df = getattr(block, 'right_eye_data', None)\n",
    "                if df is None:\n",
    "                    df = getattr(block, 'right_eye_data_clean', None)\n",
    "\n",
    "            if df is None or 'ms_axis' not in df.columns:\n",
    "                continue\n",
    "\n",
    "            _plot_example(row['block'], row['eye'], df)\n",
    "            shown += 1\n",
    "            if shown >= 2*plot_examples:  # up to N per eye\n",
    "                break\n",
    "\n",
    "    # ----------------------------\n",
    "    # Print a compact summary (version-agnostic)\n",
    "    # ----------------------------\n",
    "    if bouts_df.empty:\n",
    "        print(f\"No eye-closure bouts  {min_closure_s:.1f}s detected.\")\n",
    "    else:\n",
    "        try:\n",
    "            summary = (\n",
    "                bouts_df\n",
    "                .groupby(['block','eye'], as_index=False)\n",
    "                .agg(\n",
    "                    n_bouts=('duration_s', 'count'),\n",
    "                    total_s=('duration_s', 'sum'),\n",
    "                    median_s=('duration_s', 'median'),\n",
    "                    max_s=('duration_s', 'max'),\n",
    "                )\n",
    "            )\n",
    "        except TypeError:\n",
    "            g = bouts_df.groupby(['block','eye'])['duration_s']\n",
    "            summary = g.agg(['count','sum','median','max']).reset_index()\n",
    "            summary = summary.rename(columns={'count':'n_bouts','sum':'total_s','median':'median_s','max':'max_s'})\n",
    "\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            display(summary)\n",
    "        except Exception:\n",
    "            print(summary.to_string(index=False))\n",
    "\n",
    "        if outdir is not None:\n",
    "            summary.to_csv(outdir / \"closure_summary.csv\", index=False)\n",
    "            print(\"Saved:\", outdir)\n",
    "\n",
    "    # *** ALWAYS return ***\n",
    "    return bouts_df, diagnostics\n",
    "\n",
    "# ----------------------------\n",
    "# Example usage\n",
    "# ----------------------------\n",
    "bouts_df, diagnostics = find_eye_closure_bouts(\n",
    "    block_dict,\n",
    "    min_closure_s=5.0,\n",
    "    bridge_gap_ms=200.0,\n",
    "    use_tiny_rule=True,\n",
    "    low_quantile=0.002,\n",
    "    export_dir=r\"Z:\\Nimrod\\experiments\\unihemispheric_analysis\",\n",
    "    plot_examples=0,\n",
    "    suppress_qc=True,\n",
    ")\n"
   ],
   "id": "5f2c53b882ddfbe4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               block eye  n_bouts     total_s    median_s      max_s\n",
       "0   PV_106_block_008   L        8    85.18140   10.023300   18.56475\n",
       "1   PV_106_block_008   R        6    58.07520   10.023300   12.85380\n",
       "2   PV_106_block_009   L        9   110.37285   10.872450   26.35695\n",
       "3   PV_106_block_009   R        7    79.60365    9.240750   20.69595\n",
       "4   PV_106_block_010   L       13   135.58095   10.672650   16.63335\n",
       "5   PV_106_block_010   R       15   153.16335   10.972350   15.45120\n",
       "6   PV_106_block_011   L       23   280.00305    9.357300   65.96730\n",
       "7   PV_106_block_011   R       11   150.46605    8.175150   47.53575\n",
       "8   PV_106_block_012   L       38   454.66155   10.797525   32.48415\n",
       "9   PV_106_block_012   R       27   269.28045    8.524800   21.49515\n",
       "10  PV_126_block_007   L        1     7.03330    7.033300    7.03330\n",
       "11  PV_126_block_007   R        4    53.48330   10.258325   24.85000\n",
       "12  PV_126_block_008   L       17  1662.91505   38.488350  716.70450\n",
       "13  PV_126_block_008   R       30  1403.25620   23.879675  248.88730\n",
       "14  PV_126_block_009   L       30   589.41600   12.920650   81.58060\n",
       "15  PV_126_block_009   R       26   922.35415   24.139275  151.36330\n",
       "16  PV_126_block_010   L       13   443.81235   32.853450   94.24560\n",
       "17  PV_126_block_010   R       15   557.09920   20.750750  140.54645\n",
       "18  PV_143_block_001   L       17   173.87595    9.040950   29.95335\n",
       "19  PV_143_block_001   R        9   122.89365   12.604050   26.50680\n",
       "20  PV_143_block_002   L       18   439.69320   18.697950   59.54040\n",
       "21  PV_143_block_002   R       23   610.63875   17.682300   86.53005\n",
       "22  PV_143_block_003   L       14   382.90005   18.073575  101.54835\n",
       "23  PV_143_block_003   R       14   381.46815   19.913400   58.87440\n",
       "24  PV_143_block_004   L       18   455.81040   15.359625  139.41045\n",
       "25  PV_143_block_004   R       11   697.18545   17.382600  423.54270\n",
       "26   PV_57_block_007   R        3    22.99025    6.835100   11.02945\n",
       "27   PV_57_block_009   L        1   258.48160  258.481600  258.48160\n",
       "28   PV_57_block_009   R        1   238.21360  238.213600  238.21360\n",
       "29   PV_57_block_012   L        1     5.11025    5.110250    5.11025\n",
       "30   PV_57_block_013   L        1    77.46465   77.464650   77.46465\n",
       "31   PV_57_block_013   R        1    77.54925   77.549250   77.54925\n",
       "32   PV_62_block_024   R        3    25.59840    7.795500   11.21095\n",
       "33   PV_62_block_026   L        1     5.80850    5.808500    5.80850\n",
       "34   PV_62_block_038   L       11    91.71265    7.998200   11.63650\n",
       "35   PV_62_block_038   R        6    55.80495    7.980850   17.19045"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>eye</th>\n",
       "      <th>n_bouts</th>\n",
       "      <th>total_s</th>\n",
       "      <th>median_s</th>\n",
       "      <th>max_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PV_106_block_008</td>\n",
       "      <td>L</td>\n",
       "      <td>8</td>\n",
       "      <td>85.18140</td>\n",
       "      <td>10.023300</td>\n",
       "      <td>18.56475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PV_106_block_008</td>\n",
       "      <td>R</td>\n",
       "      <td>6</td>\n",
       "      <td>58.07520</td>\n",
       "      <td>10.023300</td>\n",
       "      <td>12.85380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PV_106_block_009</td>\n",
       "      <td>L</td>\n",
       "      <td>9</td>\n",
       "      <td>110.37285</td>\n",
       "      <td>10.872450</td>\n",
       "      <td>26.35695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PV_106_block_009</td>\n",
       "      <td>R</td>\n",
       "      <td>7</td>\n",
       "      <td>79.60365</td>\n",
       "      <td>9.240750</td>\n",
       "      <td>20.69595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PV_106_block_010</td>\n",
       "      <td>L</td>\n",
       "      <td>13</td>\n",
       "      <td>135.58095</td>\n",
       "      <td>10.672650</td>\n",
       "      <td>16.63335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PV_106_block_010</td>\n",
       "      <td>R</td>\n",
       "      <td>15</td>\n",
       "      <td>153.16335</td>\n",
       "      <td>10.972350</td>\n",
       "      <td>15.45120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PV_106_block_011</td>\n",
       "      <td>L</td>\n",
       "      <td>23</td>\n",
       "      <td>280.00305</td>\n",
       "      <td>9.357300</td>\n",
       "      <td>65.96730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PV_106_block_011</td>\n",
       "      <td>R</td>\n",
       "      <td>11</td>\n",
       "      <td>150.46605</td>\n",
       "      <td>8.175150</td>\n",
       "      <td>47.53575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PV_106_block_012</td>\n",
       "      <td>L</td>\n",
       "      <td>38</td>\n",
       "      <td>454.66155</td>\n",
       "      <td>10.797525</td>\n",
       "      <td>32.48415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PV_106_block_012</td>\n",
       "      <td>R</td>\n",
       "      <td>27</td>\n",
       "      <td>269.28045</td>\n",
       "      <td>8.524800</td>\n",
       "      <td>21.49515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PV_126_block_007</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>7.03330</td>\n",
       "      <td>7.033300</td>\n",
       "      <td>7.03330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PV_126_block_007</td>\n",
       "      <td>R</td>\n",
       "      <td>4</td>\n",
       "      <td>53.48330</td>\n",
       "      <td>10.258325</td>\n",
       "      <td>24.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PV_126_block_008</td>\n",
       "      <td>L</td>\n",
       "      <td>17</td>\n",
       "      <td>1662.91505</td>\n",
       "      <td>38.488350</td>\n",
       "      <td>716.70450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PV_126_block_008</td>\n",
       "      <td>R</td>\n",
       "      <td>30</td>\n",
       "      <td>1403.25620</td>\n",
       "      <td>23.879675</td>\n",
       "      <td>248.88730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PV_126_block_009</td>\n",
       "      <td>L</td>\n",
       "      <td>30</td>\n",
       "      <td>589.41600</td>\n",
       "      <td>12.920650</td>\n",
       "      <td>81.58060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PV_126_block_009</td>\n",
       "      <td>R</td>\n",
       "      <td>26</td>\n",
       "      <td>922.35415</td>\n",
       "      <td>24.139275</td>\n",
       "      <td>151.36330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PV_126_block_010</td>\n",
       "      <td>L</td>\n",
       "      <td>13</td>\n",
       "      <td>443.81235</td>\n",
       "      <td>32.853450</td>\n",
       "      <td>94.24560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PV_126_block_010</td>\n",
       "      <td>R</td>\n",
       "      <td>15</td>\n",
       "      <td>557.09920</td>\n",
       "      <td>20.750750</td>\n",
       "      <td>140.54645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PV_143_block_001</td>\n",
       "      <td>L</td>\n",
       "      <td>17</td>\n",
       "      <td>173.87595</td>\n",
       "      <td>9.040950</td>\n",
       "      <td>29.95335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PV_143_block_001</td>\n",
       "      <td>R</td>\n",
       "      <td>9</td>\n",
       "      <td>122.89365</td>\n",
       "      <td>12.604050</td>\n",
       "      <td>26.50680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PV_143_block_002</td>\n",
       "      <td>L</td>\n",
       "      <td>18</td>\n",
       "      <td>439.69320</td>\n",
       "      <td>18.697950</td>\n",
       "      <td>59.54040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PV_143_block_002</td>\n",
       "      <td>R</td>\n",
       "      <td>23</td>\n",
       "      <td>610.63875</td>\n",
       "      <td>17.682300</td>\n",
       "      <td>86.53005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PV_143_block_003</td>\n",
       "      <td>L</td>\n",
       "      <td>14</td>\n",
       "      <td>382.90005</td>\n",
       "      <td>18.073575</td>\n",
       "      <td>101.54835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PV_143_block_003</td>\n",
       "      <td>R</td>\n",
       "      <td>14</td>\n",
       "      <td>381.46815</td>\n",
       "      <td>19.913400</td>\n",
       "      <td>58.87440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PV_143_block_004</td>\n",
       "      <td>L</td>\n",
       "      <td>18</td>\n",
       "      <td>455.81040</td>\n",
       "      <td>15.359625</td>\n",
       "      <td>139.41045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PV_143_block_004</td>\n",
       "      <td>R</td>\n",
       "      <td>11</td>\n",
       "      <td>697.18545</td>\n",
       "      <td>17.382600</td>\n",
       "      <td>423.54270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PV_57_block_007</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>22.99025</td>\n",
       "      <td>6.835100</td>\n",
       "      <td>11.02945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PV_57_block_009</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>258.48160</td>\n",
       "      <td>258.481600</td>\n",
       "      <td>258.48160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PV_57_block_009</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>238.21360</td>\n",
       "      <td>238.213600</td>\n",
       "      <td>238.21360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PV_57_block_012</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>5.11025</td>\n",
       "      <td>5.110250</td>\n",
       "      <td>5.11025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PV_57_block_013</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>77.46465</td>\n",
       "      <td>77.464650</td>\n",
       "      <td>77.46465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PV_57_block_013</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>77.54925</td>\n",
       "      <td>77.549250</td>\n",
       "      <td>77.54925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PV_62_block_024</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>25.59840</td>\n",
       "      <td>7.795500</td>\n",
       "      <td>11.21095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PV_62_block_026</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>5.80850</td>\n",
       "      <td>5.808500</td>\n",
       "      <td>5.80850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PV_62_block_038</td>\n",
       "      <td>L</td>\n",
       "      <td>11</td>\n",
       "      <td>91.71265</td>\n",
       "      <td>7.998200</td>\n",
       "      <td>11.63650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PV_62_block_038</td>\n",
       "      <td>R</td>\n",
       "      <td>6</td>\n",
       "      <td>55.80495</td>\n",
       "      <td>7.980850</td>\n",
       "      <td>17.19045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Z:\\Nimrod\\experiments\\unihemispheric_analysis\\eye_closure_bouts_2025_11_09_12_24_00\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:26:28.476778Z",
     "start_time": "2025-11-09T10:26:28.456655Z"
    }
   },
   "cell_type": "code",
   "source": "print(diagnostics)",
   "id": "f81441839fe6778e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PV_106_block_008': {'L': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.4440854273007206, 'source_signal': 'pupil_diameter', 'n_samples': 57621, 'n_nan': 5533}, 'R': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.3387097646875374, 'source_signal': 'pupil_diameter', 'n_samples': 57621, 'n_nan': 4154}}, 'PV_106_block_009': {'L': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.459378938004748, 'source_signal': 'pupil_diameter', 'n_samples': 57637, 'n_nan': 8085}, 'R': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.3981903035321968, 'source_signal': 'pupil_diameter', 'n_samples': 57637, 'n_nan': 6728}}, 'PV_106_block_010': {'L': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.4358608669272046, 'source_signal': 'pupil_diameter', 'n_samples': 57610, 'n_nan': 9746}, 'R': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.3608593288522708, 'source_signal': 'pupil_diameter', 'n_samples': 57610, 'n_nan': 10411}}, 'PV_106_block_011': {'L': {'fs': 60.06006006005481, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.133113410496008, 'source_signal': 'pupil_diameter', 'n_samples': 129713, 'n_nan': 20877}, 'R': {'fs': 60.06006006005481, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.186688120448499, 'source_signal': 'pupil_diameter', 'n_samples': 129713, 'n_nan': 11329}}, 'PV_106_block_012': {'L': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.4093809976521923, 'source_signal': 'pupil_diameter', 'n_samples': 112178, 'n_nan': 31590}, 'R': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.3975997834313219, 'source_signal': 'pupil_diameter', 'n_samples': 112178, 'n_nan': 19367}}, 'PV_143_block_001': {'L': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.1968722778979346, 'source_signal': 'pupil_diameter', 'n_samples': 73151, 'n_nan': 15118}, 'R': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.2622489770423606, 'source_signal': 'pupil_diameter', 'n_samples': 73151, 'n_nan': 8131}}, 'PV_143_block_002': {'L': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.1209555223962535, 'source_signal': 'pupil_diameter', 'n_samples': 80795, 'n_nan': 28032}, 'R': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.2035249655071618, 'source_signal': 'pupil_diameter', 'n_samples': 80795, 'n_nan': 36764}}, 'PV_143_block_003': {'L': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.2723181787648876, 'source_signal': 'pupil_diameter', 'n_samples': 85414, 'n_nan': 25210}, 'R': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.3088223472937117, 'source_signal': 'pupil_diameter', 'n_samples': 85414, 'n_nan': 23741}}, 'PV_143_block_004': {'L': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.3538693428930073, 'source_signal': 'pupil_diameter', 'n_samples': 73201, 'n_nan': 27993}, 'R': {'fs': 60.060060059976074, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.4351653011183325, 'source_signal': 'pupil_diameter', 'n_samples': 73201, 'n_nan': 41799}}, 'PV_62_block_024': {'L': {'fs': 58.8235294117647, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.5035552026128625, 'source_signal': 'pupil_diameter', 'n_samples': 91953, 'n_nan': 403}, 'R': {'fs': 58.8235294117647, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.5331809067005553, 'source_signal': 'pupil_diameter', 'n_samples': 91953, 'n_nan': 2131}}, 'PV_62_block_026': {'L': {'fs': 58.8235294117647, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.4740226740226214, 'source_signal': 'pupil_diameter', 'n_samples': 99208, 'n_nan': 872}, 'R': {'fs': 58.8235294117647, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.5468731742524235, 'source_signal': 'pupil_diameter', 'n_samples': 99208, 'n_nan': 935}}, 'PV_62_block_038': {'L': {'fs': 58.8235294117647, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 6.711121149960306, 'source_signal': 'pupil_diameter', 'n_samples': 156180, 'n_nan': 16122}, 'R': {'fs': 58.8235294117647, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 9.497111312703145, 'source_signal': 'pupil_diameter', 'n_samples': 156180, 'n_nan': 11470}}, 'PV_126_block_007': {'L': {'fs': 60.060060059556136, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.5601639471174682, 'source_signal': 'pupil_diameter', 'n_samples': 121575, 'n_nan': 940}, 'R': {'fs': 60.060060059556136, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.427021835750939, 'source_signal': 'pupil_diameter', 'n_samples': 121575, 'n_nan': 4150}}, 'PV_126_block_008': {'L': {'fs': 60.790273556403086, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.1789538341175614, 'source_signal': 'pupil_diameter', 'n_samples': 202363, 'n_nan': 102030}, 'R': {'fs': 60.790273556403086, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.504861699303663, 'source_signal': 'pupil_diameter', 'n_samples': 202363, 'n_nan': 85584}}, 'PV_126_block_009': {'L': {'fs': 60.790273556403086, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.486087359065792, 'source_signal': 'pupil_diameter', 'n_samples': 160547, 'n_nan': 36612}, 'R': {'fs': 60.790273556403086, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.409103955185031, 'source_signal': 'pupil_diameter', 'n_samples': 160547, 'n_nan': 58934}}, 'PV_126_block_010': {'L': {'fs': 60.790273556403086, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.4632938221412748, 'source_signal': 'pupil_diameter', 'n_samples': 154069, 'n_nan': 27359}, 'R': {'fs': 60.790273556403086, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.4799750336623654, 'source_signal': 'pupil_diameter', 'n_samples': 154069, 'n_nan': 34353}}, 'PV_126_block_011': {'L': {'fs': 60.8828006086554, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.3767822599875876, 'source_signal': 'pupil_diameter', 'n_samples': 109187, 'n_nan': 943}, 'R': {'fs': 60.8828006086554, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.3092253531660591, 'source_signal': 'pupil_diameter', 'n_samples': 109187, 'n_nan': 511}}, 'PV_126_block_012': {'L': {'fs': 60.88280060887116, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.5714438651304043, 'source_signal': 'pupil_diameter', 'n_samples': 50901, 'n_nan': 753}, 'R': {'fs': 60.88280060887116, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.5983703359618293, 'source_signal': 'pupil_diameter', 'n_samples': 50901, 'n_nan': 120}}, 'PV_57_block_007': {'L': {'fs': 59.171597633054574, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.3322356657875982, 'source_signal': 'pupil_diameter', 'n_samples': 53581, 'n_nan': 103}, 'R': {'fs': 59.171597633054574, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.211598719089719, 'source_signal': 'pupil_diameter', 'n_samples': 53581, 'n_nan': 3532}}, 'PV_57_block_008': {'L': {'fs': 59.171597633054574, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.2589103324332052, 'source_signal': 'pupil_diameter', 'n_samples': 53581, 'n_nan': 263}, 'R': {'fs': 59.171597633054574, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.3045806750061637, 'source_signal': 'pupil_diameter', 'n_samples': 53581, 'n_nan': 586}}, 'PV_57_block_009': {'L': {'fs': 59.171597633054574, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.0258832600213226, 'source_signal': 'pupil_diameter', 'n_samples': 53581, 'n_nan': 15818}, 'R': {'fs': 59.171597633054574, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.236204317415227, 'source_signal': 'pupil_diameter', 'n_samples': 53581, 'n_nan': 14691}}, 'PV_57_block_012': {'L': {'fs': 59.171597633054574, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.236615021477283, 'source_signal': 'pupil_diameter', 'n_samples': 53581, 'n_nan': 559}, 'R': {'fs': 59.171597633054574, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.238155800047494, 'source_signal': 'pupil_diameter', 'n_samples': 53581, 'n_nan': 645}}, 'PV_57_block_013': {'L': {'fs': 59.171597633054574, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.2125645784803105, 'source_signal': 'pupil_diameter', 'n_samples': 53581, 'n_nan': 5813}, 'R': {'fs': 59.171597633054574, 'bridge_gap_ms': 200.0, 'low_quantile': 0.002, 'tiny_threshold': 1.0605603002488846, 'source_signal': 'pupil_diameter', 'n_samples': 53581, 'n_nan': 4973}}}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:26:53.906532Z",
     "start_time": "2025-11-09T10:26:53.895509Z"
    }
   },
   "cell_type": "code",
   "source": "print(bouts_df)",
   "id": "8b9e5afa5541150b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                block eye    start_ms      end_ms  duration_s         rule\n",
      "0    PV_106_block_008   L    35138.65    42031.75     6.89310  nan_or_tiny\n",
      "1    PV_106_block_008   L    43846.60    50639.80     6.79320  nan_or_tiny\n",
      "2    PV_106_block_008   L   537635.65   547425.85     9.79020  nan_or_tiny\n",
      "3    PV_106_block_008   L   832557.10   851121.85    18.56475  nan_or_tiny\n",
      "4    PV_106_block_008   L   897308.95   907565.35    10.25640  nan_or_tiny\n",
      "..                ...  ..         ...         ...         ...          ...\n",
      "441   PV_62_block_038   R  1873468.15  1890658.60    17.19045  nan_or_tiny\n",
      "442   PV_62_block_038   R  1898352.40  1906724.60     8.37220  nan_or_tiny\n",
      "443   PV_62_block_038   R  1970098.40  1977687.90     7.58950  nan_or_tiny\n",
      "444   PV_62_block_038   R  1982357.35  1992444.55    10.08720  nan_or_tiny\n",
      "445   PV_62_block_038   R  2261011.65  2266240.30     5.22865  nan_or_tiny\n",
      "\n",
      "[446 rows x 6 columns]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:29:52.115615Z",
     "start_time": "2025-11-09T10:29:51.921176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_bout(block_key, eye, row_idx):\n",
    "    row = bouts_df.query(\"block==@block_key and eye==@eye\").iloc[row_idx]\n",
    "    print(row)\n",
    "    block = block_dict[block_key]\n",
    "    df = block.left_eye_data if eye=='L' else block.right_eye_data\n",
    "    df = df if df is not None else (block.left_eye_data_clean if eye=='L' else block.right_eye_data_clean)\n",
    "    sel = (df['ms_axis']>=row.start_ms-2000) & (df['ms_axis']<=row.end_ms+2000)\n",
    "    ax = df.loc[sel, ['ms_axis','pupil_diameter']].plot(x='ms_axis', y='pupil_diameter', figsize=(7,2), legend=False)\n",
    "    ax.axvspan(row.start_ms, row.end_ms, color='k', alpha=0.15)\n",
    "    ax.set_xlabel('ms'); ax.set_ylabel('pupil'); ax.set_title(f\"{block_key} {eye} bout\")\n",
    "show_bout('PV_126_block_008','L',0)\n"
   ],
   "id": "ccd087261bfae4bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block         PV_126_block_008\n",
      "eye                          L\n",
      "start_ms                391999\n",
      "end_ms                  423857\n",
      "duration_s             31.8584\n",
      "rule               nan_or_tiny\n",
      "Name: 162, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x200 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ae26aa36dfd8a12d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
